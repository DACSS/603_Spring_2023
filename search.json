[
  {
    "objectID": "about/MiguelCuriel.html",
    "href": "about/MiguelCuriel.html",
    "title": "Miguel Curiel",
    "section": "",
    "text": "Bachelor in Psychology and currently pursuing an MS in Data Analytics and Computational Social Science.\nCurrently working as a Computational Social Scientist at a supply chain technology company. Previously engaged several applied research settings, such as a market research agency, a neuroscience institute, and a non-profit."
  },
  {
    "objectID": "about/MiguelCuriel.html#r-experience",
    "href": "about/MiguelCuriel.html#r-experience",
    "title": "Miguel Curiel",
    "section": "R experience",
    "text": "R experience\n\nStarted getting deep into R around May 2022; before that, I had some months of experience in SQL and Python."
  },
  {
    "objectID": "about/MiguelCuriel.html#research-interests",
    "href": "about/MiguelCuriel.html#research-interests",
    "title": "Miguel Curiel",
    "section": "Research interests",
    "text": "Research interests\n\nInterested in modeling and understanding complex social systems, such as social media, economic ecosystems, and supply chains. Also interested in neuropsychology, neuroscience, and mental health in general."
  },
  {
    "objectID": "about/MiguelCuriel.html#hometown",
    "href": "about/MiguelCuriel.html#hometown",
    "title": "Miguel Curiel",
    "section": "Hometown",
    "text": "Hometown\n\nOriginally from Colima, Mexico; currently living in Washington, DC."
  },
  {
    "objectID": "about/MiguelCuriel.html#hobbies",
    "href": "about/MiguelCuriel.html#hobbies",
    "title": "Miguel Curiel",
    "section": "Hobbies",
    "text": "Hobbies\n\nPlaying guitar and video games, hanging out with family and friends, traveling, and discovering new bars and restaurants."
  },
  {
    "objectID": "about/MiguelCuriel.html#fun-fact",
    "href": "about/MiguelCuriel.html#fun-fact",
    "title": "Miguel Curiel",
    "section": "Fun fact",
    "text": "Fun fact\n\nIn a past life, I attempted to be a YouTube blogger - had one channel creating comedy sketches with friends; and another where I posted guitar covers."
  },
  {
    "objectID": "about/Rowena.Kosher.html",
    "href": "about/Rowena.Kosher.html",
    "title": "Rowena",
    "section": "",
    "text": "##Instructions"
  },
  {
    "objectID": "about/Rowena.Kosher.html#educationwork-background",
    "href": "about/Rowena.Kosher.html#educationwork-background",
    "title": "Rowena",
    "section": "Education/Work Background",
    "text": "Education/Work Background\n-BA Columbia University in Human Rights & Gender & Sexuality Studies -Background in nonprofit, academic, research and activism -current main jobs: Consultant and data analyst at Unsiloed, DEI Consulting Firm- focuses on psychological safety, inclusive leadership, neurodiversity, antiracism, dialogue for transformational change -Also freelance writer, teaching assistant"
  },
  {
    "objectID": "about/Rowena.Kosher.html#r-experience",
    "href": "about/Rowena.Kosher.html#r-experience",
    "title": "Rowena",
    "section": "R experience",
    "text": "R experience\n-minimal to none, though eager to learn"
  },
  {
    "objectID": "about/Rowena.Kosher.html#research-interests",
    "href": "about/Rowena.Kosher.html#research-interests",
    "title": "Rowena",
    "section": "Research interests",
    "text": "Research interests\n-Sociology PhD in the pipeline (hopefully), with intent to focus on gender and secualtiy studies and queer theory -interests include: trans and nonbinary menstruation (for eg. conducted cyberethnography of language use in YouTube videos), queer identity and familial structures, gender identity development and theory, intersectional queer identity, neurodiversity"
  },
  {
    "objectID": "about/Rowena.Kosher.html#hometown",
    "href": "about/Rowena.Kosher.html#hometown",
    "title": "Rowena",
    "section": "Hometown",
    "text": "Hometown\nGrew up in Connecticut, have lived in New York City since 2017 (currently in Brooklyn)"
  },
  {
    "objectID": "about/Rowena.Kosher.html#hobbies",
    "href": "about/Rowena.Kosher.html#hobbies",
    "title": "Rowena",
    "section": "Hobbies",
    "text": "Hobbies\n-Yoga and movement -spending time with my two italian greyhounds and one cat- an entire zoo in one tiny apartment -spending my time with one foot in the art world thanks to my talented friends and a fun foray into film production"
  },
  {
    "objectID": "about/Rowena.Kosher.html#fun-fact",
    "href": "about/Rowena.Kosher.html#fun-fact",
    "title": "Rowena",
    "section": "Fun fact",
    "text": "Fun fact\nI barista and bartend- my go-to coffee is a Black eye (Black drip w/ 2 shots of espresso) and my favorite cocktail is the negroni"
  },
  {
    "objectID": "about/PranavKomaravolu.html",
    "href": "about/PranavKomaravolu.html",
    "title": "Pranav Bharadwaj Komaravolu",
    "section": "",
    "text": "A Computer Science Graduate student who is ever ready to take on challenges and eager to leverage my knowledge and passion for computers to create an impact on the organization or project I will be part of."
  },
  {
    "objectID": "about/PranavKomaravolu.html#educationwork-background",
    "href": "about/PranavKomaravolu.html#educationwork-background",
    "title": "Pranav Bharadwaj Komaravolu",
    "section": "Education/Work Background",
    "text": "Education/Work Background\n\nMaster of Science in Computer Science  from University of Massachusetts Amherst (Aug 2022 - )\nIntegrated Master of Technology  in Computer Science from University of Hyderabad, India  (Jul 2017 - Jun 2022)"
  },
  {
    "objectID": "about/PranavKomaravolu.html#r-experience",
    "href": "about/PranavKomaravolu.html#r-experience",
    "title": "Pranav Bharadwaj Komaravolu",
    "section": "R experience",
    "text": "R experience\nLearnt some R as a part of Stat-501 course. Slight acquaintance with mosaic library. But willing to master it through this course."
  },
  {
    "objectID": "about/PranavKomaravolu.html#research-interests",
    "href": "about/PranavKomaravolu.html#research-interests",
    "title": "Pranav Bharadwaj Komaravolu",
    "section": "Research interests",
    "text": "Research interests\nCurrently interested in the following areas:\n\nBio-NLP, which involves the use of natural language techniques and models to interpret genome sequences and also identify protein structures.\nDistributed learning, which involves the task of distributing the training task of a large machine learning model over various nodes in a compute cluster."
  },
  {
    "objectID": "about/PranavKomaravolu.html#hometown",
    "href": "about/PranavKomaravolu.html#hometown",
    "title": "Pranav Bharadwaj Komaravolu",
    "section": "Hometown",
    "text": "Hometown\nHyderabad, India"
  },
  {
    "objectID": "about/PranavKomaravolu.html#hobbies",
    "href": "about/PranavKomaravolu.html#hobbies",
    "title": "Pranav Bharadwaj Komaravolu",
    "section": "Hobbies",
    "text": "Hobbies\n\nSwimming\nTennis\nReading comics\nI also like taking walk (only when the weather is pleasant)"
  },
  {
    "objectID": "about/PranavKomaravolu.html#fun-fact",
    "href": "about/PranavKomaravolu.html#fun-fact",
    "title": "Pranav Bharadwaj Komaravolu",
    "section": "Fun fact",
    "text": "Fun fact\nWill learn some by the end of this semester :)"
  },
  {
    "objectID": "about/AdithyaParupudi_about.html",
    "href": "about/AdithyaParupudi_about.html",
    "title": "Adithya Parupudi",
    "section": "",
    "text": "University Of Massachusetts Amherst Amherst, MA M.S in Data Analytics and Computational Social Science | August 2022 - Present\nJawaharlal Nehru Technological University Hyderabad, Telangana, India B. Tech in Computer Science and Engineering | Aug 2022 – Exp. Dec 2023"
  },
  {
    "objectID": "about/AdithyaParupudi_about.html#r-experience",
    "href": "about/AdithyaParupudi_about.html#r-experience",
    "title": "Adithya Parupudi",
    "section": "R Experience",
    "text": "R Experience\nCompleted 601, Text-As-Data in Summer and Fall."
  },
  {
    "objectID": "about/AdithyaParupudi_about.html#research-interests",
    "href": "about/AdithyaParupudi_about.html#research-interests",
    "title": "Adithya Parupudi",
    "section": "Research interests",
    "text": "Research interests\nInterested in healthcare, finance"
  },
  {
    "objectID": "about/AdithyaParupudi_about.html#hometown",
    "href": "about/AdithyaParupudi_about.html#hometown",
    "title": "Adithya Parupudi",
    "section": "Hometown",
    "text": "Hometown\nHyderabad, India"
  },
  {
    "objectID": "about/AdithyaParupudi_about.html#hobbies",
    "href": "about/AdithyaParupudi_about.html#hobbies",
    "title": "Adithya Parupudi",
    "section": "Hobbies",
    "text": "Hobbies\n\ncooking\nworking out\nanime"
  },
  {
    "objectID": "about/AdithyaParupudi_about.html#fun-fact",
    "href": "about/AdithyaParupudi_about.html#fun-fact",
    "title": "Adithya Parupudi",
    "section": "Fun fact",
    "text": "Fun fact\nError 404"
  },
  {
    "objectID": "about/RahulSomu.html",
    "href": "about/RahulSomu.html",
    "title": "Rahul Somu",
    "section": "",
    "text": "##Instructions"
  },
  {
    "objectID": "about/RahulSomu.html#educationwork-background",
    "href": "about/RahulSomu.html#educationwork-background",
    "title": "Rahul Somu",
    "section": "Education/Work Background",
    "text": "Education/Work Background\nBachelors in Electrical engineering at BITS Pilani -India 3years of professional work experience as software engineer"
  },
  {
    "objectID": "about/RahulSomu.html#r-experience",
    "href": "about/RahulSomu.html#r-experience",
    "title": "Rahul Somu",
    "section": "R experience",
    "text": "R experience\nBeginner"
  },
  {
    "objectID": "about/RahulSomu.html#research-interests",
    "href": "about/RahulSomu.html#research-interests",
    "title": "Rahul Somu",
    "section": "Research interests",
    "text": "Research interests\nBig Data Analytics"
  },
  {
    "objectID": "about/RahulSomu.html#hometown",
    "href": "about/RahulSomu.html#hometown",
    "title": "Rahul Somu",
    "section": "Hometown",
    "text": "Hometown\nHyderabad - India"
  },
  {
    "objectID": "about/RahulSomu.html#hobbies",
    "href": "about/RahulSomu.html#hobbies",
    "title": "Rahul Somu",
    "section": "Hobbies",
    "text": "Hobbies\nSoccer and gaming"
  },
  {
    "objectID": "about/RahulSomu.html#fun-fact",
    "href": "about/RahulSomu.html#fun-fact",
    "title": "Rahul Somu",
    "section": "Fun fact",
    "text": "Fun fact"
  },
  {
    "objectID": "about/about_abbybalint603.html",
    "href": "about/about_abbybalint603.html",
    "title": "Abby Balint",
    "section": "",
    "text": "I graduated from UMass Amherst SBS in 2017 with a double major in Communications and Sociology. After graduation, I began a career in market research. Throughout the last five years my career has included project management, full cycle survey research, cleaning and weighting data, preparing and writing reports in various formats, and vendor/client management. I currently work at S&P Global Market Intelligence as a Research Analyst with a focus in consumer Digital Endpoints research."
  },
  {
    "objectID": "about/about_abbybalint603.html#r-experience",
    "href": "about/about_abbybalint603.html#r-experience",
    "title": "Abby Balint",
    "section": "R experience",
    "text": "R experience\nI have no experience in R at all outside of taking 601 last semester. In my day to day I typically use Excel, SPSS, and various online data processing platforms."
  },
  {
    "objectID": "about/about_abbybalint603.html#research-interests",
    "href": "about/about_abbybalint603.html#research-interests",
    "title": "Abby Balint",
    "section": "Research interests",
    "text": "Research interests\nGiven my background in Comm/Sociology, I am personally interested in social science research and topics like wealth inequality, or any data about the way humans behave. Professionally, I am interested in researching ways we anticipate the world will look different in the coming years - things like fin-tech changing financial planning accessibility, or the pandemic changing the way we work forever."
  },
  {
    "objectID": "about/about_abbybalint603.html#hometown",
    "href": "about/about_abbybalint603.html#hometown",
    "title": "Abby Balint",
    "section": "Hometown",
    "text": "Hometown\nCurrently living in Providence, RI but from Connecticut"
  },
  {
    "objectID": "about/about_abbybalint603.html#hobbies",
    "href": "about/about_abbybalint603.html#hobbies",
    "title": "Abby Balint",
    "section": "Hobbies",
    "text": "Hobbies\nPainting, writing poetry, going to music festivals, and traveling"
  },
  {
    "objectID": "about/about_abbybalint603.html#fun-fact",
    "href": "about/about_abbybalint603.html#fun-fact",
    "title": "Abby Balint",
    "section": "Fun fact",
    "text": "Fun fact\nI have two orange brother cats that are one year old, and they love to make appearances on Zoom calls :)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Contributors",
    "section": "",
    "text": "Find out more about our DACSS students who contributed to the blog.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbby Balint\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdithya Parupudi\n\n\n\n\n\n\n\n\n\n\n\n\n\nMiguel Curiel\n\n\n\n\n\n\n\n\n\n\n\n\n\nPranav Bharadwaj Komaravolu\n\n\n\n\n\n\n\n\n\n\n\n\n\nRahul Somu\n\n\n\n\n\n\n\n\n\n\n\n\n\nRowena\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Homework1_AlexaPotter.html",
    "href": "posts/Homework1_AlexaPotter.html",
    "title": "Homework 1",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\n\n\n-- Attaching packages --------------------------------------- tidyverse 1.3.2 --\nv ggplot2 3.4.0      v purrr   0.3.5 \nv tibble  3.1.8      v dplyr   1.0.10\nv tidyr   1.2.1      v stringr 1.5.0 \nv readr   2.1.3      v forcats 0.5.2 \n-- Conflicts ------------------------------------------ tidyverse_conflicts() --\nx dplyr::filter() masks stats::filter()\nx dplyr::lag()    masks stats::lag()\n\n\nCode\nlibrary(ggplot2)\nlibrary(formattable)"
  },
  {
    "objectID": "posts/Homework1_AlexaPotter.html#a",
    "href": "posts/Homework1_AlexaPotter.html#a",
    "title": "Homework 1",
    "section": "a",
    "text": "a\nFirst, let’s read in the data from the Excel file:\n\n\nCode\nlibrary(readxl)\ndf <- read_excel(\"_data/LungCapData.xls\")\n\n\nThe distribution of LungCap looks as follows:\n\n\nCode\nhist(df$LungCap, xlab= 'LungCap', main = 'Histogram of LungCap Distribution')\n\n\n\n\n\nThe histogram suggests that the distribution is close to a normal distribution. Most of the observations are close to the mean. Very few observations are close to the margins (0 and 15).\n##b\nCompare the probability distribution of the LungCap with respect to Males and Females:\n\n\nCode\nboxplot(df$LungCap~df$Gender, xlab = 'Gender', ylab = 'LungCap')\n\n\n\n\n\n##c\nCompare the mean lung capacities for smokers and non-smokers. Does it make sense?\n\n\nCode\nLungCap_mean <- df %>% \n  group_by(Smoke) %>%\n  summarise(Lungcap_Mean = mean(LungCap))\n\nLungCap_mean\n\n\n# A tibble: 2 x 2\n  Smoke Lungcap_Mean\n  <chr>        <dbl>\n1 no            7.77\n2 yes           8.65\n\n\nThese results show the lung capacity for non-smokers is lower than the lung capacity for smokers. With no background knowledge of lung capacity, I would think these are not standard results.\n##d)\nExamine the relationship between Smoking and Lung Capacity within age groups: “less than or equal to 13”, “14 to 15”, “16 to 17”, and “greater than or equal to 18”.\n\n\nCode\ndf_Agegroup <- df %>% \n  mutate(\n    Age_group = dplyr::case_when(\n      Age <= 13            ~ \"0-13\",\n      Age > 13 & Age <= 15 ~ \"14-15\",\n      Age > 15 & Age <= 17 ~ \"16-17\",\n      Age >= 18             ~ \"18+\"))\n\n\nggplot(data = df_Agegroup, aes(x=Age_group, y=LungCap)) + \n  geom_boxplot(aes(fill=Gender))\n\n\n\n\n\n##e)\nCompare the lung capacities for smokers and non-smokers within each age group. Is your answer different from the one in part c. What could possibly be going on here?\n\n\nCode\nggplot(data = df_Agegroup, aes(x=Age_group, y=LungCap)) + \n  geom_boxplot(aes(fill=Smoke))\n\n\n\n\n\nThis data is different from what was seen in part C. The only age group displaying greater lung capacity for smokers is the group 0-13. This would suggest this sample of the population is influencing the overall lung capacity mean. This by far is the largest sample of age groups with 428 participants\n\n\nCode\ncount(df_Agegroup, Age_group, Smoke)\n\n\n# A tibble: 8 x 3\n  Age_group Smoke     n\n  <chr>     <chr> <int>\n1 0-13      no      401\n2 0-13      yes      27\n3 14-15     no      105\n4 14-15     yes      15\n5 16-17     no       77\n6 16-17     yes      20\n7 18+       no       65\n8 18+       yes      15"
  },
  {
    "objectID": "posts/ZhiyuanZhou_HW1.html",
    "href": "posts/ZhiyuanZhou_HW1.html",
    "title": "Homework 1",
    "section": "",
    "text": "Code\nlibrary(dplyr)\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union"
  },
  {
    "objectID": "posts/ZhiyuanZhou_HW1.html#a",
    "href": "posts/ZhiyuanZhou_HW1.html#a",
    "title": "Homework 1",
    "section": "a",
    "text": "a\nFirst, let’s read in the data from the Excel file:\n\n\nCode\nlibrary(readxl)\ndf <- read_excel(\"_data/LungCapData.xls\")\n\n\nThe distribution of LungCap looks as follows:\n\n\nCode\nhist(df$LungCap)\n\n\n\n\n\nThe histogram suggests that the distribution is close to a normal distribution. Most of the observations are close to the mean. Very few observations are close to the margins (0 and 15).\n##b\n\n\nCode\nboxplot(df$LungCap~df$Gender,\nmain = \"Lung Capacity by Gender\",\nxlab = \"Gender\",\nylab = \"Lung Capacity\",\n)\n\n\n\n\n\n##c\n\n\nCode\ndf %>%\n  group_by(Smoke) %>%\n  summarize(mean = mean(LungCap))\n\n\n# A tibble: 2 × 2\n  Smoke  mean\n  <chr> <dbl>\n1 no     7.77\n2 yes    8.65\n\n\nThis result surprised me that smokers have more lung capacity than non-smokers.\n##d\n\n\nCode\ndf[\"AgeGroup\"] = \n  cut(df$Age,\n      c(0, 13, 15, 17, Inf),\n      c(\"<=13\", \"14-15\",\"16-17\", \">=18\"),\n      right = T\n  )\n\ndf%>%\n  group_by(AgeGroup, Smoke)%>%\n  summarize(meanLungCap = mean(LungCap), meanAge = mean(Age), count = n())\n\n\n`summarise()` has grouped output by 'AgeGroup'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 8 × 5\n# Groups:   AgeGroup [4]\n  AgeGroup Smoke meanLungCap meanAge count\n  <fct>    <chr>       <dbl>   <dbl> <int>\n1 <=13     no           6.36    9.49   401\n2 <=13     yes          7.20   11.7     27\n3 14-15    no           9.14   14.5    105\n4 14-15    yes          8.39   14.6     15\n5 16-17    no          10.5    16.4     77\n6 16-17    yes          9.38   16.6     20\n7 >=18     no          11.1    18.5     65\n8 >=18     yes         10.5    18.1     15\n\n\n##e In age group “0-13”, smokers have higher lung capacity than non-smokers. In all other groups, smokers have less lung capacity than non-smokers. The number of samples under 13 gave it a clue about the interesting finding in 1c. And the mean age difference among smokers and non-smokers pointed out that the age difference is more likely to be the reason of higher lung capacity instead of smoking.\n#Question 2\n##a\n\n\nCode\nprob_2 <- (160 / 810)\nprob_2\n\n\n[1] 0.1975309\n\n\n##b\n\n\nCode\nprob_fewer2 <- (128 + 434) / 810\nprob_fewer2\n\n\n[1] 0.6938272\n\n\n##c\n\n\nCode\nprob_2OrFewer <- (128 + 434 + 160) / 810\nprob_2OrFewer\n\n\n[1] 0.891358\n\n\n##d\n\n\nCode\nprob_more2 <- (64 + 24) / 810\nprob_more2\n\n\n[1] 0.108642\n\n\n##e\n\n\nCode\nexpectation <- (0 * 128 + 1 * 434 + 2 * 160 + 3 * 64 + 4 * 24) / 810\nexpectation\n\n\n[1] 1.28642\n\n\n##f\n\n\nCode\nvariance <- sum(128 * (0 - expectation) ^ 2,\n                434 * (1 - expectation) ^ 2,\n                160 * (2 - expectation) ^ 2,\n                64 * (3 - expectation) ^ 2,\n                24 * (4 - expectation) ^ 2) / 810\nvariance\n\n\n[1] 0.8562353\n\n\nCode\nsd <- sqrt(variance)\nsd\n\n\n[1] 0.9253298"
  },
  {
    "objectID": "posts/hw1_asch_harwood.html",
    "href": "posts/hw1_asch_harwood.html",
    "title": "Homework 1",
    "section": "",
    "text": "Code\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(knitr)\nlibrary(kableExtra)"
  },
  {
    "objectID": "posts/hw1_asch_harwood.html#d",
    "href": "posts/hw1_asch_harwood.html#d",
    "title": "Homework 1",
    "section": "d",
    "text": "d\n\n\nCode\ndf$AgeGroup <- cut(df$Age, breaks = c(0, 13, 15, 17, Inf),\n                    labels = c(\"<=13\", \"14 to 15\", \"16 to 17\", \">=18\"))\n\n\n\n\nCode\nage_group_mean <- df %>%\n  group_by(AgeGroup) %>%\n  summarise(mean(LungCap))\nkable(age_group_mean)\n\n\n\n\n \n  \n    AgeGroup \n    mean(LungCap) \n  \n \n\n  \n    <=13 \n    6.411932 \n  \n  \n    14 to 15 \n    9.045417 \n  \n  \n    16 to 17 \n    10.245876 \n  \n  \n    >=18 \n    10.964688 \n  \n\n\n\n\n\n\n\nCode\nggplot(df, aes(x = AgeGroup, y = LungCap)) +\n  geom_boxplot()\n\n\n\n\n\nThere appears to be a relationship between age and lung capacity, where as age group increases, lung capacity increases as well. This is understandable given that developmentally a younger child would have a lower lung capacity than a young adult."
  },
  {
    "objectID": "posts/hw1_asch_harwood.html#e",
    "href": "posts/hw1_asch_harwood.html#e",
    "title": "Homework 1",
    "section": "e",
    "text": "e\n\n\nCode\nggplot(df, aes(x = AgeGroup, y = LungCap, fill=Smoke)) +\n  geom_boxplot() \n\n\n\n\n\n\n\nCode\nggplot(df, aes(x = LungCap, fill = Smoke)) +\n  geom_histogram(alpha = 0.5, bins = 10, position = \"identity\") +\n  facet_wrap(~AgeGroup, nrow = 2, scales = \"free\") +\n  labs(x = \"Lung Capacity\", y = \"Frequency\") +\n  ggtitle(\"Distribution of Lung Capacity by Age Group, by Smoking Status\")\n\n\n\n\n\nWhen controlling for age, average smoker lung capacity is lower across the board for all age groups except “13 <=”. In the later group, there are far fewer smokers, as one would (hope to) expect, which explains the slightly higher mean lung capacity for smokers."
  },
  {
    "objectID": "posts/Kristin_Abijaoude_HW1.html",
    "href": "posts/Kristin_Abijaoude_HW1.html",
    "title": "Hw 1 by Kristin Abijaoude",
    "section": "",
    "text": "Code\nlibrary(ggplot2)\nlibrary(readxl)\nlibrary(dplyr)\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nCode\nlibrary(summarytools)\nlibrary(stats)\n\n\n\nLung Capacity\n\n\nCode\nLungCapData <- read_excel(\"~/Documents/GitHub/Github Help/603_Spring_2023/posts/_data/LungCapData.xls\")\nLungCapData\n\n\n# A tibble: 725 × 6\n   LungCap   Age Height Smoke Gender Caesarean\n     <dbl> <dbl>  <dbl> <chr> <chr>  <chr>    \n 1    6.48     6   62.1 no    male   no       \n 2   10.1     18   74.7 yes   female no       \n 3    9.55    16   69.7 no    female yes      \n 4   11.1     14   71   no    male   no       \n 5    4.8      5   56.9 no    male   no       \n 6    6.22    11   58.7 no    female no       \n 7    4.95     8   63.3 no    male   yes      \n 8    7.32    11   70.4 no    male   no       \n 9    8.88    15   70.5 no    male   no       \n10    6.8     11   59.2 no    male   no       \n# … with 715 more rows\n\n\n\n\nCode\nprint(dfSummary(LungCapData,\n                        varnumbers = FALSE,\n                        plain.ascii  = FALSE, \n                        style        = \"grid\", \n                        graph.magnif = 0.70, \n                        valid.col    = FALSE),\n      method = 'render',\n      table.classes = 'table-condensed')\n\n\n\n\nData Frame Summary\nLungCapData\nDimensions: 725 x 6\n  Duplicates: 0\n\n\n  \n    \n      Variable\n      Stats / Values\n      Freqs (% of Valid)\n      Graph\n      Missing\n    \n  \n  \n    \n      LungCap\n[numeric]\n      Mean (sd) : 7.9 (2.7)min ≤ med ≤ max:0.5 ≤ 8 ≤ 14.7IQR (CV) : 3.7 (0.3)\n      342 distinct values\n      \n      0\n(0.0%)\n    \n    \n      Age\n[numeric]\n      Mean (sd) : 12.3 (4)min ≤ med ≤ max:3 ≤ 13 ≤ 19IQR (CV) : 6 (0.3)\n      17 distinct values\n      \n      0\n(0.0%)\n    \n    \n      Height\n[numeric]\n      Mean (sd) : 64.8 (7.2)min ≤ med ≤ max:45.3 ≤ 65.4 ≤ 81.8IQR (CV) : 10.4 (0.1)\n      274 distinct values\n      \n      0\n(0.0%)\n    \n    \n      Smoke\n[character]\n      1. no2. yes\n      648(89.4%)77(10.6%)\n      \n      0\n(0.0%)\n    \n    \n      Gender\n[character]\n      1. female2. male\n      358(49.4%)367(50.6%)\n      \n      0\n(0.0%)\n    \n    \n      Caesarean\n[character]\n      1. no2. yes\n      561(77.4%)164(22.6%)\n      \n      0\n(0.0%)\n    \n  \n\nGenerated by summarytools 1.0.1 (R version 4.2.2)2023-03-16\n\n\n\n\n\nCode\ncolnames(LungCapData)\n\n\n[1] \"LungCap\"   \"Age\"       \"Height\"    \"Smoke\"     \"Gender\"    \"Caesarean\"\n\n\nCode\ndim(LungCapData)\n\n\n[1] 725   6\n\n\n\n\nCode\nhist(LungCapData$LungCap)\n\n\n\n\n\n1a. The distribution looks pretty normal to me, with capacity between 6 and 9 being the most frequent.\n\n\nCode\nboxplot(LungCap ~ Gender, data=LungCapData)\n\n\n\n\n\n1b. Separating the two genders, it looks like men have a higher lung capacity rate in comparison to women.\n\n\nCode\nLungCapData %>%\n  group_by(Smoke) %>%\n  summarise(mean = mean(LungCap), n = n())\n\n\n# A tibble: 2 × 3\n  Smoke  mean     n\n  <chr> <dbl> <int>\n1 no     7.77   648\n2 yes    8.65    77\n\n\n1c. The average lung capacity for a non-smoker is around 7.78, while for smokers it’s 8.65. In other words, on average, the smokers have a higher lung capacity rate than non-smokers… this doesn’t make sense because smoking is supposed to be bad for your lungs.\n\n\nCode\nagegroup <- LungCapData %>%\n  mutate(agegroup = case_when(Age <= 13 ~ \"Less than 13 years old\",\n                              Age == 14| Age == 15 ~ \"14 to 15 years old\",\n                              Age == 16 | Age == 17 ~ \"16 to 17 years old\",\n                              Age >= 18 ~ \"18 years old and older\"))\nagegroup %>%\n  ggplot(aes(x=LungCap, fill=Smoke)) +\n  geom_histogram() +\n  facet_wrap(~agegroup)\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n1d. Obviously, older teens are more likely to be smokers, as well as have higher lung capacity, than younger teens. The vast majority of teens 13 years and younger are non-smoker (I would be horrified at the sight of a kid smoking).\n\n\nCode\nagegroup <- agegroup %>%\n  mutate(AgeGroup = factor(agegroup, level= c(\"Less than 13 years old\", \n                                              \"14 to 15 years old\",\n                                              \"16 to 17 years old\",\n                                              \"18 years old and older\")))\n\nboxplot(LungCap ~ AgeGroup, data=agegroup)\n\n\n\n\n\n1e. There is a correlation between age and lung capacity. The lung capacity rate increases as the person gets older.\n\n\nPrior Convictions\nAnother dataset I created here deals with prison convictions. The sample size is 810 prisoners in a state prison, some of the prisoners are there for the first time, while others have been imprison as many as 4 times, or have 4 prior convictions in other words. prior means numbers of prior convictions. freq means how many prisoners have a set of convictions (434 prisoners have 1 prior convictions, 160 prisoners have 2 prior convictions etc.). Finally, I created a new variable called probability, where I divided the freq variable by the total number of prisoners, to denote the probability that a prisoner had a certain number of prior convictions.\n\n\nCode\ndf <- data.frame(prior = c(0:4), \n                 freq = c(128, 434, 160, 64, 24)\n                 )\n\ndf <- df %>%\n  mutate(probability = freq/810)\ndf\n\n\n  prior freq probability\n1     0  128  0.15802469\n2     1  434  0.53580247\n3     2  160  0.19753086\n4     3   64  0.07901235\n5     4   24  0.02962963\n\n\n\n\nCode\n# alternatively\n(dbinom(x = 1, size = 1, prob = 160/810))*100\n\n\n[1] 19.75309\n\n\n2a. There is a less than 20% probability that a randomly selected inmate has exactly 2 prior convictions.\n\n\nCode\n128 + 434\n\n\n[1] 562\n\n\nCode\n(dbinom(x = 1, size = 1, prob = 562/810))*100\n\n\n[1] 69.38272\n\n\n2b. There is a 69% probability that a randomly selected inmate has fewer than 2 prior convictions.\n\n\nCode\n128 + 434 + 160\n\n\n[1] 722\n\n\nCode\n(dbinom(x = 1, size = 1, prob = 722/810))*100\n\n\n[1] 89.1358\n\n\n2c. There is a 89% probability that a randomly selected inmate has 2 or fewer prior convictions.\n\n\nCode\n64 + 24\n\n\n[1] 88\n\n\nCode\n(dbinom(x = 1, size = 1, prob = 88/810))*100\n\n\n[1] 10.8642\n\n\n2d. There is a 10% probability that a randomly selected inmate has more than 2 prior convictions.\n\n\nCode\nprior <- df$prior\nprob <- df$probability\nfreq <- df$freq\n\nexval <- sum(prior*prob)\nexval\n\n\n[1] 1.28642\n\n\n2e. The expected value exval, or long term mean, is 1.28642. I separated the variables into its own set and multiplied prior (# of prior convictions) and prob (the probability a given prisoner has a certain number of prior convictions).\n\n\nCode\n# variance\nvar(rep(df$prior, df$freq))\n\n\n[1] 0.8572937\n\n\nCode\n# standard deviation\nsd(rep(df$prior, df$freq))\n\n\n[1] 0.9259016\n\n\nThe variance is 0.86, which mean the data is close to one another.\nThe standard deviation is 0.93, which means the data is more clustered around the mean.\n\n\nCode\nrender(\"Kristin_Abijaoude_HW1.qmd\", output_format = \"pdf_document\", output_file = \"Kristin_Abijaoude_HW1.pdf\")\n\n\nError in render(\"Kristin_Abijaoude_HW1.qmd\", output_format = \"pdf_document\", : could not find function \"render\""
  },
  {
    "objectID": "posts/Tyler_Tewksbury_Final1.html",
    "href": "posts/Tyler_Tewksbury_Final1.html",
    "title": "Final Project Part 1",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nknitr::opts_chunk$set(echo = TRUE)"
  },
  {
    "objectID": "posts/Tyler_Tewksbury_Final1.html#background-and-research-question",
    "href": "posts/Tyler_Tewksbury_Final1.html#background-and-research-question",
    "title": "Final Project Part 1",
    "section": "Background and Research Question",
    "text": "Background and Research Question\nIn 2020, after the release of the Netflix series The Queen’s Gambit, interest in chess was at an all-time high. This led many fans of the show to use popular websites such as Chess.com and Lichess.org to begin learning the game. These websites use a rating system that mimics that of official in-person chess leagues, increasing your rating number as you win and decreasing as you lose. This can be used to measure one’s skill in chess, and determining if they can enter certain competitions.\nWhen playing chess online, as you face someone completely random that the website matches you against, there is no guarantee that you will play against someone with an identical rating. Thus, there will typically be a difference between the two players’ rating. Obviously the player with the higher rating would be more likely to win, right? That is where this study comes in. By quantifying the effect of rating difference on win chance, players may be able to understand more about the match they are currently in. Knowing how likely they are to win, how likely their opponent is to win, and this could lead to further interesting research about making the most fair chess matches possible. As there are not any academic studies on the topic, there is no proven indicator that a slight discrepancy in rating has is an indicator to a player’s win chance. This poses the research question:\nHow strong of a predictor is the difference between players chess rating in determining the victor?"
  },
  {
    "objectID": "posts/Tyler_Tewksbury_Final1.html#dataset",
    "href": "posts/Tyler_Tewksbury_Final1.html#dataset",
    "title": "Final Project Part 1",
    "section": "Dataset",
    "text": "Dataset\nThe dataset being used is sourced from Kaggle: https://www.kaggle.com/datasets/datasnaek/chess\nGathered in 2016, the dataset contains information from over 20,000 matches on Lichess.org via the Lichess API. Information on the players’, their opening moves, the results of the match, and more are all columns within the dataset.\n\n\nCode\n#reading in the dataset\nchess <- read.csv(\"_data/chess_games.csv\")"
  },
  {
    "objectID": "posts/Tyler_Tewksbury_Final1.html#descriptive-statistics",
    "href": "posts/Tyler_Tewksbury_Final1.html#descriptive-statistics",
    "title": "Final Project Part 1",
    "section": "Descriptive Statistics",
    "text": "Descriptive Statistics\n\n\nCode\nstr(chess)\n\n\n'data.frame':   20058 obs. of  16 variables:\n $ id            : chr  \"TZJHLljE\" \"l1NXvwaE\" \"mIICvQHh\" \"kWKvrqYL\" ...\n $ rated         : chr  \"FALSE\" \"TRUE\" \"TRUE\" \"TRUE\" ...\n $ created_at    : num  1.5e+12 1.5e+12 1.5e+12 1.5e+12 1.5e+12 ...\n $ last_move_at  : num  1.5e+12 1.5e+12 1.5e+12 1.5e+12 1.5e+12 ...\n $ turns         : int  13 16 61 61 95 5 33 9 66 119 ...\n $ victory_status: chr  \"outoftime\" \"resign\" \"mate\" \"mate\" ...\n $ winner        : chr  \"white\" \"black\" \"white\" \"white\" ...\n $ increment_code: chr  \"15+2\" \"5+10\" \"5+10\" \"20+0\" ...\n $ white_id      : chr  \"bourgris\" \"a-00\" \"ischia\" \"daniamurashov\" ...\n $ white_rating  : int  1500 1322 1496 1439 1523 1250 1520 1413 1439 1381 ...\n $ black_id      : chr  \"a-00\" \"skinnerua\" \"a-00\" \"adivanov2009\" ...\n $ black_rating  : int  1191 1261 1500 1454 1469 1002 1423 2108 1392 1209 ...\n $ moves         : chr  \"d4 d5 c4 c6 cxd5 e6 dxe6 fxe6 Nf3 Bb4+ Nc3 Ba5 Bf4\" \"d4 Nc6 e4 e5 f4 f6 dxe5 fxe5 fxe5 Nxe5 Qd4 Nc6 Qe5+ Nxe5 c4 Bb4+\" \"e4 e5 d3 d6 Be3 c6 Be2 b5 Nd2 a5 a4 c5 axb5 Nc6 bxc6 Ra6 Nc4 a4 c3 a3 Nxa3 Rxa3 Rxa3 c4 dxc4 d5 cxd5 Qxd5 exd5 \"| __truncated__ \"d4 d5 Nf3 Bf5 Nc3 Nf6 Bf4 Ng4 e3 Nc6 Be2 Qd7 O-O O-O-O Nb5 Nb4 Rc1 Nxa2 Ra1 Nb4 Nxa7+ Kb8 Nb5 Bxc2 Bxc7+ Kc8 Qd\"| __truncated__ ...\n $ opening_eco   : chr  \"D10\" \"B00\" \"C20\" \"D02\" ...\n $ opening_name  : chr  \"Slav Defense: Exchange Variation\" \"Nimzowitsch Defense: Kennedy Variation\" \"King's Pawn Game: Leonardis Variation\" \"Queen's Pawn Game: Zukertort Variation\" ...\n $ opening_ply   : int  5 4 3 3 5 4 10 5 6 4 ...\n\n\nThe dataset contains 20058 observations across 16 variables.\n\n\nCode\nsummary(chess)\n\n\n      id               rated             created_at         last_move_at      \n Length:20058       Length:20058       Min.   :1.377e+12   Min.   :1.377e+12  \n Class :character   Class :character   1st Qu.:1.478e+12   1st Qu.:1.478e+12  \n Mode  :character   Mode  :character   Median :1.496e+12   Median :1.496e+12  \n                                       Mean   :1.484e+12   Mean   :1.484e+12  \n                                       3rd Qu.:1.503e+12   3rd Qu.:1.503e+12  \n                                       Max.   :1.504e+12   Max.   :1.504e+12  \n     turns        victory_status        winner          increment_code    \n Min.   :  1.00   Length:20058       Length:20058       Length:20058      \n 1st Qu.: 37.00   Class :character   Class :character   Class :character  \n Median : 55.00   Mode  :character   Mode  :character   Mode  :character  \n Mean   : 60.47                                                           \n 3rd Qu.: 79.00                                                           \n Max.   :349.00                                                           \n   white_id          white_rating    black_id          black_rating \n Length:20058       Min.   : 784   Length:20058       Min.   : 789  \n Class :character   1st Qu.:1398   Class :character   1st Qu.:1391  \n Mode  :character   Median :1567   Mode  :character   Median :1562  \n                    Mean   :1597                      Mean   :1589  \n                    3rd Qu.:1793                      3rd Qu.:1784  \n                    Max.   :2700                      Max.   :2723  \n    moves           opening_eco        opening_name        opening_ply    \n Length:20058       Length:20058       Length:20058       Min.   : 1.000  \n Class :character   Class :character   Class :character   1st Qu.: 3.000  \n Mode  :character   Mode  :character   Mode  :character   Median : 4.000  \n                                                          Mean   : 4.817  \n                                                          3rd Qu.: 6.000  \n                                                          Max.   :28.000  \n\n\nLooking at the summary, it is clear what variables will be used and if any new columns will be added. The following will prove relevance to the research question:\n\n`rated``\n`victory_status``\nwinner\nwhite_id\nwhite_rating\nblack_id\nblack_rating\n\nA new column containing the difference between the rating will be added in the next iteration for analysis. Having this added column will make the functions necessary for analysis easier, as calculating the difference will not need to be repeated for each observation.\n\nwhite_rating and black_rating\n\n\nCode\nrange(chess$white_rating)\n\n\n[1]  784 2700\n\n\nCode\nrange(chess$black_rating)\n\n\n[1]  789 2723\n\n\nThe ranges of the two sides are nearly identical, and are quite large nearing 2000. This could be both good and bad for the study, as the large range could prove significant, but it may be necessary to break the models into smaller ranges. This could also be interesting, perhaps seeing if the rating differences at a lower level matter more than that of a higher level, or vice versa."
  },
  {
    "objectID": "posts/Tyler_Tewksbury_Final1.html#proposed-models",
    "href": "posts/Tyler_Tewksbury_Final1.html#proposed-models",
    "title": "Final Project Part 1",
    "section": "Proposed Models",
    "text": "Proposed Models\nThe obvious model for this question will be a a linear probability regression, as the victory status is a binary variable. Proposed models initially are:\nLinear probability including unranked Linear probability excluding unranked\nThere will be more models, potentially differentiating between the different ranges as stated earlier. More possibilities include looking at exclusively drawn game data, analyzing favored openings depending on rank, or possibly finding other predictors if the rank difference is not significant."
  },
  {
    "objectID": "posts/Jerin_Jacob_Final_Project.html",
    "href": "posts/Jerin_Jacob_Final_Project.html",
    "title": "Final Project 603",
    "section": "",
    "text": "Now a days, movies are a well marketed entertainment product. Just like any other products in the market, movies are also having an allocated a marketing budget and promotional activities are done in scale. This often result in the opening weekend’s gross ticketing volume to rise. But are the pre-release promotional activities helping the movie to collect more or is it just creating a hype initially? Or does the movie’s gross collection is not at all dependant on pre release promotions? This dataset has 200 highest grossing movies of 2022. It has both the opening week’s gross as well as the total gross collection of the movies, along with other variables. Assuming that opening week’s collection is depending on the pre-release promotion, by looking on the relationship between opening week’s gross and total gross, I am trying to see how the pre-release activities help the producers earn more in boxoffice.\nResearch Question: Is the total collection of a movie depending on the pre-release promotional activities?\nNull hypothesis: The total gross collection of a movie is not dependant on the opening week’s collection\nAlternative hypotheses: Total gross collection is positively dependant on the opening week’s collection"
  },
  {
    "objectID": "posts/Jerin_Jacob_Final_Project.html#reading-the-data",
    "href": "posts/Jerin_Jacob_Final_Project.html#reading-the-data",
    "title": "Final Project 603",
    "section": "Reading the data",
    "text": "Reading the data\n\n\nCode\nlibrary(readxl)\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.0     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.1     ✔ tibble    3.2.0\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the \u001b]8;;http://conflicted.r-lib.org/\u0007conflicted package\u001b]8;;\u0007 to force all conflicts to become errors\n\n\n\n\nCode\ndf <- read.csv(\"_data/project_data.csv\")\n#df\n\n\nThere are 10 variables with 200 rows.\n\nCOLUMN DESCRIPTION\n\n‘Rank’: rank of the movie\n‘Release’: release date of the movie\n‘Gross’: domestic gross of the movie\n‘max_th’: maximum number of theaters the movie was released in\n‘Opening’: gross on opening weekend\n‘perc_tot_gr’: domestic percentage of the total gross\n‘open_th’: number of theaters the movie opened in\n‘Open’: opening date\n‘Close’: closing date\n‘Distributor’: name of the distributor\n‘int_gross’: international gross\n‘world_gross’: worldwide gross"
  },
  {
    "objectID": "posts/Jerin_Jacob_Final_Project.html#summary-of-each-variables",
    "href": "posts/Jerin_Jacob_Final_Project.html#summary-of-each-variables",
    "title": "Final Project 603",
    "section": "Summary of each variables",
    "text": "Summary of each variables\n\n\nCode\nsummary(df)\n\n\n      Rank          Release              Gross               max_th      \n Min.   :  1.00   Length:200         Min.   :   304287   Min.   :   5.0  \n 1st Qu.: 50.75   Class :character   1st Qu.:  1028500   1st Qu.: 457.8  \n Median :100.50   Mode  :character   Median :  3995788   Median :1083.5  \n Mean   :100.50                      Mean   : 36977151   Mean   :1760.2  \n 3rd Qu.:150.25                      3rd Qu.: 21273142   3rd Qu.:3189.0  \n Max.   :200.00                      Max.   :718732821   Max.   :4751.0  \n                                                                         \n    Opening           perc_tot_gr       open_th           Open          \n Min.   :     3265   Min.   : 0.10   Min.   :   1.0   Length:200        \n 1st Qu.:   243919   1st Qu.:20.50   1st Qu.: 160.5   Class :character  \n Median :  1066404   Median :35.45   Median : 916.5   Mode  :character  \n Mean   : 11649361   Mean   :32.05   Mean   :1588.8                     \n 3rd Qu.:  8137392   3rd Qu.:43.25   3rd Qu.:3156.2                     \n Max.   :187420998   Max.   :77.80   Max.   :4735.0                     \n                                                                        \n    Close           Distributor          int_gross          world_gross       \n Length:200         Length:200         Min.   :4.201e+03   Min.   :5.100e+03  \n Class :character   Class :character   1st Qu.:7.076e+05   1st Qu.:2.099e+06  \n Mode  :character   Mode  :character   Median :6.311e+06   Median :1.287e+07  \n                                       Mean   :5.177e+07   Mean   :8.765e+07  \n                                       3rd Qu.:3.040e+07   3rd Qu.:6.049e+07  \n                                       Max.   :1.539e+09   Max.   :2.176e+09  \n                                       NA's   :3                              \n\n\nUsing the glimpse() function, let’s have a look at how our data would look like!\n\n\nCode\nglimpse(df)\n\n\nRows: 200\nColumns: 12\n$ Rank        <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…\n$ Release     <chr> \"Top Gun: Maverick\", \"Avatar: The Way of Water\", \"Black Pa…\n$ Gross       <int> 718732821, 636955746, 453474324, 411331607, 376851080, 369…\n$ max_th      <int> 4751, 4340, 4396, 4534, 4697, 4427, 4417, 4375, 4258, 4402…\n$ Opening     <int> 126707459, 134100226, 181339761, 187420998, 145075625, 107…\n$ perc_tot_gr <dbl> 17.6, 21.1, 40.0, 45.6, 38.5, 28.9, 36.3, 42.0, 37.8, 39.8…\n$ open_th     <int> 4735, 4202, 4396, 4534, 4676, 4391, 4417, 4375, 4234, 4402…\n$ Open        <chr> \"2022-05-27\", \"2022-12-16\", \"2022-11-11\", \"2022-05-06\", \"2…\n$ Close       <chr> \"2022-12-16\", \"\", \"\", \"\", \"2022-09-23\", \"\", \"\", \"2022-10-1…\n$ Distributor <chr> \"Paramount Pictures\", \"20th Century Studios\", \"Walt Disney…\n$ int_gross   <int> 770000000, 1539273359, 389276658, 544444197, 625127000, 56…\n$ world_gross <dbl> 1488732821, 2176229105, 842750982, 955775804, 1001978080, …"
  },
  {
    "objectID": "posts/Jerin_Jacob_Final_Project.html#references",
    "href": "posts/Jerin_Jacob_Final_Project.html#references",
    "title": "Final Project 603",
    "section": "References:",
    "text": "References:\n\nNasir, Suphan & Öcal, Figen. (2016). Film Marketing: The Impact of Publicity Activities on Demand Generation. 10.4018/978-1-5225-0143-5.ch019.\nElizabeth Cooper-Martin (1991) ,“Consumers and Movies: Some Findings on Experiential Products”, in NA - Advances in Consumer Research Volume 18, eds. Rebecca H. Holman and Michael R. Solomon, Provo, UT : Association for Consumer Research, Pages: 372-378."
  },
  {
    "objectID": "posts/DerianToth_M_HW1.html",
    "href": "posts/DerianToth_M_HW1.html",
    "title": "Homework_One",
    "section": "",
    "text": "Question 1\n\n(1a) What does the distribution of LungCap look like?\nFirst, let’s read in the data from the Excel file:\n\n\nCode\nlibrary(\"quarto\")\nlibrary(\"tidyverse\")\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.0     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.1     ✔ tibble    3.1.8\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the \u001b]8;;http://conflicted.r-lib.org/\u0007conflicted package\u001b]8;;\u0007 to force all conflicts to become errors\n\n\nCode\nlibrary(\"palmerpenguins\")\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(ggplot2)\ndf <- read_excel(\"_data/LungCapData.xls\")\n#View(df)\n\n\nThe distribution of LungCap looks as follows:\n\n\nCode\nhist(df$LungCap)\n\n\n\n\n\nThe histogram suggests that the distribution is close to a normal distribution. Most of the observations are close to the mean. Very few observations are close to the margins (0 and 15).\n\n\n(1b) The probability distribution of the LungCap with respect to gender is as follows:\n\n\nCode\nboxplot(df$LungCap ~ df$Gender)\n\n\n\n\n\n\n\n(1c) The mean lung capacities for smokers and non-smokers can be found in the table below:\n\n\nCode\ndf %>%\n  group_by(Smoke) %>%\n  summarise_at(vars(LungCap), list(name = mean))\n\n\n# A tibble: 2 × 2\n  Smoke  name\n  <chr> <dbl>\n1 no     7.77\n2 yes    8.65\n\n\nThese means are not what I would expect. It looks like those who smoke (“yes”) have a higher long capacity (8.65) than those who do not smoke (7.77).\n\n\n(1d) The relationship between Smoking and Lung Capacity within age groups\n\n\nCode\n#Age groups defined by:\n#“less than or\n#equal to 13”, \n#“14 to 15”, \n#“16 to 17”, \n#“greater than or equal to 18”.\n\n# Create variable\ndf <- df %>% \n  mutate(age_group = case_when(\n      Age <= 13 ~ \"0-13\",\n      Age > 13 & Age < 16 ~ \"14-15\",\n      Age > 15 & Age < 18 ~ \"16-18\",\n      Age >= 18 ~ \">= 18\"),\n    # Convert to factor\n    age_group = factor(\n      age_group,\n      level = c(\"0-13\", \"14-15\",\"16-18\", \">= 18\")))\n\nView(df)\n\ndf %>%\n  group_by(age_group,Smoke) %>%\n  summarise_at(vars(LungCap), list(name = mean))\n\n\n# A tibble: 8 × 3\n# Groups:   age_group [4]\n  age_group Smoke  name\n  <fct>     <chr> <dbl>\n1 0-13      no     6.36\n2 0-13      yes    7.20\n3 14-15     no     9.14\n4 14-15     yes    8.39\n5 16-18     no    10.5 \n6 16-18     yes    9.38\n7 >= 18     no    11.1 \n8 >= 18     yes   10.5 \n\n\nCode\ndbinom(x=8,size=8,prob=.5)\n\n\n[1] 0.00390625\n\n\nCode\ndbinom(x=6,size=8,prob=.5)\n\n\n[1] 0.109375\n\n\n\n\n(1e) Compare the lung capacities for smokers and non-smokers within each age group.\n\n\nCode\nggplot(df, aes(x=age_group, y=LungCap, color = Smoke)) +\n  geom_boxplot()\n\n\n\n\n\nThis data visualization makes more sense for what we expect from lung capacity when comparing smokers to non smokers. It looks like lunch capacity increases as the participants get older. The data could have more participants who are smokers and who are older. This unbalance in participants could be skewing the overall average lunch capacity.\n\n\n\nQuestion 2:Setting up the Dataframe\n\n\nCode\nStatePrison <- data.frame(number_convictions = 0:4, InMateCount = c(128, 434, 160, 64, 24)) %>%\n                            mutate(Probability = InMateCount/810)\n\nView(StatePrison)\n\n\n\n(2a) What is the probability that a randomly selected inmate has exactly 2 prior convictions?\n\n\nCode\ndbinom(x = 1, size = 1, p = 160/810)\n\n\n[1] 0.1975309\n\n\n\n\n(2b) What is the probability that a randomly selected inmate has fewer than 2 prior convictions?\n\n\nCode\ndbinom(x = 1, size = 1, p = sum(128+434)/810)\n\n\n[1] 0.6938272\n\n\n\n\n(2c) What is the probability that a randomly selected inmate has 2 or fewer prior convictions?\n\n\nCode\ndbinom(x = 1, size = 1, p = sum(128+434+160)/810)\n\n\n[1] 0.891358\n\n\n\n\n(2d) What is the probability that a randomly selected inmate has more than 2 prior convictions?\n\n\nCode\ndbinom(x = 1, size = 1, p = sum(64+24)/810)\n\n\n[1] 0.108642\n\n\n\n\n(2e) What is the expected value for the number of prior convictions?\n\n\nCode\nEV <- sum(StatePrison$number_convictions *StatePrison$Probability)\nprint(EV)\n\n\n[1] 1.28642\n\n\n\n\n(2f) Calculate the variance and the standard deviation for the Prior Convictions.\n\n\nCode\nVar <- sum((StatePrison$number_convictions - EV) ^ 2 * StatePrison$Probability)\n\nprint(Var)\n\n\n[1] 0.8562353\n\n\n\n\nCode\nSD <- sqrt(Var)\n\nprint(SD)\n\n\n[1] 0.9253298"
  },
  {
    "objectID": "posts/Derian-Toth_FinalProjectProposal.html",
    "href": "posts/Derian-Toth_FinalProjectProposal.html",
    "title": "Final Project Proposal Check-in1",
    "section": "",
    "text": "Code\n#reading in data\njobs_gender <- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-05/jobs_gender.csv\")\n\n\nRows: 2088 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): occupation, major_category, minor_category\ndbl (9): year, total_workers, workers_male, workers_female, percent_female, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCode\nearnings_female <- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-05/earnings_female.csv\") \n\n\nRows: 264 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): group\ndbl (2): Year, percent\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCode\nemployed_gender <- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-05/employed_gender.csv\") \n\n\nRows: 49 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (7): year, total_full_time, total_part_time, full_time_female, part_time...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCode\n#View(employed_gender)\n#View(jobs_gender)\n#View(earnings_female)\n\n#bringing in libraries\nlibrary(dplyr)\n\n\n\nAttaching package: 'dplyr'\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nCode\nlibrary(vtable)\n\n\nLoading required package: kableExtra\n\nAttaching package: 'kableExtra'\n\nThe following object is masked from 'package:dplyr':\n\n    group_rows\n\n\nCode\nlibrary(ggplot2)\nlibrary(readr)\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ lubridate 1.9.2     ✔ tibble    3.1.8\n✔ purrr     1.0.1     ✔ tidyr     1.3.0\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter()          masks stats::filter()\n✖ kableExtra::group_rows() masks dplyr::group_rows()\n✖ dplyr::lag()             masks stats::lag()\nℹ Use the \u001b]8;;http://conflicted.r-lib.org/\u0007conflicted package\u001b]8;;\u0007 to force all conflicts to become errors\n\n\nCode\nlibrary(stringr)\nlibrary(lubridate)"
  },
  {
    "objectID": "posts/Derian-Toth_FinalProjectProposal.html#introduction",
    "href": "posts/Derian-Toth_FinalProjectProposal.html#introduction",
    "title": "Final Project Proposal Check-in1",
    "section": "Introduction",
    "text": "Introduction\nThis research exploration takes a close look at the gender wage gap over the years. While the wage gap has decreased, women are still making on average, about 82 cents for every dollar men make (Aragao, 2023). Women are entering the workforce at a higher rate than in the past, yet are still not making the same salary as men who work the same jobs.\nFrom the two line graphs below we can see that women 16 years and older, working full time, are increasingly entering the workforce (Graph 1: Percent of Men and Women Working Full Time by Year); yet women are still not making 100% of the wage that men make (Graph 2: Female Salary Percent of Male Salary).\n\n\nCode\n#percent of women working full time compared to men\n#Still would like to add a legend to this graphs\nggplot(data = employed_gender, aes(x = year)) +\n  geom_line(aes(y = full_time_female), colour = \"red\") +\n  geom_point(aes(y = full_time_female), colour = \"red\") +\n  geom_line(aes(y = full_time_male), colour = \"blue\") +\n  geom_point(aes(y = full_time_male), colour = \"blue\") +\n  labs(title = \"Percent of Men and Women Working Full Time by Year\", \n       x=\"Year\", \n       y=\"Percent Working\") +\n  ylim(0,100)\n\n\n\n\n\nCode\n#wage gap by year\n#Would also like to add a legend and labels to the this graphs\nearnings_female%>%\n  filter(str_detect(group,\"Total, 16 years and older\")) %>%\n  ggplot(aes(x = Year)) +\n  geom_line(aes(y = percent)) +\n  geom_point(aes(y = percent)) +\n  labs(title = \"Female Salary Percent of Male Salary\", \n       x=\"Year\", \n       y=\"Percent of Salary\") +\n  ylim(0,100)\n\n\n\n\n\n\nThe Data set\nThe data used in this exploration and analysis come from the Bureau of Labor Statistics and the Census Bureau. These data describe different variables about women in the workforce across time. The three data frames are: (1) historical data, providing the percent of earnings women make compared to men, broken down by age group and ranging from 1979 - 2011, (2) Another historical dataset providing the workforce information (percent of women and men working full time and part time), by year, ranging from 1968 - 2016, (3) and lastly, detailed data regarding occupation (including two levels of categorization for the occupation), earnings for those occupations by gender, and percent of earnings women make compared to men, ranging from 2013 - 2016.\nThe tables below provide the descriptive statistics for the dependent variable, womens’ wage percent of male wage. The first table is the dependent variable across occupations and year (from 2013 to 2016). The second table below show the dependent variable for women who are 16 years or older, across many years (1979 - 2011).\n\n\nCode\n#Descriptive Statistics for the dependent variable: wage percent of male \nSumWage<-data_frame(jobs_gender$year, jobs_gender$wage_percent_of_male)\n\n\nWarning: `data_frame()` was deprecated in tibble 1.1.0.\nℹ Please use `tibble()` instead.\n\n\nCode\nSumWage<- SumWage%>%\n  rename('Year'='jobs_gender$year',\n         'wage_percent_of_male' = 'jobs_gender$wage_percent_of_male')\nsumtable(SumWage)  \n\n\n\n\nSummary Statistics\n \n  \n    Variable \n    N \n    Mean \n    Std. Dev. \n    Min \n    Pctl. 25 \n    Pctl. 75 \n    Max \n  \n \n\n  \n    Year \n    2088 \n    2014 \n    1.1 \n    2013 \n    2014 \n    2015 \n    2016 \n  \n  \n    wage_percent_of_male \n    1242 \n    84 \n    9.4 \n    51 \n    78 \n    91 \n    117 \n  \n\n\n\n\n\nCode\n#Descriptive Statistics for the historical data of the Dependent variable: wage percent of male\nearnings_female %>%\n  group_by(group) %>%\n  filter(str_detect(group,\"Total, 16 years and older\")) %>%\n  sumtable()\n\n\n\n\nSummary Statistics\n \n  \n    Variable \n    N \n    Mean \n    Std. Dev. \n    Min \n    Pctl. 25 \n    Pctl. 75 \n    Max \n  \n \n\n  \n    Year \n    33 \n    1995 \n    9.7 \n    1979 \n    1987 \n    2003 \n    2011 \n  \n  \n    group \n    33 \n     \n     \n     \n     \n     \n     \n  \n  \n    ... Total, 16 years and older \n    33 \n    100% \n     \n     \n     \n     \n     \n  \n  \n    percent \n    33 \n    74 \n    5.7 \n    62 \n    70 \n    79 \n    82 \n  \n\n\n\n\n\n\n\nResearch Question\nThe purpose of the following exploration and analysis is to answer the question: What are the contributing factors that lead to the gender wage gap to be greater or smaller? The factors explored in this particular analysis are age and occupation. Occupation is categorized into broad and detailed categories, and will be explored by comparing female dominated fields compared to male dominated fields.\nThese factors have been explored in the literature, though the question regarding age (Aragao, 2023; Blau & Kahn, 2016; Kochhar, 2023) has been more thoroughly explored than occupation (Wrohlich 2017). Wrohlick, 2017 found that there is less of a wage gap in the public sector when compared to the private sector. The intention of this analysis is to go beyond comparing occupation by private versus public and into male dominated versus female dominated. This analysis has been done considerably less and is an important piece of knowing where to target closing the wage gap.\n\n\nHypothesis\nAccording to the research, the wage gap for a woman widens as she gets older (Aragao, 2023; Blau & Kahn, 2016; Kochhar, 2023), and the wage gap is wider for women in the private sector compared to the public sector (Wrohlich 2017). Based on this literature, we hypothesize that younger woman and women working in traditionally female-dominated fields will experience a smaller wage gap than older women and those working in traditionally male-dominated fields.\n\nWage Gap by Age\nThe graph below shows the average wage gap across age groups. These data show that as women age, the wage gap widens, it takes a particular dip around 35 - 44 years old.\n\n\nCode\n#wage gap by age\nearnings_female %>%\n  group_by(group) %>%\n  filter(!str_detect(group,\"Total, 16 years and older\")) %>%\n  summarize(Mean_Percent_salary = mean(percent))%>%\n  ggplot(aes(group,Mean_Percent_salary)) +\n  geom_col(aes(fill = group)) +\n  labs(title = \"Female Salary Percent of Male Salary\",\n       x=\"Age Group\", \n       y=\"Average Percent of Salary\") +\n  geom_text(aes(y=Mean_Percent_salary, \n                label=sprintf(\"%0.2f\", round(Mean_Percent_salary, digits = 2)))) +\n  theme(axis.text.x = element_text(angle = 45, vjust = 0.5))\n\n\n\n\n\nOne hypothesis for this is that the younger generation is experiencing a more narrow wage gap. And in that case, we would expect to the see wage gap decrease across time.\nThe graph and table below shows the the wage gap across time using the same data. From these visualizations we can conclude that the wage gap did not decrease, and that as women age, the wage gap widens.\n\n\nCode\n#wage gap by year\nSummaryYear <- jobs_gender %>%\n  group_by(year)%>%\n  drop_na(wage_percent_of_male)%>%\n  summarise(Average_Percent_of_Salary = mean(wage_percent_of_male))\n\nkable(SummaryYear)\n\n\n\n\n \n  \n    year \n    Average_Percent_of_Salary \n  \n \n\n  \n    2013 \n    83.77102 \n  \n  \n    2014 \n    83.70873 \n  \n  \n    2015 \n    84.45372 \n  \n  \n    2016 \n    84.19526 \n  \n\n\n\n\n\nCode\njobs_gender %>%\n  group_by(year)%>%\n  drop_na(wage_percent_of_male)%>%\n  summarise(Mean_wage_percent_of_males = mean(wage_percent_of_male))%>%\n  ggplot(aes(fill = year, y = `Mean_wage_percent_of_males`, x=year)) +\n  geom_bar(position = \"dodge\", stat = \"identity\") +\n  labs(title = \"Female Salary Percent of Male Salary by Year\",\n       x=\"Year\", \n       y=\"Average Percent of Salary\") +\n  geom_text(aes(y=Mean_wage_percent_of_males, \n                label=sprintf(\"%0.2f\", round(Mean_wage_percent_of_males, digits = 2)))) +\n  theme(axis.text.x = element_text(angle = 45, vjust = 0.5))\n\n\n\n\n\n\n\nWage Gap by Occupation\nThe visualization below shows the average number of total female workers versus total male workers averaged across 3 year (2013- 2016), by minor job category. The table is sorted in order to see the categories of which women tend to work at the top.\n\n\nCode\n#creating a table of just total workers by gender and category\nJobsCategoryGen<- data_frame(jobs_gender$year, jobs_gender$minor_category, jobs_gender$workers_male, jobs_gender$workers_female)\nJobsCategoryGen<- JobsCategoryGen%>%\n  rename('Year'='jobs_gender$year',\n         'Occupation Category (Minor)' = 'jobs_gender$minor_category',\n         'Total Male Worker' = 'jobs_gender$workers_male',\n         'Total Female Workers' = 'jobs_gender$workers_female')\n\nSummaryJobsCatGen <- JobsCategoryGen%>%\n  group_by(`Occupation Category (Minor)`)%>%\n  summarise(AverageMaleWorkers = mean(`Total Male Worker`), \n            AverageFemaleWorkers = mean(`Total Female Workers`))\n\nkable(SummaryJobsCatGen[order(SummaryJobsCatGen$AverageFemaleWorkers, decreasing=TRUE),])\n\n\n\n\n \n  \n    Occupation Category (Minor) \n    AverageMaleWorkers \n    AverageFemaleWorkers \n  \n \n\n  \n    Education, Training, and Library \n    138707.95 \n    336849.955 \n  \n  \n    Sales and Related \n    324403.33 \n    226652.667 \n  \n  \n    Building and Grounds Cleaning and Maintenance \n    377726.67 \n    188702.792 \n  \n  \n    Office and Administrative Support \n    73641.55 \n    182680.466 \n  \n  \n    Healthcare Support \n    28363.98 \n    169199.227 \n  \n  \n    Management \n    269406.44 \n    167326.808 \n  \n  \n    Community and Social Service \n    87166.78 \n    148718.469 \n  \n  \n    Healthcare Practitioners and Technical \n    54026.68 \n    139826.234 \n  \n  \n    Legal \n    137979.85 \n    138897.400 \n  \n  \n    Food Preparation and Serving Related \n    149773.50 \n    128210.135 \n  \n  \n    Business and Financial Operations \n    96380.12 \n    113663.170 \n  \n  \n    Personal Care and Service \n    33068.60 \n    97494.512 \n  \n  \n    Computer and mathematical \n    169581.77 \n    56163.156 \n  \n  \n    Arts, Design, Entertainment, Sports, and Media \n    56255.49 \n    41269.278 \n  \n  \n    Material Moving \n    146246.23 \n    32834.804 \n  \n  \n    Protective Service \n    113246.58 \n    27095.264 \n  \n  \n    Production \n    58897.09 \n    20524.166 \n  \n  \n    Life, Physical, and Social Science \n    25409.11 \n    19563.148 \n  \n  \n    Transportation \n    171202.30 \n    18166.075 \n  \n  \n    Architecture and Engineering \n    96430.32 \n    15617.167 \n  \n  \n    Farming, Fishing, and Forestry \n    66716.75 \n    13853.938 \n  \n  \n    Installation, Maintenance, and Repair \n    105593.08 \n    3813.965 \n  \n  \n    Construction and Extraction \n    137969.88 \n    3553.678 \n  \n\n\n\n\n\nFrom this visualization, we can see the following are the top 10 occupation categories that are on average more dominated by women:\n(1) Education, Training, and Library\n(2) Sales and Related\n(3) Building and Grounds Cleaning and Maintenance\n(4) Office and Administrative Support\n(5) Healthcare Support\n(6) Management\n(7) Community and Social Service\n(8) Healthcare Practitioners and Technical\n(9) Legal\n(10) Food Preparation and Serving Related\nThe following four visualizations below shows the average percent of salary women make compared to men across occupation categories. The first set of categories in more broad than the second, these are the “Major Categories”, while the more detailed categories are referred to as “Minor Categories”. These categories were created in order to compare the wage gap across occupations in a more digestible way than job title alone.\nBelow we can see that there is a higher wage gap for women working in “Management, Business, and Financial” with women making 80.5% of what men make, and those in”Production, Transportation, and Material Moving” with women making 79% of what men make.\n\n\nCode\n#wage gap by major occupation category\n \nSummaryMajorCat <- jobs_gender%>%\n  group_by(major_category)%>%\n  drop_na(wage_percent_of_male) %>%\n  summarise(Average_Percent_of_Salary = mean(wage_percent_of_male))\n\n#I would like to round these numbers by 2 digits past the decimal, as well as title the table and rename the variables.\nkable(SummaryMajorCat[order(SummaryMajorCat$Average_Percent_of_Salary, SummaryMajorCat$major_category, decreasing=TRUE),])\n\n\n\n\n \n  \n    major_category \n    Average_Percent_of_Salary \n  \n \n\n  \n    Computer, Engineering, and Science \n    86.80344 \n  \n  \n    Service \n    86.56902 \n  \n  \n    Education, Legal, Community Service, Arts, and Media \n    86.24398 \n  \n  \n    Healthcare Practitioners and Technical \n    86.00865 \n  \n  \n    Natural Resources, Construction, and Maintenance \n    85.41490 \n  \n  \n    Sales and Office \n    83.81083 \n  \n  \n    Management, Business, and Financial \n    80.48905 \n  \n  \n    Production, Transportation, and Material Moving \n    79.17389 \n  \n\n\n\n\n\nCode\n#This graph still needs to be reformatted so the title of the graph and the title of legand do not overlap. \njobs_gender %>%\n  group_by(major_category)%>%\n  drop_na(wage_percent_of_male)%>%\n  summarise(Mean_wage_percent_of_males = mean(wage_percent_of_male))%>%\n  ggplot(aes(fill = major_category, y = `Mean_wage_percent_of_males`, x=major_category)) +\n  geom_bar(position = \"dodge\", stat = \"identity\") +\n  labs(title = \"Female Salary Percent of Male Salary by Major Occupation Category\",\n       x=\"Occupation Cateogry\", \n       y=\"Average Percent of Salary\") +\n  geom_text(aes(y=Mean_wage_percent_of_males, \n                label=sprintf(\"%0.2f\", round(Mean_wage_percent_of_males, digits = 1)))) +\n  theme(axis.text.x = element_text(angle = 45, vjust = 0.5))\n\n\n\n\n\nWhen we break these categories down into more detail, we can see more instances of a wider wage gap. Women who work in occupations that fall into the “Community and Social Services” category make, on average, 91% of every dollar a man in their field makes. Whereas a woman working in Production” makes, on average, 77% of every dollar a man in their field makes. There seems to be a bigger increase in wage gap for the following occupational categories: “Management”, “Business and Financial Operations”, “Transportation”, “Farming, Fishing, and Forestry”, “Building and Grounds Cleaning and Maintenance”, “Sales and Related”, “Legal”, and “Production”.\n\n\nCode\n#wagegap by minor occupation category\nSummaryMinorCat <- jobs_gender%>%\n  group_by(minor_category)%>%\n  drop_na(wage_percent_of_male) %>%\n  summarise(Mean_wage_percent_of_males = mean(wage_percent_of_male))\n\nkable(SummaryMinorCat[order(SummaryMinorCat$Mean_wage_percent_of_males, SummaryMinorCat$minor_category, decreasing=FALSE),])\n\n\n\n\n \n  \n    minor_category \n    Mean_wage_percent_of_males \n  \n \n\n  \n    Production \n    77.23993 \n  \n  \n    Legal \n    77.81342 \n  \n  \n    Sales and Related \n    77.83065 \n  \n  \n    Building and Grounds Cleaning and Maintenance \n    79.31545 \n  \n  \n    Farming, Fishing, and Forestry \n    79.61618 \n  \n  \n    Transportation \n    79.88060 \n  \n  \n    Business and Financial Operations \n    80.16418 \n  \n  \n    Management \n    80.80490 \n  \n  \n    Arts, Design, Entertainment, Sports, and Media \n    84.79955 \n  \n  \n    Life, Physical, and Social Science \n    84.94294 \n  \n  \n    Installation, Maintenance, and Repair \n    85.45982 \n  \n  \n    Healthcare Practitioners and Technical \n    86.00865 \n  \n  \n    Protective Service \n    86.02423 \n  \n  \n    Office and Administrative Support \n    86.18804 \n  \n  \n    Personal Care and Service \n    86.73739 \n  \n  \n    Education, Training, and Library \n    87.19622 \n  \n  \n    Food Preparation and Serving Related \n    87.44786 \n  \n  \n    Architecture and Engineering \n    87.59434 \n  \n  \n    Construction and Extraction \n    87.94221 \n  \n  \n    Computer and mathematical \n    88.12798 \n  \n  \n    Material Moving \n    89.10787 \n  \n  \n    Healthcare Support \n    90.31624 \n  \n  \n    Community and Social Service \n    91.43559 \n  \n\n\n\n\n\nCode\n#The visualization below is in VERY draft form, and cannot provide helpful information until it is reformatted. \n#jobs_gender %>%\n  #group_by(minor_category)%>%\n  #drop_na(wage_percent_of_male)%>%\n  #summarise(Mean_wage_percent_of_males = mean(wage_percent_of_male))%>%\n  #ggplot(aes(fill = minor_category, y = `Mean_wage_percent_of_males`, x=minor_category)) +\n  #geom_bar(position = \"dodge\", stat = \"identity\") +\n  #labs(title = \"Female Salary Percent of Male Salary by Minor Occupation Category\",\n       #x=\"Occupation Cateogry\", \n       #y=\"Average Percent of Salary\") +\n  #theme(axis.text.x = element_text(angle = 45, vjust = 0.5))\n\n\nWhen comparing the top 10 minor occupation categories that are on average more dominated by women (“Occupation Categories Dominated by Women”) with the list of occupation categories with the smallest wage gap (“Occupation Categories with the Smallest Wage Gap”), we can see some overlap.\nOccupation Categories Dominated by Women\n\nEducation, Training, and Library\nSales and Related\nBuilding and Grounds Cleaning and Maintenance\nOffice and Administrative Support\nHealthcare Support\nManagement\nCommunity and Social Service\nHealthcare Practitioners and Technical\nLegal\nFood Preparation and Serving Related\n\nOccupation Categories with the Smallest Wage Gap\n\nProduction\nLegal\nSales and Related\nBuilding and Grounds Cleaning and Maintenance\nFarming, Fishing, and Forestry\nTransportation\nBusiness and Financial Operations\nManagement\nArts, Design, Entertainment, Sports, and Media\nLife, Physical, and Social Science\n\nFurther analysis is necessary to know if female dominated occupation categories is a statistically significant factor that contributes to the wage gap."
  },
  {
    "objectID": "posts/HW1_ChristineBrydges.html",
    "href": "posts/HW1_ChristineBrydges.html",
    "title": "Homework 1",
    "section": "",
    "text": "First, let’s read in the data from the Excel file:\n\n\nCode\nlibrary(readxl)\ndf <- read_excel(\"_data/LungCapData.xls\")\n\n\nThe distribution of LungCap looks as follows:\n\n\nCode\nhist(df$LungCap)\n\n\n\n\n\nThe histogram suggests that the distribution is close to a normal distribution. Most of the observations are close to the mean. Very few observations are close to the margins (0 and 15).\n\n\n\nThe distribution and mean of the probability density of Lung Capacity can be shown in the box plots below, separated by genders ‘Male’ and ‘Female’\n\n\nCode\n# Create a Box Plot with Lung Capacity on y-axis, grouped by gender\nboxplot(LungCap~ Gender, data = df)\n\n# Add a title\ntitle(\"Lung Capacity: Males vs. Females\")\n\n\n\n\n\nThe boxplot suggests that there is no significant difference between lung capacity of females and males, as the error bars of each boxplot significantly overlap. Additionally, the mean of the probability density of lung capacity appear to be close between female and male constituents.\n\n\n\n\n\nCode\n# Create a Box Plot with Lung Capacity on y-axis, grouped by populations that smoke or do not smoke \nboxplot(LungCap~ Smoke, data = df)\n\n# Add a title\ntitle(\"Lung Capacity: Smokers vs. Non-Smokers\")\n\n\n\n\n\nThe boxplot suggests that smokers have a higher lung capacity than non-smokers, which is counter-intuitive.\n#c Next, we will explore the differences of lung capacity of non-smokers and smokers, broken down by age group, as shown in the boxplot below. The green color is used to call out groups that do smoke while the blue color is used to call out groups that do not smoke.\n\n\nCode\n#Group respondents into specific Age Groups \nAgeGroups <- cut(df$Age, breaks=c(0,13,15,17,19), labels=c('<13','14-15','16-17','>=18'))\nlevels(AgeGroups)\n\n\n[1] \"<13\"   \"14-15\" \"16-17\" \">=18\" \n\n\nCode\n#Create a stratified box plot based on two factors: Smoking vs. Nonsmoking and Age groups\nboxplot(df$LungCap~df$Smoke*AgeGroups, ylab=\"LungCap\", main=\"LungCap vs. Smoke, by AgeGroup\", las = 2, col=c(4,3))\n\n\n\n\n\nFrom these boxplots, you can see that when you separate the smoking and nonsmoking groups by age, the smokers have a higher lung capacity than non-smokers. This is because age is a confounding variable, with young people gaining lung capacity as they have bigger bodies, and with older peope generally smoking more than younger people . Once you take out age from consideration and compare “apples to apples” people of the same age but differences in whether they smoke or not, you can see that smoking DOES have a negative effect on lung capacity."
  },
  {
    "objectID": "posts/HW1_ChristineBrydges.html#a.-here-we-will-explore-the-probability-that-a-randomly-selected-inmate-has-exactly-2-prior-convictions-based-on-a-dataset-given-to-us.",
    "href": "posts/HW1_ChristineBrydges.html#a.-here-we-will-explore-the-probability-that-a-randomly-selected-inmate-has-exactly-2-prior-convictions-based-on-a-dataset-given-to-us.",
    "title": "Homework 1",
    "section": "a. Here, we will explore the probability that a randomly selected inmate has exactly 2 prior convictions, based on a dataset given to us.",
    "text": "a. Here, we will explore the probability that a randomly selected inmate has exactly 2 prior convictions, based on a dataset given to us.\nSince the data set is not continuous or binomial, we will use basic probability functions to find probabilities.\n\n\nCode\n#Calculate the probability of a prisoner having exactly 2 convictions (events/total possible events)\nprobability = (150/810) * 100\nprint(probability)\n\n\n[1] 18.51852\n\n\nWe can see that the probability of a prisoner having exactly 2 convictions is 18.5%."
  },
  {
    "objectID": "posts/HW1_ChristineBrydges.html#b.",
    "href": "posts/HW1_ChristineBrydges.html#b.",
    "title": "Homework 1",
    "section": "b.",
    "text": "b.\nNext, we’ll look at the probability that a randomly selected inmate has fewer than 2 prior convictions.\n\n\nCode\n# Calculate the probability of a prisoner having 0, or 1 convictions (fewer than 2 prior convictions) (events/total possible events)\nlessthan2convictions <- 128 + 434 \nprobabilitylessthan2 <- (lessthan2convictions/810) * 100\nprint(probabilitylessthan2)\n\n\n[1] 69.38272\n\n\nWe can see that the probability of a prisoner having less than 2 convictions is 69.4%."
  },
  {
    "objectID": "posts/HW1_ChristineBrydges.html#c.",
    "href": "posts/HW1_ChristineBrydges.html#c.",
    "title": "Homework 1",
    "section": "c. ",
    "text": "c. \nNext, we’ll look at the probability that a randomly selected inmate has 2 or less prior convictions.\n\n\nCode\n# Calculate the probability of a prisoner having 0, 1, or 2 convictions ( 2 or fewer prior convictions) (events/total possible events)\ntwoorlessconvictions <- 128 + 434 + 160\nprobability2orless <- (twoorlessconvictions/810) * 100\nprint(probability2orless)\n\n\n[1] 89.1358\n\n\nWe can see that the probability of a prisoner having 2 or less convictions is 89.1%."
  },
  {
    "objectID": "posts/HW1_ChristineBrydges.html#d.",
    "href": "posts/HW1_ChristineBrydges.html#d.",
    "title": "Homework 1",
    "section": "d. ",
    "text": "d. \nNext, we’ll look at the probability that a randomly selected inmate has more than 2 prior convictions.\n\n\nCode\n#Calculate the probability of a prisoner having more than 2 convictions ( 3 or 4 prior convictions) (events/total possible events)\nmorethan2convictions <- 64 + 24\nprobabilitymorethan2 <- (morethan2convictions/810) * 100\nprint(probabilitymorethan2)\n\n\n[1] 10.8642\n\n\nWe can see that the probability of a prisoner having more than 2 convictions is 10.9%."
  },
  {
    "objectID": "posts/HW1_ChristineBrydges.html#d.-1",
    "href": "posts/HW1_ChristineBrydges.html#d.-1",
    "title": "Homework 1",
    "section": "d. ",
    "text": "d. \nHere, we’ll calculate the expected value for the number of prior convictions.\n\n\nCode\n#define values\nx <- c(0,1,2,3,4)\n\n#define probabilities\nfrequency <- c(128/810, 434/810, 160/810, 64/810, 24/810)\n\n#calculate expected value\nsum(x * frequency)\n\n\n[1] 1.28642\n\n\nThe expected value is 1.29 prior convictions."
  },
  {
    "objectID": "posts/HW1_ChristineBrydges.html#f.",
    "href": "posts/HW1_ChristineBrydges.html#f.",
    "title": "Homework 1",
    "section": "f. ",
    "text": "f. \nIn this final section, we’ll calculate the variance and standard deviation for the prior convictions.\n\n\nCode\n# calculate variance of frequencies\nfrequency <- c(128, 434, 160, 64, 24)\nvar(frequency)\n\n\n[1] 25948\n\n\nThe variance is 5948.\n\n\nCode\n# calculate standard deviation of prior convictions \nfrequency <- c(128, 434, 160, 64, 24)\nsd(frequency)\n\n\n[1] 161.0838\n\n\nThe standard deviation is 161.1."
  },
  {
    "objectID": "posts/dacss603hw1_LauraCollazo.html",
    "href": "posts/dacss603hw1_LauraCollazo.html",
    "title": "DACSS 603 Homework 1",
    "section": "",
    "text": "Code\nlibrary(readxl)\nlibrary(tidyverse)"
  },
  {
    "objectID": "posts/dacss603hw1_LauraCollazo.html#a",
    "href": "posts/dacss603hw1_LauraCollazo.html#a",
    "title": "DACSS 603 Homework 1",
    "section": "a",
    "text": "a\nThe distribution of LungCap looks as follows:\n\n\nCode\nhist(df$LungCap)\n\n\n\n\n\nThe histogram suggests that the distribution is close to a normal distribution. Most of the observations are close to the mean. Very few observations are close to the margins (0 and 15)."
  },
  {
    "objectID": "posts/dacss603hw1_LauraCollazo.html#b",
    "href": "posts/dacss603hw1_LauraCollazo.html#b",
    "title": "DACSS 603 Homework 1",
    "section": "b",
    "text": "b\nThe distribution of LungCap by Gender looks as follows:\n\n\nCode\nboxplot(df$LungCap ~ df$Gender)\n\n\n\n\n\nThe distribution shows that males, on average, have a higher lung capacity than females."
  },
  {
    "objectID": "posts/dacss603hw1_LauraCollazo.html#c",
    "href": "posts/dacss603hw1_LauraCollazo.html#c",
    "title": "DACSS 603 Homework 1",
    "section": "c",
    "text": "c\nThe mean lung capacities for smokers and non-smokers is shown below.\n\n\nCode\ndf %>% \n  group_by(Smoke) %>% \n  summarise(mean = mean(LungCap))\n\n\n# A tibble: 2 × 2\n  Smoke  mean\n  <chr> <dbl>\n1 no     7.77\n2 yes    8.65\n\n\nThese means are not what I would have expected to see. This shows smokers have a higher mean lung capacity than non-smokers."
  },
  {
    "objectID": "posts/dacss603hw1_LauraCollazo.html#d",
    "href": "posts/dacss603hw1_LauraCollazo.html#d",
    "title": "DACSS 603 Homework 1",
    "section": "d",
    "text": "d\nThe mean lung capacities for smokers and non-smokers by age group is shown below.\n\n\nCode\ndf_age_group <- df %>% \n  mutate(\n    age_group = case_when(\n      Age < 14 ~ \"less than or equal to 13\",\n      Age == 14 ~ \"14 to 15\",\n      Age == 15 ~ \"14 to 15\",\n      Age == 16 ~ \"16 to 17\",\n      Age == 17 ~ \"16 to 17\",\n      Age > 17 ~ \"greater than or equal to 18\")\n  ) \n\ndf_age_group %>%\n  group_by(age_group, Smoke) %>% \n  summarise(mean = mean(LungCap))\n\n\n`summarise()` has grouped output by 'age_group'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 8 × 3\n# Groups:   age_group [4]\n  age_group                   Smoke  mean\n  <chr>                       <chr> <dbl>\n1 14 to 15                    no     9.14\n2 14 to 15                    yes    8.39\n3 16 to 17                    no    10.5 \n4 16 to 17                    yes    9.38\n5 greater than or equal to 18 no    11.1 \n6 greater than or equal to 18 yes   10.5 \n7 less than or equal to 13    no     6.36\n8 less than or equal to 13    yes    7.20"
  },
  {
    "objectID": "posts/dacss603hw1_LauraCollazo.html#e",
    "href": "posts/dacss603hw1_LauraCollazo.html#e",
    "title": "DACSS 603 Homework 1",
    "section": "e",
    "text": "e\nThe distribution of LungCap by age_group and smoker looks as follows:\n\n\nCode\nggplot(df_age_group, aes(x=age_group, y=LungCap, color = Smoke)) +\n  geom_boxplot()\n\n\n\n\n\nThe mean lung capacity for non-smokers is higher than smokers for all age groups except for those age 13 or younger. This is interesting as it was observed earlier that overall smokers have a higher mean lung capacity than non-smokers. This led me to wonder if there are more individuals age 13 or younger in this sample than other age groups, and also what the count of smokers versus non smokers is for this sample.\nThe count by age group and smoker type is shown below.\n\n\nCode\ndf_age_group %>% \n  group_by(age_group, Smoke) %>% \n  summarise(total_count = n())\n\n\n`summarise()` has grouped output by 'age_group'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 8 × 3\n# Groups:   age_group [4]\n  age_group                   Smoke total_count\n  <chr>                       <chr>       <int>\n1 14 to 15                    no            105\n2 14 to 15                    yes            15\n3 16 to 17                    no             77\n4 16 to 17                    yes            20\n5 greater than or equal to 18 no             65\n6 greater than or equal to 18 yes            15\n7 less than or equal to 13    no            401\n8 less than or equal to 13    yes            27\n\n\nThe overall count by smoker type is shown below.\n\n\nCode\ndf %>% \n  group_by(Smoke) %>% \n  summarise(total_count = n())\n\n\n# A tibble: 2 × 2\n  Smoke total_count\n  <chr>       <int>\n1 no            648\n2 yes            77"
  },
  {
    "objectID": "posts/dacss603hw1_LauraCollazo.html#a-1",
    "href": "posts/dacss603hw1_LauraCollazo.html#a-1",
    "title": "DACSS 603 Homework 1",
    "section": "a",
    "text": "a\nThe probability that a randomly selected inmate has exactly 2 prior convictions is as follows:\n\n\nCode\ndbinom(x= 1, size= 1, prob= 160/810)\n\n\n[1] 0.1975309"
  },
  {
    "objectID": "posts/dacss603hw1_LauraCollazo.html#b-1",
    "href": "posts/dacss603hw1_LauraCollazo.html#b-1",
    "title": "DACSS 603 Homework 1",
    "section": "b",
    "text": "b\nThe probability that a randomly selected inmate has fewer than 2 prior convictions is as follows:\n\n\nCode\ndbinom(x= 1, size= 1, prob= sum(128/810 + 434/810))\n\n\n[1] 0.6938272"
  },
  {
    "objectID": "posts/dacss603hw1_LauraCollazo.html#c-1",
    "href": "posts/dacss603hw1_LauraCollazo.html#c-1",
    "title": "DACSS 603 Homework 1",
    "section": "c",
    "text": "c\nThe probability that a randomly selected inmate has 2 or fewer prior convictions is as follows:\n\n\nCode\ndbinom(x= 1, size= 1, prob= sum(128/810 + 434/810 + 160/810))\n\n\n[1] 0.891358"
  },
  {
    "objectID": "posts/dacss603hw1_LauraCollazo.html#d-1",
    "href": "posts/dacss603hw1_LauraCollazo.html#d-1",
    "title": "DACSS 603 Homework 1",
    "section": "d",
    "text": "d\nThe probability that a randomly selected inmate has more than 2 prior convictions is as follows:\n\n\nCode\ndbinom(x= 1, size= 1, prob= sum(64/810 + 24/810))\n\n\n[1] 0.108642"
  },
  {
    "objectID": "posts/dacss603hw1_LauraCollazo.html#e-1",
    "href": "posts/dacss603hw1_LauraCollazo.html#e-1",
    "title": "DACSS 603 Homework 1",
    "section": "e",
    "text": "e\nThe expected value for the number of prior convictions is as follows:\n\n\nCode\nev <- sum(convictions$number_convictions * convictions$prop)\n\nprint(ev)\n\n\n[1] 1.28642"
  },
  {
    "objectID": "posts/dacss603hw1_LauraCollazo.html#f",
    "href": "posts/dacss603hw1_LauraCollazo.html#f",
    "title": "DACSS 603 Homework 1",
    "section": "f",
    "text": "f\nThe variance for prior convictions is as follows:\n\n\nCode\nvar <- sum((convictions$number - ev) ^ 2 * convictions$prop)\n\nprint(var)\n\n\n[1] 0.8562353\n\n\nThe standard deviation for prior convictions is as follows:\n\n\nCode\nsd <- sqrt(var)\n\nprint(sd)\n\n\n[1] 0.9253298"
  },
  {
    "objectID": "posts/FelixBetancourt_HW1_v2.html",
    "href": "posts/FelixBetancourt_HW1_v2.html",
    "title": "Homework 1",
    "section": "",
    "text": "Code\nknitr::opts_chunk$set(echo = TRUE, warning = FALSE)"
  },
  {
    "objectID": "posts/FelixBetancourt_HW1_v2.html#homework-1",
    "href": "posts/FelixBetancourt_HW1_v2.html#homework-1",
    "title": "Homework 1",
    "section": "Homework 1",
    "text": "Homework 1\nDACSS 603, Spring 2023\n\n\nCode\n# Loading packages\n\nsuppressPackageStartupMessages(library(dplyr))\nsuppressPackageStartupMessages(library(tidyverse))\nlibrary(formattable)\nsuppressPackageStartupMessages(library(kableExtra))\nlibrary(ggplot2)\nlibrary(readxl)\n\n# Setting working directory and loading dataset.\n\n\n\nlung <- read_excel(\"_data/LungCapData.xls\")"
  },
  {
    "objectID": "posts/FelixBetancourt_HW1_v2.html#part-a---lung-capacity-dataset",
    "href": "posts/FelixBetancourt_HW1_v2.html#part-a---lung-capacity-dataset",
    "title": "Homework 1",
    "section": "Part A - Lung Capacity Dataset",
    "text": "Part A - Lung Capacity Dataset\nLet’s first explore the database\nStructure\n\n\nCode\nstr(lung)\n\n\ntibble [725 × 6] (S3: tbl_df/tbl/data.frame)\n $ LungCap  : num [1:725] 6.47 10.12 9.55 11.12 4.8 ...\n $ Age      : num [1:725] 6 18 16 14 5 11 8 11 15 11 ...\n $ Height   : num [1:725] 62.1 74.7 69.7 71 56.9 58.7 63.3 70.4 70.5 59.2 ...\n $ Smoke    : chr [1:725] \"no\" \"yes\" \"no\" \"no\" ...\n $ Gender   : chr [1:725] \"male\" \"female\" \"female\" \"male\" ...\n $ Caesarean: chr [1:725] \"no\" \"no\" \"yes\" \"no\" ...\n\n\nSummary\n\n\nCode\nLC_table1 <- summary(lung)\nprint(LC_table1)\n\n\n    LungCap            Age            Height         Smoke          \n Min.   : 0.507   Min.   : 3.00   Min.   :45.30   Length:725        \n 1st Qu.: 6.150   1st Qu.: 9.00   1st Qu.:59.90   Class :character  \n Median : 8.000   Median :13.00   Median :65.40   Mode  :character  \n Mean   : 7.863   Mean   :12.33   Mean   :64.84                     \n 3rd Qu.: 9.800   3rd Qu.:15.00   3rd Qu.:70.30                     \n Max.   :14.675   Max.   :19.00   Max.   :81.80                     \n    Gender           Caesarean        \n Length:725         Length:725        \n Class :character   Class :character  \n Mode  :character   Mode  :character  \n                                      \n                                      \n                                      \n\n\n\na) What does the distribution of LungCap look like?\n\n\nCode\n# Density histogram\nhist(lung$LungCap, freq = FALSE, col=\"white\", main = \"Histogram of Probability Density for Lung Capacity\", xlab = \"Values\", ylab = \"Density\")\nlines(density(lung$LungCap), col = \"blue\", lwd = 2)\n\n\n\n\n\nDistribution looks like a normal distribution, most of the observation close to the mean and a few cases close to the extrems (0.5 and 14.6).\n\n\nb) Compare the probability distribution of the LungCap with respect to Males and Females? (Hint: make boxplots separated by gender using the boxplot() function)\n\n\nCode\nbox_plot_crop<-ggplot(data=lung, aes(x=Gender, y=LungCap, fill=Gender)) \nbox_plot_crop+ geom_boxplot() +\n  theme(legend.position = \"right\") +\n  theme (axis.text.x=element_blank(),\n        axis.ticks.x=element_blank())+\n  coord_cartesian(ylim =  c(0, 15))+\n  labs(title=\"Box Plot - Lung Capacity\",\n        x =\"Gender\", y = \"Frequency\")\n\n\n\n\n\n\n\nCode\nsuppressPackageStartupMessages (library(hrbrthemes))\nsuppressPackageStartupMessages (library(viridis))\n\nGender_d <- ggplot(data=lung, aes(x=LungCap, group=Gender, fill=Gender)) +\n    geom_density(adjust=1.5, alpha=.4) +\n    theme_ipsum()\nGender_d\n\n\n\n\n\n\n\nCode\nLC_table <- lung %>%  \n group_by(Gender) %>%\n  summarise(N = n(), LC.Mean = mean(LungCap, na.rm=TRUE), LC.Median = median(LungCap, na.rm=TRUE), LC.SD = sd(LungCap, na.rm=TRUE))\n  \nLC_table_o <- LC_table[with (LC_table, order(-LC.Mean)),]\nformattable(LC_table_o) %>% \n  kable(\"html\", escape = F, caption = \"Summary of Lung Capacity Grouped by Gender\", align = c(\"l\", \"c\", \"c\", \"c\", \"c\", \"c\")) %>% \n  kable_classic(full_width = F, html_font = \"Cambria\")\n\n\n\n\nSummary of Lung Capacity Grouped by Gender\n \n  \n    Gender \n    N \n    LC.Mean \n    LC.Median \n    LC.SD \n  \n \n\n  \n    male \n    367 \n    8.309332 \n    8.35 \n    2.683238 \n  \n  \n    female \n    358 \n    7.405746 \n    7.75 \n    2.564242 \n  \n\n\n\n\n\nIt was not possible for me to plot a Box Plot with Density like I did for Histogram but I was able to plot separately the Box Plot and Density. It seems that the distribution for the two genders are similar while the Male distribution shows a bit higher average lung capacity.\n\n\nc. Compare the mean lung capacities for smokers and non-smokers. Does it make sense?\nLet’s visualize the differences\n\n\nCode\nbox_plot_crop <- ggplot(data=lung, aes(x=Smoke, y=LungCap, fill=Smoke)) \nbox_plot_crop+ geom_boxplot() +\n  theme(legend.position = \"right\") +\n  theme (axis.text.x=element_blank(),\n        axis.ticks.x=element_blank())+\n  coord_cartesian(ylim =  c(0, 15))+\n  labs(title=\"Box Plot - Lung Capacity\",\n        x =\"Smoke\", y = \"Density\")\n\n\n\n\n\nNow let’s see the specific numbers in this summary\n\n\nCode\nLC_table_s <- lung %>%  \n group_by(Smoke) %>%\n  summarise(N = n(), LC.Mean = mean(LungCap, na.rm=TRUE), LC.Median = median(LungCap, na.rm=TRUE), LC.SD = sd(LungCap, na.rm=TRUE))\n\nLC_table_s2 <- LC_table_s[with (LC_table_s, order(-LC.Mean)),]\nformattable(LC_table_s2) %>% \n  kable(\"html\", escape = F, caption = \"Summary of Lung Capacity Grouped by Smoker\", align = c(\"l\", \"c\", \"c\", \"c\", \"c\", \"c\")) %>% \n  kable_classic(full_width = F, html_font = \"Cambria\")\n\n\n\n\nSummary of Lung Capacity Grouped by Smoker\n \n  \n    Smoke \n    N \n    LC.Mean \n    LC.Median \n    LC.SD \n  \n \n\n  \n    yes \n    77 \n    8.645454 \n    8.65 \n    1.882894 \n  \n  \n    no \n    648 \n    7.770188 \n    7.90 \n    2.726113 \n  \n\n\n\n\n\nSeems that smokers has more lung capacity than non-smokers, and I would expect the opposite. It is interesting to note that the lung capacity in smokers is more homogeneous distribution (lower SD) compared to non-smokers, even though the number of smokers is significantly smaller than non-smokers.\n\n\nd. Examine the relationship between Smoking and Lung Capacity within age groups: “less than or equal to 13”, “14 to 15”, “16 to 17”, and “greater than or equal to 18”.\n\n\ne. Compare the lung capacities for smokers and non-smokers within each age group. Is your answer different from the one in part c. What could possibly be going on here?\n\n\nCode\n# First, let's create the categories for age\n\nlung2 <-lung %>%\n  mutate(Age_Cat = case_when(\n        Age >= 0 & Age <= 13 ~ \"13 or less\",\n        Age >= 14 & Age <= 15 ~ \"14 to 15\" ,\n        Age >= 16 & Age <= 17 ~ \"16 to 17\" ,\n        Age >= 18 ~ \"18 or more\" ,\n        ))\n\nbox_plot_crop2<-ggplot(data=lung2, aes(x=Smoke, y=LungCap, fill=Smoke)) \nbox_plot_crop2+ geom_boxplot() +\n  theme(legend.position = \"right\") +\n  theme (axis.text.x=element_blank(),\n        axis.ticks.x=element_blank())+\n  coord_cartesian(ylim =  c(0, 15))+\n  labs(title=\"Box Plot - Lung Capacity\",\n        x =\"Smoke\", y = \"Density\")+\n  facet_wrap(.~Age_Cat, scales= \"free\")\n\n\n\n\n\nFrom this graph I can note the following:\n\nExcept for the group of 13 or less, non-smokers shows higher lung capacity compared with smokers.\nOn the other hand, seems that the Lung Capacity increases with the years regardless the smoke condition.\n\nLet’s see more detailed numbers. I want to see the Lung Capacity Means and dispersion for each group. for this we will do a crosstab showing n, mean, median and sd.\nFirst let’s see the frequencies for both variables in a crosstab.\n\n\nCode\nxtabs(~Age_Cat+Smoke, data=lung2)\n\n\n            Smoke\nAge_Cat       no yes\n  13 or less 401  27\n  14 to 15   105  15\n  16 to 17    77  20\n  18 or more  65  15\n\n\nMean Lung Capacity by Age Group and Smoke condition\n\n\nCode\nwith(lung2, tapply(LungCap, list(Age_Group=Age_Cat,Smoker=Smoke), mean) )\n\n\n            Smoker\nAge_Group           no       yes\n  13 or less  6.358746  7.201852\n  14 to 15    9.138810  8.391667\n  16 to 17   10.469805  9.383750\n  18 or more 11.068846 10.513333\n\n\nMedian Lung Capacity by Age Group and Smoke condition\n\n\nCode\nwith(lung2, tapply(LungCap, list(Age_Group=Age_Cat,Smoker=Smoke), median) )\n\n\n            Smoker\nAge_Group        no    yes\n  13 or less  6.575  7.025\n  14 to 15    9.000  8.475\n  16 to 17   10.600  9.550\n  18 or more 10.850 10.475\n\n\nStandard Deviation Lung Capacity by Age Group and Smoke condition\n\n\nCode\nwith(lung2, tapply(LungCap, list(Age_Group=Age_Cat,Smoker=Smoke), sd) )\n\n\n            Smoker\nAge_Group          no      yes\n  13 or less 2.214412 1.577728\n  14 to 15   1.546130 1.437497\n  16 to 17   1.536745 1.326136\n  18 or more 1.555139 1.250959\n\n\nClearly the lung capacity is higher for non smokers within each age group except 13 or less years old group, where the smoker’s mean (and median) is higher than non-smokers.\nAs noted before it is also clear that the lung capacity increases with the age regardless the smoke condition.\nHowever it is interesting to note that:\n\nThe number of cases in the group 13 or less is aout the 50% of the whole sample. So it is explaining the findings in the question part “c” above (higher overall Lung Capacity average for smokers).\nThe lung capacity makes a bigger jump for non-smokers from 13 or less to the next bracket (14-15 years) compared to smokers. In other words, non-smokers close the gap and exceed smokers when they pass the 13 years.\n\nIt seems that smoking in early ages affects lungs capacity and making it falling behind consistently from non-smokers as getting older."
  },
  {
    "objectID": "posts/FelixBetancourt_HW1_v2.html#part-b---let-x-number-of-prior-convictions-for-prisoners-at-a-state-prison-at-which-there-are-810-prisoners.",
    "href": "posts/FelixBetancourt_HW1_v2.html#part-b---let-x-number-of-prior-convictions-for-prisoners-at-a-state-prison-at-which-there-are-810-prisoners.",
    "title": "Homework 1",
    "section": "Part B - Let X = number of prior convictions for prisoners at a state prison at which there are 810 prisoners.",
    "text": "Part B - Let X = number of prior convictions for prisoners at a state prison at which there are 810 prisoners.\n\n\nCode\n# create the frequency table\nconvicted <- data.frame(\n  p_convic = c(0, 1, 2, 3, 4),\n  freq = c(128, 434, 160, 64, 24))\n\n\nFrequency Table and Cumulative Frequency Table:\n\n\nCode\nconv.tbl <- xtabs(freq ~ p_convic, data=convicted)\nprint (conv.tbl)\n\n\np_convic\n  0   1   2   3   4 \n128 434 160  64  24 \n\n\nCode\ncumfreq_data <- cumsum(conv.tbl)\nprint (cumfreq_data)\n\n\n  0   1   2   3   4 \n128 562 722 786 810 \n\n\n\n\nCode\n# \nprob_data <- conv.tbl/810\n\nprob_data2 <- as.vector(prob_data)\nprob_data3 <- data.frame (\n  p_convic = c(convicted$p_convic),\n  prob = c(prob_data2))\n\n\n\na) What is the probability that a randomly selected inmate has exactly 2 prior convictions?\n\n\nCode\nsum(prob_data3[which(prob_data3$p_convic == 2), 2])\n\n\n[1] 0.1975309\n\n\nThe Probability is 19.7%\n\n\nb) What is the probability that a randomly selected inmate has fewer than 2 prior convictions?\n\n\nCode\nsum(prob_data3[which(prob_data3$p_convic < 2), 2])\n\n\n[1] 0.6938272\n\n\nThe Probability is 69.3%\n\n\nc) What is the probability that a randomly selected inmate has 2 or fewer prior convictions?\n\n\nCode\nsum(prob_data3[which(prob_data3$p_convic <= 2), 2])\n\n\n[1] 0.891358\n\n\nThe Probability is 89.1%\n\n\nd) What is the probability that a randomly selected inmate has more than 2 prior convictions?\n\n\nCode\nsum(prob_data3[which(prob_data3$p_convic > 2), 2])\n\n\n[1] 0.108642\n\n\nThe Probability is 10.8%\n\n\ne) What is the expected value for the number of prior convictions?\n\n\nCode\np_convic2 <- as.vector(convicted$p_convic)\nconvicted_prob <- as.vector(prob_data)\n\nExpected_mean <- sum(p_convic2*convicted_prob)\nExpected_mean\n\n\n[1] 1.28642\n\n\nThe long term mean for prior convictions is 1.29\n\n\nf) Calculate the variance and the standard deviation for the Prior Convictions.\nVariance\n\n\nCode\n#Variance\n\nVar_c <- var(rep(convicted$p_convic, convicted$freq))\nVar_c\n\n\n[1] 0.8572937\n\n\nStandard Deviation\n\n\nCode\nSD_c <- sd(rep(convicted$p_convic, convicted$freq))\nSD_c\n\n\n[1] 0.9259016"
  },
  {
    "objectID": "posts/HW1_DarronBunt.html#a",
    "href": "posts/HW1_DarronBunt.html#a",
    "title": "Homework - 1",
    "section": "A",
    "text": "A\nWhat does the distribution of LungCap look like? (Hint: Plot a histogram with probability density on the y axis)\nFirst, let’s read in the data from the Excel file:\n\n\nCode\nLungCapData <- read_excel(\"_data/LungCapData.xls\")\n\n\nThe distribution of LungCap looks as follows:\n\n\nCode\nhist(LungCapData$LungCap)\n\n\n\n\n\nThe histogram suggests that the distribution is close to a normal distribution. Most of the observations are close to the mean, while very few observations are close to the margins (0 and 15)."
  },
  {
    "objectID": "posts/HW1_DarronBunt.html#b",
    "href": "posts/HW1_DarronBunt.html#b",
    "title": "Homework - 1",
    "section": "B",
    "text": "B\nCompare the probability distribution of the LungCap with respect to Males and Females? (Hint: make boxplots separated by gender using the boxplot() function)\n\n\nCode\n# Create a boxplot comparing LungCap for males and females\nboxplot(LungCap~Gender, data=LungCapData)\n\n\n\n\n\nThe boxplot suggests that the median for lung capacity in males is slightly higher than that of females. The IQR for lung capacity in males is also slightly higher than that of females. The minimum value for females is lower than that of males, as is the maximum. All of this suggests that males are more likely to have a greater lung capacity than females."
  },
  {
    "objectID": "posts/HW1_DarronBunt.html#c",
    "href": "posts/HW1_DarronBunt.html#c",
    "title": "Homework - 1",
    "section": "C",
    "text": "C\nCompare the mean lung capacities for smokers and non-smokers. Does it make sense?\n\n\nCode\n# Calculate mean lung capacity for smokers and non-smokers\nLungCapData %>%\n  group_by(Smoke) %>%\n  summarise_at(vars(LungCap),\n               list(LCap = mean))\n\n\n# A tibble: 2 × 2\n  Smoke  LCap\n  <chr> <dbl>\n1 no     7.77\n2 yes    8.65\n\n\nThis suggests that the mean lung capacity for smokers is greater than that of non-smokers. This is not what I would have expected given the (negative) impact that smoking has on the lungs."
  },
  {
    "objectID": "posts/HW1_DarronBunt.html#d",
    "href": "posts/HW1_DarronBunt.html#d",
    "title": "Homework - 1",
    "section": "D",
    "text": "D\nExamine the relationship between Smoking and Lung Capacity within age groups: “less than or equal to 13”, “14 to 15”, “16 to 17”, and “greater than or equal to 18”.\n\n\nCode\n# Create a new variable, AgeGroup, using the parameters outlined above\nAgeSmokeLC <- LungCapData %>%\n mutate(\n   AgeGroup = case_when(\n     Age <= 13 ~ \"13 and Under\",\n     Age == 14 | Age == 15 ~ \"14-15\",\n     Age == 16 | Age == 17 ~ \"16-17\", \n     Age >= 18 ~ \"18 and Over\")) \n\n# Calculate the mean lung capacity for smokers and non-smokers in each age group  \n  AgeSmokeLCMean <- AgeSmokeLC %>%\n    group_by(AgeGroup, Smoke) %>%\n  summarise_at(vars(LungCap),\n               list(MeanLungCap = mean)) %>%\n  arrange(desc(MeanLungCap))\nAgeSmokeLCMean\n\n\n# A tibble: 8 × 3\n# Groups:   AgeGroup [4]\n  AgeGroup     Smoke MeanLungCap\n  <chr>        <chr>       <dbl>\n1 18 and Over  no          11.1 \n2 18 and Over  yes         10.5 \n3 16-17        no          10.5 \n4 16-17        yes          9.38\n5 14-15        no           9.14\n6 14-15        yes          8.39\n7 13 and Under yes          7.20\n8 13 and Under no           6.36\n\n\nThis suggests that lung capacity increases with age; the mean lung capacity for each subsequent age category is greater than the one before it. Individuals aged 13 and under who smoke have a greater mean lung capacity than those who do not; however, at ages 14-15, 16-17, and 18+, non-smokers have a greater lung capacity than their similarly aged smoking counterparts."
  },
  {
    "objectID": "posts/HW1_DarronBunt.html#e",
    "href": "posts/HW1_DarronBunt.html#e",
    "title": "Homework - 1",
    "section": "E",
    "text": "E\nCompare the lung capacities for smokers and non-smokers within each age group. Is your answer different from the one in part c. What could possibly be going on here?\nFrom the age group data above, we can ascertain that in the majority of age groups (three of the four), non-smokers have greater mean lung capacity than smokers, and yet when we calculated the mean lung capacity solely for smokers/non-smokers (ie. not accounting for age), smokers had greater mean lung capacity. The mean lung capacities for smokers/non-smokers (again, not accounting for age) are also lower than one might expect considering that when we do account for age, most of the represented groups have a higher mean lung capacity. This would suggest that something is skewing our results.\nOne way to gain insight into this is to examine how many respondents fell into each age/smoking status category.\n\n\nCode\n# Count number of responses in each age group who are smokers/non-smokers\nAgeSmokeLC %>%\n  count(AgeGroup, Smoke)\n\n\n# A tibble: 8 × 3\n  AgeGroup     Smoke     n\n  <chr>        <chr> <int>\n1 13 and Under no      401\n2 13 and Under yes      27\n3 14-15        no      105\n4 14-15        yes      15\n5 16-17        no       77\n6 16-17        yes      20\n7 18 and Over  no       65\n8 18 and Over  yes      15\n\n\nThere are more non-smoking individuals aged 13 and Under in this sample than all other categories combined. Accordingly, data from this group can (and has) skewed the overall non-smoking mean."
  },
  {
    "objectID": "posts/HW1_DarronBunt.html#a-1",
    "href": "posts/HW1_DarronBunt.html#a-1",
    "title": "Homework - 1",
    "section": "A",
    "text": "A\nWhat is the probability that a randomly selected inmate has exactly 2 prior convictions?\nTo answer this question, we are going to need to know the total number of inmates.\n\n\nCode\n#Find total number of inmates\nsum(PriorConvictions$Inmates)\n\n\n[1] 810\n\n\nTo calculate this probability we are going calculate the binomial distribution. For this, we require three main arguments: x - the number specifying the outcomes you’re trying to calculate (for this question, x=1) size - the size of the experiment (for this question, size=1) prob - the probability of success for any one trial in the experiment (for this question, prob = the total number of inmates with two convictions / the total number of inmates, or 160/810)\n\n\nCode\n# Calculate probability of randomly selecting an inmate with two prior convictions\ndbinom(x=1, size=1, prob=(160/810))\n\n\n[1] 0.1975309\n\n\nThe probability of randomly selecting an inmate with two prior convictions is roughly 19.8%."
  },
  {
    "objectID": "posts/HW1_DarronBunt.html#b-1",
    "href": "posts/HW1_DarronBunt.html#b-1",
    "title": "Homework - 1",
    "section": "B",
    "text": "B\nWhat is the probability that a randomly selected inmate has fewer than 2 prior convictions?\nHaving fewer than two prior convictions would mean that the inmate could either have zero or one prior convictions.\nx = 1 size = 1 prob = ((the total number of inmates with no prior convictions + inmates with 1 conviction) / the total number of inmates, or ((128 + 434)/810), or 562/810.\n\n\nCode\n# Calculate probability of randomly selecting an inmate with less than two prior convictions\ndbinom(x=1, size=1, prob=(562/810))\n\n\n[1] 0.6938272\n\n\nThe probability of randomly selecting an inmate with fewer than two prior convictions is roughly 69.4%."
  },
  {
    "objectID": "posts/HW1_DarronBunt.html#c-1",
    "href": "posts/HW1_DarronBunt.html#c-1",
    "title": "Homework - 1",
    "section": "C",
    "text": "C\nWhat is the probability that a randomly selected inmate has 2 or fewer prior convictions?\nHaving two or fewer prior convictions would mean that the inmate could either have zero, one, or two prior convictions.\nx = 1 size = 1 prob = ((the total number of inmates with no prior convictions + inmates with 1 conviction + inmates with 2 convictions) / the total number of inmates, or ((128 + 434 + 160)/810), or 722/810.\n\n\nCode\n# Calculate probability of randomly selecting an inmate with two or fewer prior convictions\ndbinom(x=1, size=1, prob=(722/810))\n\n\n[1] 0.891358\n\n\nThe probability of randomly selecting an inmate with two or fewer prior convictions is roughly 89.1%."
  },
  {
    "objectID": "posts/HW1_DarronBunt.html#d-1",
    "href": "posts/HW1_DarronBunt.html#d-1",
    "title": "Homework - 1",
    "section": "D",
    "text": "D\nWhat is the probability that a randomly selected inmate has more than 2 prior convictions?\nHaving more than two prior convictions would mean that the inmate could either have three or four prior convictions.\nx = 1 size = 1 prob = ((the total number of inmates with 3 convictions + inmates with 4 convictions) / the total number of inmates, or ((64+24)/810), or 88/810.\n\n\nCode\n# Calculate probability of randomly selecting an inmate with more than two prior convictions\ndbinom(x=1, size=1, prob=(88/810))\n\n\n[1] 0.108642\n\n\nThe probability of randomly selecting an inmate with more than two prior convictions is roughly 10.9%."
  },
  {
    "objectID": "posts/HW1_DarronBunt.html#e-1",
    "href": "posts/HW1_DarronBunt.html#e-1",
    "title": "Homework - 1",
    "section": "E",
    "text": "E\nWhat is the expected value for the number of prior convictions? (The expected value of a discrete random variable X, symbolized as E(X), is often referred to as the long-term average or mean)\nIn order to calculate the expected value for the number of prior convictions, we will need to use the proportional breakdown of the number of inmates with each number of convictions.\n\n\nCode\n# Calculate proportion of inmates with 0,1,2,3,4 convictions\nPriorConvictionsProp <- PriorConvictions %>%\n  mutate(Proportion = Inmates/810)\nPriorConvictionsProp\n\n\n  PriorConv Inmates Proportion\n1         0     128 0.15802469\n2         1     434 0.53580247\n3         2     160 0.19753086\n4         3      64 0.07901235\n5         4      24 0.02962963\n\n\n\n\nCode\n# Calculate the expected value for prior number of convictions\nExpValue <- sum(PriorConvictionsProp$PriorConv*PriorConvictionsProp$Proportion)\nExpValue\n\n\n[1] 1.28642\n\n\nThe expected value is 1.29 prior convictions."
  },
  {
    "objectID": "posts/HW1_DarronBunt.html#f",
    "href": "posts/HW1_DarronBunt.html#f",
    "title": "Homework - 1",
    "section": "F",
    "text": "F\nCalculate the variance and the standard deviation for the Prior Convictions.\n\n\nCode\n# Calculate the variance for prior convictions\nPriorConvVar <- sum((PriorConvictionsProp$PriorConv - ExpValue) ^ 2 * PriorConvictionsProp$Proportion)\nPriorConvVar\n\n\n[1] 0.8562353\n\n\n\n\nCode\n# Calculate the standard deviation for prior convictions\nPriorConvSTD <- sqrt(PriorConvVar)\nPriorConvSTD\n\n\n[1] 0.9253298"
  },
  {
    "objectID": "posts/dacss603_final_LauraCollazo.html",
    "href": "posts/dacss603_final_LauraCollazo.html",
    "title": "Proposal for DACSS 603 Final Project",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(psych)\nlibrary(lattice)\nlibrary(FSA)\nlibrary(kableExtra)\n\nknitr::opts_chunk$set(echo = TRUE)"
  },
  {
    "objectID": "posts/dacss603_final_LauraCollazo.html#dataset",
    "href": "posts/dacss603_final_LauraCollazo.html#dataset",
    "title": "Proposal for DACSS 603 Final Project",
    "section": "Dataset",
    "text": "Dataset\nThe data for this study was collected during the last month of the Fall 2021 semester at a large public university in the mid-west of the United States (Jeng et al., 2023). Students were recruited through voluntary response sampling in an online introduction to statistics course and received extra credit for participating in the study. The instructor of this course was not a member of the research team. A total of 240 students completed the survey and responses from 17 students were removed due to either missing demographics, the same rating for every example, or identical response made to more than 50% of open-ended questions. In total, responses from 223 students are included.\nThe full dataset can be found here.\n\nVariables\nTo answer the research question for the present study, the following variables have been selected. Details on these variables are included in following sections.\n\ngender\nrace\nbel_1\nbel_2\nbel_2_r\nbel_3\nbel_4\nbel_4_r\nbel_5\nbel_5_r\nbel_6\n\nUsing the above variables, additional variables were created to aid in analysis. These included 6 belonging variables with the data un-coded to show the actual response options and 6 more belonging variables as order factors. The variable bel_sum was also created to create an overall belonging score for each participant.\n\nGender\nThe responses for gender include “Man” (2) and “Woman or non-binary” (1). The researchers who collected this data explain that their were so few students who identified as non-binary that the sample was too small for a separate analysis (Jeng et al., 2023). What they did do was run all analysis twice, once with non-binary students excluded and once with this group combine with respondents who identified as women. They found their findings to be the same in both instances and therefore choose to combine these two groups. For the purpose of this study, this variable will be coded as “Male” and “Female.”\n\n\nRace/Ethnicity\nThe response options for race include “Asian or Asian American” (1), “Black or African American” (2), “Hispanic or Latino” (3), “White” (4), and “Other” (5).\n\n\nBelonging\nA total of 6 Likert questions were asked to measure social belonging which were adapted from Goodenow’s (1993) Psychological Sense of School Membership (PSSM) scale. Five response options (“Not at all true”, “Slightly true”, “Moderately true”, “Mostly true”, and “Completely true”) were provided to students to answer the below questions. Questions 2, 4, and 5 were reversed scored which is why 2 variables exist for each of these questions.\n\nI feel like a real part of this class\nSometimes I feel as if I don’t belong in this class\nI am included in lots of activities in this class\nI feel very different from most other students in this class\nI wish I were in a different class\nI feel proud of belonging to this class\n\n\n\nExplore Data\n\nPrepare Data\n\n\nCode\n# read in data\n\nbelonging_data <- read_csv(\"_data/belonging_survey_2022-07-08.csv\", show_col_types = FALSE)\n\n# tidy data\n\ndata <- belonging_data %>%\n  \n# filter to include only 1 set of student belonging responses\n  \n  filter(example_num == 1) %>% \n  \n# select needed columns\n  \n  select(gender, race, bel_1, bel_2, bel_2_r, bel_3, bel_4, bel_4_r, bel_5, bel_5_r, bel_6) %>%\n\n# create variable bel_sum which sums all belonging responses\n  \n  mutate(bel_sum = rowSums(across(c(bel_1, bel_2_r, bel_3, bel_4_r, bel_5_r, bel_6))))\n\n### Create new variables with Likert scores as an ordered factor\n\ndata$f_bel_1 = factor(data$bel_1,\n                       ordered = TRUE,\n                       levels = c(\"1\", \"2\", \"3\", \"4\", \"5\")\n                       )\n\ndata$f_bel_2 = factor(data$bel_2,\n                       ordered = TRUE,\n                       levels = c(\"1\", \"2\", \"3\", \"4\", \"5\")\n                       )\n\ndata$f_bel_3 = factor(data$bel_3,\n                       ordered = TRUE,\n                       levels = c(\"1\", \"2\", \"3\", \"4\", \"5\")\n                       )\n\ndata$f_bel_4 = factor(data$bel_4,\n                       ordered = TRUE,\n                       levels = c(\"1\", \"2\", \"3\", \"4\", \"5\")\n                       )\n\ndata$f_bel_5 = factor(data$bel_5,\n                       ordered = TRUE,\n                       levels = c(\"1\", \"2\", \"3\", \"4\", \"5\")\n                       )\n\ndata$f_bel_6 = factor(data$bel_6,\n                       ordered = TRUE,\n                       levels = c(\"1\", \"2\", \"3\", \"4\", \"5\")\n                       )\n  \n# recode data\n  \ndata <- data %>% \n  mutate(gender = recode(gender,\n                            `1` = \"Female\",\n                            `2` = \"Male\")) %>%\n  mutate(race = recode(race,\n                            `1` = \"Asian\",\n                            `2` = \"Black\",\n                            `3` = \"Hispanic\",\n                            `4` = \"White\",\n                            `5` = \"Other\")) %>%\n  mutate(across(bel_1:bel_6, \n                ~ recode(.x, `1` = \"Not at all true\",\n                             `2` = \"Slightly true\",\n                             `3` = \"Moderately true\",\n                             `4` = \"Mostly true\",\n                             `5` = \"Completely true\"))) \n\n\n\n\nExamine Data\n\n\nCode\n# examine data\n\ndescribe_data <- describe(x=data) %>% \n  select(c(vars, n, mean, sd, median, min, max, range))\n\nkable(describe_data) %>% \n  kable_styling(\"striped\")\n\n\n\n\n \n  \n      \n    vars \n    n \n    mean \n    sd \n    median \n    min \n    max \n    range \n  \n \n\n  \n    gender* \n    1 \n    223 \n    1.233184 \n    0.4238096 \n    1 \n    1 \n    2 \n    1 \n  \n  \n    race* \n    2 \n    223 \n    3.318386 \n    1.7037249 \n    3 \n    1 \n    5 \n    4 \n  \n  \n    bel_1* \n    3 \n    223 \n    2.479821 \n    1.2148837 \n    2 \n    1 \n    5 \n    4 \n  \n  \n    bel_2* \n    4 \n    223 \n    3.829596 \n    0.8261619 \n    4 \n    1 \n    5 \n    4 \n  \n  \n    bel_2_r* \n    5 \n    223 \n    1.645740 \n    1.1605634 \n    1 \n    1 \n    5 \n    4 \n  \n  \n    bel_3* \n    6 \n    223 \n    3.094170 \n    1.3672858 \n    3 \n    1 \n    5 \n    4 \n  \n  \n    bel_4* \n    7 \n    223 \n    3.735426 \n    1.0725698 \n    4 \n    1 \n    5 \n    4 \n  \n  \n    bel_4_r* \n    8 \n    223 \n    1.973094 \n    1.1965389 \n    1 \n    1 \n    5 \n    4 \n  \n  \n    bel_5* \n    9 \n    223 \n    3.991031 \n    0.7473137 \n    4 \n    1 \n    5 \n    4 \n  \n  \n    bel_5_r* \n    10 \n    223 \n    1.488789 \n    0.9341421 \n    1 \n    1 \n    5 \n    4 \n  \n  \n    bel_6* \n    11 \n    223 \n    2.206278 \n    1.1978043 \n    2 \n    1 \n    5 \n    4 \n  \n  \n    bel_sum \n    12 \n    223 \n    23.614350 \n    4.4846254 \n    25 \n    6 \n    30 \n    24 \n  \n  \n    f_bel_1* \n    13 \n    223 \n    3.686099 \n    1.0905551 \n    4 \n    1 \n    5 \n    4 \n  \n  \n    f_bel_2* \n    14 \n    223 \n    1.565022 \n    1.0107690 \n    1 \n    1 \n    5 \n    4 \n  \n  \n    f_bel_3* \n    15 \n    223 \n    2.932735 \n    1.2979385 \n    3 \n    1 \n    5 \n    4 \n  \n  \n    f_bel_4* \n    16 \n    223 \n    1.878924 \n    1.0690801 \n    1 \n    1 \n    5 \n    4 \n  \n  \n    f_bel_5* \n    17 \n    223 \n    1.381166 \n    0.8236397 \n    1 \n    1 \n    5 \n    4 \n  \n  \n    f_bel_6* \n    18 \n    223 \n    3.820628 \n    1.1756254 \n    4 \n    1 \n    5 \n    4 \n  \n\n\n\n\n\nCode\nstr(data)\n\n\ntibble [223 × 18] (S3: tbl_df/tbl/data.frame)\n $ gender : chr [1:223] \"Female\" \"Male\" \"Female\" \"Female\" ...\n $ race   : chr [1:223] \"White\" \"White\" \"Asian\" \"White\" ...\n $ bel_1  : chr [1:223] \"Mostly true\" \"Slightly true\" \"Completely true\" \"Mostly true\" ...\n $ bel_2  : chr [1:223] \"Moderately true\" \"Slightly true\" \"Not at all true\" \"Not at all true\" ...\n $ bel_2_r: chr [1:223] \"Moderately true\" \"Mostly true\" \"Completely true\" \"Completely true\" ...\n $ bel_3  : chr [1:223] \"Mostly true\" \"Mostly true\" \"Mostly true\" \"Mostly true\" ...\n $ bel_4  : chr [1:223] \"Slightly true\" \"Moderately true\" \"Mostly true\" \"Slightly true\" ...\n $ bel_4_r: chr [1:223] \"Mostly true\" \"Moderately true\" \"Slightly true\" \"Mostly true\" ...\n $ bel_5  : chr [1:223] \"Slightly true\" \"Slightly true\" \"Not at all true\" \"Not at all true\" ...\n $ bel_5_r: chr [1:223] \"Mostly true\" \"Mostly true\" \"Completely true\" \"Completely true\" ...\n $ bel_6  : chr [1:223] \"Mostly true\" \"Moderately true\" \"Completely true\" \"Completely true\" ...\n $ bel_sum: num [1:223] 23 20 26 27 28 24 17 23 25 29 ...\n $ f_bel_1: Ord.factor w/ 5 levels \"1\"<\"2\"<\"3\"<\"4\"<..: 4 2 5 4 4 3 4 3 4 4 ...\n $ f_bel_2: Ord.factor w/ 5 levels \"1\"<\"2\"<\"3\"<\"4\"<..: 3 2 1 1 1 1 4 1 1 1 ...\n $ f_bel_3: Ord.factor w/ 5 levels \"1\"<\"2\"<\"3\"<\"4\"<..: 4 4 4 4 4 5 3 2 1 5 ...\n $ f_bel_4: Ord.factor w/ 5 levels \"1\"<\"2\"<\"3\"<\"4\"<..: 2 3 4 2 1 3 3 1 1 1 ...\n $ f_bel_5: Ord.factor w/ 5 levels \"1\"<\"2\"<\"3\"<\"4\"<..: 2 2 1 1 1 1 2 1 1 1 ...\n $ f_bel_6: Ord.factor w/ 5 levels \"1\"<\"2\"<\"3\"<\"4\"<..: 4 3 5 5 5 3 1 3 5 5 ...\n\n\n\n\nExamine Variables\n\n\nCode\n# create xtabs and bar plot to visualize variables\n\n# gender\n\nxt_gender <- xtabs(~gender, data = data)\n\nkable(xt_gender) %>% \n  kable_styling(\"striped\")\n\n\n\n\n \n  \n    gender \n    Freq \n  \n \n\n  \n    Female \n    171 \n  \n  \n    Male \n    52 \n  \n\n\n\n\n\nCode\nbarplot(xt_gender, \n        xlab = \"Gender\",\n        ylab = \"Frequency\")\n\n\n\n\n\nCode\n# race\n\nxt_race <- xtabs(~race, data = data)\n\nkable(xt_race) %>% \n  kable_styling(\"striped\")\n\n\n\n\n \n  \n    race \n    Freq \n  \n \n\n  \n    Asian \n    59 \n  \n  \n    Black \n    21 \n  \n  \n    Hispanic \n    33 \n  \n  \n    Other \n    10 \n  \n  \n    White \n    100 \n  \n\n\n\n\n\nCode\nbarplot(xt_race, \n        xlab = \"Race\",\n        ylab = \"Frequency\")\n\n\n\n\n\nCode\n# bel_sum\n\nxt_sum <- xtabs(~bel_sum, data = data)\n\nkable(xt_sum) %>% \n  kable_styling(\"striped\")\n\n\n\n\n \n  \n    bel_sum \n    Freq \n  \n \n\n  \n    6 \n    1 \n  \n  \n    8 \n    1 \n  \n  \n    10 \n    1 \n  \n  \n    11 \n    2 \n  \n  \n    12 \n    1 \n  \n  \n    13 \n    2 \n  \n  \n    14 \n    2 \n  \n  \n    15 \n    3 \n  \n  \n    16 \n    1 \n  \n  \n    17 \n    8 \n  \n  \n    18 \n    9 \n  \n  \n    19 \n    7 \n  \n  \n    20 \n    7 \n  \n  \n    21 \n    12 \n  \n  \n    22 \n    15 \n  \n  \n    23 \n    19 \n  \n  \n    24 \n    17 \n  \n  \n    25 \n    32 \n  \n  \n    26 \n    21 \n  \n  \n    27 \n    25 \n  \n  \n    28 \n    12 \n  \n  \n    29 \n    12 \n  \n  \n    30 \n    13 \n  \n\n\n\n\n\nCode\nbarplot(xt_sum, \n        xlab = \"Belonging\",\n        ylab = \"Frequency\")\n\n\n\n\n\nCode\n# f_bel_1\n\nxt_1 <- xtabs(~f_bel_1, data = data)\n\nkable(xt_1) %>% \n  kable_styling(\"striped\")\n\n\n\n\n \n  \n    f_bel_1 \n    Freq \n  \n \n\n  \n    1 \n    9 \n  \n  \n    2 \n    23 \n  \n  \n    3 \n    55 \n  \n  \n    4 \n    78 \n  \n  \n    5 \n    58 \n  \n\n\n\n\n\nCode\nbarplot(xt_1, \n        xlab = \"I feel like a real part of this class\",\n        ylab = \"Frequency\")\n\n\n\n\n\nCode\n# f_bel_2\n\nxt_2 <- xtabs(~f_bel_2, data = data)\n\nkable(xt_2) %>% \n  kable_styling(\"striped\")\n\n\n\n\n \n  \n    f_bel_2 \n    Freq \n  \n \n\n  \n    1 \n    157 \n  \n  \n    2 \n    28 \n  \n  \n    3 \n    20 \n  \n  \n    4 \n    14 \n  \n  \n    5 \n    4 \n  \n\n\n\n\n\nCode\nbarplot(xt_2, \n        xlab = \"Sometimes I feel as if I don’t belong in this class\",\n        ylab = \"Frequency\")\n\n\n\n\n\nCode\n# f_bel_3\n\nxt_3 <- xtabs(~f_bel_3, data = data)\n\nkable(xt_3) %>% \n  kable_styling(\"striped\")\n\n\n\n\n \n  \n    f_bel_3 \n    Freq \n  \n \n\n  \n    1 \n    38 \n  \n  \n    2 \n    50 \n  \n  \n    3 \n    55 \n  \n  \n    4 \n    49 \n  \n  \n    5 \n    31 \n  \n\n\n\n\n\nCode\nbarplot(xt_3, \n        xlab = \"I am included in lots of activities in this class\",\n        ylab = \"Frequency\")\n\n\n\n\n\nCode\n# f_bel_4\n\nxt_4 <- xtabs(~f_bel_4, data = data)\n\nkable(xt_4) %>% \n  kable_styling(\"striped\")\n\n\n\n\n \n  \n    f_bel_4 \n    Freq \n  \n \n\n  \n    1 \n    112 \n  \n  \n    2 \n    51 \n  \n  \n    3 \n    40 \n  \n  \n    4 \n    15 \n  \n  \n    5 \n    5 \n  \n\n\n\n\n\nCode\nbarplot(xt_4, \n        xlab = \"I feel very different from most other students in this class\",\n        ylab = \"Frequency\")\n\n\n\n\n\nCode\n# f_bel_5\n\nxt_5 <- xtabs(~f_bel_5, data = data)\n\nkable(xt_5) %>% \n  kable_styling(\"striped\")\n\n\n\n\n \n  \n    f_bel_5 \n    Freq \n  \n \n\n  \n    1 \n    169 \n  \n  \n    2 \n    36 \n  \n  \n    3 \n    10 \n  \n  \n    4 \n    3 \n  \n  \n    5 \n    5 \n  \n\n\n\n\n\nCode\nbarplot(xt_5, \n        xlab = \"I wish I were in a different class\",\n        ylab = \"Frequency\")\n\n\n\n\n\nCode\n# f_bel_6\n\nxt_6 <- xtabs(~f_bel_6, data = data)\n\nkable(xt_6) %>% \n  kable_styling(\"striped\")\n\n\n\n\n \n  \n    f_bel_6 \n    Freq \n  \n \n\n  \n    1 \n    13 \n  \n  \n    2 \n    15 \n  \n  \n    3 \n    54 \n  \n  \n    4 \n    58 \n  \n  \n    5 \n    83 \n  \n\n\n\n\n\nCode\nbarplot(xt_6, \n        xlab = \"I feel proud of belonging to this class\",\n        ylab = \"Frequency\")"
  },
  {
    "objectID": "posts/HW1_AkhileshKumarMeghwal.html",
    "href": "posts/HW1_AkhileshKumarMeghwal.html",
    "title": "Homework 1 - Akhilesh Kumar",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(ggplot2)\nlibrary(stats)\nlibrary(viridis)\n\nknitr::opts_chunk$set(echo = TRUE, warning = FALSE)"
  },
  {
    "objectID": "posts/HW1_AkhileshKumarMeghwal.html#reading-data",
    "href": "posts/HW1_AkhileshKumarMeghwal.html#reading-data",
    "title": "Homework 1 - Akhilesh Kumar",
    "section": "Reading Data",
    "text": "Reading Data\nFirst, let’s read in the data from the Excel file:\n\n\nCode\nlibrary(readxl)\ndf <- read_excel(\"_data/LungCapData.xls\")\n\n\nThe distribution of LungCap looks as follows:\nThe LungCap dataset contains 725 observations and six variables, namely LungCap, Age, Height, Smoke, Gender, and Cesarean. LungCap is the primary variable of interest, measuring the lung capacity of participants. Age and Height provide demographic information, indicating the age and height of each participant.\nEach row in the dataset corresponds to a unique participant and provides their values for the six variables. Smoke is a categorical variable that denotes whether the participant smokes or not. Gender is another categorical variable that identifies the gender of each participant. Cesarean is a binary variable indicating whether the participant was born via cesarean section or not.\nThe LungCap dataset may be useful in exploring the relationships between lung capacity, demographic variables, and smoking status."
  },
  {
    "objectID": "posts/HW1_AkhileshKumarMeghwal.html#a-what-does-the-distribution-of-lungcap-look-like",
    "href": "posts/HW1_AkhileshKumarMeghwal.html#a-what-does-the-distribution-of-lungcap-look-like",
    "title": "Homework 1 - Akhilesh Kumar",
    "section": "1a: What does the distribution of LungCap look like?",
    "text": "1a: What does the distribution of LungCap look like?\nThe following plot displays the distribution of LungCap:\n\n\nCode\nlibrary(tidyverse)\nlibrary(ggplot2)\n\ndf %>%\n  ggplot(aes(LungCap, ..density..)) +\n  geom_histogram(bins = 25, color = \"black\", fill = \"orange\") +\n  geom_density(color = \"darkblue\", linewidth = 1.25) +\n  theme_classic() + \n  theme(plot.title = element_text(hjust = 0.65, color = \"darkblue\")) +\n  theme(axis.text = element_text(face = \"bold\", color=\"darkblue\"), axis.title = element_text(face = \"bold\", size=12, color=\"darkblue\")) +\n  xlab(\"Lung Capacity\") +\n  ylab(\"Probability Density\") +\n  labs(title = \"Probability Distribution of LungCap\")\n\n\n\n\n\nThe plot displays the distribution of lung capacity measurements in a sample of individuals. The histogram and density plots indicate that the data is approximately normally distributed, with the majority of observations clustered near the mean. Specifically, the histogram shows a bell-shaped curve, with the highest frequency of observations centered around the mean value.\nThe density plot shows a smooth, symmetric curve, which closely follows the histogram and suggests that the data follows a normal distribution. These results are consistent with what we might expect, given that lung capacity is a physiological measure that is likely to vary around a central tendency. Taken together, these findings suggest that the sample data is well-behaved and that the majority of individuals in the sample have lung capacities that are close to the average value."
  },
  {
    "objectID": "posts/HW1_AkhileshKumarMeghwal.html#b-compare-the-probability-distribution-of-the-lungcap-with-respect-to-males-and-females",
    "href": "posts/HW1_AkhileshKumarMeghwal.html#b-compare-the-probability-distribution-of-the-lungcap-with-respect-to-males-and-females",
    "title": "Homework 1 - Akhilesh Kumar",
    "section": "1b: Compare the probability distribution of the LungCap with respect to Males and Females?",
    "text": "1b: Compare the probability distribution of the LungCap with respect to Males and Females?\n\n\nCode\ndf %>%\n  ggplot(aes(y = dnorm(LungCap), x = Gender, color = Gender)) +\n  geom_boxplot(alpha = 0.5) +\n  scale_fill_manual(values = c(\"green\", \"orange\")) +\n  theme_classic() + \n  theme(plot.title = element_text(hjust = 0.5, color = \"darkblue\", face = \"bold\", size = 14),\n        axis.text = element_text(face = \"bold\", color=\"darkblue\"), \n        axis.title = element_text(face = \"bold\", size=12, color=\"darkblue\")) +\n  labs(title = \"LungCap Probability Distribution based on Gender\", y = \"Probability density\")\n\n\n\n\n\nThe probability density of LungCap for females is higher than for males, as evidenced by the higher median value and larger range of data in the female group compared to the male group. This suggests that gender may be a significant factor in determining LungCap values."
  },
  {
    "objectID": "posts/HW1_AkhileshKumarMeghwal.html#c-compare-the-mean-lung-capacities-for-smokers-and-non-smokers.-does-it-make-sense",
    "href": "posts/HW1_AkhileshKumarMeghwal.html#c-compare-the-mean-lung-capacities-for-smokers-and-non-smokers.-does-it-make-sense",
    "title": "Homework 1 - Akhilesh Kumar",
    "section": "1c: Compare the mean lung capacities for smokers and non-smokers. Does it make sense?",
    "text": "1c: Compare the mean lung capacities for smokers and non-smokers. Does it make sense?\n\n\nCode\nlibrary(knitr)\n\nMean_Lung_Capacity <- df %>%\n  group_by(Smoke) %>%\n  summarise(mean = mean(LungCap))\n\n\nMean_Lung_Capacity\n\n\n\n\n  \n\n\n\nThe above table shows the lung capacity of individuals who smoke versus those who do not smoke. The table suggests that the mean lung capacity of those who smoke is greater than that of those who do not smoke. However, the statement argues that this result does not make sense and cannot be conclusively interpreted as a difference between smokers and non-smokers.\nThe output suggests that the lung capacity of an individual who smokes may be influenced by various biological factors unique to each person. Therefore, while smoking can be a contributing factor to reduced lung capacity, it cannot be the sole factor responsible for differences in lung capacity between smokers and non-smokers.\nThe output emphasizes that the difference in mean lung capacity between smokers and non-smokers is not a conclusive indicator of the effects of smoking on lung capacity. Other factors, such as age, gender and overall health, may also play a role in lung capacity. Therefore, it is important to consider these factors when drawing conclusions about the impact of smoking on lung capacity or other health outcomes."
  },
  {
    "objectID": "posts/HW1_AkhileshKumarMeghwal.html#d-examine-the-relationship-between-smoking-and-lung-capacity-within-age-groups-less-than-or-equal-to-13-14-to-15-16-to-17-and-greater-than-or-equal-to-18.",
    "href": "posts/HW1_AkhileshKumarMeghwal.html#d-examine-the-relationship-between-smoking-and-lung-capacity-within-age-groups-less-than-or-equal-to-13-14-to-15-16-to-17-and-greater-than-or-equal-to-18.",
    "title": "Homework 1 - Akhilesh Kumar",
    "section": "1d: Examine the relationship between Smoking and Lung Capacity within age groups: “less than or equal to 13”, “14 to 15”, “16 to 17”, and “greater than or equal to 18”.",
    "text": "1d: Examine the relationship between Smoking and Lung Capacity within age groups: “less than or equal to 13”, “14 to 15”, “16 to 17”, and “greater than or equal to 18”.\n\n\nCode\nLc <- mutate(Lc, AgeGrp = case_when(\n    Age <= 13 ~ \"less than or equal to 13\",\n    Age == 14 | Age == 15 ~ \"14 to 15\",\n    Age == 16 | Age == 17 ~ \"16 to 17\",\n    Age >= 18 ~ \"greater than or equal to 18\"\n))\n\n\nError in mutate(Lc, AgeGrp = case_when(Age <= 13 ~ \"less than or equal to 13\", : object 'Lc' not found\n\n\nCode\nLc %>%\n  ggplot(aes(x = LungCap, fill = Smoke)) +\n  geom_histogram(bins = 25, color = \"black\") +\n  facet_wrap(vars(AgeGrp)) +\n  scale_fill_manual(values = c(\"darkgreen\", \"darkblue\")) +\n  theme_classic() + \n  labs(title = \"Relationship of LungCap and Smoke based on age categories\", y = \"Frequency\", x = \"Lung Capacity\")\n\n\nError in ggplot(., aes(x = LungCap, fill = Smoke)): object 'Lc' not found\n\n\nThe graph shows the frequency of lung capacity for non-smokers and smokers in different age categories, namely:\n\n“less than or equal to 13”,\n“14 to 15”,\n“16 to 17”, and\n“greater than or equal to 18”\n\nFrom the above plot, we can derive two important observations. Firstly, we observe that non-smokers generally have a higher lung capacity compared to smokers. This is indicated by the fact that the bars for non-smokers are consistently taller than the bars for smokers across all age groups. This observation is consistent with the known negative impact of smoking on lung function.\nSecondly, we observe that the number of smokers is relatively lower in the age group “less than or equal to 13”. This is shown by the relatively shorter bars for smokers in this age group. This observation could be due to several factors, such as lower access to cigarettes or lower rates of smoking initiation in younger age groups.\nAdditionally, we can also observe that there is a general trend of decreasing lung capacity as age increases, regardless of smoking status. This is indicated by the fact that the bars for all age groups are shorter compared to the bars for the previous age group. This trend is consistent with the natural decline in lung function that occurs with aging.\nIn summary, the above graph shows that non-smokers generally have a higher lung capacity compared to smokers, and that smoking rates are relatively lower in younger age groups. The graph also highlights the general trend of decreasing lung capacity as age increases, regardless of smoking status. These observations provide important insights into the relationship between lung capacity, smoking, and age, and can be useful for informing public health interventions and promoting healthy lifestyles."
  },
  {
    "objectID": "posts/HW1_AkhileshKumarMeghwal.html#e-compare-the-lung-capacities-for-smokers-and-non-smokers-within-each-age-group.-is-your-answer-different-from-the-one-in-part-c.-what-could-possibly-be-going-on-here",
    "href": "posts/HW1_AkhileshKumarMeghwal.html#e-compare-the-lung-capacities-for-smokers-and-non-smokers-within-each-age-group.-is-your-answer-different-from-the-one-in-part-c.-what-could-possibly-be-going-on-here",
    "title": "Homework 1 - Akhilesh Kumar",
    "section": "1e: Compare the lung capacities for smokers and non-smokers within each age group. Is your answer different from the one in part c. What could possibly be going on here?",
    "text": "1e: Compare the lung capacities for smokers and non-smokers within each age group. Is your answer different from the one in part c. What could possibly be going on here?\n\n\nCode\nLc %>%\n  ggplot(aes(x = Age, y = LungCap, color = Smoke)) +\n  geom_line(linewidth = 1.25) +\n  scale_color_manual(values = c(\"darkgreen\", \"darkred\")) +\n  theme_classic() + \n  facet_wrap(vars(Smoke)) +\n  labs(title = \"Relationship of Lung Capacity and Smoking Status by Age\", y = \"Lung Capacity\", x = \"Age\") +\n  theme(plot.title = element_text(face = \"bold\", size = 14, hjust = 0.5),\n        axis.title.x = element_text(face = \"bold\", size = 12),\n        axis.title.y = element_text(face = \"bold\", size = 12),\n        axis.text.x = element_text(size = 10),\n        axis.text.y = element_text(size = 10),\n        legend.title = element_blank(),\n        legend.text = element_text(face = \"bold\", size = 10),\n        panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank(),\n        panel.background = element_blank())\n\n\nError in ggplot(., aes(x = Age, y = LungCap, color = Smoke)): object 'Lc' not found\n\n\n1c presents a the mean lung capacity of individuals who smoke versus those who do not smoke. The statement argues that this result cannot be conclusively interpreted as a difference between smokers and non-smokers, as other biological factors unique to each individual may also influence lung capacity.\nOn the other hand, 1e presents a line graph that compares lung capacity with age for smokers and non-smokers. The graph suggests that non-smokers generally have higher lung capacity compared to smokers, and that the difference in lung capacity between the two groups increases with age.\nIn summary, 1c presents a summary statistic that may be influenced by other factors, while 1e presents a visual representation of the relationship between smoking and lung capacity over time, which provides a more nuanced understanding of the impact of smoking on lung capacity."
  },
  {
    "objectID": "posts/HW1_AkhileshKumarMeghwal.html#question-2",
    "href": "posts/HW1_AkhileshKumarMeghwal.html#question-2",
    "title": "Homework 1 - Akhilesh Kumar",
    "section": "Question 2",
    "text": "Question 2"
  },
  {
    "objectID": "posts/HW1_AkhileshKumarMeghwal.html#reading-the-table",
    "href": "posts/HW1_AkhileshKumarMeghwal.html#reading-the-table",
    "title": "Homework 1 - Akhilesh Kumar",
    "section": "Reading the table",
    "text": "Reading the table\n\n\nCode\nPrior_convictions <- c(0:4)\nInmate_count <- c(128, 434, 160, 64, 24)\nPc <- tibble(Prior_convictions, Inmate_count)\nPc\n\n\n\n\n  \n\n\n\n\n\nCode\nPc <- mutate(Pc, Probability = Inmate_count/sum(Inmate_count))\nPc"
  },
  {
    "objectID": "posts/HW1_AkhileshKumarMeghwal.html#a-what-is-the-probability-that-a-randomly-selected-inmate-has-exactly-2-prior-convictions",
    "href": "posts/HW1_AkhileshKumarMeghwal.html#a-what-is-the-probability-that-a-randomly-selected-inmate-has-exactly-2-prior-convictions",
    "title": "Homework 1 - Akhilesh Kumar",
    "section": "2a: What is the probability that a randomly selected inmate has exactly 2 prior convictions?",
    "text": "2a: What is the probability that a randomly selected inmate has exactly 2 prior convictions?\n\n\nCode\nPc %>%\n  filter(Prior_convitions == 2) %>%\n  select(Probability)\n\n\nError in `filter()`:\n! Problem while computing `..1 = Prior_convitions == 2`.\nCaused by error in `mask$eval_all_filter()`:\n! object 'Prior_convitions' not found\n\n\nProbability that a randomly selected inmate has exactly 2 prior convictions is 0.1975309."
  },
  {
    "objectID": "posts/HW1_AkhileshKumarMeghwal.html#b-what-is-the-probability-that-a-randomly-selected-inmate-has-fewer-than-2-prior-convictions",
    "href": "posts/HW1_AkhileshKumarMeghwal.html#b-what-is-the-probability-that-a-randomly-selected-inmate-has-fewer-than-2-prior-convictions",
    "title": "Homework 1 - Akhilesh Kumar",
    "section": "2b: What is the probability that a randomly selected inmate has fewer than 2 prior convictions?",
    "text": "2b: What is the probability that a randomly selected inmate has fewer than 2 prior convictions?\n\n\nCode\ntemp <- Pc %>%\n  filter(Prior_convitions < 2)\n\n\nError in `filter()`:\n! Problem while computing `..1 = Prior_convitions < 2`.\nCaused by error in `mask$eval_all_filter()`:\n! object 'Prior_convitions' not found\n\n\nCode\nsum(temp$Probability)\n\n\nError in eval(expr, envir, enclos): object 'temp' not found\n\n\nProbability that a randomly selected inmate has fewer than 2 convictions is 0.6938272"
  },
  {
    "objectID": "posts/HW1_AkhileshKumarMeghwal.html#c-what-is-the-probability-that-a-randomly-selected-inmate-has-2-or-fewer-prior-convictions",
    "href": "posts/HW1_AkhileshKumarMeghwal.html#c-what-is-the-probability-that-a-randomly-selected-inmate-has-2-or-fewer-prior-convictions",
    "title": "Homework 1 - Akhilesh Kumar",
    "section": "2c: What is the probability that a randomly selected inmate has 2 or fewer prior convictions?",
    "text": "2c: What is the probability that a randomly selected inmate has 2 or fewer prior convictions?\n\n\nCode\ntemp <- Pc %>%\n  filter(Prior_convitions <= 2)\n\n\nError in `filter()`:\n! Problem while computing `..1 = Prior_convitions <= 2`.\nCaused by error in `mask$eval_all_filter()`:\n! object 'Prior_convitions' not found\n\n\nCode\nsum(temp$Probability)\n\n\nError in eval(expr, envir, enclos): object 'temp' not found\n\n\nProbability that a randomly selected inmate has 2 or fewer prior convictions: 0.891358"
  },
  {
    "objectID": "posts/HW1_AkhileshKumarMeghwal.html#d-what-is-the-probability-that-a-randomly-selected-inmate-has-more-than-2-prior-convictions",
    "href": "posts/HW1_AkhileshKumarMeghwal.html#d-what-is-the-probability-that-a-randomly-selected-inmate-has-more-than-2-prior-convictions",
    "title": "Homework 1 - Akhilesh Kumar",
    "section": "2d: What is the probability that a randomly selected inmate has more than 2 prior convictions?",
    "text": "2d: What is the probability that a randomly selected inmate has more than 2 prior convictions?\n\n\nCode\ntemp <- Pc %>%\n  filter(Prior_convitions > 2)\n\n\nError in `filter()`:\n! Problem while computing `..1 = Prior_convitions > 2`.\nCaused by error in `mask$eval_all_filter()`:\n! object 'Prior_convitions' not found\n\n\nCode\nsum(temp$Probability)\n\n\nError in eval(expr, envir, enclos): object 'temp' not found\n\n\nProbability that a randomly selected inmate has more than 2 prior convictions is 0.108642"
  },
  {
    "objectID": "posts/HW1_AkhileshKumarMeghwal.html#e-what-is-the-expected-value-for-the-number-of-prior-convictions",
    "href": "posts/HW1_AkhileshKumarMeghwal.html#e-what-is-the-expected-value-for-the-number-of-prior-convictions",
    "title": "Homework 1 - Akhilesh Kumar",
    "section": "2e: What is the expected value for the number of prior convictions?",
    "text": "2e: What is the expected value for the number of prior convictions?\n\n\nCode\nPc <- mutate(Pc, Wm = Prior_convitions*Probability)\n\n\nError in `mutate()`:\n! Problem while computing `Wm = Prior_convitions * Probability`.\nCaused by error in `mask$eval_all_mutate()`:\n! object 'Prior_convitions' not found\n\n\nCode\ne <- sum(Pc$Wm)\ne\n\n\n[1] 0\n\n\nExpected value for the number of prior convictions: 1.28642"
  },
  {
    "objectID": "posts/HW1_AkhileshKumarMeghwal.html#f-calculate-the-variance-and-the-standard-deviation-for-the-prior-convictions.",
    "href": "posts/HW1_AkhileshKumarMeghwal.html#f-calculate-the-variance-and-the-standard-deviation-for-the-prior-convictions.",
    "title": "Homework 1 - Akhilesh Kumar",
    "section": "2f: Calculate the variance and the standard deviation for the Prior Convictions.",
    "text": "2f: Calculate the variance and the standard deviation for the Prior Convictions.\nVariance for the Prior Convictions:\n\n\nCode\nv <-sum(((Pc$Prior_convictions-e)^2)*Pc$Probability)\nv\n\n\n[1] 2.511111\n\n\nStandard Deviation for the Prior Convictions:\n\n\nCode\nsqrt(v)\n\n\n[1] 1.584649\n\n\nVariance and Standard Deviation for the Prior Convictions are 0.8562353 and 0.9253298 respectively."
  },
  {
    "objectID": "posts/AdithyaParupudi_hw1.html",
    "href": "posts/AdithyaParupudi_hw1.html",
    "title": "Homework1 - EDA of LungCap Data",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.1     ✔ purrr   0.3.4\n✔ tibble  3.1.8     ✔ dplyr   1.0.9\n✔ tidyr   1.2.1     ✔ stringr 1.4.1\n✔ readr   2.1.3     ✔ forcats 0.5.2\n\n\nWarning: package 'ggplot2' was built under R version 4.2.2\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\nCode\nlibrary(hrbrthemes)\n\n\nNOTE: Either Arial Narrow or Roboto Condensed fonts are required to use these themes.\n      Please use hrbrthemes::import_roboto_condensed() to install Roboto Condensed and\n      if Arial Narrow is not on your system, please see https://bit.ly/arialnarrow\n\n\nCode\nlibrary(viridis)\n\n\nWarning: package 'viridis' was built under R version 4.2.2\n\n\nLoading required package: viridisLite\n\n\nCode\nlibrary(readxl)"
  },
  {
    "objectID": "posts/AdithyaParupudi_hw1.html#question-1",
    "href": "posts/AdithyaParupudi_hw1.html#question-1",
    "title": "Homework1 - EDA of LungCap Data",
    "section": "Question 1",
    "text": "Question 1\n\n1a) The distribution of LungCap looks as follows:\n\n\nCode\nhist(df$LungCap)\n\n\n\n\n\nThe histogram suggests that the distribution is close to a normal distribution. Most of the observations are close to the mean. Very few observations are close to the margins (0 and 15).\n\n\n1b) Compare the probability distribution of the LungCap with respect to Males and Females? (Hint:make boxplots separated by gender using the boxplot() function)\n\n\nCode\n#boxplot code\n\ndf %>%\n  ggplot( aes(x=Gender, y=LungCap, fill=Gender)) +\n    geom_boxplot() +\n    theme_ipsum() +\n    theme(\n      legend.position=\"none\",\n      plot.title = element_text(size=12)\n    ) +\n    ggtitle(\"Lungcap vs Gender\") +\n    xlab(\"Gender\") +\n  ylab(\"Lung Cap\")\n\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family not\nfound in Windows font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family not\nfound in Windows font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family not\nfound in Windows font database\n\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\n\nWarning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, :\nfont family not found in Windows font database\n\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\n\n\n\n\n\n\nc) Compare the mean lung capacities for smokers and non-smokers. Does it make sense?\n\n\nCode\nmean_smoke <- df %>%\n  group_by(Smoke) %>%\n  summarise(mean = mean(LungCap))\nmean_smoke\n\n\n# A tibble: 2 × 2\n  Smoke  mean\n  <chr> <dbl>\n1 no     7.77\n2 yes    8.65\n\n\nAccording to this mean, it doesn’t make sense that lung capacities of smokers is greater than that of non-smokers.\n\n\nd) Examine the relationship between Smoking and Lung Capacity within age groups: “less than or\nequal to 13”, “14 to 15”, “16 to 17”, and “greater than or equal to 18”.\n\n\nCode\ndf <- mutate(df, AgeGrp = case_when(Age <= 13 ~ \"less than or equal to 13\",\n                                    Age == 14 | Age == 15 ~ \"14 to 15\",\n                                    Age == 16 | Age == 17 ~ \"16 to 17\",\n                                    Age >= 18 ~ \"greater than or equal to 18\"))\n\ndf %>%\n  ggplot(aes(y = LungCap, color = Smoke)) +\n  geom_histogram(bins = 25) +\n  facet_wrap(vars(AgeGrp)) +\n  labs(title = \"Relationship of LungCap and Smoke based on Age\", y = \"Lung Capacity\", x = \"Frequency\")\n\n\n\n\n\n\n\ne) Compare the lung capacities for smokers and non-smokers within each age group. Is your answer different from the one in part c. What could possibly be going on here?\n\n\nCode\ndf %>%\n  ggplot(aes(x = Age, y = LungCap, color = Smoke)) +\n  geom_line() +\n  theme_classic() + \n  facet_wrap(vars(Smoke)) +\n  labs(title = \"Relationship of LungCap and Smoke v/s Age\", y = \"Lung Capacity\", x = \"Age\")"
  },
  {
    "objectID": "posts/AdithyaParupudi_hw1.html#question-2",
    "href": "posts/AdithyaParupudi_hw1.html#question-2",
    "title": "Homework1 - EDA of LungCap Data",
    "section": "Question 2",
    "text": "Question 2\n\nReading the table\n\n\nCode\nPrior_convitions <- c(0:4)\nInmate_count <- c(128, 434, 160, 64, 24)\nPc <- data_frame(Prior_convitions, Inmate_count)\n\n\nWarning: `data_frame()` was deprecated in tibble 1.1.0.\nℹ Please use `tibble()` instead.\n\n\nCode\nPc\n\n\n# A tibble: 5 × 2\n  Prior_convitions Inmate_count\n             <int>        <dbl>\n1                0          128\n2                1          434\n3                2          160\n4                3           64\n5                4           24\n\n\n\n\nCode\nPc <- mutate(Pc, Probability = Inmate_count/sum(Inmate_count))\nPc\n\n\n# A tibble: 5 × 3\n  Prior_convitions Inmate_count Probability\n             <int>        <dbl>       <dbl>\n1                0          128      0.158 \n2                1          434      0.536 \n3                2          160      0.198 \n4                3           64      0.0790\n5                4           24      0.0296\n\n\n\n\n2a - Probability that a randomly selected inmate has exactly 2 prior convictions:\n\n\nCode\nPc %>%\n  filter(Prior_convitions == 2) %>%\n  select(Probability)\n\n\n# A tibble: 1 × 1\n  Probability\n        <dbl>\n1       0.198\n\n\n\n\n2b - Probability that a randomly selected inmate has fewer than 2 convictions:\n\n\nCode\ntemp <- Pc %>%\n  filter(Prior_convitions < 2)\nsum(temp$Probability)\n\n\n[1] 0.6938272\n\n\n\n\n2c - Probability that a randomly selected inmate has 2 or fewer prior convictions:\n\n\nCode\ntemp <- Pc %>%\n  filter(Prior_convitions <= 2)\nsum(temp$Probability)\n\n\n[1] 0.891358\n\n\n\n\n2d - Probability that a randomly selected inmate has more than 2 prior convictions:\n\n\nCode\ntemp <- Pc %>%\n  filter(Prior_convitions > 2)\nsum(temp$Probability)\n\n\n[1] 0.108642\n\n\n\n\n2e - Expected value for the number of prior convictions:\n\n\nCode\nPc <- mutate(Pc, Wm = Prior_convitions*Probability)\ne <- sum(Pc$Wm)\ne\n\n\n[1] 1.28642\n\n\n\n\n2f - Variance for the Prior Convictions:\n\n\nCode\nv <-sum(((Pc$Prior_convitions-e)^2)*Pc$Probability)\nv\n\n\n[1] 0.8562353\n\n\nstandard deviation for the Prior Convictions:\n\n\nCode\nsqrt(v)\n\n\n[1] 0.9253298"
  },
  {
    "objectID": "posts/Final_Project_Check1_GHTan.html",
    "href": "posts/Final_Project_Check1_GHTan.html",
    "title": "Final Project Check 1",
    "section": "",
    "text": "My final project will be a further investigation on digital devices in schools that I have submitted as the final project for DACSS 601. I still explore the data from the survey “Programme for International Student Assessment” in 2018. In this assignment, I will propose my hypothesis, and present the descriptive statistics with minor changes base on my last project.\n\n\nCode\nlibrary(tidyverse)\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0      ✔ purrr   0.3.5 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.4.1 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\nCode\nlibrary(ggplot2)\nlibrary(dbplyr)\n\n\n\nAttaching package: 'dbplyr'\n\nThe following objects are masked from 'package:dplyr':\n\n    ident, sql\n\n\nCode\npisa <- read_csv('_data/CY07_MSU_SCH_QQQ.csv')\n\n\nNew names:\nRows: 21903 Columns: 198\n── Column specification\n──────────────────────────────────────────────────────── Delimiter: \",\" chr\n(8): CNT, CYC, NatCen, STRATUM, SUBNATIO, SC053D11TA, PRIVATESCH, VER_DAT dbl\n(189): ...1, CNTRYID, CNTSCHID, Region, OECD, ADMINMODE, LANGTEST, SC001... lgl\n(1): BOOKID\nℹ Use `spec()` to retrieve the full column specification for this data. ℹ\nSpecify the column types or set `show_col_types = FALSE` to quiet this message.\n• `` -> `...1`\n\n\n\nResearch Questions\nMy final project will probe into what factors contribute to the accessibility to and human resources’ support for digital devices in schools. Additionally, I will explore if there is a correlations between career guidance and digital devices? I will conduct this research based on the data “Programme for International Student Assessment” (PISA) collected by the The Organization for Economic Co-operation and Development (OECD) in 2018.\n\n\nHpyotheis\nI propose that the size of urban population primarily contributes to the conditions of digital device. “OECD or Non-OECD” and “public or private schools” may be two cofounders, which is suppose to be incorporated into the regression analysis. Also, I hypothesize that the higher score a school report regarding career guidance, the higher score a school reports in terms of digital divices.\n\n\nCode\n# create a data frame\n#view(pisa)\n# select related variable\npisa_selected <- select(pisa,starts_with(c(\"SC001\", \"SC013\", \"SC016\", \"SC161\",\"SC155\")))\npisa2018_joint <-cbind(pisa[, 1:12], pisa_selected)\n# pisa_SC155\npisa2018_joint$Accessibility=rowMeans(pisa2018_joint[,c(\"SC155Q01HA\",\"SC155Q02HA\",                                                  \"SC155Q03HA\",\"SC155Q04HA\")])\npisa2018_joint$Human_Resource_Support=rowMeans(pisa2018_joint[\n  ,c(\"SC155Q05HA\",\"SC155Q06HA\", \"SC155Q07HA\",\"SC155Q08HA\",\"SC155Q09HA\", \"SC155Q10HA\", \"SC155Q11HA\")])\npisa2018_joint$Career_Guidance=rowSums(pisa2018_joint[, c(\"SC161Q02SA\",\"SC161Q03SA\",\"SC161Q04SA\",\"SC161Q04SA\")])\npisa_SC155 <- pisa2018_joint %>%\n  select(CNT, STRATUM, OECD, Career_Guidance,Accessibility, Human_Resource_Support, SC001Q01TA, SC013Q01TA) %>%\n  mutate(Urban=SC001Q01TA, Public_or_Private=SC013Q01TA) %>%\n  select(-c(SC001Q01TA, SC013Q01TA)) %>%\n  select(c(CNT,STRATUM,OECD,Urban, Public_or_Private,Career_Guidance,Accessibility,Human_Resource_Support))\npisa_SC155\n\n\n\n\nDescriptive Statistics\nThis original OECD PISA 2018 School Questionnaire Dataset is one part of PISA 2018 dataset with a focus on schools. It covers 80 countries and regions all over the world. The dataset documents 21,903 schools’ responses regarding 187 questions.After cleaning the data, the dataset includes 8 variables: CNT identifies countries. STRATUM identifies schools. OECD indicates if a school locates in a OECD country or not. Urban describes different conditions of urban communities where a school locates. Public_or_Private presents if a school is public or private. Career_Guidance demonstrates the score a school reports in terms of career guidance. Accessibility demonstrates the score a school reports in terms of accessibility to digital devices. Human_Resource_Support suggests the score a school reports in terms of human ressource support for digital devices.\nAfter using the summary function and visualization, I have already show the descriptive statistics. A large number of NA stands out. I will figure out how to deal with them properly.\n\n\nCode\nsummary(pisa_SC155)\n\n\n     CNT              STRATUM               OECD            Urban      \n Length:21903       Length:21903       Min.   :0.0000   Min.   :1.000  \n Class :character   Class :character   1st Qu.:0.0000   1st Qu.:2.000  \n Mode  :character   Mode  :character   Median :1.0000   Median :3.000  \n                                       Mean   :0.5171   Mean   :3.007  \n                                       3rd Qu.:1.0000   3rd Qu.:4.000  \n                                       Max.   :1.0000   Max.   :5.000  \n                                                        NA's   :1363   \n Public_or_Private Career_Guidance Accessibility   Human_Resource_Support\n Min.   :1.00      Min.   :0.000   Min.   :1.000   Min.   :1.000         \n 1st Qu.:1.00      1st Qu.:1.000   1st Qu.:2.000   1st Qu.:2.286         \n Median :1.00      Median :1.000   Median :2.750   Median :2.714         \n Mean   :1.19      Mean   :1.518   Mean   :2.674   Mean   :2.658         \n 3rd Qu.:1.00      3rd Qu.:2.000   3rd Qu.:3.250   3rd Qu.:3.000         \n Max.   :2.00      Max.   :4.000   Max.   :4.000   Max.   :4.000         \n NA's   :2092      NA's   :1499    NA's   :1185    NA's   :1236          \n\n\nCode\npisa_SC155_boxplot<-pisa_SC155 %>%\n  select(STRATUM, Career_Guidance, Accessibility, Human_Resource_Support) %>% \n  pivot_longer(cols=c(Career_Guidance, Accessibility, Human_Resource_Support), \n               names_to = \"Group\", values_to = \"Evaluation\")\n\nggplot(pisa_SC155_boxplot,aes(Evaluation, fill=Group))+\n  stat_boxplot(geom = \"errorbar\", # Error bars\n               width = 0.2)+\n  geom_boxplot()+\n  facet_wrap(~Group)+\n  labs(title=\"Pisa2018 Evaluation\")+\n  coord_flip()\n\n\nWarning: Removed 3920 rows containing non-finite values (`stat_boxplot()`).\nRemoved 3920 rows containing non-finite values (`stat_boxplot()`)."
  },
  {
    "objectID": "posts/HW1_solution_Pang.html",
    "href": "posts/HW1_solution_Pang.html",
    "title": "Homework 1 Solution",
    "section": "",
    "text": "First, let’s read in the data from the Excel file:\n\n\nCode\nlibrary(readxl)\nlibrary(dplyr, warn.conflicts = F)\nlibrary(magrittr)\ndf <- read_excel(\"_data/LungCapData.xls\")\n\n\nThe distribution of LungCap looks as follows:\n\n\nCode\nhist(df$LungCap, xlab = 'Lung Capacity', main = '', freq = F)\n\n\n\n\n\nThe histogram suggests that the distribution is close to a normal distribution. Most of the observations are close to the mean. Very few observations are close to the margins (0 and 15).\n\n\n\n\n\nCode\nboxplot(LungCap ~ Gender, data = df)\n\n\n\n\n\nThe shape of the distribution is similar for males and females. The median, first quartile, third quartile lung capacity values all seem to be somewhat higher for males.\n\n\n\n\n\nCode\ndf %>%\n  group_by(Smoke) %>%\n  summarize(LungCap = mean(LungCap))\n\n\n# A tibble: 2 × 2\n  Smoke LungCap\n  <chr>   <dbl>\n1 no       7.77\n2 yes      8.65\n\n\nThe lung capacity for smokers seems to be higher than non-smokers. It goes against the common idea that smoking would hurt lung capacity.\n\n\n\n\nLess than or equal to 13\n\n\n\nCode\ndf %>%\n  filter(Age <= 13) %>%\n  group_by(Smoke) %>%\n  summarize(LungCap = mean(LungCap))\n\n\n# A tibble: 2 × 2\n  Smoke LungCap\n  <chr>   <dbl>\n1 no       6.36\n2 yes      7.20\n\n\n\n14 to 15\n\n\n\nCode\ndf %>%\n  filter(Age == 14 | Age == 15) %>%\n  group_by(Smoke) %>%\n  summarize(LungCap = mean(LungCap))\n\n\n# A tibble: 2 × 2\n  Smoke LungCap\n  <chr>   <dbl>\n1 no       9.14\n2 yes      8.39\n\n\n\n16 to 17\n\n\n\nCode\ndf %>%\n  filter(Age == 16 | Age == 17) %>%\n  group_by(Smoke) %>%\n  summarize(LungCap = mean(LungCap))\n\n\n# A tibble: 2 × 2\n  Smoke LungCap\n  <chr>   <dbl>\n1 no      10.5 \n2 yes      9.38\n\n\n\nGreater than or equal to 18\n\n\n\nCode\ndf %>%\n  filter(Age >= 18) %>%\n  group_by(Smoke) %>%\n  summarize(LungCap = mean(LungCap))\n\n\n# A tibble: 2 × 2\n  Smoke LungCap\n  <chr>   <dbl>\n1 no       11.1\n2 yes      10.5\n\n\n\n\n\nFor three out of the four groups, lung capacity if smaller for smokers. This makes another explanation plausible. Smoking is inversely related to lung capacity, but older people both smoke more and have more lung capacity. Thus, considering the relationship between smoking and lung capacity without looking at age makes the relationship look the opposite of what it is."
  },
  {
    "objectID": "posts/HW1_solution_Pang.html#a-1",
    "href": "posts/HW1_solution_Pang.html#a-1",
    "title": "Homework 1 Solution",
    "section": "a",
    "text": "a\n\n\nCode\ntb %>%\n  filter(X == 2) %>%\n  pull(Frequency) %>%\n  divide_by(n)\n\n\n[1] 0.1975309"
  },
  {
    "objectID": "posts/HW1_solution_Pang.html#b-1",
    "href": "posts/HW1_solution_Pang.html#b-1",
    "title": "Homework 1 Solution",
    "section": "b",
    "text": "b\n\n\nCode\ntb %>%\n  filter(X < 2) %>%\n  pull(Frequency) %>%\n  sum() %>%\n  divide_by(n)\n\n\n[1] 0.6938272"
  },
  {
    "objectID": "posts/HW1_solution_Pang.html#c-1",
    "href": "posts/HW1_solution_Pang.html#c-1",
    "title": "Homework 1 Solution",
    "section": "c",
    "text": "c\n\n\nCode\ntb %>%\n  filter(X <= 2) %>%\n  pull(Frequency) %>%\n  sum() %>%\n  divide_by(n)\n\n\n[1] 0.891358"
  },
  {
    "objectID": "posts/HW1_solution_Pang.html#d-1",
    "href": "posts/HW1_solution_Pang.html#d-1",
    "title": "Homework 1 Solution",
    "section": "d",
    "text": "d\n\n\nCode\ntb %>%\n  filter(X > 2) %>%\n  pull(Frequency) %>%\n  sum() %>%\n  divide_by(n)\n\n\n[1] 0.108642"
  },
  {
    "objectID": "posts/HW1_solution_Pang.html#e-1",
    "href": "posts/HW1_solution_Pang.html#e-1",
    "title": "Homework 1 Solution",
    "section": "e",
    "text": "e\nExpected number of prior convictions is just a weighted average of the number of prior convictions.\n\nMethod 1: Multiply every value with their frequency, then divide by total frequency i.e. (0 * 128 + 1 * 434 + 2 * 160 ……) / 810.\n\n\n\nCode\nsum(tb$X * tb$Frequency) / n\n\n\n[1] 1.28642\n\n\n\nMethod 2: Multiply every value with their probility, sum them up.\n\n\n\nCode\ntb %>%\n  mutate(probability = Frequency / n) -> tb\n\nprint(tb)\n\n\n# A tibble: 5 × 3\n      X Frequency probability\n  <dbl>     <dbl>       <dbl>\n1     0       128      0.158 \n2     1       434      0.536 \n3     2       160      0.198 \n4     3        64      0.0790\n5     4        24      0.0296\n\n\n\n\nCode\nsum(tb$X * tb$probability)\n\n\n[1] 1.28642\n\n\n\nMethod 3: Recreate the whole sample (a vector that has 128 zeroes, 434 ones, 160 twos, ….) with a total length/size of 810. Take the mean.\n\n\n\nCode\nsample <- c(rep(0, 128), rep(1, 434), rep(2, 160), rep(3, 64), rep(4, 24))\nmean(sample)\n\n\n[1] 1.28642"
  },
  {
    "objectID": "posts/HW1_solution_Pang.html#f",
    "href": "posts/HW1_solution_Pang.html#f",
    "title": "Homework 1 Solution",
    "section": "f",
    "text": "f\n\nMethod 1: Let’s start from the end: we have the sample, just call var() and sd()\n\n\n\nCode\ncat('Variance:', var(sample))\n\n\nVariance: 0.8572937\n\n\nCode\ncat('\\nStandard Deviation:', sd(sample))\n\n\n\nStandard Deviation: 0.9259016\n\n\nMethod 2: Manually apply the formula using weights.\nStandard deviation is square root of variance. So let’s calculate variance first. For that we need the mean. Let’s pull the expected value from the previous section:\n\n\nCode\nm <- sum(tb$X * tb$Frequency) / n\n\n\nFor every observation, we’ll need the squared difference from mean (squared deviation from mean).\n\n\nCode\ntb %>%\n  mutate(sq_deviation = (X - m)^2) -> tb \nprint(tb)\n\n\n# A tibble: 5 × 4\n      X Frequency probability sq_deviation\n  <dbl>     <dbl>       <dbl>        <dbl>\n1     0       128      0.158        1.65  \n2     1       434      0.536        0.0820\n3     2       160      0.198        0.509 \n4     3        64      0.0790       2.94  \n5     4        24      0.0296       7.36  \n\n\nThen, we can now multiply them with probability.\n\n\nCode\nsum(tb$sq_deviation * tb$probability)\n\n\n[1] 0.8562353\n\n\nThis gives us the ‘population’ variance. If we wanted the ‘sample’ variance, what the var() function does, we could manually apply the Bessel’s correction:\n\n\nCode\nvariance <- sum(tb$sq_deviation * tb$probability) * (n / (n-1))\nprint(variance)\n\n\n[1] 0.8572937\n\n\nStandard deviation is then just the square root:\n\n\nCode\nsqrt(variance)\n\n\n[1] 0.9259016\n\n\nThis replicated what we found directly using the sample."
  },
  {
    "objectID": "posts/FinalPart1_MiguelCuriel.html",
    "href": "posts/FinalPart1_MiguelCuriel.html",
    "title": "The Pandemic’s Toll on Mental Health: A Look at the Tech Sector (DRAFT)",
    "section": "",
    "text": "Research Question\nThe technology industry - aka tech - has been one of the highest employers in the twenty-first century. Not only that, but it has been praised for having some of the happiest workers1 2.\nBut, what has made this industry so appealing? A case study on Google published in the International Journal of Corporate Social Responsibility in 20173 points to several elements that make high-tech unique, such as having a distinct culture proposition, aligning individual behaviors to company-wide goals, having managers be coaches rather than bosses, and being able to interact with people from other cultures.\nEvidently, Google is one-in-a-million high-tech company, but there are certainly commonalities shared with smaller new tech (startup) companies. Culture Amp, a company focused on surveying employees in startups, elaborated an analysis based on their results from 2015-2020 surveys4 and mention that elements such as an open and honest two-way communication, workplace flexibility, and fair division of workload, are what make new tech companies valued.\nHowever, the previous data omits the downsides of such cultures. Besides the multiple blog posts and news articles one can find talking about burnout5, the darker side of tech also includes (but is not limited to) ageism6, gender inequality7 8, and even migration issues9 10.\nA survey lead by Blind in 202111 found that, out of 2400 workers in tech, 64% said their mental health is worse after the pandemic. Further, layoffs by the thousands, plummeting stock prices, and generalized revaluation of an entire industry’s value, are just few words that can describe what has happened to tech in 2022 and 2023. An industry that once employed over 5 million people in the US alone12 and had nearly 700 billion dollars in funding worldwide13 has now laid off over 300 thousand people14 and nearly halved in funding.\nIt is reasonable to hypothesize that the aforementioned events will take a toll on the workers of this industry, but what was the mental health state before this unfortunate series of events? More specifically, the proposed research question is:\n\nWhat is the trend in mental health issues among workers in the technology industry from 2017 to 2021, as measured by survey data, and what factors may contribute to these changes?\n\n\n\n\nHypothesis\nBased on the present research question and on previous studies, these are the hypotheses that come to mind:\n\nH1: There has been an increase in the prevalence of mental health issues among workers in the technology industry from 2017 to 2021.\nH2: There has been no significant change in the prevalence of mental health issues among workers in the technology industry from 2017 to 2021.\nH3: The increase in mental health issues among workers in the technology industry from 2017 to 2021 is related to factors such as age, gender, and company policies with regards to mental health care.\nH4: The increase in mental health issues among workers in the technology industry from 2017 to 2021 is not related to any specific factors but rather a general trend across all demographics.\n\n\n\n\nDescriptive Statistics\nTo analyze the state of mental health and the contributing factors, I will rely on data provided by the Open Sourcing Mental Health (OSMH), specifically using their Mental Health in Tech Survey.\nOSMH15 is a non-profit dedicated to raising awareness, educating, and providing resources to support mental wellness in the tech and open source communities. It began operations in 2013 and since 2014 it has conducted and published an annual or bi-annual survey analyzing several mental health indicators.\nAs of March 20, 2023, the 2022 survey has not yet been published. Therefore, this analysis employs historical data, specifically utilizing surveys conducted from 2017 through 2021. All datasets are publicly available on OSMH’s website or on Kaggle:\n\nhttps://osmhhelp.org/research.html\nhttps://www.kaggle.com/osmihelp/datasets\n\nGiven the size of the data, both files were appended using Microsoft Excel and were then exported to a CSV file. Also, there was not a 100% match between columns in both files, and some re-coding had to be implemented before importing into R. The steps taken to consolidate both files offline are noted in the section below.\n\n\n\n\n\n\nNote\n\n\n\n\n\n\nA “year” column was added to differentiate between both files.\nData pertaining to insurance information (e.g., “Does you company provide a mental health insurance plan?”) was removed because in the 2019 it was optional and was, therefore, almost entirely blank.\nBoth files contained columns pertaining to the mental disorder each respondent may or may not have. However, these columns were inconsistent and could not be interpreted without making assumptions which may lead to an incorrect interpretation of the data. For that reason, these columns were removed.\nThe raw data files followed a title case naming convention (e.g., “Does your employer provide mental health resources?”). All column names were changed to a snake_case format (e.g., “employer_provides_mental_health_resources”).\nThe rest of the columns and data therein contained is left as is.\n\n\n\n\nThe raw consolidated file contains over 70 columns. After reviewing findings from past research and taking the present research question into consideration, the following are the variables of interest:\n\nDEPENDENT VARIABLE\n\nhas_mental_disorder: Do you currently have a mental health disorder?\n\nINDEPENDENT VARIABLES\n\nage: What is your age?\ngender: What is your gender?\nrace: What is your race?\nfamily_history_mental_illness: Do you have a family history of mental illness?\nhad_mental_disorder: Have you had a mental health disorder in the past?\nsought_treatment: Have you ever sought treatment for a mental health disorder from a mental health professional?\nwillingness_to_share_with_friends: How willing would you be to share with friends and family that you have a mental illness?\ntech_industry_supports_mh: Overall, how well do you think the tech industry supports employees with mental health issues?\nnumber_of_employees: How many employees does your company or organization have?\ncompany_provides_mhcare: Does your employer provide mental health benefits as part of healthcare coverage?\nanonymity_protected_if_use_resources: Is your anonymity protected if you choose to take advantage of mental health or substance abuse treatment resources provided by your employer?\neasy_to_leave_for_mhcare: If a mental health issue prompted you to request a medical leave from work, how easy or difficult would it be to ask for that leave?\ncomfortable_talking_to_supervisor: Would you feel comfortable discussing a mental health issue with your direct supervisor(s)?\ncomfortable_talking_to_coworkers_about_mh: Would you feel comfortable discussing a mental health issue with your coworkers?\nemployer_mh_importance: Overall, how much importance does your employer place on mental health?\ncurrent_or_previous_employer_supportive: Have you observed or experienced a supportive or well handled response to a mental health issue in your current or previous workplace?\nyear: In what year was the survey conducted?\n\n\nAfter manually merging the files in R, some additional cleansing is still entailed before the dataset is fully operational. These changes are easier to implement in R, can be found in the code chunk below and include steps such as treating inconsistent categorical columns. Once these changes are made, a summary of the resulting dataframe is created:\n\n\nCode\n# load neccesary packages\nlibrary(tidyverse) # used for elementary data wrangling and visualization\nlibrary(naniar) # used for missing values visualization\nlibrary(summarytools) # used for table summarizing descriptive statistics\n\n# temporarily set working directory to read in data\nsetwd(\"/Users/macuriels/Documents/Umass/umass_dacss_quantitativeanalysis/posts/_data\")\n\n# read in consolidated file with 2019 and 2021 data\ndf <- read_csv(\"mhit.csv\")\n\n# treating inconsistent binary code in column(s) of interest\ndf$sought_treatment <- ifelse(df$sought_treatment == \"TRUE\", 1, 0)\n\n# treating inconsistent gender naming conventions\ndf$gender <- ifelse(grepl(\"female\", df$gender, ignore.case = TRUE), \"Female\" \n                    ,ifelse(grepl(\"male\", df$gender, ignore.case = TRUE), \"Male\"\n                           ,\"Other\"))\n\n# create new dataframe with columns of interest\ndf <- df |>\n  select(\n    year\n    ,has_mental_disorder\n    ,age\n    ,gender\n    ,race\n    ,family_history_mental_illness\n    ,had_mental_disorder\n    ,sought_treatment\n    ,willingness_to_share_with_friends\n    ,tech_industry_supports_mh\n    ,number_of_employees\n    ,company_provides_mhcare\n    ,anonymity_protected_if_use_resources\n    ,easy_to_leave_for_mhcare\n    ,comfortable_talking_to_supervisor\n    ,comfortable_talking_to_coworkers_about_mh\n    ,employer_mh_importance\n    ,current_or_previous_employer_supportive\n  )\n\n# remove rows with missing values\ndf <- df[complete.cases(df),]\n\n# remove columns with missing values\ndf <- df[,colSums(is.na(df)) == 0]\n\n# summarize resulting dataframe\ndfSummary(df)\n\n\nData Frame Summary  \ndf  \nDimensions: 988 x 18  \nDuplicates: 0  \n\n-----------------------------------------------------------------------------------------------------------------------------------------------\nNo   Variable                                    Stats / Values                 Freqs (% of Valid)   Graph                 Valid      Missing  \n---- ------------------------------------------- ------------------------------ -------------------- --------------------- ---------- ---------\n1    year                                        Mean (sd) : 2018 (1.1)         2017 : 432 (43.7%)   IIIIIIII              988        0        \n     [numeric]                                   min < med < max:               2018 : 272 (27.5%)   IIIII                 (100.0%)   (0.0%)   \n                                                 2017 < 2018 < 2021             2019 : 182 (18.4%)   III                                       \n                                                 IQR (CV) : 2 (0)               2020 :  56 ( 5.7%)   I                                         \n                                                                                2021 :  46 ( 4.7%)                                             \n\n2    has_mental_disorder                         1. Don't Know                   52 ( 5.3%)          I                     988        0        \n     [character]                                 2. No                          243 (24.6%)          IIII                  (100.0%)   (0.0%)   \n                                                 3. Possibly                    195 (19.7%)          III                                       \n                                                 4. Yes                         498 (50.4%)          IIIIIIIIII                                \n\n3    age                                         1. 30                           67 ( 6.8%)          I                     988        0        \n     [character]                                 2. 37                           54 ( 5.5%)          I                     (100.0%)   (0.0%)   \n                                                 3. 28                           53 ( 5.4%)          I                                         \n                                                 4. 27                           47 ( 4.8%)                                                    \n                                                 5. 32                           45 ( 4.6%)                                                    \n                                                 6. 35                           45 ( 4.6%)                                                    \n                                                 7. 34                           44 ( 4.5%)                                                    \n                                                 8. 36                           42 ( 4.3%)                                                    \n                                                 9. 31                           38 ( 3.8%)                                                    \n                                                 10. 33                          38 ( 3.8%)                                                    \n                                                 [ 38 others ]                  515 (52.1%)          IIIIIIIIII                                \n\n4    gender                                      1. Female                      285 (28.8%)          IIIII                 988        0        \n     [character]                                 2. Male                        525 (53.1%)          IIIIIIIIII            (100.0%)   (0.0%)   \n                                                 3. Other                       178 (18.0%)          III                                       \n\n5    race                                        1. American Indian or Alaska     1 ( 0.1%)                                988        0        \n     [character]                                 2. Asian                        48 ( 4.9%)                                (100.0%)   (0.0%)   \n                                                 3. Black or African American    15 ( 1.5%)                                                    \n                                                 4. Caucasian                     1 ( 0.1%)                                                    \n                                                 5. Hispanic                      1 ( 0.1%)                                                    \n                                                 6. I prefer not to answer       28 ( 2.8%)                                                    \n                                                 7. More than one of the abov    34 ( 3.4%)                                                    \n                                                 8. White                       859 (86.9%)          IIIIIIIIIIIIIIIII                         \n                                                 9. White Hispanic                1 ( 0.1%)                                                    \n\n6    family_history_mental_illness               1. I don't know                242 (24.5%)          IIII                  988        0        \n     [character]                                 2. No                          219 (22.2%)          IIII                  (100.0%)   (0.0%)   \n                                                 3. Yes                         527 (53.3%)          IIIIIIIIII                                \n\n7    had_mental_disorder                         1. Don't Know                   64 ( 6.5%)          I                     988        0        \n     [character]                                 2. No                          248 (25.1%)          IIIII                 (100.0%)   (0.0%)   \n                                                 3. Possibly                    167 (16.9%)          III                                       \n                                                 4. Yes                         509 (51.5%)          IIIIIIIIII                                \n\n8    sought_treatment                            Min  : 0                       0 : 857 (86.7%)      IIIIIIIIIIIIIIIII     988        0        \n     [numeric]                                   Mean : 0.1                     1 : 131 (13.3%)      II                    (100.0%)   (0.0%)   \n                                                 Max  : 1                                                                                      \n\n9    willingness_to_share_with_friends           1. 0                            30 ( 3.0%)                                988        0        \n     [character]                                 2. 1                            23 ( 2.3%)                                (100.0%)   (0.0%)   \n                                                 3. 10                          176 (17.8%)          III                                       \n                                                 4. 2                            48 ( 4.9%)                                                    \n                                                 5. 3                            47 ( 4.8%)                                                    \n                                                 6. 4                            42 ( 4.3%)                                                    \n                                                 7. 5                           117 (11.8%)          II                                        \n                                                 8. 6                            88 ( 8.9%)          I                                         \n                                                 9. 7                           146 (14.8%)          II                                        \n                                                 10. 8                          158 (16.0%)          III                                       \n                                                 11. 9                          113 (11.4%)          II                                        \n\n10   tech_industry_supports_mh                   Mean (sd) : 2.6 (0.9)          1 : 121 (12.2%)      II                    988        0        \n     [numeric]                                   min < med < max:               2 : 301 (30.5%)      IIIIII                (100.0%)   (0.0%)   \n                                                 1 < 3 < 5                      3 : 406 (41.1%)      IIIIIIII                                  \n                                                 IQR (CV) : 1 (0.4)             4 : 150 (15.2%)      III                                       \n                                                                                5 :  10 ( 1.0%)                                                \n\n11   number_of_employees                         1. 1-5                          22 ( 2.2%)                                988        0        \n     [character]                                 2. 100-500                     269 (27.2%)          IIIII                 (100.0%)   (0.0%)   \n                                                 3. 26-100                      179 (18.1%)          III                                       \n                                                 4. 500-1000                     86 ( 8.7%)          I                                         \n                                                 5. 6-25                        118 (11.9%)          II                                        \n                                                 6. More than 1000              314 (31.8%)          IIIIII                                    \n\n12   company_provides_mhcare                     1. I don't know                239 (24.2%)          IIII                  988        0        \n     [character]                                 2. No                           46 ( 4.7%)                                (100.0%)   (0.0%)   \n                                                 3. Not eligible for coverage    29 ( 2.9%)                                                    \n                                                 4. Yes                         674 (68.2%)          IIIIIIIIIIIII                             \n\n13   anonymity_protected_if_use_resources        1. I don't know                585 (59.2%)          IIIIIIIIIII           988        0        \n     [character]                                 2. No                           29 ( 2.9%)                                (100.0%)   (0.0%)   \n                                                 3. Yes                         374 (37.9%)          IIIIIII                                   \n\n14   easy_to_leave_for_mhcare                    1. Difficult                    88 ( 8.9%)          I                     988        0        \n     [character]                                 2. I don't know                184 (18.6%)          III                   (100.0%)   (0.0%)   \n                                                 3. Neither easy nor difficul   114 (11.5%)          II                                        \n                                                 4. Somewhat difficult          125 (12.7%)          II                                        \n                                                 5. Somewhat easy               270 (27.3%)          IIIII                                     \n                                                 6. Very easy                   207 (21.0%)          IIII                                      \n\n15   comfortable_talking_to_supervisor           1. Maybe                       345 (34.9%)          IIIIII                988        0        \n     [character]                                 2. No                          256 (25.9%)          IIIII                 (100.0%)   (0.0%)   \n                                                 3. Yes                         387 (39.2%)          IIIIIII                                   \n\n16   comfortable_talking_to_coworkers_about_mh   1. Maybe                       448 (45.3%)          IIIIIIIII             988        0        \n     [character]                                 2. No                          242 (24.5%)          IIII                  (100.0%)   (0.0%)   \n                                                 3. Yes                         298 (30.2%)          IIIIII                                    \n\n17   employer_mh_importance                      Mean (sd) : 5.1 (2.4)          11 distinct values           :             988        0        \n     [numeric]                                   min < med < max:                                            :             (100.0%)   (0.0%)   \n                                                 0 < 5 < 10                                                  :   .                             \n                                                 IQR (CV) : 4 (0.5)                                  : . : . : : : :                           \n                                                                                                     : : : : : : : : . .                       \n\n18   current_or_previous_employer_supportive     1. Maybe/Not sure              246 (24.9%)          IIII                  988        0        \n     [character]                                 2. No                          333 (33.7%)          IIIIII                (100.0%)   (0.0%)   \n                                                 3. Yes, I experienced          214 (21.7%)          IIII                                      \n                                                 4. Yes, I observed             195 (19.7%)          III                                       \n-----------------------------------------------------------------------------------------------------------------------------------------------\n\n\nAt this point, the dataset has no null values and categorical variables have been harmonized, therefore the data should be ready for further analysis and visualizations.\n\n\n\n\n\n\n\nFootnotes\n\n\nFox, M. (2016, November 11). Why Are Tech Workers So Satisfied With Their Jobs? Retrieved March 17, 2023, from https://www.forbes.com/sites/meimeifox/2016/11/11/why-are-tech-workers-so-satisfied-with-their-jobs/?sh=4eac1918a059↩︎\nWronski, L., & Cohen, J. (2019, November 4). This is the industry sector that has some of the happiest workers in America. Retrieved March 17, 2023, from https://www.cnbc.com/2019/11/04/this-is-the-industry-that-has-some-of-the-happiness-workers-in-america.html↩︎\nKim, K. T. (2017). GOOGLE: A reflection of culture, leader, and management. International Journal of Corporate Social Responsibility, 2(10). https://doi.org/10.1186/s40991-017-0021-0↩︎\nMcPherson, J. (n.d.). Tech company cultures are not all the same. Culture Amp. Retrieved March 17, 2023, from https://www.cultureamp.com/blog/tech-company-culture↩︎\nGoncharov, A. (2023, March 13). How I burnt out in FAANG, but my job was not the problem. Blog.Goncharov.ai. Retrieved March 17, 2023, from https://blog.goncharov.ai/how-i-burnt-out-in-faang-but-my-job-was-not-the-problem↩︎\nRosales, A., & Jakob, S. (2021). Perceptions of age in contemporary tech. Sciendo, 42(1), 79-91. https://doi.org/10.2478/nor-2021-0021↩︎\nMickey, E. L. (2021). The Organization of Networking and Gender Inequality in the New Economy: Evidence from the Tech Industry. Work & Occupations, 49(4), 383-420. https://doi.org/10.1177/07308884221102134↩︎\nHardey, M. (2020). The Culture of Women in Tech : An Unsuitable Job for a Woman (1st ed.). Emerald Publishing.↩︎\nBanerjee, P., & Rincón, L. (2019). Trouble in Tech Paradise. Journal of Water Resources Planning & Management, 145(4), 24-29. https://doi.org/10.1177/1536504219854714↩︎\nMatloff, N. (2013). Immigration and the tech industry: As a labour shortage remedy, for innovation, or for cost savings? Migration Letters, 10(2), 210-227. ISSN: 1741-8984 Online ISSN: 1741-8992↩︎\nBlind (2021, January 29). Deteriorating Mental Health In The Workplace. Retrieved March 17, 2023, from https://www.teamblind.com/blog/index.php/2021/01/29/deteriorating-mental-health-in-the-workplace/↩︎\nThe United States Bureau of Labor and Statistics via CompTIA (2023, March 3). Cyberstates 2021: The Definitive Guide to the Tech Industry and Workforce. Retrieved March 17, 2023, from https://www.comptia.org/content/tech-jobs-report↩︎\nCrunchbase News. (2023, January 5). Global VC Funding on a Slide since Q4 2022. Retrieved March 17, 2023, from https://news.crunchbase.com/venture/global-vc-funding-slide-q4-2022↩︎\nLayoffs.fyi. (n.d.). Layoffs.fyi - Tracking all tech startup layoffs since COVID-19. https://layoffs.fyi↩︎\nOpen Sourcing Mental Health (n.d.). About OSMH. Retrieved March 18, 2023, from https://osmhhelp.org/about/about-osmi.html↩︎"
  },
  {
    "objectID": "posts/Jerin_Jacob_HW1.html",
    "href": "posts/Jerin_Jacob_HW1.html",
    "title": "Homework 1",
    "section": "",
    "text": "Code\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(magrittr)\nknitr::opts_chunk$set(echo = TRUE)"
  },
  {
    "objectID": "posts/Jerin_Jacob_HW1.html#loading-the-data",
    "href": "posts/Jerin_Jacob_HW1.html#loading-the-data",
    "title": "Homework 1",
    "section": "Loading the Data",
    "text": "Loading the Data\n\n\nCode\ndf <- read_excel(\"_data/LungCapData.xls\")\ndf\n\n\n# A tibble: 725 × 6\n   LungCap   Age Height Smoke Gender Caesarean\n     <dbl> <dbl>  <dbl> <chr> <chr>  <chr>    \n 1    6.48     6   62.1 no    male   no       \n 2   10.1     18   74.7 yes   female no       \n 3    9.55    16   69.7 no    female yes      \n 4   11.1     14   71   no    male   no       \n 5    4.8      5   56.9 no    male   no       \n 6    6.22    11   58.7 no    female no       \n 7    4.95     8   63.3 no    male   yes      \n 8    7.32    11   70.4 no    male   no       \n 9    8.88    15   70.5 no    male   no       \n10    6.8     11   59.2 no    male   no       \n# … with 715 more rows"
  },
  {
    "objectID": "posts/Jerin_Jacob_HW1.html#a",
    "href": "posts/Jerin_Jacob_HW1.html#a",
    "title": "Homework 1",
    "section": "A",
    "text": "A\n\n\nCode\nsummary(df)\n\n\n    LungCap            Age            Height         Smoke          \n Min.   : 0.507   Min.   : 3.00   Min.   :45.30   Length:725        \n 1st Qu.: 6.150   1st Qu.: 9.00   1st Qu.:59.90   Class :character  \n Median : 8.000   Median :13.00   Median :65.40   Mode  :character  \n Mean   : 7.863   Mean   :12.33   Mean   :64.84                     \n 3rd Qu.: 9.800   3rd Qu.:15.00   3rd Qu.:70.30                     \n Max.   :14.675   Max.   :19.00   Max.   :81.80                     \n    Gender           Caesarean        \n Length:725         Length:725        \n Class :character   Class :character  \n Mode  :character   Mode  :character  \n                                      \n                                      \n                                      \n\n\nCode\nhist(df$LungCap, xlab = \"Lung Capacity\", main = \"\", freq = F)\n\n\n\n\n\nThe histogram shows that the distribution is almost a normal distribution with most of the values close to the mean. ## B\n\n\nCode\nboxplot(LungCap ~ Gender, df)\n\n\n\n\n\nThe minimum, first quartile, median, third quartile and maximum, all of them appear to be slightly higher for males than females."
  },
  {
    "objectID": "posts/Jerin_Jacob_HW1.html#c",
    "href": "posts/Jerin_Jacob_HW1.html#c",
    "title": "Homework 1",
    "section": "C",
    "text": "C\n\n\nCode\ndff<- df |>\n  group_by(Smoke) |>\n  summarise(LungCap = mean(LungCap))\n\n\nLung capacity of non-smokers is higher than that of smokers which is against the expectation!"
  },
  {
    "objectID": "posts/Jerin_Jacob_HW1.html#d",
    "href": "posts/Jerin_Jacob_HW1.html#d",
    "title": "Homework 1",
    "section": "D",
    "text": "D\n\nAge less than or equal to 13\n\n\nCode\ndf1 <- df |>\n  filter(Age <= 13) |>\n  group_by(Smoke)|>\n  summarise(LungCap = mean(LungCap)) |>\n  mutate(Age = \"<=13\")\ndf1\n\n\n# A tibble: 2 × 3\n  Smoke LungCap Age  \n  <chr>   <dbl> <chr>\n1 no       6.36 <=13 \n2 yes      7.20 <=13 \n\n\n\n\nAge 14 & 15\n\n\nCode\ndf2 <- df |>\n  filter(Age >= 14 & Age <= 15) |>\n  group_by(Smoke)|>\n  summarise(LungCap = mean(LungCap))|>\n  mutate(Age = \"14&15\")\nclass(df2)\n\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\n\n\nAge 16 to 17\n\n\nCode\ndf3 <- df |>\n  filter(Age >= 16 & Age <= 17) |>\n  group_by(Smoke)|>\n  summarise(LungCap = mean(LungCap))|>\n  mutate(Age = \"16&17\")\n\n\n\n\nAge greater than or equal to 18\n\n\nCode\ndf4 <- df |>\n  filter(Age >= 18) |>\n  group_by(Smoke)|>\n  summarise(LungCap = mean(LungCap))|>\n  mutate(Age = \">=18\")"
  },
  {
    "objectID": "posts/Jerin_Jacob_HW1.html#e",
    "href": "posts/Jerin_Jacob_HW1.html#e",
    "title": "Homework 1",
    "section": "E",
    "text": "E\n\n\nCode\nnew_df <- rbind(df1,df2, df3,df4)\nnew_df\n\n\n# A tibble: 8 × 3\n  Smoke LungCap Age  \n  <chr>   <dbl> <chr>\n1 no       6.36 <=13 \n2 yes      7.20 <=13 \n3 no       9.14 14&15\n4 yes      8.39 14&15\n5 no      10.5  16&17\n6 yes      9.38 16&17\n7 no      11.1  >=18 \n8 yes     10.5  >=18 \n\n\nCode\nggplot(new_df, aes(fill=Smoke, y=LungCap, x=Age)) +\n  geom_bar(position='dodge', stat='identity')\n\n\nError in ggplot(new_df, aes(fill = Smoke, y = LungCap, x = Age)): could not find function \"ggplot\"\n\n\nCode\nggplot(dff, aes(y=LungCap, x=Smoke, fill = Smoke)) +\n  geom_bar(position='dodge', stat='identity')  \n\n\nError in ggplot(dff, aes(y = LungCap, x = Smoke, fill = Smoke)): could not find function \"ggplot\"\n\n\nOnly age group that showed similar result that of step C is <=13. The analysis could go wrong if the lung capacity of smokers and non smokers are studied without considering the age."
  },
  {
    "objectID": "posts/abigailbalint_hw1.html",
    "href": "posts/abigailbalint_hw1.html",
    "title": "Homework 1",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(readxl)\nknitr::opts_chunk$set(echo = TRUE)"
  },
  {
    "objectID": "posts/abigailbalint_hw1.html#question-1---lung-capacity",
    "href": "posts/abigailbalint_hw1.html#question-1---lung-capacity",
    "title": "Homework 1",
    "section": "Question 1 - Lung Capacity",
    "text": "Question 1 - Lung Capacity\nReading in LungCapData –\n\n\nCode\nlung <- read_excel(\"_data/LungCapData.xls\")\nhead(lung,2)\n\n\n# A tibble: 2 × 6\n  LungCap   Age Height Smoke Gender Caesarean\n    <dbl> <dbl>  <dbl> <chr> <chr>  <chr>    \n1    6.48     6   62.1 no    male   no       \n2   10.1     18   74.7 yes   female no       \n\n\nLooking at some basic descriptive stats –\n\n\nCode\nglimpse(lung)\n\n\nRows: 725\nColumns: 6\n$ LungCap   <dbl> 6.475, 10.125, 9.550, 11.125, 4.800, 6.225, 4.950, 7.325, 8.…\n$ Age       <dbl> 6, 18, 16, 14, 5, 11, 8, 11, 15, 11, 19, 17, 12, 10, 10, 13,…\n$ Height    <dbl> 62.1, 74.7, 69.7, 71.0, 56.9, 58.7, 63.3, 70.4, 70.5, 59.2, …\n$ Smoke     <chr> \"no\", \"yes\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\",…\n$ Gender    <chr> \"male\", \"female\", \"female\", \"male\", \"male\", \"female\", \"male\"…\n$ Caesarean <chr> \"no\", \"no\", \"yes\", \"no\", \"no\", \"no\", \"yes\", \"no\", \"no\", \"no\"…\n\n\nCode\nmean(lung$LungCap, na.rm = T)\n\n\n[1] 7.863148\n\n\nCode\nvar(lung$LungCap, na.rm = T)\n\n\n[1] 7.086288\n\n\nCode\nsd(lung$LungCap, na.rm = T)\n\n\n[1] 2.662008\n\n\nCode\nrange(lung$LungCap, na.rm = T)\n\n\n[1]  0.507 14.675\n\n\n\nWhat does the distribution of LungCap look like?\n\n\n\nCode\nggplot(lung, aes(x = LungCap)) +\n  geom_histogram()\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nThe distribution looks relatively normal. There is a clear concentration of the sample around 7-8 and the outliers are only a very small portion of the sample.\n\nCompare the probability distribution of the LungCap with respect to Males and Females\n\n\n\nCode\nggplot(lung, aes(x=LungCap)) + \n    geom_boxplot(fill=\"slateblue\", alpha=0.2) + \n    xlab(\"Lung Capacity\") +\n  facet_wrap(\"Gender\")\n\n\n\n\n\nThe probability distribution is pretty similar between male and female, but males skew to a higher lung capacity overall and the median line is at around 8 whereas female is closer to 7.5.\n\nCompare the mean lung capacities for smokers and non-smokers. Does it make sense?\n\n\n\nCode\nlung %>%\n  group_by(Smoke) %>%\n  summarise(mean = mean(LungCap), n = n())\n\n\n# A tibble: 2 × 3\n  Smoke  mean     n\n  <chr> <dbl> <int>\n1 no     7.77   648\n2 yes    8.65    77\n\n\nWe would expect the lung capacities for non smokers to be higher but the mean for smokers is actually a little bit higher.\n\nExamine the relationship between Smoking and Lung Capacity within age groups: “less than or equal to 13”, “14 to 15”, “16 to 17”, and “greater than or equal to 18”.\n\nRecoding the age groups –\n\n\nCode\nlunggroup <- lung %>%\n  mutate(`AgeGroup` = dplyr::case_when(\n    `Age` >= 0 & `Age` < 14 ~ \"0-13\",\n    `Age` >= 14 & `Age` < 16 ~ \"14-15\",\n    `Age` >= 16 & `Age` < 18 ~ \"16-17\",\n    `Age` >= 18 ~ \"18+\" ))\nhead(lunggroup)\n\n\n# A tibble: 6 × 7\n  LungCap   Age Height Smoke Gender Caesarean AgeGroup\n    <dbl> <dbl>  <dbl> <chr> <chr>  <chr>     <chr>   \n1    6.48     6   62.1 no    male   no        0-13    \n2   10.1     18   74.7 yes   female no        18+     \n3    9.55    16   69.7 no    female yes       16-17   \n4   11.1     14   71   no    male   no        14-15   \n5    4.8      5   56.9 no    male   no        0-13    \n6    6.22    11   58.7 no    female no        0-13    \n\n\nMean lung capacity by age group –\n\n\nCode\nlunggroup %>%\ngroup_by(Smoke, AgeGroup) %>%\n  summarise(mean = mean(LungCap), n = n())\n\n\n`summarise()` has grouped output by 'Smoke'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 8 × 4\n# Groups:   Smoke [2]\n  Smoke AgeGroup  mean     n\n  <chr> <chr>    <dbl> <int>\n1 no    0-13      6.36   401\n2 no    14-15     9.14   105\n3 no    16-17    10.5     77\n4 no    18+      11.1     65\n5 yes   0-13      7.20    27\n6 yes   14-15     8.39    15\n7 yes   16-17     9.38    20\n8 yes   18+      10.5     15\n\n\nFor both smokers and non-smokers, the lung capacity goes up as the age increases with 18+ having the highest average capacity. In all age ranges besides 0-13 (the broadest range), the mean is higher for non-smokers than smokers.\n\nCompare the lung capacities for smokers and non-smokers within each age group. Is your answer different from the one in part c. What could possibly be going on here?\n\n\n\nCode\nggplot(lunggroup, aes(x=LungCap, fill=Smoke)) + \n    geom_boxplot() + \n    xlab(\"Lung Capacity\") +\n  facet_wrap(\"AgeGroup\")\n\n\n\n\n\nI’m seeing that the results by age group are slightly different than in part C. Above I can see that the average for all age ranges is higher for non-smokers, besides age group 0-13. I can see in my results in part D that the sample size for 0-13 non-smokers is extremely high, much higher than any other group of smokers or non-smokers, so with this higher sample size comes more variance. The median lines are actually pretty close but the outliers are probably affecting the mean."
  },
  {
    "objectID": "posts/abigailbalint_hw1.html#question-2",
    "href": "posts/abigailbalint_hw1.html#question-2",
    "title": "Homework 1",
    "section": "Question 2",
    "text": "Question 2\nCreating a data frame –\n\n\nCode\npriorconviction <- c(0,1,2,3,4)\nprisoners <- c(128,434,160,64,24)\nq2 <- data.frame(priorconviction, prisoners)\nhead(q2)\n\n\n  priorconviction prisoners\n1               0       128\n2               1       434\n3               2       160\n4               3        64\n5               4        24\n\n\n\nWhat is the probability that a randomly selected inmate has exactly 2 prior convictions?\n\n\n\nCode\n160/810\n\n\n[1] 0.1975309\n\n\nI found it to be .1975 or 19.75%\n\nWhat is the probability that a randomly selected inmate has fewer than 2 prior convictions?\n\n\n\nCode\n(434+128)/810\n\n\n[1] 0.6938272\n\n\nTo get this I added the sample of 0 or 1 prior conviction and it comes out to .69 or 69%.\n\nWhat is the probability that a randomly selected inmate has 2 or fewer prior convictions?\n\n\n\nCode\n(128+434+160)/810\n\n\n[1] 0.891358\n\n\nTo get this I added the sample of 0 or 1 or 2 prior convictions and it comes out to .89 or 89%.\n\nWhat is the probability that a randomly selected inmate has more than 2 prior convictions?\n\n\n\nCode\n(64+24)/810\n\n\n[1] 0.108642\n\n\nTo get this I added the sample of 3 or 4 prior convictions and it comes out to .108 or 11%.\n\nWhat is the expected value1 for the number of prior convictions?\n\n\n\nCode\nsum(q2$priorconviction*prisoners)\n\n\n[1] 1042\n\n\nCode\n1042/810\n\n\n[1] 1.28642\n\n\nTo get this I summed all of the numbers of prior convictions by the amount of prisoners (1042) then divided this by total sample (810) to get a final expected value of 1.28 prior convictions.\n\nCalculate the variance and the standard deviation for the Prior Convictions.\n\n\n\nCode\nvar(q2$priorconviction)\n\n\n[1] 2.5\n\n\nCode\nvar(q2$priorconviction)*(5-1)/5\n\n\n[1] 2\n\n\nI used the above code to find a sample variance of 2.5 and a population variance of 2.\n\n\nCode\nsd(q2$priorconviction)\n\n\n[1] 1.581139\n\n\nI used the standard deviation function to calculate the above.\n:::"
  },
  {
    "objectID": "posts/AlexisGamez_HW1.html",
    "href": "posts/AlexisGamez_HW1.html",
    "title": "Blog Post #1",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(readxl)\n\nknitr::opts_chunk$set(echo = TRUE)"
  },
  {
    "objectID": "posts/AlexisGamez_HW1.html#a",
    "href": "posts/AlexisGamez_HW1.html#a",
    "title": "Blog Post #1",
    "section": "a)",
    "text": "a)\nFirst, let’s read in the data from the Excel file:\n\n\nCode\ngetwd()\n\n\n[1] \"C:/Users/Leshiii/Desktop/DACSS Master's/DACSS 603/603_Spring_2023/posts\"\n\n\nCode\ndf <- read_excel(\"_data/LungCapData.xls\")\n\n\nThe distribution of LungCap looks as follows:\n\n\nCode\nhist(df$LungCap, main = \"Lung Capacity Distribution\", xlab = \"Lung Capacity\", ylab = \"Probability Density\", prob = TRUE)\n\n\n\n\n\nThe histogram suggests that the distribution is close to a normal distribution. Most of the observations are close to the mean. Very few observations are close to the margins (0 and 15)."
  },
  {
    "objectID": "posts/AlexisGamez_HW1.html#b",
    "href": "posts/AlexisGamez_HW1.html#b",
    "title": "Blog Post #1",
    "section": "b)",
    "text": "b)\nProvided below is a box plot of the probability distributions of the Lung Capacity data for the male and female genders.\n\n\nCode\nboxplot(df$LungCap ~ df$Gender, \n        ylab = \"Gender\",\n        xlab = \"Lung Capacity\",\n        horizontal = TRUE,\n        col = \"maroon\")"
  },
  {
    "objectID": "posts/AlexisGamez_HW1.html#c",
    "href": "posts/AlexisGamez_HW1.html#c",
    "title": "Blog Post #1",
    "section": "c)",
    "text": "c)\nI don’t believe the data provided below make much sense. I would argue that it is much more likely for smokers to have a smaller lung capacity than those that do not smoke. I suspect that something could be going on with our sample.\n\n\nCode\nboxplot(df$LungCap ~ df$Smoke, \n        ylab = \"Smoking Preference\",\n        xlab = \"Lung Capacity\",\n        horizontal = TRUE,\n        col = \"bisque\")\n\n\n\n\n\nCode\nno_smoke <- subset(df, Smoke == \"no\")\nyes_smoke <- subset(df, Smoke == \"yes\")\nmean(no_smoke$LungCap)\n\n\n[1] 7.770188\n\n\nCode\nmean(yes_smoke$LungCap)\n\n\n[1] 8.645455"
  },
  {
    "objectID": "posts/AlexisGamez_HW1.html#d",
    "href": "posts/AlexisGamez_HW1.html#d",
    "title": "Blog Post #1",
    "section": "d)",
    "text": "d)\nComparing the charts below, we can see that as the participant ages, the mean and ranges of Lung Capacity increases. This could be due to natural maturation, with Lungs growing as children grow to adolescents, stalling circa 18 years old. However, I suspect there might be more to it, particularly our sample of smokers being so small compared to that of non-smokers.\n\n\nCode\nno_smoke_mean <- mean(no_smoke$LungCap)\n`13_under` <- subset(yes_smoke, Age <= 13)\n\n`14_to_15` <- subset(yes_smoke, subset = Age == 14 | Age == 15)\n\n`16_to_17` <- subset(yes_smoke, subset = Age == 16 | Age == 17)\n\n`18_over` <- subset(yes_smoke, Age >= 18)\n\nhist(`13_under`$LungCap, main = \"Smoker Lung Capacity Distribution by Age\", xlab = \"Lung Capacity\", ylab = \"Probability Density\", prob = TRUE)\nlegend(\"topright\", legend=c(\"13 & Under\",\"14 to 15\", \"16 to 17\", \"18 & Over\"), col=c(\"gray\", rgb(0,0,1,0.5), \n     rgb(0,1,0,0.5), rgb(1,0,0,0.5)), pt.cex=2, pch=15)\n\n\n\n\n\nCode\nhist(`14_to_15`$LungCap, prob = TRUE, col = rgb(0,0,1,0.5), main = \"Smoker Lung Capacity Distribution by Age\", xlab = \"Lung Capacity\", ylab = \"Probability Density\")\nlegend(\"topright\", legend=c(\"13 & Under\",\"14 to 15\", \"16 to 17\", \"18 & Over\"), col=c(\"gray\", rgb(0,0,1,0.5), \n     rgb(0,1,0,0.5), rgb(1,0,0,0.5)), pt.cex=2, pch=15)\n\n\n\n\n\nCode\nhist(`16_to_17`$LungCap, prob = TRUE, col = rgb(0,1,0,0.5), main = \"Smoker Lung Capacity Distribution by Age\", xlab = \"Lung Capacity\", ylab = \"Probability Density\")\nlegend(\"topright\", legend=c(\"13 & Under\",\"14 to 15\", \"16 to 17\", \"18 & Over\"), col=c(\"gray\", rgb(0,0,1,0.5), \n     rgb(0,1,0,0.5), rgb(1,0,0,0.5)), pt.cex=2, pch=15)\n\n\n\n\n\nCode\nhist(`18_over`$LungCap, prob = TRUE, col = rgb(1,0,0,0.5), main = \"Smoker Lung Capacity Distribution by Age\", xlab = \"Lung Capacity\", ylab = \"Probability Density\")\nlegend(\"topright\", legend=c(\"13 & Under\",\"14 to 15\", \"16 to 17\", \"18 & Over\"), col=c(\"gray\", rgb(0,0,1,0.5), \n     rgb(0,1,0,0.5), rgb(1,0,0,0.5)), pt.cex=2, pch=15)"
  },
  {
    "objectID": "posts/AlexisGamez_HW1.html#e",
    "href": "posts/AlexisGamez_HW1.html#e",
    "title": "Blog Post #1",
    "section": "e)",
    "text": "e)\n\n\nCode\ndf_Agegroup <- df %>% \n  mutate(\nAge_group = dplyr::case_when(\n      Age <= 13            ~ \"0-13\",\n      Age > 13 & Age <= 15 ~ \"14-15\",\n      Age > 15 & Age <= 17 ~ \"16-17\",\n      Age >= 18             ~ \"18+\"))\n\nggplot(data = df_Agegroup, aes(x=Age_group, y=LungCap)) + \n  geom_boxplot(aes(fill=Smoke)) +\n  labs(x=\"Age Group\",y=\"Lung Capacity\",title=\"Lung Capacity of Smokers vs Non Smokers by Age Group\")\n\n\n\n\n\nLooking at the box plot above, its seems as though the ranges of data for the latter 3 age group divisions are naturally larger for non-smokers than for smokers. Additionally, the means for said divisions under non-smokers are also higher! What seems to be skewing the data is the large quantity of participants equal to 13 years of age or younger. I believe this is why our data hasn’t made much sense until now. There might be other factors in play here, like respondent bias, but I believe the sample size here is the main influence."
  },
  {
    "objectID": "posts/AlexisGamez_HW1.html#a-1",
    "href": "posts/AlexisGamez_HW1.html#a-1",
    "title": "Blog Post #1",
    "section": "a)",
    "text": "a)\nReading in our data.\n\n\nCode\nConvictions <- seq(0,4)\nFreq <- c(128, 434, 160, 64, 24)/810\n\n\nThe probability of that a randomly selected inmate has exactly 2 prior convictions is:\n\n\nCode\ndbinom(x=1, size = 1, prob = 160/810)\n\n\n[1] 0.1975309"
  },
  {
    "objectID": "posts/AlexisGamez_HW1.html#b-1",
    "href": "posts/AlexisGamez_HW1.html#b-1",
    "title": "Blog Post #1",
    "section": "b)",
    "text": "b)\nThe probability that a randomly selected inmate has fewer than 2 prior convictions is:\n\n\nCode\ndbinom(x = 1, size = 1, prob = (128+434)/810)\n\n\n[1] 0.6938272"
  },
  {
    "objectID": "posts/AlexisGamez_HW1.html#c-1",
    "href": "posts/AlexisGamez_HW1.html#c-1",
    "title": "Blog Post #1",
    "section": "c)",
    "text": "c)\nThe probability that a randomly selected inmate has 2 or fewer prior convictions is:\n\n\nCode\ndbinom(x = 1, size = 1, prob = (128+434+160)/810)\n\n\n[1] 0.891358"
  },
  {
    "objectID": "posts/AlexisGamez_HW1.html#d-1",
    "href": "posts/AlexisGamez_HW1.html#d-1",
    "title": "Blog Post #1",
    "section": "d)",
    "text": "d)\nThe probability that a randomly selected inmate has more than 2 prior convictions is:\n\n\nCode\ndbinom(x = 1, size = 1, prob = (64+24)/810)\n\n\n[1] 0.108642"
  },
  {
    "objectID": "posts/AlexisGamez_HW1.html#e-1",
    "href": "posts/AlexisGamez_HW1.html#e-1",
    "title": "Blog Post #1",
    "section": "e)",
    "text": "e)\nThe expected value for the number of prior convictions is:\n\n\nCode\nExpected_v <- sum(Freq*Convictions)\nExpected_v\n\n\n[1] 1.28642"
  },
  {
    "objectID": "posts/AlexisGamez_HW1.html#f",
    "href": "posts/AlexisGamez_HW1.html#f",
    "title": "Blog Post #1",
    "section": "f)",
    "text": "f)\nThe variance for prior convictions is:\n\n\nCode\nVariance <- sum((Convictions-Expected_v)^2*Freq)\nVariance\n\n\n[1] 0.8562353\n\n\nThe standard deviation for prior convictions is:\n\n\nCode\nSD <- sqrt(Variance)\nSD\n\n\n[1] 0.9253298\n\n\nPlotting our data further validates our calculations as all values we’ve presented seem to coincide with their respective points on the plot.\n\n\nCode\nConv_data <- tibble(\n  x= Convictions,\n  y= Freq)\n\nggplot(Conv_data, aes(x,y))+\n  geom_line()+\n  geom_vline(xintercept = 2, col=\"red\",size=1)+\n  geom_text(x=2.15,y=.245,label=\"c = 2\")+\n  labs(x=\"# of Prior Convictions\",y=\"Probability\",title=\"Probability Distribution of Prisoner # of Prior Convictions\")\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead."
  },
  {
    "objectID": "posts/HW1_SaisrinivasAmbatipudi.html",
    "href": "posts/HW1_SaisrinivasAmbatipudi.html",
    "title": "Homework 1",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(ggplot2)\nlibrary(stats)\n\nknitr::opts_chunk$set(echo = TRUE)"
  },
  {
    "objectID": "posts/HW1_SaisrinivasAmbatipudi.html#question-1",
    "href": "posts/HW1_SaisrinivasAmbatipudi.html#question-1",
    "title": "Homework 1",
    "section": "Question 1",
    "text": "Question 1"
  },
  {
    "objectID": "posts/HW1_SaisrinivasAmbatipudi.html#reading-data",
    "href": "posts/HW1_SaisrinivasAmbatipudi.html#reading-data",
    "title": "Homework 1",
    "section": "Reading data",
    "text": "Reading data\n\n\nCode\nLc <- read_excel(\"C:/UMass/DACSS_603/603_Spring_2023/posts/_data/LungCapData.xls\")\nLc\n\n\n\n\n  \n\n\n\nThe data consists of 725 rows and 6 columns. It determines the lung capacity of the based on their age, height and different characteristics. The main key classification that I can see is if they smoke or not."
  },
  {
    "objectID": "posts/HW1_SaisrinivasAmbatipudi.html#a",
    "href": "posts/HW1_SaisrinivasAmbatipudi.html#a",
    "title": "Homework 1",
    "section": "1a",
    "text": "1a\nThe distribution of LungCap looks as follows:\n\n\nCode\nLc %>%\n  ggplot(aes(LungCap, ..density..)) +\n  geom_histogram(bins= 25, color = \"orange\") +\n  geom_density(color = \"darkblue\") +\n  theme_classic() + \n  labs(title = \"Probability distribution of LungCap\", x = \"Lung Capcity\", y = \"Probability density\")\n\n\nWarning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(density)` instead.\n\n\n\n\n\nThe histogram and density plots show that it is pretty close to a normal distribution. Most of the observations are close to the mean."
  },
  {
    "objectID": "posts/HW1_SaisrinivasAmbatipudi.html#b",
    "href": "posts/HW1_SaisrinivasAmbatipudi.html#b",
    "title": "Homework 1",
    "section": "1b",
    "text": "1b\nThe distribution of LungCap on basis of gender looks as follows:\n\n\nCode\nLc %>%\n  ggplot(aes(y = dnorm(LungCap), color = Gender)) +\n  geom_boxplot() +\n  theme_classic() + \n  labs(title = \"Probability distribution of LungCap based on gender\", y = \"Probability density\")\n\n\n\n\n\nThe box plot shows that the probability density of the male is lesser than the female."
  },
  {
    "objectID": "posts/HW1_SaisrinivasAmbatipudi.html#c",
    "href": "posts/HW1_SaisrinivasAmbatipudi.html#c",
    "title": "Homework 1",
    "section": "1c",
    "text": "1c\nComparison of mean lung capacities between smokers and non-smokers:\n\n\nCode\nMean_smoke <- Lc %>%\n  group_by(Smoke) %>%\n  summarise(mean = mean(LungCap))\nMean_smoke\n\n\n\n\n  \n\n\n\nFrom the above table, we see that the mean lung capacity of those who smoke is greater than those who don’t smoke, but it doesn’t make sense. It also depends on the biological factors of the person who smoke, so we can’t conclude it."
  },
  {
    "objectID": "posts/HW1_SaisrinivasAmbatipudi.html#d",
    "href": "posts/HW1_SaisrinivasAmbatipudi.html#d",
    "title": "Homework 1",
    "section": "1d",
    "text": "1d\nRelationship between Smoke and Lung capacity on basis of given age categories:\n\n\nCode\nLc <- mutate(Lc, AgeGrp = case_when(Age <= 13 ~ \"less than or equal to 13\",\n                                    Age == 14 | Age == 15 ~ \"14 to 15\",\n                                    Age == 16 | Age == 17 ~ \"16 to 17\",\n                                    Age >= 18 ~ \"greater than or equal to 18\"))\n\nLc %>%\n  ggplot(aes(y = LungCap, color = Smoke)) +\n  geom_histogram(bins = 25) +\n  facet_wrap(vars(AgeGrp)) +\n  theme_classic() + \n  labs(title = \"Relationship of LungCap and Smoke based on age categories\", y = \"Lung Capacity\", x = \"Frequency\")\n\n\n\n\n\nFrom the above plot, we can derive two important observations: 1. The lung capacity of non smokers is more than smokers. 2. The people who smoke are less in age group of “less than or equal to 13”. So as the result as age increases the lung capacity decreases."
  },
  {
    "objectID": "posts/HW1_SaisrinivasAmbatipudi.html#e",
    "href": "posts/HW1_SaisrinivasAmbatipudi.html#e",
    "title": "Homework 1",
    "section": "1e",
    "text": "1e\nRelationship between Smoke and Lung capacity on basis of age:\n\n\nCode\nLc %>%\n  ggplot(aes(x = Age, y = LungCap, color = Smoke)) +\n  geom_line() +\n  theme_classic() + \n  facet_wrap(vars(Smoke)) +\n  labs(title = \"Relationship of LungCap and Smoke based on age\", y = \"Lung Capacity\", x = \"Age\")\n\n\n\n\n\nForm the above data we can compare 1d and 1e and can say the results are pretty similar. Only 10 and above age group smoke."
  },
  {
    "objectID": "posts/HW1_SaisrinivasAmbatipudi.html#f",
    "href": "posts/HW1_SaisrinivasAmbatipudi.html#f",
    "title": "Homework 1",
    "section": "1f",
    "text": "1f\nCalculating the correlation and covariance between Lung Capacity and Age:\n\n\nCode\nCovariance <- cov(Lc$LungCap, Lc$Age)\nCorrelation <- cor(Lc$LungCap, Lc$Age)\nCovariance\n\n\n[1] 8.738289\n\n\nCode\nCorrelation\n\n\n[1] 0.8196749\n\n\nWe can observe from the comparison that the covariance is positive and it indicates that there is a direct relationship between age and lung capacity. And the correlation is also positive, so they move in same direction. We can say from these results that as the age increases, the lung capacity also increases that is they are directly proportional to each other."
  },
  {
    "objectID": "posts/HW1_SaisrinivasAmbatipudi.html#question-2",
    "href": "posts/HW1_SaisrinivasAmbatipudi.html#question-2",
    "title": "Homework 1",
    "section": "Question 2",
    "text": "Question 2"
  },
  {
    "objectID": "posts/HW1_SaisrinivasAmbatipudi.html#reading-the-table",
    "href": "posts/HW1_SaisrinivasAmbatipudi.html#reading-the-table",
    "title": "Homework 1",
    "section": "Reading the table",
    "text": "Reading the table\n\n\nCode\nPrior_convitions <- c(0:4)\nInmate_count <- c(128, 434, 160, 64, 24)\nPc <- data_frame(Prior_convitions, Inmate_count)\n\n\nWarning: `data_frame()` was deprecated in tibble 1.1.0.\nℹ Please use `tibble()` instead.\n\n\nCode\nPc\n\n\n\n\n  \n\n\n\n\n\nCode\nPc <- mutate(Pc, Probability = Inmate_count/sum(Inmate_count))\nPc"
  },
  {
    "objectID": "posts/HW1_SaisrinivasAmbatipudi.html#a-1",
    "href": "posts/HW1_SaisrinivasAmbatipudi.html#a-1",
    "title": "Homework 1",
    "section": "2a",
    "text": "2a\nProbability that a randomly selected inmate has exactly 2 prior convictions:\n\n\nCode\nPc %>%\n  filter(Prior_convitions == 2) %>%\n  select(Probability)"
  },
  {
    "objectID": "posts/HW1_SaisrinivasAmbatipudi.html#b-1",
    "href": "posts/HW1_SaisrinivasAmbatipudi.html#b-1",
    "title": "Homework 1",
    "section": "2b",
    "text": "2b\nProbability that a randomly selected inmate has fewer than 2 convictions:\n\n\nCode\ntemp <- Pc %>%\n  filter(Prior_convitions < 2)\nsum(temp$Probability)\n\n\n[1] 0.6938272"
  },
  {
    "objectID": "posts/HW1_SaisrinivasAmbatipudi.html#c-1",
    "href": "posts/HW1_SaisrinivasAmbatipudi.html#c-1",
    "title": "Homework 1",
    "section": "2c",
    "text": "2c\nProbability that a randomly selected inmate has 2 or fewer prior convictions:\n\n\nCode\ntemp <- Pc %>%\n  filter(Prior_convitions <= 2)\nsum(temp$Probability)\n\n\n[1] 0.891358"
  },
  {
    "objectID": "posts/HW1_SaisrinivasAmbatipudi.html#d-1",
    "href": "posts/HW1_SaisrinivasAmbatipudi.html#d-1",
    "title": "Homework 1",
    "section": "2d",
    "text": "2d\nProbability that a randomly selected inmate has more than 2 prior convictions:\n\n\nCode\ntemp <- Pc %>%\n  filter(Prior_convitions > 2)\nsum(temp$Probability)\n\n\n[1] 0.108642"
  },
  {
    "objectID": "posts/HW1_SaisrinivasAmbatipudi.html#e-1",
    "href": "posts/HW1_SaisrinivasAmbatipudi.html#e-1",
    "title": "Homework 1",
    "section": "2e",
    "text": "2e\nExpected value for the number of prior convictions:\n\n\nCode\nPc <- mutate(Pc, Wm = Prior_convitions*Probability)\ne <- sum(Pc$Wm)\ne\n\n\n[1] 1.28642"
  },
  {
    "objectID": "posts/HW1_SaisrinivasAmbatipudi.html#f-1",
    "href": "posts/HW1_SaisrinivasAmbatipudi.html#f-1",
    "title": "Homework 1",
    "section": "2f",
    "text": "2f\nVariance for the Prior Convictions:\n\n\nCode\nv <-sum(((Pc$Prior_convitions-e)^2)*Pc$Probability)\nv\n\n\n[1] 0.8562353\n\n\nstandard deviation for the Prior Convictions:\n\n\nCode\nsqrt(v)\n\n\n[1] 0.9253298"
  },
  {
    "objectID": "posts/HW1_JustineShakespeare.html",
    "href": "posts/HW1_JustineShakespeare.html",
    "title": "Homework 1",
    "section": "",
    "text": "We start by loading the appropriate packages and reading in the data from the Excel file:\n\n\nCode\nlibrary(readxl)\nlibrary(tidyverse)\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0      ✔ purrr   1.0.1 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.3.0      ✔ stringr 1.5.0 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\nCode\ndf <- read_excel(\"_data/LungCapData.xls\")\n\n\nWe can use the glimpse() function to take a look at the data:\n\n\nCode\nglimpse(df)\n\n\nRows: 725\nColumns: 6\n$ LungCap   <dbl> 6.475, 10.125, 9.550, 11.125, 4.800, 6.225, 4.950, 7.325, 8.…\n$ Age       <dbl> 6, 18, 16, 14, 5, 11, 8, 11, 15, 11, 19, 17, 12, 10, 10, 13,…\n$ Height    <dbl> 62.1, 74.7, 69.7, 71.0, 56.9, 58.7, 63.3, 70.4, 70.5, 59.2, …\n$ Smoke     <chr> \"no\", \"yes\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\",…\n$ Gender    <chr> \"male\", \"female\", \"female\", \"male\", \"male\", \"female\", \"male\"…\n$ Caesarean <chr> \"no\", \"no\", \"yes\", \"no\", \"no\", \"no\", \"yes\", \"no\", \"no\", \"no\"…\n\n\nThis shows that this dataset has 725 observations (rows) and 6 variables (columns). The first three columns are labeled: LungCap, Age, and Height and they are all classified as double, which is a type of numeric variable. The last three columns are Smoke, Gender, and Caesarean, which are all classified as character variables. LungCap refers to the lung capacity of the person, Age, Height, and Gender all describe the relevant characteristics of that person. Smoke is a dichotomous variable which records whether a person smokes or not. Caesarean is also a dichotomous variable that reflects whether a person was born by a caesaren or not.\n\n\nThe distribution of the LungCap variable looks as follows:\n\n\nCode\nhist(df$LungCap)\n\n\n\n\n\nThe histogram suggests that the distribution is close to a normal distribution. Most of the observations are close to the mean.\n\n\n\nWe can use the boxplot function to compare the distribution of the LungCap variable with respect to males and females.\n\n\nCode\nboxplot(LungCap ~ Gender, data=df)\n\n\n\n\n\n\n\n\nBy using pipes, the group_by() and the summarize() functions we can take a look at the mean lung capacity of smokers and non-smokers. The results are counter-intuitive: it looks as though the mean lung capacity for those who smoke is larger than those who do not.\n\n\nCode\ndf %>% \n  group_by(Smoke) %>% \n  summarize(\"Mean_LungCap\"=mean(LungCap))\n\n\n# A tibble: 2 × 2\n  Smoke Mean_LungCap\n  <chr>        <dbl>\n1 no            7.77\n2 yes           8.65\n\n\n\n\n\nTo examine the relationship between smoking and lung capacity within age groups we can use the mutate() and case_when() functions and piping to create an ordinal variable that captures different age groups:\n\n\nCode\ndf <- df %>% \n  mutate(AgeGroups = case_when(\n    Age<=13 ~ \"a. Less than or equal to 13\",\n    Age==14 | Age==15 ~ \"b. 14 or 15\", \n    Age==16 | Age==17 ~ \"c. 16 or 17\",\n    Age>=18 ~ \"d. Greater than or equal to 18\"))\n\n\nWith this new variable we can more easily compare the lung capacities for smokers and non-smokers within each age group. The following tables show the mean lung capacity for study subjects arranged by age group, first for those who reported not smoking and second for those who did report smoking:\n\n\n\n\nCode\nfilter(df, Smoke==\"no\") %>% \n  group_by(AgeGroups) %>% \n  summarize(\"Mean_LungCap\"=mean(LungCap)) %>% \n  arrange(AgeGroups)\n\n\n# A tibble: 4 × 2\n  AgeGroups                      Mean_LungCap\n  <chr>                                 <dbl>\n1 a. Less than or equal to 13            6.36\n2 b. 14 or 15                            9.14\n3 c. 16 or 17                           10.5 \n4 d. Greater than or equal to 18        11.1 \n\n\n\n\n\n\n\nCode\nfilter(df, Smoke==\"yes\") %>% \n  group_by(AgeGroups) %>% \n  summarize(\"Mean_LungCap\"=mean(LungCap)) %>% \n  arrange(AgeGroups)\n\n\n# A tibble: 4 × 2\n  AgeGroups                      Mean_LungCap\n  <chr>                                 <dbl>\n1 a. Less than or equal to 13            7.20\n2 b. 14 or 15                            8.39\n3 c. 16 or 17                            9.38\n4 d. Greater than or equal to 18        10.5 \n\n\nThis data shows that lung capacity generally increases with age.\nIt is interesting to note that on average all age groups that did not smoke had a higher lung capacity except for those who were 13 or under. The group found to have the lowest lung capacity in the whole dataset were children 13 or under who did not smoke.\nSince the finding related to this age group (study subjects aged 13 or under) was unexpected, I used the filter() and table() functions to examine the sample size of this group.\n\n\nCode\nThirteen_and_under <- filter(df, AgeGroups == \"a. Less than or equal to 13\")\ntable(Thirteen_and_under$Smoke)\n\n\n\n no yes \n401  27 \n\n\nAccording to this data, there were only 27 children in this study 13 years old or under who reported smoking. In order to better understand the relationship between age, smoking status and lung capacity we could run another study with a larger sample size."
  },
  {
    "objectID": "posts/HW1_JustineShakespeare.html#a.-1",
    "href": "posts/HW1_JustineShakespeare.html#a.-1",
    "title": "Homework 1",
    "section": "2a.",
    "text": "2a.\nWhat is the probability that a randomly selected inmate has exactly 2 prior convictions?\nIn the table above we can see that the probability that a randomly selected inmate has 2 prior convictions is .1975, or .2 rounded."
  },
  {
    "objectID": "posts/HW1_JustineShakespeare.html#b.-1",
    "href": "posts/HW1_JustineShakespeare.html#b.-1",
    "title": "Homework 1",
    "section": "2b.",
    "text": "2b.\nWhat is the probability that a randomly selected inmate has fewer than 2 prior convictions?\nThis question is looking for the cumulative probability that an inmate has less than 2 prior convictions. We can find cumulative probability by adding the relevant probabilities: The probability that an inmate has 0 convictions is .16 and the probability that an inmate has 1 conviction is .54.\n\n\nCode\n# We can see these numbers in the table above, but as a reminder and a way to \n# double check, we can calculate those probabilities again before adding them:\nzero_convictions <- 128/810\none_conviction <- 434/810\nProb_fewer_than_2 <- zero_convictions + one_conviction\nProb_fewer_than_2\n\n\n[1] 0.6938272"
  },
  {
    "objectID": "posts/HW1_JustineShakespeare.html#c.-1",
    "href": "posts/HW1_JustineShakespeare.html#c.-1",
    "title": "Homework 1",
    "section": "2c.",
    "text": "2c.\nWhat is the probability that a randomly selected inmate has 2 or fewer prior convictions?\nTo find the probability that a randomly selected inmate has 2 or fewer prior convictions we use the same method as the in the previous question: add together the probabilities for X = 0, X = 1, and X = 2:\n\n\nCode\n# We can see these numbers in the table above, but as a reminder and a way to \n# double check, we can calculate those probabilities again before adding them:\ntwo_convictions <- 160/810\nProb_2_or_fewer <- zero_convictions + one_conviction + two_convictions\nProb_2_or_fewer \n\n\n[1] 0.891358"
  },
  {
    "objectID": "posts/HW1_JustineShakespeare.html#d.",
    "href": "posts/HW1_JustineShakespeare.html#d.",
    "title": "Homework 1",
    "section": "2d.",
    "text": "2d.\nWhat is the probability that a randomly selected inmate has more than 2 prior convictions?\nTo find the probability that a randomly selected inmate has more than 2 prior convictions we use the same method as in the previous questions, except that we add the probabilities of X = 3 and X = 4:\n\n\nCode\n# We can see these numbers in the table above, but as a reminder and a way to \n# double check, we can calculate those probabilities again before adding them:\nthree_convictions <- 64/810\nfour_convictions <- 24/810\nProb_2_or_more <- three_convictions + four_convictions\nProb_2_or_more \n\n\n[1] 0.108642"
  },
  {
    "objectID": "posts/HW1_JustineShakespeare.html#e.",
    "href": "posts/HW1_JustineShakespeare.html#e.",
    "title": "Homework 1",
    "section": "2e.",
    "text": "2e.\nWhat is the expected value for the number of prior convictions?\nTo find the expected value for the number of prior convictions we multiply each possible value of X by its probability of occurring and add that up over all X. To do this in R I used some of the same variables I created above to calculate the expected value:\n\n\nCode\nExpVal <- sum(probability*X_prior_convictions)\nExpVal\n\n\n[1] 1.28642"
  },
  {
    "objectID": "posts/HW1_JustineShakespeare.html#f.",
    "href": "posts/HW1_JustineShakespeare.html#f.",
    "title": "Homework 1",
    "section": "2f.",
    "text": "2f.\nCalculate the variance and the standard deviation for the Prior Convictions.\nTo calculate the variance I used the expected value we just calculated and the following equation for variance: E[(X-u)^2]. Once I found the variance, I was able to find the standard deviation, since it is the square root of the variance:\n\n\nCode\nVarX <- sum((X_prior_convictions-ExpVal)^2*probability)\nVarX\n\n\n[1] 0.8562353\n\n\nCode\nsdX <- sqrt(VarX)\nsdX\n\n\n[1] 0.9253298"
  },
  {
    "objectID": "posts/HW1_RahulSomu.html",
    "href": "posts/HW1_RahulSomu.html",
    "title": "Homework1",
    "section": "",
    "text": "First, let’s read in the data from the Excel file:\n\n\nCode\nlibrary(readxl)\nlibrary(dplyr)\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nCode\nlibrary(ggplot2)\ngetwd()\n\n\n[1] \"/Users/rahulsomu/Documents/DACSS_601/603_repo/posts\"\n\n\nCode\ndf <- read_excel(\"_data/LungCapData.xls\")\n\n\nThe distribution of LungCap looks as follows:\n1a) The histogram suggests that the distribution is close to a normal distribution. Most of the observations are close to the mean. Very few observations are close to the margins (0 and 15).\n\n\nCode\nhist(df$LungCap)\n\n\n\n\n\n1b) Median lung capacity of male is greater than that of female.\n\n\nCode\nboxplot(LungCap ~ Gender, data = df, xlab = \"Gender\", ylab = \"Lung Capacity\",\n        main = \"Distribution of Lung Capacity by Gender\")\n\n\n\n\n\n1c) Logically mean lung capacity of non-smokers should be more than of smokers but with the data, it’s other way round\n\n\nCode\n# Calculate the mean lung capacity for smokers and non-smokers\nmean_lungcap_smokers <- mean(df$LungCap[df$Smoke == \"yes\"])\nmean_lungcap_non_smokers <- mean(df$LungCap[df$Smoke == \"no\"])\n\n# Print the mean lung capacities\ncat(\"Mean lung capacity for smokers:\", round(mean_lungcap_smokers, 2), \"\\n\")\n\n\nMean lung capacity for smokers: 8.65 \n\n\nCode\ncat(\"Mean lung capacity for non-smokers:\", round(mean_lungcap_non_smokers, 2), \"\\n\")\n\n\nMean lung capacity for non-smokers: 7.77 \n\n\n1d) The average lung capacity growth for the non-smokers is more that of the smokers. The lung capacity has been gradually increasing with age 1e) The discrepancy in 1c is due the data for the 13 or younger age where the average lung capacity for the non-smokers is less that of the smokers. Also there have been more data points for 13 or younger age group non-smokers which is affecting the mean of entire distribution.\n\n\nCode\n# Define the age groups\ndf <- df %>%\n  mutate(age_groups = cut(Age, c(0, 13, 15, 17, Inf), labels = c(\"<= 13\", \"14-15\", \"16-17\", \">= 18\")))\n\n# Compare the probability distribution of lung capacity by gender\ndf %>%\n  ggplot(aes(x = Gender, y = LungCap)) +\n  geom_boxplot() +\n  labs(x = \"Gender\", y = \"Lung Capacity\", \n       title = \"Lung Capacity by Gender\")\n\n\n\n\n\nCode\n# Compare the mean lung capacities for smokers and non-smokers\ndf %>%\n  group_by(Smoke) %>%\n  summarize(mean_lungcap = mean(LungCap)) %>%\n  print()\n\n\n# A tibble: 2 × 2\n  Smoke mean_lungcap\n  <chr>        <dbl>\n1 no            7.77\n2 yes           8.65\n\n\nCode\n# Examine the relationship between smoking and lung capacity within age groups\ndf %>%\n  filter(Smoke %in% c(\"yes\", \"no\")) %>%\n  group_by(age_groups, Smoke) %>%\n  summarize(mean_lungcap = mean(LungCap)) %>%\n  print()\n\n\n`summarise()` has grouped output by 'age_groups'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 8 × 3\n# Groups:   age_groups [4]\n  age_groups Smoke mean_lungcap\n  <fct>      <chr>        <dbl>\n1 <= 13      no            6.36\n2 <= 13      yes           7.20\n3 14-15      no            9.14\n4 14-15      yes           8.39\n5 16-17      no           10.5 \n6 16-17      yes           9.38\n7 >= 18      no           11.1 \n8 >= 18      yes          10.5 \n\n\nCode\n# Compare the lung capacities for smokers and non-smokers within each age group\ndf %>%\n  filter(Smoke %in% c(\"yes\", \"no\")) %>%\n  ggplot(aes(x = age_groups, y = LungCap, fill = Smoke)) +\n  geom_boxplot() +\n  labs(x = \"Age Group\", y = \"Lung Capacity\", \n       title = \"Lung Capacity by Smoking Status and Age Group\")\n\n\n\n\n\n#Challange2"
  },
  {
    "objectID": "posts/FinalPart1_LTucksmith.html",
    "href": "posts/FinalPart1_LTucksmith.html",
    "title": "FinalPart1",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(janitor)\nknitr::opts_chunk$set(echo = TRUE)\n\n\nThe most profitable sports league in the world, the National Football League, generated $18 billion in revenue in 2021 according to sportico.com. This total represents national media rights, league sponsorships with gambling companies, news outlets, and other companies, and shared revenue and royalties from the league’s various affiliates and subsidiaries, such as NFL Enterprises, NFL Properties, and NFL International. While the 32 teams which make up the NFL have separate revenue streams stemming from merchandise and ticketing sales and various other endeavors, each team also receives a slice of shared revenue from the NFL from the games’ national and local broadcasts and sponsorships. As money is what keeps the NFL afloat and allows teams to competitively pay for top players and coaches, NFL teams benefit from working with media outlets and appearing in media and news. What I plan to analyze is how the relationship between the NFL and media plays out in games, if it does at all. Can the relationship between media and game outcome be measured? Does a team’s weekly media attention share affect their weekly game outcome? My analysis will attempt to measure this relationship by comparing Google Trends generated News Interest Over Time scores for the 2020-21 and 2021-22 for each match up that occurred in those two seasons.\nMy hypothesis is that the highest scored weeks for each team will generate the highest probability of winning that same or next given week. In addition, I plan to analyze how the relationship between the media and game scores changes given the media score of the opposition team, and if the relationship between the media scores and the sports betting data differs from that of the media scores and game outcome. I hypothesize that the team with the higher media score will be favored and that the spread will widen if the individual media score is above a to be determined .\nThe first dataset is a collection of all the matchups and scores that occurred in the NFL since 1966. The matchup information includes the names of the two teams competing, home/away team status, the match site, the weather on game day, and the final score for each team. Sports betting data for each game since 1977 is also included, and includes who was favored, the point spread, and the over/under line. The dataset is from https://www.kaggle.com/datasets/tobycrabtree/nfl-scores-and-betting-data and was created from a variety of sources including games and scores from public websites such as ESPN, NFL.com, and Pro Football Reference. Weather information is from NOAA data, cross-referenced with NFLweather.com. Betting data reflects lines available at sportsline.com and aussportsbetting.com. For the analysis, I will limit the data to the data collected from the 2020-21 and 2021-22 seasons.\n\n\nCode\ngame_scores <- read.csv(\"~/Documents/GitHub/603_Spring_2023/posts/_data/spreadspoke_scores.csv\")\ncolnames(game_scores)\n\n\n [1] \"schedule_date\"       \"schedule_season\"     \"schedule_week\"      \n [4] \"schedule_playoff\"    \"team_home\"           \"score_home\"         \n [7] \"score_away\"          \"team_away\"           \"team_favorite_id\"   \n[10] \"spread_favorite\"     \"over_under_line\"     \"stadium\"            \n[13] \"stadium_neutral\"     \"weather_temperature\" \"weather_wind_mph\"   \n[16] \"weather_humidity\"    \"weather_detail\"     \n\n\nCode\ngame_scores <- game_scores[game_scores$schedule_season == 2021 | game_scores$schedule_season == 2022, ]\nsummary(game_scores)\n\n\n schedule_date      schedule_season schedule_week      schedule_playoff\n Length:569         Min.   :2021    Length:569         Mode :logical   \n Class :character   1st Qu.:2021    Class :character   FALSE:543       \n Mode  :character   Median :2021    Mode  :character   TRUE :26        \n                    Mean   :2021                                       \n                    3rd Qu.:2022                                       \n                    Max.   :2022                                       \n                                                                       \n  team_home           score_home      score_away     team_away        \n Length:569         Min.   : 0.00   Min.   : 0.00   Length:569        \n Class :character   1st Qu.:17.00   1st Qu.:15.00   Class :character  \n Mode  :character   Median :23.00   Median :21.00   Mode  :character  \n                    Mean   :23.53   Mean   :21.52                     \n                    3rd Qu.:30.00   3rd Qu.:28.00                     \n                    Max.   :56.00   Max.   :51.00                     \n                                                                      \n team_favorite_id   spread_favorite   over_under_line   stadium         \n Length:569         Min.   :-20.000   Min.   :32.00   Length:569        \n Class :character   1st Qu.: -7.000   1st Qu.:42.00   Class :character  \n Mode  :character   Median : -4.000   Median :45.00   Mode  :character  \n                    Mean   : -5.452   Mean   :45.33                     \n                    3rd Qu.: -3.000   3rd Qu.:48.00                     \n                    Max.   : -1.000   Max.   :58.50                     \n                                                                        \n stadium_neutral weather_temperature weather_wind_mph weather_humidity\n Mode :logical   Min.   : 7.00       Min.   : 0.000   Min.   :  8.00  \n FALSE:558       1st Qu.:72.00       1st Qu.: 0.000   1st Qu.: 52.50  \n TRUE :11        Median :72.00       Median : 0.000   Median : 64.00  \n                 Mean   :64.57       Mean   : 2.411   Mean   : 66.11  \n                 3rd Qu.:72.00       3rd Qu.: 0.000   3rd Qu.: 81.00  \n                 Max.   :82.00       Max.   :33.000   Max.   :100.00  \n                 NA's   :334         NA's   :333      NA's   :506     \n weather_detail    \n Length:569        \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n                   \n\n\nCode\nglimpse(game_scores)\n\n\nRows: 569\nColumns: 17\n$ schedule_date       <chr> \"9/9/2021\", \"9/12/2021\", \"9/12/2021\", \"9/12/2021\",…\n$ schedule_season     <int> 2021, 2021, 2021, 2021, 2021, 2021, 2021, 2021, 20…\n$ schedule_week       <chr> \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", …\n$ schedule_playoff    <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, F…\n$ team_home           <chr> \"Tampa Bay Buccaneers\", \"Atlanta Falcons\", \"Buffal…\n$ score_home          <int> 31, 6, 16, 19, 27, 33, 37, 16, 33, 34, 16, 38, 13,…\n$ score_away          <int> 29, 32, 23, 14, 24, 41, 21, 28, 29, 14, 17, 3, 27,…\n$ team_away           <chr> \"Dallas Cowboys\", \"Philadelphia Eagles\", \"Pittsbur…\n$ team_favorite_id    <chr> \"TB\", \"ATL\", \"BUF\", \"CAR\", \"MIN\", \"SF\", \"JAX\", \"SE…\n$ spread_favorite     <dbl> -7.5, -3.5, -6.5, -5.0, -3.0, -7.5, -3.0, -2.5, -6…\n$ over_under_line     <dbl> 51.5, 48.0, 48.5, 44.5, 48.0, 46.0, 44.5, 48.5, 53…\n$ stadium             <chr> \"Raymond James Stadium\", \"Mercedes-Benz Stadium\", …\n$ stadium_neutral     <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, F…\n$ weather_temperature <int> NA, 72, NA, NA, NA, 72, 72, 72, NA, 72, NA, NA, NA…\n$ weather_wind_mph    <int> NA, 0, NA, NA, NA, 0, 0, 0, NA, 0, NA, NA, NA, NA,…\n$ weather_humidity    <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ weather_detail      <chr> \"\", \"indoor\", \"\", \"\", \"\", \"indoor\", \"indoor\", \"ind…\n\n\nThe second dataset I will use is a combination of data from Google Trends. To collect this data I pulled weekly “News Search” scores for each of the 32 NFL teams over the 2020-21 and 2021-22 season. To populate these scores, Google determines the week with the highest volume of News Searches within the time frame for each team and assigns it a score of 100. From there, the other weeks of the time frame get assigned their score to be the percentage of news search volume in proportion to the week scored as 100. For example, if week 7 was scored at 100 and week 3 had 30% of the news search volume that week 7 did, week 3’s score would be 30.\n\n\nCode\n#import csv for each NFL team\ndf1 <- read.csv(\"~/Documents/GitHub/603_Spring_2023/posts/_data/multiTimeline.csv\")\ndf2 <- read.csv(\"~/Documents/GitHub/603_Spring_2023/posts/_data/multiTimeline (1).csv\")\ndf3 <- read.csv(\"~/Documents/GitHub/603_Spring_2023/posts/_data/multiTimeline (2).csv\")\ndf4 <- read.csv(\"~/Documents/GitHub/603_Spring_2023/posts/_data/multiTimeline (3).csv\")\ndf5 <- read.csv(\"~/Documents/GitHub/603_Spring_2023/posts/_data/multiTimeline (4).csv\")\ndf6 <- read.csv(\"~/Documents/GitHub/603_Spring_2023/posts/_data/multiTimeline (5).csv\")\ndf7 <- read.csv(\"~/Documents/GitHub/603_Spring_2023/posts/_data/multiTimeline (6).csv\")\ndf8 <- read.csv(\"~/Documents/GitHub/603_Spring_2023/posts/_data/multiTimeline (7).csv\")\ndf9 <- read.csv(\"~/Documents/GitHub/603_Spring_2023/posts/_data/multiTimeline (8).csv\")\ndf10 <- read.csv(\"~/Documents/GitHub/603_Spring_2023/posts/_data/multiTimeline (9).csv\")\ndf11 <- read.csv(\"~/Documents/GitHub/603_Spring_2023/posts/_data/multiTimeline (10).csv\")\ndf12 <- read.csv(\"~/Documents/GitHub/603_Spring_2023/posts/_data/multiTimeline (11).csv\")\ndf13 <- read.csv(\"~/Documents/GitHub/603_Spring_2023/posts/_data/multiTimeline (12).csv\")\ndf14 <- read.csv(\"~/Documents/GitHub/603_Spring_2023/posts/_data/multiTimeline (13).csv\")\ndf15 <- read.csv(\"~/Documents/GitHub/603_Spring_2023/posts/_data/multiTimeline (14).csv\")\ndf16 <- read.csv(\"~/Documents/GitHub/603_Spring_2023/posts/_data/multiTimeline (15).csv\")\ndf17 <- read.csv(\"~/Documents/GitHub/603_Spring_2023/posts/_data/multiTimeline (16).csv\")\ndf18 <- read.csv(\"~/Documents/GitHub/603_Spring_2023/posts/_data/multiTimeline (17).csv\")\ndf19 <- read.csv(\"~/Documents/GitHub/603_Spring_2023/posts/_data/multiTimeline (18).csv\")\ndf20 <- read.csv(\"~/Documents/GitHub/603_Spring_2023/posts/_data/multiTimeline (19).csv\")\ndf21 <- read.csv(\"~/Documents/GitHub/603_Spring_2023/posts/_data/multiTimeline (20).csv\")\ndf22 <- read.csv(\"~/Documents/GitHub/603_Spring_2023/posts/_data/multiTimeline (21).csv\")\ndf23 <- read.csv(\"~/Documents/GitHub/603_Spring_2023/posts/_data/multiTimeline (22).csv\")\ndf24 <- read.csv(\"~/Documents/GitHub/603_Spring_2023/posts/_data/multiTimeline (23).csv\")\ndf25 <- read.csv(\"~/Documents/GitHub/603_Spring_2023/posts/_data/multiTimeline (24).csv\")\ndf26 <- read.csv(\"~/Documents/GitHub/603_Spring_2023/posts/_data/multiTimeline (25).csv\")\ndf27 <- read.csv(\"~/Documents/GitHub/603_Spring_2023/posts/_data/multiTimeline (26).csv\")\ndf28 <- read.csv(\"~/Documents/GitHub/603_Spring_2023/posts/_data/multiTimeline (27).csv\")\ndf29 <- read.csv(\"~/Documents/GitHub/603_Spring_2023/posts/_data/multiTimeline (28).csv\")\ndf30 <- read.csv(\"~/Documents/GitHub/603_Spring_2023/posts/_data/multiTimeline (29).csv\")\ndf31 <- read.csv(\"~/Documents/GitHub/603_Spring_2023/posts/_data/multiTimeline (30).csv\")\ndf32 <- read.csv(\"~/Documents/GitHub/603_Spring_2023/posts/_data/multiTimeline (31).csv\")\n\n#bind columns to create one data frame that holds all the scores for each team\ntrend_scores <- bind_cols(df1,df2,df3,df4,df5,df6,df7,df8,df9,df10,df11,df12,df13,df14,df15,\n                          df16,df17,df18,df19,df20,df21,df22,df23,df24,df25,df26,df27,df28,df29,df30,df31,df32)\n\n\nNew names:\n* Category..All.categories -> Category..All.categories...1\n* Category..All.categories -> Category..All.categories...2\n* Category..All.categories -> Category..All.categories...3\n* Category..All.categories -> Category..All.categories...4\n* Category..All.categories -> Category..All.categories...5\n* ...\n\n\nCode\n#create new column that holds the dates for each week, which R stored as the row names\ntrend_scores <- rownames_to_column(trend_scores, \"Week\")\n#rename column names to be row one values so that each column is the team name\ntrend_scores <- trend_scores %>% \n  row_to_names(row_number = 1)\nsummary(trend_scores)\n\n\n     Week           Tennessee Titans: (United States)\n Length:83          Length:83                        \n Class :character   Class :character                 \n Mode  :character   Mode  :character                 \n Jacksonville Jaguars: (United States) Philadelphia Eagles: (United States)\n Length:83                             Length:83                           \n Class :character                      Class :character                    \n Mode  :character                      Mode  :character                    \n Kansas City Chiefs: (United States) Chicago Bears: (United States)\n Length:83                           Length:83                     \n Class :character                    Class :character              \n Mode  :character                    Mode  :character              \n Green Bay Packers: (United States) San Francisco 49ers: (United States)\n Length:83                          Length:83                           \n Class :character                   Class :character                    \n Mode  :character                   Mode  :character                    \n Minnesota Vikings: (United States) New York Giants: (United States)\n Length:83                          Length:83                       \n Class :character                   Class :character                \n Mode  :character                   Mode  :character                \n Las Vegas Raiders: (United States) Buffalo Bills: (United States)\n Length:83                          Length:83                     \n Class :character                   Class :character              \n Mode  :character                   Mode  :character              \n New England Patriots: (United States) Carolina Panthers: (United States)\n Length:83                             Length:83                         \n Class :character                      Class :character                  \n Mode  :character                      Mode  :character                  \n Miami Dolphins: (United States) Seattle Seahawks: (United States)\n Length:83                       Length:83                        \n Class :character                Class :character                 \n Mode  :character                Mode  :character                 \n Detroit Lions: (United States) Cincinnati Bengals: (United States)\n Length:83                      Length:83                          \n Class :character               Class :character                   \n Mode  :character               Mode  :character                   \n New Orleans Saints: (United States) Denver Broncos: (United States)\n Length:83                           Length:83                      \n Class :character                    Class :character               \n Mode  :character                    Mode  :character               \n Baltimore Ravens: (United States) New York Jets: (United States)\n Length:83                         Length:83                     \n Class :character                  Class :character              \n Mode  :character                  Mode  :character              \n Washington Commanders: (United States) Houston Texans: (United States)\n Length:83                              Length:83                      \n Class :character                       Class :character               \n Mode  :character                       Mode  :character               \n Tampa Bay Buccaneers: (United States) Indianapolis Colts: (United States)\n Length:83                             Length:83                          \n Class :character                      Class :character                   \n Mode  :character                      Mode  :character                   \n Cleveland Browns: (United States) Arizona Cardinals: (United States)\n Length:83                         Length:83                         \n Class :character                  Class :character                  \n Mode  :character                  Mode  :character                  \n Los Angeles Chargers: (United States) Los Angeles Rams: (United States)\n Length:83                             Length:83                        \n Class :character                      Class :character                 \n Mode  :character                      Mode  :character                 \n Atlanta Falcons: (United States) Dallas Cowboys: (United States)\n Length:83                        Length:83                      \n Class :character                 Class :character               \n Mode  :character                 Mode  :character               \n Pittsburgh Steelers: (United States)\n Length:83                           \n Class :character                    \n Mode  :character                    \n\n\nCode\nglimpse(trend_scores)\n\n\nRows: 83\nColumns: 33\n$ Week                                     <chr> \"2021-08-01\", \"2021-08-08\", \"…\n$ `Tennessee Titans: (United States)`      <chr> \"12\", \"29\", \"32\", \"41\", \"37\",…\n$ `Jacksonville Jaguars: (United States)`  <chr> \"10\", \"14\", \"17\", \"24\", \"16\",…\n$ `Philadelphia Eagles: (United States)`   <chr> \"17\", \"19\", \"15\", \"18\", \"16\",…\n$ `Kansas City Chiefs: (United States)`    <chr> \"6\", \"4\", \"14\", \"7\", \"10\", \"1…\n$ `Chicago Bears: (United States)`         <chr> \"15\", \"26\", \"30\", \"21\", \"46\",…\n$ `Green Bay Packers: (United States)`     <chr> \"21\", \"18\", \"22\", \"17\", \"33\",…\n$ `San Francisco 49ers: (United States)`   <chr> \"11\", \"9\", \"18\", \"26\", \"31\", …\n$ `Minnesota Vikings: (United States)`     <chr> \"30\", \"29\", \"38\", \"36\", \"60\",…\n$ `New York Giants: (United States)`       <chr> \"18\", \"42\", \"31\", \"30\", \"54\",…\n$ `Las Vegas Raiders: (United States)`     <chr> \"15\", \"22\", \"39\", \"15\", \"46\",…\n$ `Buffalo Bills: (United States)`         <chr> \"2\", \"1\", \"1\", \"2\", \"3\", \"3\",…\n$ `New England Patriots: (United States)`  <chr> \"30\", \"26\", \"38\", \"32\", \"92\",…\n$ `Carolina Panthers: (United States)`     <chr> \"9\", \"20\", \"57\", \"38\", \"48\", …\n$ `Miami Dolphins: (United States)`        <chr> \"13\", \"22\", \"27\", \"19\", \"45\",…\n$ `Seattle Seahawks: (United States)`      <chr> \"22\", \"19\", \"19\", \"22\", \"28\",…\n$ `Detroit Lions: (United States)`         <chr> \"33\", \"32\", \"42\", \"39\", \"51\",…\n$ `Cincinnati Bengals: (United States)`    <chr> \"0\", \"1\", \"3\", \"4\", \"0\", \"2\",…\n$ `New Orleans Saints: (United States)`    <chr> \"26\", \"24\", \"23\", \"59\", \"46\",…\n$ `Denver Broncos: (United States)`        <chr> \"27\", \"34\", \"23\", \"33\", \"40\",…\n$ `Baltimore Ravens: (United States)`      <chr> \"6\", \"25\", \"47\", \"18\", \"70\", …\n$ `New York Jets: (United States)`         <chr> \"18\", \"29\", \"57\", \"29\", \"52\",…\n$ `Washington Commanders: (United States)` <chr> \"12\", \"31\", \"20\", \"40\", \"42\",…\n$ `Houston Texans: (United States)`        <chr> \"41\", \"48\", \"90\", \"12\", \"70\",…\n$ `Tampa Bay Buccaneers: (United States)`  <chr> \"7\", \"8\", \"18\", \"8\", \"29\", \"5…\n$ `Indianapolis Colts: (United States)`    <chr> \"14\", \"45\", \"37\", \"16\", \"42\",…\n$ `Cleveland Browns: (United States)`      <chr> \"18\", \"14\", \"18\", \"20\", \"24\",…\n$ `Arizona Cardinals: (United States)`     <chr> \"19\", \"11\", \"0\", \"26\", \"21\", …\n$ `Los Angeles Chargers: (United States)`  <chr> \"3\", \"14\", \"4\", \"32\", \"8\", \"1…\n$ `Los Angeles Rams: (United States)`      <chr> \"4\", \"8\", \"11\", \"12\", \"10\", \"…\n$ `Atlanta Falcons: (United States)`       <chr> \"10\", \"47\", \"19\", \"33\", \"56\",…\n$ `Dallas Cowboys: (United States)`        <chr> \"26\", \"20\", \"24\", \"20\", \"42\",…\n$ `Pittsburgh Steelers: (United States)`   <chr> \"26\", \"23\", \"25\", \"31\", \"45\",…"
  },
  {
    "objectID": "posts/HW1_young.html",
    "href": "posts/HW1_young.html",
    "title": "Homework 1",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.1     ✔ purrr   1.0.1\n✔ tibble  3.1.8     ✔ dplyr   1.1.0\n✔ tidyr   1.3.0     ✔ stringr 1.5.0\n✔ readr   2.1.4     ✔ forcats 1.0.0\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\nCode\nlibrary(dplyr)\nlibrary(readxl)\ndf <- read_excel(\"C:/Users/rotte/Documents/R/603_Spring_2023/posts/_data/LungCapData.xls\")"
  },
  {
    "objectID": "posts/HW1_young.html#a",
    "href": "posts/HW1_young.html#a",
    "title": "Homework 1",
    "section": "a",
    "text": "a\n\n\nCode\n# descriptive statistics\nsummary(df$LungCap)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  0.507   6.150   8.000   7.863   9.800  14.675 \n\n\nCode\nsd(df$LungCap)\n\n\n[1] 2.662008\n\n\n\n\nCode\n# making histogram\nhist(df$LungCap)\n\n\n\n\n\nRange is 0.507~14.675. Median is 8.00. And it’s distribution is looks like normal distribution that mean is 7.863 and sd is 2.662."
  },
  {
    "objectID": "posts/HW1_young.html#b",
    "href": "posts/HW1_young.html#b",
    "title": "Homework 1",
    "section": "b",
    "text": "b\n\n\nCode\n# descriptive statistics\ndf %>%\n  group_by(Gender) %>%\n  summarise(mean(LungCap), sd(LungCap))\n\n\n# A tibble: 2 × 3\n  Gender `mean(LungCap)` `sd(LungCap)`\n  <chr>            <dbl>         <dbl>\n1 female            7.41          2.56\n2 male              8.31          2.68\n\n\n\n\nCode\n# making boxplot\nboxplot(LungCap~Gender, df)\n\n\n\n\n\nMean and sd of female’s LungCap are 7.406 and 2.564, respectively. And Mean and sd of male’s LungCap are 8.309 and 2.683, respectively. Male’s LungCap is bigger than female’s. We can also check this through boxplot."
  },
  {
    "objectID": "posts/HW1_young.html#c",
    "href": "posts/HW1_young.html#c",
    "title": "Homework 1",
    "section": "c",
    "text": "c\n\n\nCode\n# finding lungcap for smokers and non-smokers\ndf %>% group_by(Smoke) %>%\n  summarise(mean(LungCap))\n\n\n# A tibble: 2 × 2\n  Smoke `mean(LungCap)`\n  <chr>           <dbl>\n1 no               7.77\n2 yes              8.65\n\n\nSmokers have bigger Lung cap. It’s a different result from common sense. Through the t-test, I will find out whether this result is statistically significant.\n\n\nCode\nt.test(LungCap~Smoke, df, alternative=\"less\")\n\n\n\n    Welch Two Sample t-test\n\ndata:  LungCap by Smoke\nt = -3.6498, df = 117.72, p-value = 0.0001964\nalternative hypothesis: true difference in means between group no and group yes is less than 0\n95 percent confidence interval:\n       -Inf -0.4776762\nsample estimates:\n mean in group no mean in group yes \n         7.770188          8.645455 \n\n\nAs a result of the one-sided t-test, it was found to be statistically significant at the 95% level of significance.\n##d\nFirst, a new variable cAge is created and a new value is given for each age. For those under the age of 13, “Child”, 14, 15 years of age “Middle”, 16, 17 years of age “High”, and 18 years of age or older, “Adult” will be assigned.\n\n\nCode\ndf<-mutate(df, cAge = ifelse(Age<=13, \"Child\", ifelse(Age %in% 14:15, \"Middle\", ifelse(Age %in% 16:17, \"High\", \"Adult\"))))\n\n\n\n\nCode\ndf %>% group_by(cAge) %>%\n  summarise(mean(LungCap))\n\n\n# A tibble: 4 × 2\n  cAge   `mean(LungCap)`\n  <chr>            <dbl>\n1 Adult            11.0 \n2 Child             6.41\n3 High             10.2 \n4 Middle            9.05\n\n\n\n\nCode\nggplot(df, aes(x=Age, y=LungCap)) +\n  geom_point()\n\n\n\n\n\nLooking at each group’s lung caps, child is 6.41, middle is 9.05, high is 10.25, and adult is 10.96. That is, the lung caps grow with age. Here, it is possible to infer why the lung caps of smokers and non-smokers presented in this data are different from our common sense. The more adults there are, the more smokers there will be, and that may have led to a larger lung cap for smokers.\n##e\nFirst, let’s look at the children’s group.\n\n\nCode\nchilddf<-filter(df, cAge==\"Child\")\ntable(childdf$Smoke)\n\n\n\n no yes \n401  27 \n\n\nCode\nchilddf%>%group_by(Smoke) %>%\n  summarise(mean(LungCap))\n\n\n# A tibble: 2 × 2\n  Smoke `mean(LungCap)`\n  <chr>           <dbl>\n1 no               6.36\n2 yes              7.20\n\n\nSmokers have bigger lung cap. Let’s look at the picture in more detail.\n\n\nCode\nggplot(childdf, aes(x=Age, y=LungCap)) +\n  geom_point(aes(col=factor(Smoke)))\n\n\n\n\n\nFrom the plot, the older the age, the larger the lung cap for non-smokers. In other words, when looking at the entire child group, the growth of natural lung caps with growth is not well revealed, so smokers’ lung caps seem to be larger.\nNext, let’s look at the middle group.\n\n\nCode\nmiddf<-filter(df, cAge==\"Middle\")\ntable(middf$Smoke)\n\n\n\n no yes \n105  15 \n\n\nCode\nmiddf%>%group_by(Smoke) %>%\n  summarise(mean(LungCap))\n\n\n# A tibble: 2 × 2\n  Smoke `mean(LungCap)`\n  <chr>           <dbl>\n1 no               9.14\n2 yes              8.39\n\n\n\n\nCode\nboxplot(LungCap~Smoke, middf)\n\n\n\n\n\nNon-smokers of middle group seem to have bigger lung caps.\nThen, let’s look at the high group.\n\n\nCode\nhighdf<-filter(df, cAge==\"High\")\ntable(highdf$Smoke)\n\n\n\n no yes \n 77  20 \n\n\nCode\nhighdf%>%group_by(Smoke) %>%\n  summarise(mean(LungCap))\n\n\n# A tibble: 2 × 2\n  Smoke `mean(LungCap)`\n  <chr>           <dbl>\n1 no              10.5 \n2 yes              9.38\n\n\n\n\nCode\nboxplot(LungCap~Smoke, highdf)\n\n\n\n\n\nNon-smokers of high group also have bigger lung caps.\nLastly, let me check the adult group.\n\n\nCode\nadultdf<-filter(df, cAge==\"Adult\")\ntable(adultdf$Smoke)\n\n\n\n no yes \n 65  15 \n\n\nCode\nadultdf%>%group_by(Smoke) %>%\n  summarise(mean(LungCap))\n\n\n# A tibble: 2 × 2\n  Smoke `mean(LungCap)`\n  <chr>           <dbl>\n1 no               11.1\n2 yes              10.5\n\n\n\n\nCode\nboxplot(LungCap~Smoke, adultdf)\n\n\n\n\n\nEven in the adult group, non-smokers have a bigger lung cap.\nFinally, I took a look at the overall plot.\n\n\nCode\nggplot(df, aes(x=Age, y=LungCap)) +\n  geom_point(aes(col=factor(Smoke)))\n\n\n\n\n\nOverall, it seems that the lung cap of non-smokers (red) is higher than that of smokers (blue)."
  },
  {
    "objectID": "posts/HW1_young.html#a-1",
    "href": "posts/HW1_young.html#a-1",
    "title": "Homework 1",
    "section": "a",
    "text": "a\nThe probability of selecting inmate has exact 2 priority convictions is the number of inmates with 2 priority convictions divided by the total number of inmates.\n\n\nCode\n160/sum(p_df$freq)\n\n\n[1] 0.1975309\n\n\nThe answer is 0.1975."
  },
  {
    "objectID": "posts/HW1_young.html#b-1",
    "href": "posts/HW1_young.html#b-1",
    "title": "Homework 1",
    "section": "b",
    "text": "b\nIn the same way, the frequency of 0 priority convictions and 1 priority convictions can be combined and divided into the total number of prisoners.\n\n\nCode\n(128+434)/sum(p_df$freq)\n\n\n[1] 0.6938272\n\n\nThe answer is 0.6938."
  },
  {
    "objectID": "posts/HW1_young.html#c-1",
    "href": "posts/HW1_young.html#c-1",
    "title": "Homework 1",
    "section": "c",
    "text": "c\nAdd the probabilities obtained from problems a and b to get the answer.\n\n\nCode\n(160/sum(p_df$freq))+((128+434)/sum(p_df$freq))\n\n\n[1] 0.891358\n\n\nThe answer is 0.8914."
  },
  {
    "objectID": "posts/HW1_young.html#d",
    "href": "posts/HW1_young.html#d",
    "title": "Homework 1",
    "section": "d",
    "text": "d\nThis time, we can get the answer using the probability obtained from c. The total sum of the probabilities is 1, so you can get the answer by subtracting the value obtained from 1 and c.\n\n\nCode\n1-((160/sum(p_df$freq))+((128+434)/sum(p_df$freq)))\n\n\n[1] 0.108642\n\n\nThe answer is 0.1086."
  },
  {
    "objectID": "posts/HW1_young.html#e",
    "href": "posts/HW1_young.html#e",
    "title": "Homework 1",
    "section": "e",
    "text": "e\nTo obtain the expected value, we divide the sum of priority convictions(x) times frequency (freq) by the total number of prisoners.\n\n\nCode\nsum(p_df$x*p_df$freq)/810\n\n\n[1] 1.28642\n\n\nIn another way, the probability of priority conversions can be obtained and the expected value can be obtained by summing each frequency multiplied by this value.\n\n\nCode\np_df<-mutate(p_df, pro=freq/810)\np_df\n\n\n  x freq        pro\n1 0  128 0.15802469\n2 1  434 0.53580247\n3 2  160 0.19753086\n4 3   64 0.07901235\n5 4   24 0.02962963\n\n\n\n\nCode\nsum(p_df$x*p_df$pro)\n\n\n[1] 1.28642\n\n\nThe answer is the same."
  },
  {
    "objectID": "posts/HW1_young.html#f",
    "href": "posts/HW1_young.html#f",
    "title": "Homework 1",
    "section": "f",
    "text": "f\n\n\nCode\nmean<-sum(p_df$x*p_df$pro)\n\n\nFirst, to obtain the variance, get the sum of the squared difference between the x-value and the average value (expected value) and divided by the total number of prisoners.\nThe standard deviation is the square root of the variance.\n\n\nCode\nsum((x-mean)^2*p_df$freq)/810\n\n\n[1] 0.8562353\n\n\nCode\nsqrt(sum((x-mean)^2*p_df$freq)/810)\n\n\n[1] 0.9253298\n\n\nVariance is 0.8562 and standard deviation is 0.925.\nAlternatively, the variance can be obtained by multiplying the square of the difference between the x-value and the average value by each probability.\n\n\nCode\nsum((x-mean)^2*p_df$pro)\n\n\n[1] 0.8562353\n\n\nCode\nsqrt(sum((x-mean)^2*p_df$pro))\n\n\n[1] 0.9253298\n\n\nAs expected, the answer is the same."
  },
  {
    "objectID": "posts/abigailbalint_finalpart1.html",
    "href": "posts/abigailbalint_finalpart1.html",
    "title": "Final Project Initial Research",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(dplyr)\nknitr::opts_chunk$set(echo = TRUE)"
  },
  {
    "objectID": "posts/abigailbalint_finalpart1.html#description-of-data",
    "href": "posts/abigailbalint_finalpart1.html#description-of-data",
    "title": "Final Project Initial Research",
    "section": "Description of data",
    "text": "Description of data\nThe dataset I am using comes from Kaggle https://www.kaggle.com/datasets/kaggle/kaggle-survey-2018 and is a survey titled “2018 Kaggle Machine Learning & Data Science Survey” conducted by Kaggle to capture the current state of machine learning and data science usage, mainly at the enterprise and academic level. The dataset contains survey responses from almost 24,000 respondents from varying backgrounds. The survey contains 50 questions, including 9 demographic questions and 41 questions around machine learning and data science. The questions range from platforms and products used, and tools and methodology, barriers to entry, and more. It also asks respondents about their employee experience working in these fields. I believe that the wide array of types of questions used make this dataset a good fit for research, as there are binary and categorical variables to explore but also some that ask for explicit numeric values like what percentage of their work falls to different tasks. Having several different types of questions provide opportunities for multiple types of models to be performed.\nThis survey was also run in 2017, 2019, and 2020 on Kaggle as part of an annual competition where users could submit code and analysis using this public data. However, I decided to use the 2018 dataset as my focus because certain questions that I think would be really interesting to analyze were omitted in later years/the survey was shortened overall. This survey was hosted by Kaggle, open to anyone in the industry, for one week in October 2018.\nReading in the dataset –\n\n\nCode\nfinal <- read_csv(\"_data/final_project_data.csv\")\n\n\nWarning: One or more parsing issues, see `problems()` for details\n\n\nRows: 23859 Columns: 395\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (343): Q1, Q2, Q3, Q4, Q5, Q6, Q7, Q8, Q9, Q10, Q11_Part_1, Q11_Part_2, ...\ndbl  (48): Time from Start to Finish (seconds), Q1_OTHER_TEXT, Q6_OTHER_TEXT...\nlgl   (4): Q28_Part_24, Q30_Part_15, Q38_Part_19, Q38_Part_20\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCode\nfinal2 <- read_csv(\"_data/final_project_data2.csv\")\n\n\nWarning: One or more parsing issues, see `problems()` for details\n\n\nRows: 23859 Columns: 395\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (343): What is your gender? - Selected Choice, What is your age (# years...\ndbl  (48): Duration (in seconds), What is your gender? - Prefer to self-desc...\nlgl   (4): Which of the following machine learning products have you used at...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCode\nhead(final2,10)\n\n\n# A tibble: 10 × 395\n   Duration (i…¹ What …² What …³ What …⁴ In wh…⁵ What …⁶ Which…⁷ Selec…⁸ Selec…⁹\n           <dbl> <chr>     <dbl> <chr>   <chr>   <chr>   <chr>   <chr>     <dbl>\n 1           710 Female       -1 45-49   United… Doctor… Other   Consul…      -1\n 2           434 Male         -1 30-34   Indone… Bachel… Engine… Other         0\n 3           718 Female       -1 30-34   United… Master… Comput… Data S…      -1\n 4           621 Male         -1 35-39   United… Master… Social… Not em…      -1\n 5           731 Male         -1 22-24   India   Master… Mathem… Data A…      -1\n 6          1142 Male         -1 25-29   Colomb… Bachel… Physic… Data S…      -1\n 7           959 Male         -1 35-39   Chile   Doctor… Inform… Other         1\n 8          1758 Male         -1 18-21   India   Master… Inform… Other         2\n 9           641 Male         -1 25-29   Turkey  Master… Engine… Not em…      -1\n10           751 Male         -1 30-34   Hungary Master… Engine… Softwa…      -1\n# … with 386 more variables:\n#   `In what industry is your current employer/contract (or your most recent employer if retired)? - Selected Choice` <chr>,\n#   `In what industry is your current employer/contract (or your most recent employer if retired)? - Other - Text` <dbl>,\n#   `How many years of experience do you have in your current role?` <chr>,\n#   `What is your current yearly compensation (approximate $USD)?` <chr>,\n#   `Does your current employer incorporate machine learning methods into their business?` <chr>,\n#   `Select any activities that make up an important part of your role at work: (Select all that apply) - Selected Choice - Analyze and understand data to influence product or business decisions` <chr>, …"
  },
  {
    "objectID": "posts/abigailbalint_finalpart1.html#research-question",
    "href": "posts/abigailbalint_finalpart1.html#research-question",
    "title": "Final Project Initial Research",
    "section": "Research Question",
    "text": "Research Question\nUpon doing a cursory search around this data, I see some high level executive-summary style research published about this data set, but I wasn’t able to find anything focused on more specific research questions. It was more demographic data of the state of ML and Data Science. I think there is the opportunity to speak more specifically about the state of machine learning and data science, and look deeper at what tools students and employees are using versus what their time is devoted to.\nTherefore, my main research question is “What is the state of machine learning and data science? What tools are being used in the context of individuals school and work, and how does an individual’s background (age, career, education, etc.) impact how they navigate this tech world? What barriers do users face and are those barriers the same for all users?”\nI plan to use questions like “During a typical data science project at work or school, approximately what proportion of your time is devoted to the following?” or “What percentage of your current machine learning/data science training falls under each category?” to get exact numbers that I can correlate against demos and more general usage of tools and platforms to see if there is any connection between the work one does and the tools they use.\nI am interested in this dataset because a lot of research in my career is in the machine learning space, so I am always interested in contextualizing the employee experience in these areas so that I can better understand the subject of some of my survey research. I also do more general employee engagement research in my career and I think this final is a great opportunity to try my hand at some of the correlations I would like to run at my job now but have never been able to because I don’t have any prior stats knowledge."
  },
  {
    "objectID": "posts/abigailbalint_finalpart1.html#hypothesis",
    "href": "posts/abigailbalint_finalpart1.html#hypothesis",
    "title": "Final Project Initial Research",
    "section": "Hypothesis",
    "text": "Hypothesis\nI would like to test a few different hypotheses that I have. Some of the initial ideas I have currently are:\n-Students are more likely to use free, long-standing coding and ML platforms as opposed to employees using more paid tools with user-friendly features.\n-For the question “How do you perceive the importance of the following topics? - Fairness and bias in ML algorithms, Being able to explain ML model outputs and/or predictions, Reproducibility in data science”, students will perceive this as more important than full-time workers, and younger generations will perceive this as more important than older generations.\n-For the question “During a typical data science project at work or school, approximately what proportion of your time is devoted to the following?” time spent on the analysis end of the process will be reported as a higher percentage of time the older or more experienced the data scientist is.\nThese are just a few ideas of the direction I am thinking, all of course cut by the demographics in this dataset like age, education, industry, years of experience, etc."
  },
  {
    "objectID": "posts/abigailbalint_finalpart1.html#descriptive-statistics",
    "href": "posts/abigailbalint_finalpart1.html#descriptive-statistics",
    "title": "Final Project Initial Research",
    "section": "Descriptive Statistics",
    "text": "Descriptive Statistics\nI described my dataset at the top of this as well as discussed variables of interest in the Research Question section, but here is a little bit of exploratory code:\nI can see the data contains mostly younger males, but because of the sample size can really work with lots of demographic combinations.\n\n\nCode\nggplot(final, aes(x = Q1)) +\n  geom_bar() +\n   labs(x=\"Gender\")\n\n\n\n\n\n\n\nCode\nggplot(final, aes(x = Q2)) +\n  geom_bar() +\n  labs(x=\"Age\") +\n  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))\n\n\n\n\n\nThere is also a range of coding experience in the dataset.\n\n\nCode\nggplot(final, aes(x = Q24)) +\n  geom_bar() +\n   labs(x=\"Years of coding experience\") +\n  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))\n\n\n\n\n\nThe data is split between students, tech industry employees, and other industry employees.\n\n\nCode\nggplot(final, aes(x = Q7)) +\n  geom_bar() +\n   labs(x=\"Industry\") +\n  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))\n\n\n\n\n\nThis is just a quick example of the types of thinking I want to do for my final poster. Here, I made a scatterplot showing where the amount of training from work meets the amount of time spent finding insights instead of cleaning data, coding, etc. I expected this to be much higher for those who received most or all of their training from work, but that isn’t the case. I’m interested to see once I define a few more specific hypotheses if they end up being true or false.\n\n\nCode\nggplot(final, aes(x = Q35_Part_3, y=Q34_Part_6)) +\n  geom_point() +\n   labs(x=\"Percentage of machine learning training from work\", y=\"Percentage of project time spent finding insights\")\n\n\nWarning: Removed 8114 rows containing missing values (geom_point).\n\n\n\n\n\nHere is the glimpse function to show essentially the questionaiire in text form. I’m working with the variable codes in my coding and using a key as the codes are much shorter.\n\n\nCode\nglimpse(final2)\n\n\nRows: 23,859\nColumns: 395\n$ `Duration (in seconds)`                                                                                                                                                                                                                     <dbl> …\n$ `What is your gender? - Selected Choice`                                                                                                                                                                                                    <chr> …\n$ `What is your gender? - Prefer to self-describe - Text`                                                                                                                                                                                     <dbl> …\n$ `What is your age (# years)?`                                                                                                                                                                                                               <chr> …\n$ `In which country do you currently reside?`                                                                                                                                                                                                 <chr> …\n$ `What is the highest level of formal education that you have attained or plan to attain within the next 2 years?`                                                                                                                           <chr> …\n$ `Which best describes your undergraduate major? - Selected Choice`                                                                                                                                                                          <chr> …\n$ `Select the title most similar to your current role (or most recent title if retired): - Selected Choice`                                                                                                                                   <chr> …\n$ `Select the title most similar to your current role (or most recent title if retired): - Other - Text`                                                                                                                                      <dbl> …\n$ `In what industry is your current employer/contract (or your most recent employer if retired)? - Selected Choice`                                                                                                                           <chr> …\n$ `In what industry is your current employer/contract (or your most recent employer if retired)? - Other - Text`                                                                                                                              <dbl> …\n$ `How many years of experience do you have in your current role?`                                                                                                                                                                            <chr> …\n$ `What is your current yearly compensation (approximate $USD)?`                                                                                                                                                                              <chr> …\n$ `Does your current employer incorporate machine learning methods into their business?`                                                                                                                                                      <chr> …\n$ `Select any activities that make up an important part of your role at work: (Select all that apply) - Selected Choice - Analyze and understand data to influence product or business decisions`                                             <chr> …\n$ `Select any activities that make up an important part of your role at work: (Select all that apply) - Selected Choice - Build and/or run a machine learning service that operationally improves my product or workflows`                    <chr> …\n$ `Select any activities that make up an important part of your role at work: (Select all that apply) - Selected Choice - Build and/or run the data infrastructure that my business uses for storing, analyzing, and operationalizing data`   <chr> …\n$ `Select any activities that make up an important part of your role at work: (Select all that apply) - Selected Choice - Build prototypes to explore applying machine learning to new areas`                                                 <chr> …\n$ `Select any activities that make up an important part of your role at work: (Select all that apply) - Selected Choice - Do research that advances the state of the art of machine learning`                                                 <chr> …\n$ `Select any activities that make up an important part of your role at work: (Select all that apply) - Selected Choice - None of these activities are an important part of my role at work`                                                  <chr> …\n$ `Select any activities that make up an important part of your role at work: (Select all that apply) - Selected Choice - Other`                                                                                                              <chr> …\n$ `Select any activities that make up an important part of your role at work: (Select all that apply) - Other - Text`                                                                                                                         <dbl> …\n$ `What is the primary tool that you use at work or school to analyze data? (include text response) - Selected Choice`                                                                                                                        <chr> …\n$ `What is the primary tool that you use at work or school to analyze data? (include text response) - Basic statistical software (Microsoft Excel, Google Sheets, etc.) - Text`                                                               <dbl> …\n$ `What is the primary tool that you use at work or school to analyze data? (include text response) - Advanced statistical software (SPSS, SAS, etc.) - Text`                                                                                 <dbl> …\n$ `What is the primary tool that you use at work or school to analyze data? (include text response) - Business intelligence software (Salesforce, Tableau, Spotfire, etc.) - Text`                                                            <dbl> …\n$ `What is the primary tool that you use at work or school to analyze data? (include text response) - Local or hosted development environments (RStudio, JupyterLab, etc.) - Text`                                                            <dbl> …\n$ `What is the primary tool that you use at work or school to analyze data? (include text response) - Cloud-based data software & APIs (AWS, GCP, Azure, etc.) - Text`                                                                        <dbl> …\n$ `What is the primary tool that you use at work or school to analyze data? (include text response) - Other - Text`                                                                                                                           <dbl> …\n$ `Which of the following integrated development environments (IDE's) have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Jupyter/IPython`                                                       <chr> …\n$ `Which of the following integrated development environments (IDE's) have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - RStudio`                                                               <chr> …\n$ `Which of the following integrated development environments (IDE's) have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - PyCharm`                                                               <chr> …\n$ `Which of the following integrated development environments (IDE's) have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Visual Studio Code`                                                    <chr> …\n$ `Which of the following integrated development environments (IDE's) have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - nteract`                                                               <chr> …\n$ `Which of the following integrated development environments (IDE's) have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Atom`                                                                  <chr> …\n$ `Which of the following integrated development environments (IDE's) have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - MATLAB`                                                                <chr> …\n$ `Which of the following integrated development environments (IDE's) have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Visual Studio`                                                         <chr> …\n$ `Which of the following integrated development environments (IDE's) have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Notepad++`                                                             <chr> …\n$ `Which of the following integrated development environments (IDE's) have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Sublime Text`                                                          <chr> …\n$ `Which of the following integrated development environments (IDE's) have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Vim`                                                                   <chr> …\n$ `Which of the following integrated development environments (IDE's) have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - IntelliJ`                                                              <chr> …\n$ `Which of the following integrated development environments (IDE's) have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Spyder`                                                                <chr> …\n$ `Which of the following integrated development environments (IDE's) have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - None`                                                                  <chr> …\n$ `Which of the following integrated development environments (IDE's) have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Other`                                                                 <chr> …\n$ `Which of the following integrated development environments (IDE's) have you used at work or school in the last 5 years? (Select all that apply) - Other - Text`                                                                            <dbl> …\n$ `Which of the following hosted notebooks have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Kaggle Kernels`                                                                                   <chr> …\n$ `Which of the following hosted notebooks have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Google Colab`                                                                                     <chr> …\n$ `Which of the following hosted notebooks have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Azure Notebook`                                                                                   <chr> …\n$ `Which of the following hosted notebooks have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Domino Datalab`                                                                                   <chr> …\n$ `Which of the following hosted notebooks have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Google Cloud Datalab`                                                                             <chr> …\n$ `Which of the following hosted notebooks have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Paperspace`                                                                                       <chr> …\n$ `Which of the following hosted notebooks have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Floydhub`                                                                                         <chr> …\n$ `Which of the following hosted notebooks have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Crestle`                                                                                          <chr> …\n$ `Which of the following hosted notebooks have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - JupyterHub/Binder`                                                                                <chr> …\n$ `Which of the following hosted notebooks have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - None`                                                                                             <chr> …\n$ `Which of the following hosted notebooks have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Other`                                                                                            <chr> …\n$ `Which of the following hosted notebooks have you used at work or school in the last 5 years? (Select all that apply) - Other - Text`                                                                                                       <dbl> …\n$ `Which of the following cloud computing services have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Google Cloud Platform (GCP)`                                                              <chr> …\n$ `Which of the following cloud computing services have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Amazon Web Services (AWS)`                                                                <chr> …\n$ `Which of the following cloud computing services have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Microsoft Azure`                                                                          <chr> …\n$ `Which of the following cloud computing services have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - IBM Cloud`                                                                                <chr> …\n$ `Which of the following cloud computing services have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Alibaba Cloud`                                                                            <chr> …\n$ `Which of the following cloud computing services have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - I have not used any cloud providers`                                                      <chr> …\n$ `Which of the following cloud computing services have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Other`                                                                                    <chr> …\n$ `Which of the following cloud computing services have you used at work or school in the last 5 years? (Select all that apply) - Other - Text`                                                                                               <dbl> …\n$ `What programming languages do you use on a regular basis? (Select all that apply) - Selected Choice - Python`                                                                                                                              <chr> …\n$ `What programming languages do you use on a regular basis? (Select all that apply) - Selected Choice - R`                                                                                                                                   <chr> …\n$ `What programming languages do you use on a regular basis? (Select all that apply) - Selected Choice - SQL`                                                                                                                                 <chr> …\n$ `What programming languages do you use on a regular basis? (Select all that apply) - Selected Choice - Bash`                                                                                                                                <chr> …\n$ `What programming languages do you use on a regular basis? (Select all that apply) - Selected Choice - Java`                                                                                                                                <chr> …\n$ `What programming languages do you use on a regular basis? (Select all that apply) - Selected Choice - Javascript/Typescript`                                                                                                               <chr> …\n$ `What programming languages do you use on a regular basis? (Select all that apply) - Selected Choice - Visual Basic/VBA`                                                                                                                    <chr> …\n$ `What programming languages do you use on a regular basis? (Select all that apply) - Selected Choice - C/C++`                                                                                                                               <chr> …\n$ `What programming languages do you use on a regular basis? (Select all that apply) - Selected Choice - MATLAB`                                                                                                                              <chr> …\n$ `What programming languages do you use on a regular basis? (Select all that apply) - Selected Choice - Scala`                                                                                                                               <chr> …\n$ `What programming languages do you use on a regular basis? (Select all that apply) - Selected Choice - Julia`                                                                                                                               <chr> …\n$ `What programming languages do you use on a regular basis? (Select all that apply) - Selected Choice - Go`                                                                                                                                  <chr> …\n$ `What programming languages do you use on a regular basis? (Select all that apply) - Selected Choice - C#/.NET`                                                                                                                             <chr> …\n$ `What programming languages do you use on a regular basis? (Select all that apply) - Selected Choice - PHP`                                                                                                                                 <chr> …\n$ `What programming languages do you use on a regular basis? (Select all that apply) - Selected Choice - Ruby`                                                                                                                                <chr> …\n$ `What programming languages do you use on a regular basis? (Select all that apply) - Selected Choice - SAS/STATA`                                                                                                                           <chr> …\n$ `What programming languages do you use on a regular basis? (Select all that apply) - Selected Choice - None`                                                                                                                                <chr> …\n$ `What programming languages do you use on a regular basis? (Select all that apply) - Selected Choice - Other`                                                                                                                               <chr> …\n$ `What programming languages do you use on a regular basis? (Select all that apply) - Other - Text`                                                                                                                                          <dbl> …\n$ `What specific programming language do you use most often? - Selected Choice`                                                                                                                                                               <chr> …\n$ `What specific programming language do you use most often? - Other - Text`                                                                                                                                                                  <dbl> …\n$ `What programming language would you recommend an aspiring data scientist to learn first? - Selected Choice`                                                                                                                                <chr> …\n$ `What programming language would you recommend an aspiring data scientist to learn first? - Other - Text`                                                                                                                                   <dbl> …\n$ `What machine learning frameworks have you used in the past 5 years? (Select all that apply) - Selected Choice - Scikit-Learn`                                                                                                              <chr> …\n$ `What machine learning frameworks have you used in the past 5 years? (Select all that apply) - Selected Choice - TensorFlow`                                                                                                                <chr> …\n$ `What machine learning frameworks have you used in the past 5 years? (Select all that apply) - Selected Choice - Keras`                                                                                                                     <chr> …\n$ `What machine learning frameworks have you used in the past 5 years? (Select all that apply) - Selected Choice - PyTorch`                                                                                                                   <chr> …\n$ `What machine learning frameworks have you used in the past 5 years? (Select all that apply) - Selected Choice - Spark MLlib`                                                                                                               <chr> …\n$ `What machine learning frameworks have you used in the past 5 years? (Select all that apply) - Selected Choice - H20`                                                                                                                       <chr> …\n$ `What machine learning frameworks have you used in the past 5 years? (Select all that apply) - Selected Choice - Fastai`                                                                                                                    <chr> …\n$ `What machine learning frameworks have you used in the past 5 years? (Select all that apply) - Selected Choice - Mxnet`                                                                                                                     <chr> …\n$ `What machine learning frameworks have you used in the past 5 years? (Select all that apply) - Selected Choice - Caret`                                                                                                                     <chr> …\n$ `What machine learning frameworks have you used in the past 5 years? (Select all that apply) - Selected Choice - Xgboost`                                                                                                                   <chr> …\n$ `What machine learning frameworks have you used in the past 5 years? (Select all that apply) - Selected Choice - mlr`                                                                                                                       <chr> …\n$ `What machine learning frameworks have you used in the past 5 years? (Select all that apply) - Selected Choice - Prophet`                                                                                                                   <chr> …\n$ `What machine learning frameworks have you used in the past 5 years? (Select all that apply) - Selected Choice - randomForest`                                                                                                              <chr> …\n$ `What machine learning frameworks have you used in the past 5 years? (Select all that apply) - Selected Choice - lightgbm`                                                                                                                  <chr> …\n$ `What machine learning frameworks have you used in the past 5 years? (Select all that apply) - Selected Choice - catboost`                                                                                                                  <chr> …\n$ `What machine learning frameworks have you used in the past 5 years? (Select all that apply) - Selected Choice - CNTK`                                                                                                                      <chr> …\n$ `What machine learning frameworks have you used in the past 5 years? (Select all that apply) - Selected Choice - Caffe`                                                                                                                     <chr> …\n$ `What machine learning frameworks have you used in the past 5 years? (Select all that apply) - Selected Choice - None`                                                                                                                      <chr> …\n$ `What machine learning frameworks have you used in the past 5 years? (Select all that apply) - Selected Choice - Other`                                                                                                                     <chr> …\n$ `What machine learning frameworks have you used in the past 5 years? (Select all that apply) - Other - Text`                                                                                                                                <dbl> …\n$ `Of the choices that you selected in the previous question, which ML library have you used the most? - Selected Choice`                                                                                                                     <chr> …\n$ `Of the choices that you selected in the previous question, which ML library have you used the most? - Other - Text`                                                                                                                        <dbl> …\n$ `What data visualization libraries or tools have you used in the past 5 years? (Select all that apply) - Selected Choice - ggplot2`                                                                                                         <chr> …\n$ `What data visualization libraries or tools have you used in the past 5 years? (Select all that apply) - Selected Choice - Matplotlib`                                                                                                      <chr> …\n$ `What data visualization libraries or tools have you used in the past 5 years? (Select all that apply) - Selected Choice - Altair`                                                                                                          <chr> …\n$ `What data visualization libraries or tools have you used in the past 5 years? (Select all that apply) - Selected Choice - Shiny`                                                                                                           <chr> …\n$ `What data visualization libraries or tools have you used in the past 5 years? (Select all that apply) - Selected Choice - D3`                                                                                                              <chr> …\n$ `What data visualization libraries or tools have you used in the past 5 years? (Select all that apply) - Selected Choice - Plotly`                                                                                                          <chr> …\n$ `What data visualization libraries or tools have you used in the past 5 years? (Select all that apply) - Selected Choice - Bokeh`                                                                                                           <chr> …\n$ `What data visualization libraries or tools have you used in the past 5 years? (Select all that apply) - Selected Choice - Seaborn`                                                                                                         <chr> …\n$ `What data visualization libraries or tools have you used in the past 5 years? (Select all that apply) - Selected Choice - Geoplotlib`                                                                                                      <chr> …\n$ `What data visualization libraries or tools have you used in the past 5 years? (Select all that apply) - Selected Choice - Leaflet`                                                                                                         <chr> …\n$ `What data visualization libraries or tools have you used in the past 5 years? (Select all that apply) - Selected Choice - Lattice`                                                                                                         <chr> …\n$ `What data visualization libraries or tools have you used in the past 5 years? (Select all that apply) - Selected Choice - None`                                                                                                            <chr> …\n$ `What data visualization libraries or tools have you used in the past 5 years? (Select all that apply) - Selected Choice - Other`                                                                                                           <chr> …\n$ `What data visualization libraries or tools have you used in the past 5 years? (Select all that apply) - Other - Text`                                                                                                                      <dbl> …\n$ `Of the choices that you selected in the previous question, which specific data visualization library or tool have you used the most? - Selected Choice`                                                                                    <chr> …\n$ `Of the choices that you selected in the previous question, which specific data visualization library or tool have you used the most? - Other - Text`                                                                                       <dbl> …\n$ `Approximately what percent of your time at work or school is spent actively coding?`                                                                                                                                                       <chr> …\n$ `How long have you been writing code to analyze data?`                                                                                                                                                                                      <chr> …\n$ `For how many years have you used machine learning methods (at work or in school)?`                                                                                                                                                         <chr> …\n$ `Do you consider yourself to be a data scientist?`                                                                                                                                                                                          <chr> …\n$ `Which of the following cloud computing products have you used at work or school in the last 5 years (Select all that apply)? - Selected Choice - AWS Elastic Compute Cloud (EC2)`                                                          <chr> …\n$ `Which of the following cloud computing products have you used at work or school in the last 5 years (Select all that apply)? - Selected Choice - Google Compute Engine`                                                                    <chr> …\n$ `Which of the following cloud computing products have you used at work or school in the last 5 years (Select all that apply)? - Selected Choice - AWS Elastic Beanstalk`                                                                    <chr> …\n$ `Which of the following cloud computing products have you used at work or school in the last 5 years (Select all that apply)? - Selected Choice - Google App Engine`                                                                        <chr> …\n$ `Which of the following cloud computing products have you used at work or school in the last 5 years (Select all that apply)? - Selected Choice - Google Kubernetes Engine`                                                                 <chr> …\n$ `Which of the following cloud computing products have you used at work or school in the last 5 years (Select all that apply)? - Selected Choice - AWS Lambda`                                                                               <chr> …\n$ `Which of the following cloud computing products have you used at work or school in the last 5 years (Select all that apply)? - Selected Choice - Google Cloud Functions`                                                                   <chr> …\n$ `Which of the following cloud computing products have you used at work or school in the last 5 years (Select all that apply)? - Selected Choice - AWS Batch`                                                                                <chr> …\n$ `Which of the following cloud computing products have you used at work or school in the last 5 years (Select all that apply)? - Selected Choice - Azure Virtual Machines`                                                                   <chr> …\n$ `Which of the following cloud computing products have you used at work or school in the last 5 years (Select all that apply)? - Selected Choice - Azure Container Service`                                                                  <chr> …\n$ `Which of the following cloud computing products have you used at work or school in the last 5 years (Select all that apply)? - Selected Choice - Azure Functions`                                                                          <chr> …\n$ `Which of the following cloud computing products have you used at work or school in the last 5 years (Select all that apply)? - Selected Choice - Azure Event Grid`                                                                         <chr> …\n$ `Which of the following cloud computing products have you used at work or school in the last 5 years (Select all that apply)? - Selected Choice - Azure Batch`                                                                              <chr> …\n$ `Which of the following cloud computing products have you used at work or school in the last 5 years (Select all that apply)? - Selected Choice - Azure Kubernetes Service`                                                                 <chr> …\n$ `Which of the following cloud computing products have you used at work or school in the last 5 years (Select all that apply)? - Selected Choice - IBM Cloud Virtual Servers`                                                                <chr> …\n$ `Which of the following cloud computing products have you used at work or school in the last 5 years (Select all that apply)? - Selected Choice - IBM Cloud Container Registry`                                                             <chr> …\n$ `Which of the following cloud computing products have you used at work or school in the last 5 years (Select all that apply)? - Selected Choice - IBM Cloud Kubernetes Service`                                                             <chr> …\n$ `Which of the following cloud computing products have you used at work or school in the last 5 years (Select all that apply)? - Selected Choice - IBM Cloud Foundry`                                                                        <chr> …\n$ `Which of the following cloud computing products have you used at work or school in the last 5 years (Select all that apply)? - Selected Choice - None`                                                                                     <chr> …\n$ `Which of the following cloud computing products have you used at work or school in the last 5 years (Select all that apply)? - Selected Choice - Other`                                                                                    <chr> …\n$ `Which of the following cloud computing products have you used at work or school in the last 5 years (Select all that apply)? - Other - Text`                                                                                               <dbl> …\n$ `Which of the following machine learning products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Amazon Transcribe`                                                                       <chr> …\n$ `Which of the following machine learning products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Google Cloud Speech-to-text API`                                                         <chr> …\n$ `Which of the following machine learning products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Amazon Rekognition`                                                                      <chr> …\n$ `Which of the following machine learning products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Google Cloud Vision API`                                                                 <chr> …\n$ `Which of the following machine learning products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Amazon Comprehend`                                                                       <chr> …\n$ `Which of the following machine learning products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Google Cloud Natural Language API`                                                       <chr> …\n$ `Which of the following machine learning products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Amazon Translate`                                                                        <chr> …\n$ `Which of the following machine learning products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Google Cloud Translation API`                                                            <chr> …\n$ `Which of the following machine learning products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Amazon Lex`                                                                              <chr> …\n$ `Which of the following machine learning products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Google Dialogflow Enterprise Edition`                                                    <chr> …\n$ `Which of the following machine learning products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Amazon Rekognition Video`                                                                <chr> …\n$ `Which of the following machine learning products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Google Cloud Video Intelligence API`                                                     <chr> …\n$ `Which of the following machine learning products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Google Cloud AutoML`                                                                     <chr> …\n$ `Which of the following machine learning products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Amazon SageMaker`                                                                        <chr> …\n$ `Which of the following machine learning products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Google Cloud Machine Learning Engine`                                                    <chr> …\n$ `Which of the following machine learning products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - DataRobot`                                                                               <chr> …\n$ `Which of the following machine learning products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - H20 Driverless AI`                                                                       <chr> …\n$ `Which of the following machine learning products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Domino Datalab`                                                                          <chr> …\n$ `Which of the following machine learning products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - SAS`                                                                                     <chr> …\n$ `Which of the following machine learning products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Dataiku`                                                                                 <chr> …\n$ `Which of the following machine learning products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - RapidMiner`                                                                              <chr> …\n$ `Which of the following machine learning products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Instabase`                                                                               <chr> …\n$ `Which of the following machine learning products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Algorithmia`                                                                             <chr> …\n$ `Which of the following machine learning products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Dataversity`                                                                             <lgl> …\n$ `Which of the following machine learning products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Cloudera`                                                                                <chr> …\n$ `Which of the following machine learning products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Azure Machine Learning Studio`                                                           <chr> …\n$ `Which of the following machine learning products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Azure Machine Learning Workbench`                                                        <chr> …\n$ `Which of the following machine learning products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Azure Cortana Intelligence Suite`                                                        <chr> …\n$ `Which of the following machine learning products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Azure Bing Speech API`                                                                   <chr> …\n$ `Which of the following machine learning products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Azure Speaker Recognition API`                                                           <chr> …\n$ `Which of the following machine learning products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Azure Computer Vision API`                                                               <chr> …\n$ `Which of the following machine learning products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Azure Face API`                                                                          <chr> …\n$ `Which of the following machine learning products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Azure Video API`                                                                         <chr> …\n$ `Which of the following machine learning products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - IBM Watson Studio`                                                                       <chr> …\n$ `Which of the following machine learning products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - IBM Watson Knowledge Catalog`                                                            <chr> …\n$ `Which of the following machine learning products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - IBM Watson Assistant`                                                                    <chr> …\n$ `Which of the following machine learning products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - IBM Watson Discovery`                                                                    <chr> …\n$ `Which of the following machine learning products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - IBM Watson Text to Speech`                                                               <chr> …\n$ `Which of the following machine learning products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - IBM Watson Visual Recognition`                                                           <chr> …\n$ `Which of the following machine learning products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - IBM Watson Machine Learning`                                                             <chr> …\n$ `Which of the following machine learning products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Azure Cognitive Services`                                                                <chr> …\n$ `Which of the following machine learning products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - None`                                                                                    <chr> …\n$ `Which of the following machine learning products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Other`                                                                                   <chr> …\n$ `Which of the following machine learning products have you used at work or school in the last 5 years? (Select all that apply) - Other - Text`                                                                                              <dbl> …\n$ `Which of the following relational database products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - AWS Relational Database Service`                                                      <chr> …\n$ `Which of the following relational database products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - AWS Aurora`                                                                           <chr> …\n$ `Which of the following relational database products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Google Cloud SQL`                                                                     <chr> …\n$ `Which of the following relational database products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Google Cloud Spanner`                                                                 <chr> …\n$ `Which of the following relational database products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - AWS DynamoDB`                                                                         <chr> …\n$ `Which of the following relational database products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Google Cloud Datastore`                                                               <chr> …\n$ `Which of the following relational database products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Google Cloud Bigtable`                                                                <chr> …\n$ `Which of the following relational database products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - AWS SimpleDB`                                                                         <chr> …\n$ `Which of the following relational database products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Microsoft SQL Server`                                                                 <chr> …\n$ `Which of the following relational database products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - MySQL`                                                                                <chr> …\n$ `Which of the following relational database products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - PostgresSQL`                                                                          <chr> …\n$ `Which of the following relational database products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - SQLite`                                                                               <chr> …\n$ `Which of the following relational database products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Oracle Database`                                                                      <chr> …\n$ `Which of the following relational database products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Ingres`                                                                               <chr> …\n$ `Which of the following relational database products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Microsoft Access`                                                                     <chr> …\n$ `Which of the following relational database products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - NexusDB`                                                                              <chr> …\n$ `Which of the following relational database products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - SAP IQ`                                                                               <chr> …\n$ `Which of the following relational database products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Google Fusion Tables`                                                                 <chr> …\n$ `Which of the following relational database products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Azure Database for MySQL`                                                             <chr> …\n$ `Which of the following relational database products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Azure Cosmos DB`                                                                      <chr> …\n$ `Which of the following relational database products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Azure SQL Database`                                                                   <chr> …\n$ `Which of the following relational database products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Azure Database for PostgreSQL`                                                        <chr> …\n$ `Which of the following relational database products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - IBM Cloud Compose`                                                                    <chr> …\n$ `Which of the following relational database products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - IBM Cloud Compose for MySQL`                                                          <chr> …\n$ `Which of the following relational database products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - IBM Cloud Compose for PostgreSQL`                                                     <chr> …\n$ `Which of the following relational database products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - IBM Cloud Db2`                                                                        <chr> …\n$ `Which of the following relational database products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - None`                                                                                 <chr> …\n$ `Which of the following relational database products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Other`                                                                                <chr> …\n$ `Which of the following relational database products have you used at work or school in the last 5 years? (Select all that apply) - Other - Text`                                                                                           <dbl> …\n$ `Which of the following big data and analytics products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - AWS Elastic MapReduce`                                                             <chr> …\n$ `Which of the following big data and analytics products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - AWS Batch`                                                                         <chr> …\n$ `Which of the following big data and analytics products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Google Cloud Dataproc`                                                             <chr> …\n$ `Which of the following big data and analytics products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Google Cloud Dataflow`                                                             <chr> …\n$ `Which of the following big data and analytics products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Google Cloud Dataprep`                                                             <chr> …\n$ `Which of the following big data and analytics products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - AWS Kinesis`                                                                       <chr> …\n$ `Which of the following big data and analytics products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Google Cloud Pub/Sub`                                                              <chr> …\n$ `Which of the following big data and analytics products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - AWS Athena`                                                                        <chr> …\n$ `Which of the following big data and analytics products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - AWS Redshift`                                                                      <chr> …\n$ `Which of the following big data and analytics products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Google BigQuery`                                                                   <chr> …\n$ `Which of the following big data and analytics products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Teradata`                                                                          <chr> …\n$ `Which of the following big data and analytics products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Microsoft Analysis Services`                                                       <chr> …\n$ `Which of the following big data and analytics products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Oracle Exadata`                                                                    <chr> …\n$ `Which of the following big data and analytics products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Oracle Warehouse Builder`                                                          <chr> …\n$ `Which of the following big data and analytics products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - SAP IQ`                                                                            <lgl> …\n$ `Which of the following big data and analytics products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Snowflake`                                                                         <chr> …\n$ `Which of the following big data and analytics products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Databricks`                                                                        <chr> …\n$ `Which of the following big data and analytics products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Azure SQL Data Warehouse`                                                          <chr> …\n$ `Which of the following big data and analytics products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Azure HDInsight`                                                                   <chr> …\n$ `Which of the following big data and analytics products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Azure Stream Analytics`                                                            <chr> …\n$ `Which of the following big data and analytics products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - IBM InfoSphere DataStorage`                                                        <chr> …\n$ `Which of the following big data and analytics products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - IBM Cloud Analytics Engine`                                                        <chr> …\n$ `Which of the following big data and analytics products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - IBM Cloud Streaming Analytics`                                                     <chr> …\n$ `Which of the following big data and analytics products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - None`                                                                              <chr> …\n$ `Which of the following big data and analytics products have you used at work or school in the last 5 years? (Select all that apply) - Selected Choice - Other`                                                                             <chr> …\n$ `Which of the following big data and analytics products have you used at work or school in the last 5 years? (Select all that apply) - Other - Text`                                                                                        <dbl> …\n$ `Which types of data do you currently interact with most often at work or school? (Select all that apply) - Selected Choice - Audio Data`                                                                                                   <chr> …\n$ `Which types of data do you currently interact with most often at work or school? (Select all that apply) - Selected Choice - Categorical Data`                                                                                             <chr> …\n$ `Which types of data do you currently interact with most often at work or school? (Select all that apply) - Selected Choice - Genetic Data`                                                                                                 <chr> …\n$ `Which types of data do you currently interact with most often at work or school? (Select all that apply) - Selected Choice - Geospatial Data`                                                                                              <chr> …\n$ `Which types of data do you currently interact with most often at work or school? (Select all that apply) - Selected Choice - Image Data`                                                                                                   <chr> …\n$ `Which types of data do you currently interact with most often at work or school? (Select all that apply) - Selected Choice - Numerical Data`                                                                                               <chr> …\n$ `Which types of data do you currently interact with most often at work or school? (Select all that apply) - Selected Choice - Sensor Data`                                                                                                  <chr> …\n$ `Which types of data do you currently interact with most often at work or school? (Select all that apply) - Selected Choice - Tabular Data`                                                                                                 <chr> …\n$ `Which types of data do you currently interact with most often at work or school? (Select all that apply) - Selected Choice - Text Data`                                                                                                    <chr> …\n$ `Which types of data do you currently interact with most often at work or school? (Select all that apply) - Selected Choice - Time Series Data`                                                                                             <chr> …\n$ `Which types of data do you currently interact with most often at work or school? (Select all that apply) - Selected Choice - Video Data`                                                                                                   <chr> …\n$ `Which types of data do you currently interact with most often at work or school? (Select all that apply) - Selected Choice - Other Data`                                                                                                   <chr> …\n$ `Which types of data do you currently interact with most often at work or school? (Select all that apply) - Other Data - Text`                                                                                                              <dbl> …\n$ `What is the type of data that you currently interact with most often at work or school? - Selected Choice`                                                                                                                                 <chr> …\n$ `What is the type of data that you currently interact with most often at work or school? - Other Data - Text`                                                                                                                               <dbl> …\n$ `Where do you find public datasets? (Select all that apply) - Selected Choice - Government websites`                                                                                                                                        <chr> …\n$ `Where do you find public datasets? (Select all that apply) - Selected Choice - University research group websites`                                                                                                                         <chr> …\n$ `Where do you find public datasets? (Select all that apply) - Selected Choice - Non-profit research group websites`                                                                                                                         <chr> …\n$ `Where do you find public datasets? (Select all that apply) - Selected Choice - Dataset aggregator/platform (Socrata, Kaggle Public Datasets Platform, etc.)`                                                                               <chr> …\n$ `Where do you find public datasets? (Select all that apply) - Selected Choice - I collect my own data (web-scraping, etc.)`                                                                                                                 <chr> …\n$ `Where do you find public datasets? (Select all that apply) - Selected Choice - Publicly released data from private companies`                                                                                                              <chr> …\n$ `Where do you find public datasets? (Select all that apply) - Selected Choice - Google Search`                                                                                                                                              <chr> …\n$ `Where do you find public datasets? (Select all that apply) - Selected Choice - Google Dataset Search`                                                                                                                                      <chr> …\n$ `Where do you find public datasets? (Select all that apply) - Selected Choice - GitHub`                                                                                                                                                     <chr> …\n$ `Where do you find public datasets? (Select all that apply) - Selected Choice - None/I do not work with public data`                                                                                                                        <chr> …\n$ `Where do you find public datasets? (Select all that apply) - Selected Choice - Other`                                                                                                                                                      <chr> …\n$ `Where do you find public datasets? (Select all that apply) - Other - Text`                                                                                                                                                                 <dbl> …\n$ `During a typical data science project at work or school, approximately what proportion of your time is devoted to the following? (Answers must add up to 100%) - Gathering data`                                                           <dbl> …\n$ `During a typical data science project at work or school, approximately what proportion of your time is devoted to the following? (Answers must add up to 100%) - Cleaning data`                                                            <dbl> …\n$ `During a typical data science project at work or school, approximately what proportion of your time is devoted to the following? (Answers must add up to 100%) - Visualizing data`                                                         <dbl> …\n$ `During a typical data science project at work or school, approximately what proportion of your time is devoted to the following? (Answers must add up to 100%) - Model building/model selection`                                           <dbl> …\n$ `During a typical data science project at work or school, approximately what proportion of your time is devoted to the following? (Answers must add up to 100%) - Putting the model into production`                                        <dbl> …\n$ `During a typical data science project at work or school, approximately what proportion of your time is devoted to the following? (Answers must add up to 100%) - Finding insights in the data and communicating with stakeholders`         <dbl> …\n$ `During a typical data science project at work or school, approximately what proportion of your time is devoted to the following? (Answers must add up to 100%) - Other`                                                                    <dbl> …\n$ `What percentage of your current machine learning/data science training falls under each category? (Answers must add up to 100%) - Self-taught`                                                                                             <dbl> …\n$ `What percentage of your current machine learning/data science training falls under each category? (Answers must add up to 100%) - Online courses (Coursera, Udemy, edX, etc.)`                                                             <dbl> …\n$ `What percentage of your current machine learning/data science training falls under each category? (Answers must add up to 100%) - Work`                                                                                                    <dbl> …\n$ `What percentage of your current machine learning/data science training falls under each category? (Answers must add up to 100%) - University`                                                                                              <dbl> …\n$ `What percentage of your current machine learning/data science training falls under each category? (Answers must add up to 100%) - Kaggle competitions`                                                                                     <dbl> …\n$ `What percentage of your current machine learning/data science training falls under each category? (Answers must add up to 100%) - Other`                                                                                                   <dbl> …\n$ `What percentage of your current machine learning/data science training falls under each category? (Answers must add up to 100%) - Other - Text`                                                                                            <dbl> …\n$ `On which online platforms have you begun or completed data science courses? (Select all that apply) - Selected Choice - Udacity`                                                                                                           <chr> …\n$ `On which online platforms have you begun or completed data science courses? (Select all that apply) - Selected Choice - Coursera`                                                                                                          <chr> …\n$ `On which online platforms have you begun or completed data science courses? (Select all that apply) - Selected Choice - edX`                                                                                                               <chr> …\n$ `On which online platforms have you begun or completed data science courses? (Select all that apply) - Selected Choice - DataCamp`                                                                                                          <chr> …\n$ `On which online platforms have you begun or completed data science courses? (Select all that apply) - Selected Choice - DataQuest`                                                                                                         <chr> …\n$ `On which online platforms have you begun or completed data science courses? (Select all that apply) - Selected Choice - Kaggle Learn`                                                                                                      <chr> …\n$ `On which online platforms have you begun or completed data science courses? (Select all that apply) - Selected Choice - Fast.AI`                                                                                                           <chr> …\n$ `On which online platforms have you begun or completed data science courses? (Select all that apply) - Selected Choice - developers.google.com`                                                                                             <chr> …\n$ `On which online platforms have you begun or completed data science courses? (Select all that apply) - Selected Choice - Udemy`                                                                                                             <chr> …\n$ `On which online platforms have you begun or completed data science courses? (Select all that apply) - Selected Choice - TheSchool.AI`                                                                                                      <chr> …\n$ `On which online platforms have you begun or completed data science courses? (Select all that apply) - Selected Choice - Online University Courses`                                                                                         <chr> …\n$ `On which online platforms have you begun or completed data science courses? (Select all that apply) - Selected Choice - None`                                                                                                              <chr> …\n$ `On which online platforms have you begun or completed data science courses? (Select all that apply) - Selected Choice - Other`                                                                                                             <chr> …\n$ `On which online platforms have you begun or completed data science courses? (Select all that apply) - Other - Text`                                                                                                                        <dbl> …\n$ `On which online platform have you spent the most amount of time? - Selected Choice`                                                                                                                                                        <chr> …\n$ `On which online platform have you spent the most amount of time? - Other - Text`                                                                                                                                                           <dbl> …\n$ `Who/what are your favorite media sources that report on data science topics? (Select all that apply) - Selected Choice - Twitter`                                                                                                          <chr> …\n$ `Who/what are your favorite media sources that report on data science topics? (Select all that apply) - Selected Choice - Hacker News`                                                                                                      <chr> …\n$ `Who/what are your favorite media sources that report on data science topics? (Select all that apply) - Selected Choice - r/machinelearning`                                                                                                <chr> …\n$ `Who/what are your favorite media sources that report on data science topics? (Select all that apply) - Selected Choice - Kaggle forums`                                                                                                    <chr> …\n$ `Who/what are your favorite media sources that report on data science topics? (Select all that apply) - Selected Choice - Fastai forums`                                                                                                    <chr> …\n$ `Who/what are your favorite media sources that report on data science topics? (Select all that apply) - Selected Choice - Siraj Raval YouTube Channel`                                                                                      <chr> …\n$ `Who/what are your favorite media sources that report on data science topics? (Select all that apply) - Selected Choice - DataTau News Aggregator`                                                                                          <chr> …\n$ `Who/what are your favorite media sources that report on data science topics? (Select all that apply) - Selected Choice - Linear Digressions Podcast`                                                                                       <chr> …\n$ `Who/what are your favorite media sources that report on data science topics? (Select all that apply) - Selected Choice - Cloud AI Adventures (YouTube)`                                                                                    <chr> …\n$ `Who/what are your favorite media sources that report on data science topics? (Select all that apply) - Selected Choice - FiveThirtyEight.com`                                                                                              <chr> …\n$ `Who/what are your favorite media sources that report on data science topics? (Select all that apply) - Selected Choice - ArXiv & Preprints`                                                                                                <chr> …\n$ `Who/what are your favorite media sources that report on data science topics? (Select all that apply) - Selected Choice - Journal Publications`                                                                                             <chr> …\n$ `Who/what are your favorite media sources that report on data science topics? (Select all that apply) - Selected Choice - FastML Blog`                                                                                                      <chr> …\n$ `Who/what are your favorite media sources that report on data science topics? (Select all that apply) - Selected Choice - KDnuggets Blog`                                                                                                   <chr> …\n$ `Who/what are your favorite media sources that report on data science topics? (Select all that apply) - Selected Choice - O'Reilly Data Newsletter`                                                                                         <chr> …\n$ `Who/what are your favorite media sources that report on data science topics? (Select all that apply) - Selected Choice - Partially Derivative Podcast`                                                                                     <chr> …\n$ `Who/what are your favorite media sources that report on data science topics? (Select all that apply) - Selected Choice - The Data Skeptic Podcast`                                                                                         <chr> …\n$ `Who/what are your favorite media sources that report on data science topics? (Select all that apply) - Selected Choice - Medium Blog Posts`                                                                                                <chr> …\n$ `Who/what are your favorite media sources that report on data science topics? (Select all that apply) - Selected Choice - Towards Data Science Blog`                                                                                        <lgl> …\n$ `Who/what are your favorite media sources that report on data science topics? (Select all that apply) - Selected Choice - Analytics Vidhya Blog`                                                                                            <lgl> …\n$ `Who/what are your favorite media sources that report on data science topics? (Select all that apply) - Selected Choice - None/I do not know`                                                                                               <chr> …\n$ `Who/what are your favorite media sources that report on data science topics? (Select all that apply) - Selected Choice - Other`                                                                                                            <chr> …\n$ `Who/what are your favorite media sources that report on data science topics? (Select all that apply) - Other - Text`                                                                                                                       <dbl> …\n$ `How do you perceive the quality of online learning platforms and in-person bootcamps as compared to the quality of the education provided by traditional brick and mortar institutions? - Online learning platforms and MOOCs:`            <chr> …\n$ `How do you perceive the quality of online learning platforms and in-person bootcamps as compared to the quality of the education provided by traditional brick and mortar institutions? - In-person bootcamps:`                            <chr> …\n$ `Which better demonstrates expertise in data science: academic achievements or independent projects? - Your views:`                                                                                                                         <chr> …\n$ `How do you perceive the importance of the following topics? - Fairness and bias in ML algorithms:`                                                                                                                                         <chr> …\n$ `How do you perceive the importance of the following topics? - Being able to explain ML model outputs and/or predictions`                                                                                                                   <chr> …\n$ `How do you perceive the importance of the following topics? - Reproducibility in data science`                                                                                                                                             <chr> …\n$ `What metrics do you or your organization use to determine whether or not your models were successful? (Select all that apply) - Selected Choice - Revenue and/or business goals`                                                           <chr> …\n$ `What metrics do you or your organization use to determine whether or not your models were successful? (Select all that apply) - Selected Choice - Metrics that consider accuracy`                                                          <chr> …\n$ `What metrics do you or your organization use to determine whether or not your models were successful? (Select all that apply) - Selected Choice - Metrics that consider unfair bias`                                                       <chr> …\n$ `What metrics do you or your organization use to determine whether or not your models were successful? (Select all that apply) - Selected Choice - Not applicable (I am not involved with an organization that builds ML models)`           <chr> …\n$ `What metrics do you or your organization use to determine whether or not your models were successful? (Select all that apply) - Selected Choice - Other`                                                                                   <chr> …\n$ `What metrics do you or your organization use to determine whether or not your models were successful? (Select all that apply) - Other - Text`                                                                                              <dbl> …\n$ `Approximately what percent of your data projects involved exploring unfair bias in the dataset and/or algorithm?`                                                                                                                          <chr> …\n$ `What do you find most difficult about ensuring that your algorithms are fair and unbiased? (Select all that apply) - Lack of communication between individuals who collect the data and individuals who analyze the data`                  <chr> …\n$ `What do you find most difficult about ensuring that your algorithms are fair and unbiased? (Select all that apply) - Difficulty in identifying groups that are unfairly targeted`                                                          <chr> …\n$ `What do you find most difficult about ensuring that your algorithms are fair and unbiased? (Select all that apply) - Difficulty in collecting enough data about groups that may be unfairly targeted`                                      <chr> …\n$ `What do you find most difficult about ensuring that your algorithms are fair and unbiased? (Select all that apply) - Difficulty in identifying and selecting the appropriate evaluation metrics`                                           <chr> …\n$ `What do you find most difficult about ensuring that your algorithms are fair and unbiased? (Select all that apply) - I have never found any difficulty in this task`                                                                       <chr> …\n$ `What do you find most difficult about ensuring that your algorithms are fair and unbiased? (Select all that apply) - I have never performed this task`                                                                                     <chr> …\n$ `In what circumstances would you explore model insights and interpret your model's predictions? (Select all that apply) - Only for very important models that are already in production`                                                    <chr> …\n$ `In what circumstances would you explore model insights and interpret your model's predictions? (Select all that apply) - For all models right before putting the model in production`                                                      <chr> …\n$ `In what circumstances would you explore model insights and interpret your model's predictions? (Select all that apply) - When determining whether it is worth it to put the model into production`                                         <chr> …\n$ `In what circumstances would you explore model insights and interpret your model's predictions? (Select all that apply) - When building a model that was specifically designed to produce such insights`                                    <chr> …\n$ `In what circumstances would you explore model insights and interpret your model's predictions? (Select all that apply) - When first exploring a new ML model or dataset`                                                                   <chr> …\n$ `In what circumstances would you explore model insights and interpret your model's predictions? (Select all that apply) - I do not explore and interpret model insights and predictions`                                                    <chr> …\n$ `Approximately what percent of your data projects involve exploring model insights?`                                                                                                                                                        <chr> …\n$ `What methods do you prefer for explaining and/or interpreting decisions that are made by ML models? (Select all that apply) - Selected Choice - Examine individual model coefficients`                                                     <chr> …\n$ `What methods do you prefer for explaining and/or interpreting decisions that are made by ML models? (Select all that apply) - Selected Choice - Examine feature correlations`                                                              <chr> …\n$ `What methods do you prefer for explaining and/or interpreting decisions that are made by ML models? (Select all that apply) - Selected Choice - Examine feature importances`                                                               <chr> …\n$ `What methods do you prefer for explaining and/or interpreting decisions that are made by ML models? (Select all that apply) - Selected Choice - Plot decision boundaries`                                                                  <chr> …\n$ `What methods do you prefer for explaining and/or interpreting decisions that are made by ML models? (Select all that apply) - Selected Choice - Create partial dependence plots`                                                           <chr> …\n$ `What methods do you prefer for explaining and/or interpreting decisions that are made by ML models? (Select all that apply) - Selected Choice - Dimensionality reduction techniques`                                                       <chr> …\n$ `What methods do you prefer for explaining and/or interpreting decisions that are made by ML models? (Select all that apply) - Selected Choice - Attention mapping/saliency mapping`                                                        <chr> …\n$ `What methods do you prefer for explaining and/or interpreting decisions that are made by ML models? (Select all that apply) - Selected Choice - Plot predicted vs. actual results`                                                         <chr> …\n$ `What methods do you prefer for explaining and/or interpreting decisions that are made by ML models? (Select all that apply) - Selected Choice - Print out a decision tree`                                                                 <chr> …\n$ `What methods do you prefer for explaining and/or interpreting decisions that are made by ML models? (Select all that apply) - Selected Choice - Sensitivity analysis/perturbation importance`                                              <chr> …\n$ `What methods do you prefer for explaining and/or interpreting decisions that are made by ML models? (Select all that apply) - Selected Choice - LIME functions`                                                                            <chr> …\n$ `What methods do you prefer for explaining and/or interpreting decisions that are made by ML models? (Select all that apply) - Selected Choice - ELI5 functions`                                                                            <chr> …\n$ `What methods do you prefer for explaining and/or interpreting decisions that are made by ML models? (Select all that apply) - Selected Choice - SHAP functions`                                                                            <chr> …\n$ `What methods do you prefer for explaining and/or interpreting decisions that are made by ML models? (Select all that apply) - Selected Choice - None/I do not use these model explanation techniques`                                      <chr> …\n$ `What methods do you prefer for explaining and/or interpreting decisions that are made by ML models? (Select all that apply) - Selected Choice - Other`                                                                                     <chr> …\n$ `What methods do you prefer for explaining and/or interpreting decisions that are made by ML models? (Select all that apply) - Other - Text`                                                                                                <chr> …\n$ `Do you consider ML models to be \"black boxes\" with outputs that are difficult or impossible to explain?`                                                                                                                                   <chr> …\n$ `What tools and methods do you use to make your work easy to reproduce? (Select all that apply) - Selected Choice - Share code on Github or a similar code-sharing repository`                                                              <chr> …\n$ `What tools and methods do you use to make your work easy to reproduce? (Select all that apply) - Selected Choice - Share both data and code on Github or a similar code-sharing repository`                                                <chr> …\n$ `What tools and methods do you use to make your work easy to reproduce? (Select all that apply) - Selected Choice - Share data, code, and environment using a hosted service (Kaggle Kernels, Google Colaboratory, Amazon SageMaker, etc.)` <chr> …\n$ `What tools and methods do you use to make your work easy to reproduce? (Select all that apply) - Selected Choice - Share data, code, and environment using containers (Docker, etc.)`                                                      <chr> …\n$ `What tools and methods do you use to make your work easy to reproduce? (Select all that apply) - Selected Choice - Share code, data, and environment using virtual machines (VirtualBox, etc.)`                                            <chr> …\n$ `What tools and methods do you use to make your work easy to reproduce? (Select all that apply) - Selected Choice - Make sure the code is well documented`                                                                                  <chr> …\n$ `What tools and methods do you use to make your work easy to reproduce? (Select all that apply) - Selected Choice - Make sure the code is human-readable`                                                                                   <chr> …\n$ `What tools and methods do you use to make your work easy to reproduce? (Select all that apply) - Selected Choice - Define all random seeds`                                                                                                <chr> …\n$ `What tools and methods do you use to make your work easy to reproduce? (Select all that apply) - Selected Choice - Define relative rather than absolute file paths`                                                                        <chr> …\n$ `What tools and methods do you use to make your work easy to reproduce? (Select all that apply) - Selected Choice - Include a text file describing all dependencies`                                                                        <chr> …\n$ `What tools and methods do you use to make your work easy to reproduce? (Select all that apply) - Selected Choice - None/I do not make my work easy for others to reproduce`                                                                <chr> …\n$ `What tools and methods do you use to make your work easy to reproduce? (Select all that apply) - Selected Choice - Other`                                                                                                                  <chr> …\n$ `What tools and methods do you use to make your work easy to reproduce? (Select all that apply) - Other - Text`                                                                                                                             <dbl> …\n$ `What barriers prevent you from making your work even easier to reuse and reproduce? (Select all that apply) - Selected Choice - Too expensive`                                                                                             <chr> …\n$ `What barriers prevent you from making your work even easier to reuse and reproduce? (Select all that apply) - Selected Choice - Too time-consuming`                                                                                        <chr> …\n$ `What barriers prevent you from making your work even easier to reuse and reproduce? (Select all that apply) - Selected Choice - Requires too much technical knowledge`                                                                     <chr> …\n$ `What barriers prevent you from making your work even easier to reuse and reproduce? (Select all that apply) - Selected Choice - Afraid that others will use my work without giving proper credit`                                          <chr> …\n$ `What barriers prevent you from making your work even easier to reuse and reproduce? (Select all that apply) - Selected Choice - Not enough incentives to share my work`                                                                    <chr> …\n$ `What barriers prevent you from making your work even easier to reuse and reproduce? (Select all that apply) - Selected Choice - I had never considered making my work easier for others to reproduce`                                      <chr> …\n$ `What barriers prevent you from making your work even easier to reuse and reproduce? (Select all that apply) - Selected Choice - None of these reasons apply to me`                                                                         <chr> …\n$ `What barriers prevent you from making your work even easier to reuse and reproduce? (Select all that apply) - Selected Choice - Other`                                                                                                     <chr> …\n$ `What barriers prevent you from making your work even easier to reuse and reproduce? (Select all that apply) - Other - Text`                                                                                                                <dbl> …"
  },
  {
    "objectID": "posts/abigailbalint_finalpart1.html#bibliography",
    "href": "posts/abigailbalint_finalpart1.html#bibliography",
    "title": "Final Project Initial Research",
    "section": "Bibliography",
    "text": "Bibliography\nKaggle, (2018). “2018 Kaggle Machine Learning & Data Science Survey”, Retrieved 21 March 2023 from https://www.kaggle.com/datasets/kaggle/kaggle-survey-2018.\nCC BY-SA 4.0 : https://creativecommons.org/licenses/by-sa/4.0/ :::"
  },
  {
    "objectID": "posts/HW1_Guanhua_Tan.html",
    "href": "posts/HW1_Guanhua_Tan.html",
    "title": "Homework 1",
    "section": "",
    "text": "First, let’s read in the data from the Excel file:\n\n\nCode\nlibrary(readxl)\nlibrary(tidyverse)\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0      ✔ purrr   0.3.5 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.4.1 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\nCode\nlibrary(ggplot2)\ndf <- read_excel(\"_data/LungCapData.xls\")\nhead(df)\n\n\n# A tibble: 6 × 6\n  LungCap   Age Height Smoke Gender Caesarean\n    <dbl> <dbl>  <dbl> <chr> <chr>  <chr>    \n1    6.48     6   62.1 no    male   no       \n2   10.1     18   74.7 yes   female no       \n3    9.55    16   69.7 no    female yes      \n4   11.1     14   71   no    male   no       \n5    4.8      5   56.9 no    male   no       \n6    6.22    11   58.7 no    female no       \n\n\nThe distribution of LungCap looks as follows:\n\n\nCode\nhist(df$LungCap)\n\n\n\n\n\nThe histogram suggests that the distribution is close to a normal distribution. Most of the observations are close to the mean. Very few observations are close to the margins (0 and 15).\n\n\n\n\n\nCode\ndf %>%\n  ggplot(aes(x=Gender,y=LungCap))%+%\n  stat_boxplot(geom = \"errorbar\", # Error bars\n               width = 0.2)+\n  geom_boxplot()\n\n\n\n\n\nThe box graphic suggests that the median of male lung capacities are slightly larger than the one of female ones.\n\n\n\n\n\nCode\ndf_c <- df %>%\n  group_by(Smoke) %>%\n  mutate(mean_lungcap=mean(LungCap))%>%\n  distinct(mean_lungcap)\ndf_c \n\n\n# A tibble: 2 × 2\n# Groups:   Smoke [2]\n  Smoke mean_lungcap\n  <chr>        <dbl>\n1 no            7.77\n2 yes           8.65\n\n\nThe data indicates smokers’ lung capacities are larger than no-smokers’ ones. It runs counter to the intuition.\n\n\n\n\n\nCode\n# less than or equal to 13\ndf_d_13<-df %>%\n  filter(Smoke == \"yes\" & Age <= 13) %>%\n  mutate(mean_lungcap=mean(LungCap)) %>%\n  distinct(mean_lungcap)\n\n\ndf_d_14_15 <-df %>%\n   filter(Smoke == \"yes\" & Age <= 15 | Age >= 14) %>%\n  mutate(mean_lungcap=mean(LungCap)) %>%\n  distinct(mean_lungcap)\n\n\ndf_d_16_17 <-df %>%\n   filter(Smoke == \"yes\" & Age <= 17 | Age >= 16) %>%\n  mutate(mean_lungcap=mean(LungCap)) %>%\n  distinct(mean_lungcap)\n\n\ndf_d_18 <-df %>%\n   filter(Smoke == \"yes\" & Age >= 18) %>%\n  mutate(mean_lungcap=mean(LungCap)) %>%\n  distinct(mean_lungcap)\nresult <-c(df_d_13, df_d_14_15, df_d_16_17, df_d_18)\nprint(result)\n\n\n$mean_lungcap\n[1] 7.201852\n\n$mean_lungcap\n[1] 9.725077\n\n$mean_lungcap\n[1] 10.00616\n\n$mean_lungcap\n[1] 10.51333\n\n\nThe data indicates that with the increase of the age, the lung capacities grows larger.\n\n\n\n\n\nCode\ndf_e_13<-df %>%\n  filter(Age <= 13) %>%\n  group_by(Smoke) %>%\n  mutate(mean_lungcap=mean(LungCap)) %>%\n  distinct(mean_lungcap)\n\ndf_e_14<-df %>%\n  filter(Age == 15 | Age == 14) %>%\n  group_by(Smoke) %>%\n  mutate(mean_lungcap=mean(LungCap)) %>%\n  distinct(mean_lungcap)\n\n\ndf_e_16<-df %>%\n  filter(Age == 17 | Age == 16) %>%\n  group_by(Smoke) %>%\n  mutate(mean_lungcap=mean(LungCap)) %>%\n  distinct(mean_lungcap)\n\n\ndf_e_18<-df %>%\n  filter( Age >= 18) %>%\n  group_by(Smoke) %>%\n  mutate(mean_lungcap=mean(LungCap)) %>%\n  distinct(mean_lungcap)\n\ndf_e_13\n\n\n# A tibble: 2 × 2\n# Groups:   Smoke [2]\n  Smoke mean_lungcap\n  <chr>        <dbl>\n1 no            6.36\n2 yes           7.20\n\n\nCode\ndf_e_14\n\n\n# A tibble: 2 × 2\n# Groups:   Smoke [2]\n  Smoke mean_lungcap\n  <chr>        <dbl>\n1 no            9.14\n2 yes           8.39\n\n\nCode\ndf_e_16\n\n\n# A tibble: 2 × 2\n# Groups:   Smoke [2]\n  Smoke mean_lungcap\n  <chr>        <dbl>\n1 no           10.5 \n2 yes           9.38\n\n\nCode\ndf_e_18\n\n\n# A tibble: 2 × 2\n# Groups:   Smoke [2]\n  Smoke mean_lungcap\n  <chr>        <dbl>\n1 yes           10.5\n2 no            11.1\n\n\nThe shows a big difference from the part C. Only in age group under 13, smokers have larger lung capacities than non-smokers. In other age groups, unlike what the part C suggests, non-smokers have large lung capacities that smokers."
  },
  {
    "objectID": "posts/HW1_Guanhua_Tan.html#a-what-is-the-probability-that-a-randomly-selected-inmate-has-exactly-2-prior-convictions",
    "href": "posts/HW1_Guanhua_Tan.html#a-what-is-the-probability-that-a-randomly-selected-inmate-has-exactly-2-prior-convictions",
    "title": "Homework 1",
    "section": "a) What is the probability that a randomly selected inmate has exactly 2 prior convictions?",
    "text": "a) What is the probability that a randomly selected inmate has exactly 2 prior convictions?\n\n\nCode\nc <- 160/810\nc\n\n\n[1] 0.1975309\n\n\nThe probability is 19.8%."
  },
  {
    "objectID": "posts/HW1_Guanhua_Tan.html#b-what-is-the-probability-that-a-randomly-selected-inmate-has-fewer-than-2-prior-convictions",
    "href": "posts/HW1_Guanhua_Tan.html#b-what-is-the-probability-that-a-randomly-selected-inmate-has-fewer-than-2-prior-convictions",
    "title": "Homework 1",
    "section": "b) What is the probability that a randomly selected inmate has fewer than 2 prior convictions?",
    "text": "b) What is the probability that a randomly selected inmate has fewer than 2 prior convictions?\n\n\nCode\nc<-(128+434)/810\nc\n\n\n[1] 0.6938272\n\n\nThe probability is 69.4%."
  },
  {
    "objectID": "posts/HW1_Guanhua_Tan.html#c-what-is-the-probability-that-a-randomly-selected-inmate-has-2-or-fewer-prior-convictions",
    "href": "posts/HW1_Guanhua_Tan.html#c-what-is-the-probability-that-a-randomly-selected-inmate-has-2-or-fewer-prior-convictions",
    "title": "Homework 1",
    "section": "c) What is the probability that a randomly selected inmate has 2 or fewer prior convictions?",
    "text": "c) What is the probability that a randomly selected inmate has 2 or fewer prior convictions?\n\n\nCode\nc <- (434+160+128)/810\nc\n\n\n[1] 0.891358\n\n\nThe probability is 89.1%."
  },
  {
    "objectID": "posts/HW1_Guanhua_Tan.html#d-what-is-the-probability-that-a-randomly-selected-inmate-has-more-than-2-prior-convictions",
    "href": "posts/HW1_Guanhua_Tan.html#d-what-is-the-probability-that-a-randomly-selected-inmate-has-more-than-2-prior-convictions",
    "title": "Homework 1",
    "section": "d) What is the probability that a randomly selected inmate has more than 2 prior convictions?",
    "text": "d) What is the probability that a randomly selected inmate has more than 2 prior convictions?\n\n\nCode\nc<-(64+24)/810\nc\n\n\n[1] 0.108642\n\n\nThe probability is 10.9%."
  },
  {
    "objectID": "posts/HW1_Guanhua_Tan.html#e-what-is-the-expected-value1-for-the-number-of-prior-convictions",
    "href": "posts/HW1_Guanhua_Tan.html#e-what-is-the-expected-value1-for-the-number-of-prior-convictions",
    "title": "Homework 1",
    "section": "e) What is the expected value1 for the number of prior convictions?",
    "text": "e) What is the expected value1 for the number of prior convictions?\n\n\nCode\nvals<-c(0,1,2,3,4)\nprobs<-c(128/810, 434/810, 160/810, 64/801, 24/810)\nexv<-weighted.mean(vals, probs)\nexv\n\n\n[1] 1.28794\n\n\nThe expected value is 1.29.\n\nCalculate the variance and the standard deviation for the Prior Convictions.\n\n\n\nCode\nvar <- sum((vals-exv)^2*probs)\nvar\n\n\n[1] 0.8588399\n\n\nCode\nsd <- sqrt(var)\nsd\n\n\n[1] 0.9267361\n\n\nThe variance is 0.8588. The standard deviation is 0.9267."
  },
  {
    "objectID": "posts/AdithyaParupudi_finalproject1.html",
    "href": "posts/AdithyaParupudi_finalproject1.html",
    "title": "Final Project Checkin",
    "section": "",
    "text": "Description\nThe birthwt dataset(part of the MASS package) is a widely-used data collection in the field of medical statistics and public health research, focusing on the factors influencing birth weight in newborns. It contains records of various factors such as maternal age, weight, race, smoking habits during pregnancy, and the number of prenatal visits, among others. By analyzing the relationships between these variables and birth weight, researchers and medical professionals can identify potential risk factors, better understand the determinants of low birth weight, and develop effective interventions to improve maternal and neonatal health outcomes.\n\n\nResearch Questions\n\nDoes maternal smoking during pregnancy have a significant impact on newborn birth weight?\nIs there a correlation between maternal age and the number of prenatal visits?\nDo racial differences influence birth weight, when controlling for other factors such as maternal age, weight, and smoking habits?\n\n\n\nHypothesis\n\nNull Hypothesis (H0): There is no significant relationship between maternal smoking during pregnancy and newborn birth weight, after controlling for other factors such as maternal age, weight, and race.\nThere is a significant relationship between maternal smoking during pregnancy and newborn birth weight.\nThe relationship between maternal age and newborn birth weight is moderated by the number of prenatal visits, such that the positive association between maternal age and birth weight is stronger for mothers with a higher number of prenatal visits.\n\n\n\nDescriptive Statistics\nThe birthwt data frame has 189 rows and 10 columns. The data were collected at Baystate Medical Center, Springfield, Mass during 1986.\n\nlow: an indicator of birth weight less than 2.5 kg.\nage: mother’s age in years.\nlwt: mother’s weight in pounds at last menstrual period.\nrace: mother’s race (1 = white, 2 = black, 3 = other).\nsmoke: smoking status during pregnancy.\nptl: number of previous premature labors.\nht: history of hypertension.\nui: presence of uterine irritability.\niv: number of physician visits during the first trimester.\nbwt: birth weight in grams.\n\n\n\nExploratory Data Analysis\n\n\nCode\n# column names\ncolnames(birthwt)\n\n\n [1] \"low\"   \"age\"   \"lwt\"   \"race\"  \"smoke\" \"ptl\"   \"ht\"    \"ui\"    \"ftv\"  \n[10] \"bwt\"  \n\n\n\n\nCode\nglimpse(birthwt)\n\n\nRows: 189\nColumns: 10\n$ low   <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ age   <int> 19, 33, 20, 21, 18, 21, 22, 17, 29, 26, 19, 19, 22, 30, 18, 18, …\n$ lwt   <int> 182, 155, 105, 108, 107, 124, 118, 103, 123, 113, 95, 150, 95, 1…\n$ race  <int> 2, 3, 1, 1, 1, 3, 1, 3, 1, 1, 3, 3, 3, 3, 1, 1, 2, 1, 3, 1, 3, 1…\n$ smoke <int> 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0…\n$ ptl   <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0…\n$ ht    <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ ui    <int> 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1…\n$ ftv   <int> 0, 3, 1, 2, 0, 0, 1, 1, 1, 0, 0, 1, 0, 2, 0, 0, 0, 3, 0, 1, 2, 3…\n$ bwt   <int> 2523, 2551, 2557, 2594, 2600, 2622, 2637, 2637, 2663, 2665, 2722…\n\n\n\n\nCode\nhead(birthwt)\n\n\n   low age lwt race smoke ptl ht ui ftv  bwt\n85   0  19 182    2     0   0  0  1   0 2523\n86   0  33 155    3     0   0  0  0   3 2551\n87   0  20 105    1     1   0  0  0   1 2557\n88   0  21 108    1     1   0  0  1   2 2594\n89   0  18 107    1     1   0  0  1   0 2600\n91   0  21 124    3     0   0  0  0   0 2622\n\n\n\n\nReferences\nVenables, W. N. and Ripley, B. D. (2002) Modern Applied Statistics with S. Fourth edition. Springer"
  },
  {
    "objectID": "posts/JustineShakespeare_FinalProject.html",
    "href": "posts/JustineShakespeare_FinalProject.html",
    "title": "Maternal Mortality and Women’s Empowerment: Exploring Non-Medical Factors Associated with Better Outcomes for Mothers Across the Globe",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(summarytools)\n\nknitr::opts_chunk$set(echo = TRUE)"
  },
  {
    "objectID": "posts/JustineShakespeare_FinalProject.html#research-question",
    "href": "posts/JustineShakespeare_FinalProject.html#research-question",
    "title": "Maternal Mortality and Women’s Empowerment: Exploring Non-Medical Factors Associated with Better Outcomes for Mothers Across the Globe",
    "section": "Research Question",
    "text": "Research Question\nDespite advancements in health and technology, maternal mortality remains a significant public health challenge around the world. According to the World Health Organization, approximately 287,000 women died from complications related to pregnancy or childbirth in 2020.1 Recently it was reported that global declines in maternal mortality have stalled,2 even increased in the United States,3 and data from 2020 has shown the pandemic brought a sharp uptick in maternal deaths.4 The World Health Organization has stated that the majority of maternal deaths are preventable.5\n\n\n\n\n\n\nDefinitions\n\n\n\nAccording to the World Health Organization, the maternal mortality ratio (MMR) is defined as: “the number of maternal deaths during a given time period per 100,000 live births during the same time period.”\nMaternal deaths are defined as: “deaths from any cause related to or aggravated by pregnancy or its management (excluding accidental or incidental causes) during pregnancy and childbirth or within 42 days of termination of pregnancy…”6\n\n\nPast research has investigated variables that correlate with higher rates of maternal mortality, both at the level of the individual and country. Many studies have found, unsurprisingly, that medical and health-related factors are strongly associated with maternal mortality.7 8 In developing countries in particular, where the majority of maternal deaths are taking place,9 factors related to development, including income levels, adult literacy, access to water and sanitation, as well as health-related factors were also found to be associated with maternal mortality.10\nThis research will explore further the relationship between non-health related variables and maternal mortality. In particular, variables related to women’s political and legal rights and economic empowerment will be explored, as well as those related to family development and early childhood support. In short, this analysis seeks to answer the question: How do factors related to women’s empowerment and family development impact maternal mortality?\nThis research will utilize several datasets made available by UNICEF as part of the “The State of the World’s Children 2021” set of statistical tables.11 Specifically, I will create a new dataset by pulling variables from the following tables:\n\nTable 1 - Demographics\nTable 2 - Child mortality\nTable 3 - Maternal and newborn health\nTable 16 - Economic indicators\nTable 17 - Women’s economic empowerment\n\nThe dependent variable for this research will be the Maternal Mortality Ratio (MMR) from the Maternal and newborn health table. The independent variables that will be explored are:\n\nSocial Institutions and Gender Index (SIGI)\nLegal frameworks on gender equality in employment\nWomen’s educational attainment\nWomen’s labour force participation rate\nWomen’s financial inclusion\nMaternity leave benefits\nPaternity leave benefits\n\nAlso under consideration are a few additional variables related to family development and early childhood support such as whether or not the country has ratified ILO convention 156 on workers with family responsibilities."
  },
  {
    "objectID": "posts/JustineShakespeare_FinalProject.html#hypothesis",
    "href": "posts/JustineShakespeare_FinalProject.html#hypothesis",
    "title": "Maternal Mortality and Women’s Empowerment: Exploring Non-Medical Factors Associated with Better Outcomes for Mothers Across the Globe",
    "section": "Hypothesis",
    "text": "Hypothesis\nHypothesis 1: Indicators of women’s economic and political empowerment, including the SIGI, legal frameworks on gender equality in employment, financial inclusion of women, women’s educational attainment and labor force participation rate correlate with a lower maternal mortality rate.\nHypothesis 2: Indicators that relate to family development and support, including maternity leave and paternity leave correlate with lower rates of maternal mortality."
  },
  {
    "objectID": "posts/JustineShakespeare_FinalProject.html#descriptive-statistics",
    "href": "posts/JustineShakespeare_FinalProject.html#descriptive-statistics",
    "title": "Maternal Mortality and Women’s Empowerment: Exploring Non-Medical Factors Associated with Better Outcomes for Mothers Across the Globe",
    "section": "Descriptive Statistics",
    "text": "Descriptive Statistics\nI spent quite a bit of time loading, cleaning, and joining the original tables from UNICEF, and I have already isolated the variables of interest for this research. I saved this revised dataframe as a csv file that we can load now to take a look at the data we’ll be using.\n\n\nCode\nUNICEF_MMR <- read_csv(\"/Users/justineshakespeare/603-Spring-2023/posts/UNICEF_MMR.csv\")\n\n\nRows: 184 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (4): Countries_and_areas, SIGI_2019, Maternity_Leave, Paternity_Leave\ndbl (25): Gov_Expend_percent_TOTAL, Gov_Expend_percent_HEALTH, Gov_Expend_pe...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCode\nglimpse(UNICEF_MMR)\n\n\nRows: 184\nColumns: 29\n$ Countries_and_areas                    <chr> \"Afghanistan\", \"Albania\", \"Alge…\n$ Gov_Expend_percent_TOTAL               <dbl> NA, 11.523943, 16.946099, 10.32…\n$ Gov_Expend_percent_HEALTH              <dbl> 0.4859748, 2.8415394, 4.0938535…\n$ Gov_Expend_percent_EDUCATION           <dbl> 4.05887, 3.61172, NA, NA, NA, 5…\n$ Gov_Expend_percent_SOC_Protection      <dbl> 1.844514, 9.471104, NA, NA, NA,…\n$ SIGI_2019                              <chr> \"Very high\", \"Low\", NA, NA, NA,…\n$ LegalFramework_gender_equal_employment <dbl> NA, 80, NA, NA, NA, 60, 80, 100…\n$ Maternity_Leave                        <chr> \"No\", \"Yes\", \"Yes\", \"No\", \"No\",…\n$ Paternity_Leave                        <chr> \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"No…\n$ Edu_Attain_Up_Secondary_Male           <dbl> NA, NA, NA, 19.85885, NA, 54.82…\n$ Edu_Attain_Up_Secondary_Female         <dbl> NA, NA, NA, 12.29260, NA, 59.16…\n$ LF_partic_rate_Male_Rural              <dbl> 75.3, 64.4, 74.1, 86.5, NA, 68.…\n$ LF_partic_rate_Male_Urban              <dbl> 72.4, 70.1, 64.5, 72.9, NA, 75.…\n$ LF_partic_rate_Male_Total              <dbl> 74.5, 68.0, 67.8, 78.8, NA, 72.…\n$ LF_partic_rate_Female_Rural            <dbl> 23.6, 49.6, 13.2, 89.5, NA, 48.…\n$ LF_partic_rate_Female_Urban            <dbl> 16.9, 54.1, 18.8, 65.9, NA, 52.…\n$ LF_partic_rate_Female_Total            <dbl> 21.8, 52.5, 17.0, 76.1, NA, 51.…\n$ Mobile_phone_ownership_MALE            <dbl> NA, NA, 92.62, NA, NA, NA, 75.9…\n$ Mobile_phone_ownership_FEMALE          <dbl> NA, NA, 83.07, NA, NA, NA, 76.8…\n$ Financial_Inclusion_Male               <dbl> 22.54, 42.04, 56.25, 36.13, NA,…\n$ Financial_Inclusion_Female             <dbl> 7.16, 38.10, 29.27, 22.33, NA, …\n$ Life_Expectancy_female_2020            <dbl> 66.7, 80.3, 78.3, 64.4, 78.2, 8…\n$ Adolescent_birth_rate_2015to2020       <dbl> 62.0, 14.2, 12.0, 163.0, 27.7, …\n$ Antenatal_care_at_least_ONE_VISIT      <dbl> 65.2, 88.4, 95.3, 81.6, 100.0, …\n$ Antenatal_care_at_least_FOUR_VISITS    <dbl> 20.9, 77.8, 69.8, 61.4, 100.0, …\n$ Maternal_Mortality_Ratio_2017          <dbl> 638, 15, 112, 241, 42, 39, 26, …\n$ SIGI_num                               <dbl> 5, 2, NA, NA, NA, NA, 2, 1, 1, …\n$ Mat_Leave                              <dbl> 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0…\n$ Pat_Leave                              <dbl> 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0…\n\n\nThis dataset has 184 observations and 29 variables. Each observation represents a country. The majority of variables are numeric, those that are not were transformed into numeric variables (see the last three variables: SIGI_num, Mat_Leave, Pat_Leave).\nNote that right now I have included a larger set of variables that I’d like to explore at this point in the project timeline. For the final project I will likely present a truncated list of just the variables that will be featured in the analysis.\nLet’s take a closer look at our response variable, the Maternal Mortality Ratio. We can check out the mean, standard deviation, the full range (the lowest and highest values), values in the 25th, and 75th quantiles, as well as the median. This will give us a sense of the full spread of this variable.\n\n\nCode\nMMR_spread <- UNICEF_MMR %>% \n  summarize(\"Mean\" = mean(Maternal_Mortality_Ratio_2017, na.rm = TRUE),\n            \"Standard_Deviation\" = sd(Maternal_Mortality_Ratio_2017, na.rm = TRUE),\n            \"Lowest\" = min(Maternal_Mortality_Ratio_2017, na.rm = TRUE), \n            \"25th quantile\" = quantile(x = Maternal_Mortality_Ratio_2017, probs = .25),\n            \"Median\" = median(Maternal_Mortality_Ratio_2017, na.rm = TRUE),\n            \"75th quantile\" = quantile(x = Maternal_Mortality_Ratio_2017, probs = .75),\n            \"Highest\" = max(Maternal_Mortality_Ratio_2017, na.rm = TRUE))\nMMR_spread\n\n\n# A tibble: 1 × 7\n   Mean Standard_Deviation Lowest `25th quantile` Median `75th quantile` Highest\n  <dbl>              <dbl>  <dbl>           <dbl>  <dbl>           <dbl>   <dbl>\n1  160.               233.      2            12.8     53            188.    1150\n\n\nWe can see that there is quite a range, from 2 to 1,150. The relatively large standard deviation indicates there is a fair amount of variability as well. We can see from the median and 75th quantile numbers that most of the countries in this data have MMRs lower than about 190. But the highest value here shows us that some countries have an MMR over 5 times that amount.\nLet’s take a look at which countries have the highest MMRs (the most deaths per 100,000 live births).\n\n\nCode\nMMR_high <- UNICEF_MMR %>% \n  select(\"Countries_and_areas\", \"Maternal_Mortality_Ratio_2017\") %>% \n  arrange(desc(as.numeric(Maternal_Mortality_Ratio_2017)))\n\nprint(MMR_high, limit = 10)\n\n\n# A tibble: 184 × 2\n   Countries_and_areas      Maternal_Mortality_Ratio_2017\n   <chr>                                            <dbl>\n 1 South Sudan                                       1150\n 2 Chad                                              1140\n 3 Sierra Leone                                      1120\n 4 Nigeria                                            917\n 5 Central African Republic                           829\n 6 Somalia                                            829\n 7 Mauritania                                         766\n 8 Guinea-Bissau                                      667\n 9 Liberia                                            661\n10 Afghanistan                                        638\n# … with 174 more rows\n\n\nLet’s see which countries have the lowest MMRs.\n\n\nCode\nMMR_low <- UNICEF_MMR %>% \n  select(\"Countries_and_areas\", \"Maternal_Mortality_Ratio_2017\") %>% \n  arrange(as.numeric(Maternal_Mortality_Ratio_2017))\n\nprint(MMR_low, limit = 10)\n\n\n# A tibble: 184 × 2\n   Countries_and_areas  Maternal_Mortality_Ratio_2017\n   <chr>                                        <dbl>\n 1 Belarus                                          2\n 2 Italy                                            2\n 3 Norway                                           2\n 4 Poland                                           2\n 5 Czechia                                          3\n 6 Finland                                          3\n 7 Greece                                           3\n 8 Israel                                           3\n 9 United Arab Emirates                             3\n10 Denmark                                          4\n# … with 174 more rows\n\n\nFinally, we’ll take a look at some of the explanatory variables we’re interested in exploring.\n\n\nCode\nsummary(UNICEF_MMR[, c(\"SIGI_num\", \"LegalFramework_gender_equal_employment\", \n                       \"Edu_Attain_Up_Secondary_Female\", \"LF_partic_rate_Female_Total\", \n                       \"Financial_Inclusion_Female\", \"Mat_Leave\", \"Pat_Leave\")])\n\n\n    SIGI_num     LegalFramework_gender_equal_employment\n Min.   :1.000   Min.   : 20.0                         \n 1st Qu.:1.000   1st Qu.: 60.0                         \n Median :2.000   Median : 80.0                         \n Mean   :2.458   Mean   : 76.6                         \n 3rd Qu.:3.000   3rd Qu.: 97.5                         \n Max.   :5.000   Max.   :100.0                         \n NA's   :66      NA's   :90                            \n Edu_Attain_Up_Secondary_Female LF_partic_rate_Female_Total\n Min.   : 1.572                 Min.   : 6.00              \n 1st Qu.:35.857                 1st Qu.:44.75              \n Median :59.633                 Median :54.30              \n Mean   :54.149                 Mean   :52.06              \n 3rd Qu.:75.668                 3rd Qu.:61.05              \n Max.   :96.898                 Max.   :83.90              \n NA's   :90                     NA's   :5                  \n Financial_Inclusion_Female   Mat_Leave        Pat_Leave     \n Min.   :  1.67             Min.   :0.0000   Min.   :0.0000  \n 1st Qu.: 29.85             1st Qu.:0.0000   1st Qu.:0.0000  \n Median : 52.28             Median :1.0000   Median :1.0000  \n Mean   : 54.60             Mean   :0.6298   Mean   :0.5967  \n 3rd Qu.: 79.78             3rd Qu.:1.0000   3rd Qu.:1.0000  \n Max.   :100.00             Max.   :1.0000   Max.   :1.0000  \n NA's   :31                 NA's   :3        NA's   :3       \n\n\nThere is a fair amount of variability between the ranges for each of these variables - some are a binary (such as maternity or paternity leave), with values of either 0 or 1 and nothing in between. Other variables (such as financial inclusion) range from 0 to 100. We also see that some of the variables have more NAs than others, we will need to be conscious of those when performing the analysis."
  },
  {
    "objectID": "posts/FinalProject_Part1_AlexaPotter.html",
    "href": "posts/FinalProject_Part1_AlexaPotter.html",
    "title": "Final Project Part 1",
    "section": "",
    "text": "Research Question\nGreenery is widely recognized as a vital element to any public space. Plants and natural elements of all kinds can add immense benefits to urban areas, not only to the environment but to the humans who inhabit the space as well. Studies have shown that urban greening, specifically the planting of trees, can “combat challenges such as pollution, urban heat, and flooding, as well as to improve social cohesion, human health, and well-being.”1 The understanding and implementation of this information can lead cities, developers, and anyone with a stake in their community to consciously consider what elements they can incorporate into their own public spaces. The work does not end here though, greenery in public spaces requires maintenance and year-round management to make these efforts last long enough to see the benefits.\nNew York City, with a population of about 8.4 billion people and 300 square miles, is one of the largest urban spaces in the United States.2 In 1995, the New York City Department of Parks and Recreation conducted a city wide census of all the trees. They again conducted this survey in 2005 and 2015 to tackle their goal of enhancing and restoring urban forests.3 The information this survey collected has been used to create an interactive map of tree species around New York City. The Parks department then uses this data to calculate the related impacts and needs associated with the trees and tree maintenance.4\nWhile there is a large amount of data related to the tree census published, there is a gap in information on the relation between tree data to specific neighborhoods. Critically analyzing this tree data on a neighborhood level can lead to further community involvement within and stemming from neighborhoods themselves.5 Firsthand involvement can be used to develop connections between community members and foster ownership among members with the environment they inhabit.\nThis informs my research question:\n\nWhat are the significant differences in tree characteristics across New York City neighborhoods?\n\n\n\nHypothesis\nNew York City itself is a diverse landscape with features both conducive and preventive to tree growth and sustainability. Neighborhoods across the city can see significant changes in income, traffic, infrastructure, natural resources such water or sunlight, and attitudes towards the environment.6 Tree size can relay information to researchers on the development and sustainability of their goal to promote urban greening.7 This information can then be used to inform and direct spending and efforts. While there exists a study by Jian Lin, Qiang Wang, and Xiaojiang Li regarding tree characteristics related to socioeconomic and spatial inequalities, my research aims to focus in tree characteristics to specific named neighborhoods.8 Rather than using socioeconomic elements, my research question is focused on smaller geographic areas where individuals can identify themselves as members on a more personal level than a borough.\nWith these factors, I can test the hypothesis’:\nH1: There is a significant difference in tree diameter across New York City neighborhoods\nH2: There is a significant difference in tree health across New York City neighborhoods\nH3: There is a significant difference in tree species across New York City neighborhoods\n\n\nDescriptive Statistics\n\n\nCode\nlibrary(tidyverse)\n\n\n-- Attaching packages --------------------------------------- tidyverse 1.3.2 --\nv ggplot2 3.4.0      v purrr   0.3.5 \nv tibble  3.1.8      v dplyr   1.0.10\nv tidyr   1.2.1      v stringr 1.5.0 \nv readr   2.1.3      v forcats 0.5.2 \n-- Conflicts ------------------------------------------ tidyverse_conflicts() --\nx dplyr::filter() masks stats::filter()\nx dplyr::lag()    masks stats::lag()\n\n\nCode\nlibrary(ggplot2)\nlibrary(formattable)\nlibrary(dbplyr)\n\n\n\nAttaching package: 'dbplyr'\n\nThe following objects are masked from 'package:dplyr':\n\n    ident, sql\n\n\nCode\nlibrary(summarytools)\n\n\n\nAttaching package: 'summarytools'\n\nThe following object is masked from 'package:tibble':\n\n    view\n\n\n\n\nCode\nlibrary(readxl)\ntreecensus <- read_excel(\"C:/Users/aep05/Documents/UMASS_GRAD_SCHOOL/DACSS 603/603_Spring_2023/posts/finalproject/2015_Street_Tree_Census.xls\")\nprint(treecensus)\n\n\n# A tibble: 16,383 x 45\n   tree_id block_id created_at          tree_dbh stump_d~1 curb_~2 status health\n     <dbl>    <dbl> <dttm>                 <dbl>     <dbl> <chr>   <chr>  <chr> \n 1  180683   348711 2015-08-27 00:00:00        3         0 OnCurb  Alive  Fair  \n 2  200540   315986 2015-09-03 00:00:00       21         0 OnCurb  Alive  Fair  \n 3  204026   218365 2015-09-05 00:00:00        3         0 OnCurb  Alive  Good  \n 4  204337   217969 2015-09-05 00:00:00       10         0 OnCurb  Alive  Good  \n 5  189565   223043 2015-08-30 00:00:00       21         0 OnCurb  Alive  Good  \n 6  190422   106099 2015-08-30 00:00:00       11         0 OnCurb  Alive  Good  \n 7  190426   106099 2015-08-30 00:00:00       11         0 OnCurb  Alive  Good  \n 8  208649   103940 2015-09-07 00:00:00        9         0 OnCurb  Alive  Good  \n 9  209610   407443 2015-09-08 00:00:00        6         0 OnCurb  Alive  Good  \n10  192755   207508 2015-08-31 00:00:00       21         0 Offset~ Alive  Fair  \n# ... with 16,373 more rows, 37 more variables: spc_latin <chr>,\n#   spc_common <chr>, steward <chr>, guards <chr>, sidewalk <chr>,\n#   user_type <chr>, problems <chr>, root_stone <chr>, root_grate <chr>,\n#   root_other <chr>, trunk_wire <chr>, trnk_light <chr>, trnk_other <chr>,\n#   brch_light <chr>, brch_shoe <chr>, brch_other <chr>, address <chr>,\n#   postcode <dbl>, zip_city <chr>, `community board` <dbl>, borocode <dbl>,\n#   borough <chr>, cncldist <dbl>, st_assem <dbl>, st_senate <dbl>, ...\n\n\nThis data set is obtained from the 2015 tree census through NYC Open Data provided by the New York City Department of Parks and Recreation.9\nThe information was collected by predominantly volunteers in addition to the New York City Department of Parks and Recreation staff.\nThere are 45 variables and 16,383 observations.\n\n\nCode\nsummary(treecensus)\n\n\n    tree_id          block_id        created_at                 \n Min.   :   306   Min.   :100078   Min.   :2015-05-19 00:00:00  \n 1st Qu.:182110   1st Qu.:216192   1st Qu.:2015-08-28 00:00:00  \n Median :195703   Median :301941   Median :2015-09-01 00:00:00  \n Mean   :189968   Mean   :283657   Mean   :2015-08-30 16:07:33  \n 3rd Qu.:206443   3rd Qu.:345725   3rd Qu.:2015-09-06 00:00:00  \n Max.   :276846   Max.   :516315   Max.   :2015-10-01 00:00:00  \n                                                                \n    tree_dbh        stump_diam         curb_loc            status         \n Min.   :  0.00   Min.   :  0.0000   Length:16383       Length:16383      \n 1st Qu.:  4.00   1st Qu.:  0.0000   Class :character   Class :character  \n Median :  9.00   Median :  0.0000   Mode  :character   Mode  :character  \n Mean   : 10.87   Mean   :  0.5174                                        \n 3rd Qu.: 15.00   3rd Qu.:  0.0000                                        \n Max.   :425.00   Max.   :140.0000                                        \n                                                                          \n    health           spc_latin          spc_common          steward         \n Length:16383       Length:16383       Length:16383       Length:16383      \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n    guards            sidewalk          user_type           problems        \n Length:16383       Length:16383       Length:16383       Length:16383      \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n  root_stone         root_grate         root_other         trunk_wire       \n Length:16383       Length:16383       Length:16383       Length:16383      \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n  trnk_light         trnk_other         brch_light         brch_shoe        \n Length:16383       Length:16383       Length:16383       Length:16383      \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n  brch_other          address             postcode       zip_city        \n Length:16383       Length:16383       Min.   :   83   Length:16383      \n Class :character   Class :character   1st Qu.:10308   Class :character  \n Mode  :character   Mode  :character   Median :11207   Mode  :character  \n                                       Mean   :10858                     \n                                       3rd Qu.:11356                     \n                                       Max.   :11697                     \n                                                                         \n community board    borocode      borough             cncldist    \n Min.   :101.0   Min.   :1.00   Length:16383       Min.   : 1.00  \n 1st Qu.:212.0   1st Qu.:2.00   Class :character   1st Qu.:17.00  \n Median :315.0   Median :3.00   Mode  :character   Median :29.00  \n Mean   :322.4   Mean   :3.16                      Mean   :28.15  \n 3rd Qu.:407.0   3rd Qu.:4.00                      3rd Qu.:39.00  \n Max.   :503.0   Max.   :5.00                      Max.   :51.00  \n                                                                  \n    st_assem       st_senate         nta              nta_name        \n Min.   :23.00   Min.   :10.00   Length:16383       Length:16383      \n 1st Qu.:36.00   1st Qu.:15.00   Class :character   Class :character  \n Median :52.00   Median :21.00   Mode  :character   Mode  :character  \n Mean   :51.51   Mean   :21.06                                        \n 3rd Qu.:65.00   3rd Qu.:26.00                                        \n Max.   :87.00   Max.   :36.00                                        \n                                                                      \n    boro_ct           state              latitude       longitude     \n Min.   :1000201   Length:16383       Min.   :40.50   Min.   :-74.25  \n 1st Qu.:2044200   Class :character   1st Qu.:40.64   1st Qu.:-73.98  \n Median :3063800   Mode  :character   Median :40.72   Median :-73.95  \n Mean   :3196724                      Mean   :40.71   Mean   :-73.94  \n 3rd Qu.:4071900                      3rd Qu.:40.77   3rd Qu.:-73.89  \n Max.   :5030302                      Max.   :40.91   Max.   :-73.71  \n                                                                      \n      x_sp              y_sp        council district  census tract   \n Min.   : 914125   Min.   :121318   Min.   : 1.0     Min.   :     1  \n 1st Qu.: 990034   1st Qu.:171719   1st Qu.:18.0     1st Qu.:   159  \n Median : 998821   Median :200164   Median :29.0     Median :   393  \n Mean   : 999537   Mean   :196583   Mean   :28.2     Mean   :  8356  \n 3rd Qu.:1015348   3rd Qu.:219429   3rd Qu.:39.0     3rd Qu.:  1113  \n Max.   :1065861   Max.   :269471   Max.   :51.0     Max.   :157901  \n                                    NA's   :169      NA's   :169     \n      bin               bbl           \n Min.   :1000000   Min.   :1.000e+09  \n 1st Qu.:2112823   1st Qu.:2.054e+09  \n Median :3255106   Median :3.067e+09  \n Mean   :3272538   Mean   :3.200e+09  \n 3rd Qu.:4143916   3rd Qu.:4.041e+09  \n Max.   :5166656   Max.   :5.079e+09  \n NA's   :267       NA's   :267        \n\n\nFull list of variables:\n\n\nCode\ncolnames(treecensus)\n\n\n [1] \"tree_id\"          \"block_id\"         \"created_at\"       \"tree_dbh\"        \n [5] \"stump_diam\"       \"curb_loc\"         \"status\"           \"health\"          \n [9] \"spc_latin\"        \"spc_common\"       \"steward\"          \"guards\"          \n[13] \"sidewalk\"         \"user_type\"        \"problems\"         \"root_stone\"      \n[17] \"root_grate\"       \"root_other\"       \"trunk_wire\"       \"trnk_light\"      \n[21] \"trnk_other\"       \"brch_light\"       \"brch_shoe\"        \"brch_other\"      \n[25] \"address\"          \"postcode\"         \"zip_city\"         \"community board\" \n[29] \"borocode\"         \"borough\"          \"cncldist\"         \"st_assem\"        \n[33] \"st_senate\"        \"nta\"              \"nta_name\"         \"boro_ct\"         \n[37] \"state\"            \"latitude\"         \"longitude\"        \"x_sp\"            \n[41] \"y_sp\"             \"council district\" \"census tract\"     \"bin\"             \n[45] \"bbl\"             \n\n\nThe columns I am interested in are:\ntree_id - Unique identification number for each tree point.\ntree_dbh - Diameter of the tree, measured at approximately 54” / 137cm above the ground. Data was collected for both living and dead trees; for stumps, use stump_diam\nstatus - Indicates whether the tree is alive, standing dead, or a stump.\nhealth - Indicates the user’s perception of tree health.\nspc_latin - Scientific name for species, e.g. “Acer rubrum”\nspc_common - Common name for species, e.g. “red maple”\npostcode - Five-digit zipcode in which tree is located\nzip_city - City as derived from zipcode. This is often (but not always) the same as borough.\nborocode - Code for borough in which tree point is located: 1 (Manhattan), 2 (Bronx), 3 (Brooklyn), 4 (Queens), 5 (Staten Island)\nborough - Name of borough in which tree point is located\nnta - This is the NTA Code corresponding to the neighborhood tabulation area from the 2010 US Census that the tree point falls into.\nnta_name - This is the NTA name corresponding to the neighborhood tabulation area from the 2010 US Census that the tree point falls into.\nboro_ct - This is the boro_ct identifyer for the census tract that the tree point falls into.\n\n\nCode\ntreecensus_clean <- select(treecensus, \n                    tree_id, \n                    tree_dbh, \n                    status, \n                    health, \n                    spc_latin,\n                    spc_common,\n                    postcode,\n                    zip_city,\n                    borocode,\n                    borough,\n                    nta,\n                    nta_name,\n                    boro_ct,\n                    )\n\n\n\n\nCode\ngroup_by(treecensus_clean, status, health)%>%\n summarize()\n\n\n`summarise()` has grouped output by 'status'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 5 x 2\n# Groups:   status [3]\n  status health\n  <chr>  <chr> \n1 Alive  Fair  \n2 Alive  Good  \n3 Alive  Poor  \n4 Dead   <NA>  \n5 Stump  <NA>  \n\n\nBecause I am only interested in trees with the status “Alive”, I’ll also need to clean the data set to exclude trees labeled as “Dead” or “Stump”.\n\n\nCode\ntreecensus_clean <- treecensus_clean[treecensus_clean$status != \"Dead\" & treecensus_clean$status != \"Stump\",]\ngroup_by(treecensus_clean, status, health)%>%\n summarize()\n\n\n`summarise()` has grouped output by 'status'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 3 x 2\n# Groups:   status [1]\n  status health\n  <chr>  <chr> \n1 Alive  Fair  \n2 Alive  Good  \n3 Alive  Poor  \n\n\nNow we return to the summary function to view the cleaned data frame.\n\n\nCode\nsummary(treecensus_clean)\n\n\n    tree_id          tree_dbh         status             health         \n Min.   :   306   Min.   :  0.00   Length:15442       Length:15442      \n 1st Qu.:181321   1st Qu.:  5.00   Class :character   Class :character  \n Median :195362   Median : 10.00   Mode  :character   Mode  :character  \n Mean   :189311   Mean   : 11.38                                        \n 3rd Qu.:206165   3rd Qu.: 16.00                                        \n Max.   :227192   Max.   :425.00                                        \n  spc_latin          spc_common           postcode       zip_city        \n Length:15442       Length:15442       Min.   :   83   Length:15442      \n Class :character   Class :character   1st Qu.:10308   Class :character  \n Mode  :character   Mode  :character   Median :11207   Mode  :character  \n                                       Mean   :10855                     \n                                       3rd Qu.:11355                     \n                                       Max.   :11697                     \n    borocode      borough              nta              nta_name        \n Min.   :1.00   Length:15442       Length:15442       Length:15442      \n 1st Qu.:2.00   Class :character   Class :character   Class :character  \n Median :3.00   Mode  :character   Mode  :character   Mode  :character  \n Mean   :3.16                                                           \n 3rd Qu.:4.00                                                           \n Max.   :5.00                                                           \n    boro_ct       \n Min.   :1000201  \n 1st Qu.:2044200  \n Median :3063800  \n Mean   :3196920  \n 3rd Qu.:4072100  \n Max.   :5030302  \n\n\n\n\nCode\ndfSummary(treecensus_clean)\n\n\nData Frame Summary  \ntreecensus_clean  \nDimensions: 15442 x 13  \nDuplicates: 0  \n\n-----------------------------------------------------------------------------------------------------------------------\nNo   Variable      Stats / Values                   Freqs (% of Valid)      Graph                  Valid      Missing  \n---- ------------- -------------------------------- ----------------------- ---------------------- ---------- ---------\n1    tree_id       Mean (sd) : 189310.8 (27189.2)   15442 distinct values                   :      15442      0        \n     [numeric]     min < med < max:                                                         :      (100.0%)   (0.0%)   \n                   306 < 195361.5 < 227192                                                  : :                        \n                   IQR (CV) : 24844 (0.1)                                                 : : :                        \n                                                                                        . : : :                        \n\n2    tree_dbh      Mean (sd) : 11.4 (8.7)           54 distinct values      :                      15442      0        \n     [numeric]     min < med < max:                                         :                      (100.0%)   (0.0%)   \n                   0 < 10 < 425                                             :                                          \n                   IQR (CV) : 11 (0.8)                                      :                                          \n                                                                            :                                          \n\n3    status        1. Alive                         15442 (100.0%)          IIIIIIIIIIIIIIIIIIII   15442      0        \n     [character]                                                                                   (100.0%)   (0.0%)   \n\n4    health        1. Fair                           3085 (20.0%)           III                    15442      0        \n     [character]   2. Good                          11434 (74.0%)           IIIIIIIIIIIIII         (100.0%)   (0.0%)   \n                   3. Poor                            923 ( 6.0%)           I                                          \n\n5    spc_latin     1. Platanus x acerifolia         1981 (12.8%)            II                     15442      0        \n     [character]   2. Gleditsia triacanthos var     1610 (10.4%)            II                     (100.0%)   (0.0%)   \n                   3. Quercus palustris             1354 ( 8.8%)            I                                          \n                   4. Pyrus calleryana              1350 ( 8.7%)            I                                          \n                   5. Acer platanoides               936 ( 6.1%)            I                                          \n                   6. Tilia cordata                  783 ( 5.1%)            I                                          \n                   7. Zelkova serrata                752 ( 4.9%)                                                       \n                   8. Styphnolobium japonicum        733 ( 4.7%)                                                       \n                   9. Ginkgo biloba                  629 ( 4.1%)                                                       \n                   10. Fraxinus pennsylvanica        399 ( 2.6%)                                                       \n                   [ 105 others ]                   4915 (31.8%)            IIIIII                                     \n\n6    spc_common    1. London planetree              1981 (12.8%)            II                     15442      0        \n     [character]   2. honeylocust                   1610 (10.4%)            II                     (100.0%)   (0.0%)   \n                   3. pin oak                       1354 ( 8.8%)            I                                          \n                   4. Callery pear                  1350 ( 8.7%)            I                                          \n                   5. Norway maple                   936 ( 6.1%)            I                                          \n                   6. littleleaf linden              783 ( 5.1%)            I                                          \n                   7. Japanese zelkova               752 ( 4.9%)                                                       \n                   8. Sophora                        733 ( 4.7%)                                                       \n                   9. ginkgo                         629 ( 4.1%)                                                       \n                   10. green ash                     399 ( 2.6%)                                                       \n                   [ 105 others ]                   4915 (31.8%)            IIIIII                                     \n\n7    postcode      Mean (sd) : 10855.4 (740.9)      169 distinct values                       :    15442      0        \n     [numeric]     min < med < max:                                                           :    (100.0%)   (0.0%)   \n                   83 < 11207 < 11697                                                       : :                        \n                   IQR (CV) : 1047 (0.1)                                                    : :                        \n                                                                                            : :                        \n\n8    zip_city      1. Brooklyn                      4384 (28.4%)            IIIII                  15442      0        \n     [character]   2. New York                      2612 (16.9%)            III                    (100.0%)   (0.0%)   \n                   3. Staten Island                 1970 (12.8%)            II                                         \n                   4. Bronx                         1311 ( 8.5%)            I                                          \n                   5. Astoria                        914 ( 5.9%)            I                                          \n                   6. Jackson Heights                377 ( 2.4%)                                                       \n                   7. Forest Hills                   366 ( 2.4%)                                                       \n                   8. Flushing                       288 ( 1.9%)                                                       \n                   9. Ridgewood                      257 ( 1.7%)                                                       \n                   10. Kew Gardens                   252 ( 1.6%)                                                       \n                   [ 34 others ]                    2711 (17.6%)            III                                        \n\n9    borocode      Mean (sd) : 3.2 (1.3)            1 : 2646 (17.1%)        III                    15442      0        \n     [numeric]     min < med < max:                 2 : 1311 ( 8.5%)        I                      (100.0%)   (0.0%)   \n                   1 < 3 < 5                        3 : 4384 (28.4%)        IIIII                                      \n                   IQR (CV) : 2 (0.4)               4 : 5131 (33.2%)        IIIIII                                     \n                                                    5 : 1970 (12.8%)        II                                         \n\n10   borough       1. Bronx                         1311 ( 8.5%)            I                      15442      0        \n     [character]   2. Brooklyn                      4384 (28.4%)            IIIII                  (100.0%)   (0.0%)   \n                   3. Manhattan                     2646 (17.1%)            III                                        \n                   4. Queens                        5131 (33.2%)            IIIIII                                     \n                   5. Staten Island                 1970 (12.8%)            II                                         \n\n11   nta           1. QN72                            726 ( 4.7%)                                  15442      0        \n     [character]   2. SI25                            611 ( 4.0%)                                  (100.0%)   (0.0%)   \n                   3. MN12                            547 ( 3.5%)                                                      \n                   4. BK37                            533 ( 3.5%)                                                      \n                   5. QN28                            486 ( 3.1%)                                                      \n                   6. QN17                            419 ( 2.7%)                                                      \n                   7. QN70                            323 ( 2.1%)                                                      \n                   8. SI48                            306 ( 2.0%)                                                      \n                   9. QN60                            286 ( 1.9%)                                                      \n                   10. SI45                           272 ( 1.8%)                                                      \n                   [ 172 others ]                   10933 (70.8%)           IIIIIIIIIIIIII                             \n\n12   nta_name      1. Steinway                        726 ( 4.7%)                                  15442      0        \n     [character]   2. Oakwood-Oakwood Beach           611 ( 4.0%)                                  (100.0%)   (0.0%)   \n                   3. Upper West Side                 547 ( 3.5%)                                                      \n                   4. Park Slope-Gowanus              533 ( 3.5%)                                                      \n                   5. Jackson Heights                 486 ( 3.1%)                                                      \n                   6. Forest Hills                    419 ( 2.7%)                                                      \n                   7. Astoria                         323 ( 2.1%)                                                      \n                   8. Arden Heights                   306 ( 2.0%)                                                      \n                   9. Kew Gardens                     286 ( 1.9%)                                                      \n                   10. New Dorp-Midland Beach         272 ( 1.8%)                                                      \n                   [ 172 others ]                   10933 (70.8%)           IIIIIIIIIIIIII                             \n\n13   boro_ct       Mean (sd) : 3196920 (1267854)    1015 distinct values                  :        15442      0        \n     [numeric]     min < med < max:                                                   .   :        (100.0%)   (0.0%)   \n                   1000201 < 3063800 < 5030302                              .         :   :                            \n                   IQR (CV) : 2027900 (0.4)                                 :   .     :   :   :                        \n                                                                            :   :   . :   :   :                        \n-----------------------------------------------------------------------------------------------------------------------\n\n\n\n\n\n\n\n\n\nFootnotes\n\n\nCavender, N., & Donnelly, G. (2019). Intersecting Urban Forestry and botanical gardens to address big challenges for healthier trees, people, and cities. PLANTS, PEOPLE, PLANET, 1(4), 315–322. https://doi.org/10.1002/ppp3.38↩︎\nU.S. Census Bureau . (n.d.). U.S. Census Bureau quickfacts: New York City, New York. Retrieved March 20, 2023, from https://www.census.gov/quickfacts/newyorkcitynewyork↩︎\nMerriman, D. (2017) Volunteers count every street tree in New York City. US Forest Service. Retrieved March 20, 2023, from https://www.fs.usda.gov/features/volunteers-count-every-street-tree-new-york-city-0↩︎\nCochran, C., & Greer, B. (2016, June 29). Treescount! 2015: NYC’s Third Street-Tree Census. New York State Urban Forestry Council. Retrieved March 20, 2023, from https://nysufc.org/treescount/2016/04/26/↩︎\nMa, Q., Lin, J., Ju, Y. et al. Individual structure mapping over six million trees for New York City USA. Sci Data 10, 102 (2023). https://doi.org/10.1038/s41597-023-02000-w↩︎\nNeckerman, K., Lovasi, G., Davies, S. et al. Disparities in Urban Neighborhood Conditions: Evidence from GIS Measures and Field Observation in New York City. Public Health Pol 30 (Suppl 1), S264–S285 (2009). https://doi.org/10.1057/jphp.2008.47↩︎\nColleen E. Reid, Laura D. Kubzansky, Jiayue Li, Jessie L. Shmool, Jane E. Clougherty. It’s not easy assessing greenness: A comparison of NDVI datasets and neighborhood types and their associations with self-rated health in New York City. Health & Place 54, 92-101 (2018).https://doi.org/10.1016/j.healthplace.2018.09.005.↩︎\nJian Lin, Qiang Wang, Xiaojiang Li. Socioeconomic and spatial inequalities of street tree abundance, species diversity, and size structure in New York City. Landscape and Urban Planning, Volume 206. 2021. 103992. https://doi.org/10.1016/j.landurbplan.2020.103992.↩︎\nhttps://data.cityofnewyork.us/Environment/2015-Street-Tree-Census-Tree-Data/uvpi-gqnh↩︎"
  },
  {
    "objectID": "posts/HW1_XiaoyanHu.html",
    "href": "posts/HW1_XiaoyanHu.html",
    "title": "Homework 1",
    "section": "",
    "text": "Code\nlibrary(tidyr)\nlibrary(dplyr)\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nCode\nlibrary(readxl)\nlibrary(ggplot2)\ndata<-read_excel(\"/Users/cassie199/Desktop/23spring/603_Spring_2023-1/posts/_data/LungCapData.xls\")\nhead(data)\n\n\n# A tibble: 6 × 6\n  LungCap   Age Height Smoke Gender Caesarean\n    <dbl> <dbl>  <dbl> <chr> <chr>  <chr>    \n1    6.48     6   62.1 no    male   no       \n2   10.1     18   74.7 yes   female no       \n3    9.55    16   69.7 no    female yes      \n4   11.1     14   71   no    male   no       \n5    4.8      5   56.9 no    male   no       \n6    6.22    11   58.7 no    female no       \n\n\n\nQuestion 1\n\nUse the LungCapData to answer the following questions. (Hint: Using dplyr, especially group_by() and summarize() can help you answer the following questions relatively efficiently.)\n\n\nWhat does the distribution of LungCap look like? (Hint: Plot a histogram with probability density on the y axis)\n\n-the distribution of LungCap looks like a normal distribution\n\n\nCode\nggplot(data, aes(x=LungCap)) + geom_histogram()\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\nCompare the probability distribution of the LungCap with respect to Males and Females? (Hint:make boxplots separated by gender using the boxplot() function)\n\n\n\nCode\nboxplot(data$LungCap~data$Gender)\n\n\n\n\n\n\nCompare the mean lung capacities for smokers and non-smokers. Does it make sense?\n\n\n\nCode\nboxplot(data$LungCap~data$Smoke)\n\n\n\n\n\n\nExamine the relationship between Smoking and Lung Capacity within age groups: “less than or equal to 13”, “14 to 15”, “16 to 17”, and “greater than or equal to 18”.\n\n\n\nCode\nage_ranges <- c(\"<=13\", \"14-15\", \"16-17\",  \">18\")\ndata$age_ranges <- cut(data$Age, breaks = c(13, 14,15, 16,17, 18),\n                     include.lowest = TRUE)\nggplot(data, aes(x = age_ranges, y = LungCap)) +\n  geom_boxplot() +\n  labs(x = \"Age Range\", y = \"LungCap\")\n\n\n\n\n\n\nCompare the lung capacities for smokers and non-smokers within each age group. Is your answer different from the one in part c. What could possibly be going on here?\n\n#Question 2\n\nLet X = number of prior convictions for prisoners at a state prison at which there are 810 prisoners.\n\nX 0 1 2 3 4 Frequency 128 434 160 64 24\n\nWhat is the probability that a randomly selected inmate has exactly 2 prior convictions?\n\n\n\nCode\nn<-810\nX<-tibble(x=0:4,\n          F=c(128,434,160,64,24))\nX\n\n\n# A tibble: 5 × 2\n      x     F\n  <int> <dbl>\n1     0   128\n2     1   434\n3     2   160\n4     3    64\n5     4    24\n\n\nCode\npa<-160/n\npa\n\n\n[1] 0.1975309\n\n\n\nWhat is the probability that a randomly selected inmate has fewer than 2 prior convictions?\n\n\n\nCode\npb<-(128+434)/n\npb\n\n\n[1] 0.6938272\n\n\n\nWhat is the probability that a randomly selected inmate has 2 or fewer prior convictions?\n\n\n\nCode\npc<-(128+434+160)/n\npc\n\n\n[1] 0.891358\n\n\n\nWhat is the probability that a randomly selected inmate has more than 2 prior convictions?\n\n\n\nCode\npd<-(64+24)/n\npd\n\n\n[1] 0.108642\n\n\n\nWhat is the expected value1 for the number of prior convictions?\n\n\n\nCode\nprior<-c(434,160,64,24)\nmean(prior)\n\n\n[1] 170.5\n\n\n\nCalculate the variance and the standard deviation for the Prior Convictions.\n\n\n\nCode\nvar(prior)\n\n\n[1] 34115.67\n\n\nCode\nsd(prior)\n\n\n[1] 184.7043"
  },
  {
    "objectID": "posts/FelixBetancourt_Finalpart1 v2.html",
    "href": "posts/FelixBetancourt_Finalpart1 v2.html",
    "title": "Final Project - Check point 1",
    "section": "",
    "text": "Code\nknitr::opts_chunk$set(echo = TRUE, warning = FALSE)\n\n\n\nBurnout in the workplace.\nDACSS 603, Spring 2023\nBurnout is a pervasive issue in many professions, and its consequences can be significant for individuals and organizations alike. According to Maslach and Leiter (2016), burnout is characterized by emotional exhaustion, despersonalization, and reduced personal accomplishment. It is prevalent in a variety of fields, including healthcare (West et al., 2016), among other professions. Burnout can have serious consequences, including decreased job satisfaction, increased absenteeism, and turnover (West et al., 2016).\nThere is a growing body of research exploring the causes and consequences of burnout, as well as potential solutions. Some scholars have identified factors such as job demands, lack of control, and social support as contributing to burnout (Bakker & Demerouti, 2017).\nLee & Eissenstat (2017), for instance, affirm that psychological job demands and work-to-family conflict, as well as control over working hours/schedule, decision-making authority, and role clarity, have significant effects on burnout.\nThe aim of this research paper is to provide a comprehensive understanding of how type of business, and seniority level explain the level of burnout.\nNull hypothesis: The type of business, and seniority does not affect the burnout rate.\nAlternative hypotheses:\n\nWorking in Services (vs product type of business) predict significantly higher burnout rate, especially in Female workers.\nLess years of experience (lower seniority) is significantly related to higher burnout rate.\nThe numbers of work hours allocated affect the burnout rate significantly in WFH setup (vs on site).\n\n\n\nAbout the Data\n\n\nCode\n# Loading packages\n\nsuppressPackageStartupMessages(library(dplyr))\nsuppressPackageStartupMessages(library(tidyverse))\n\n# Reading the data.\n\nburn <- read.csv(\"_data/burnout.csv\")\n\n\nThe dataset was obtained from:\nhttps://www.kaggle.com/datasets/blurredmachine/are-your-employees-burning-out\nLet’s check the strucutre of the dataset:\n\n\nCode\n#Structure\nstr(burn)\n\n\n'data.frame':   22750 obs. of  9 variables:\n $ Employee.ID         : chr  \"fffe32003000360033003200\" \"fffe3700360033003500\" \"fffe31003300320037003900\" \"fffe32003400380032003900\" ...\n $ Date.of.Joining     : chr  \"2008-09-30\" \"2008-11-30\" \"2008-03-10\" \"2008-11-03\" ...\n $ Gender              : chr  \"Female\" \"Male\" \"Female\" \"Male\" ...\n $ Company.Type        : chr  \"Service\" \"Service\" \"Product\" \"Service\" ...\n $ WFH.Setup.Available : chr  \"No\" \"Yes\" \"Yes\" \"Yes\" ...\n $ Designation         : num  2 1 2 1 3 2 3 2 3 3 ...\n $ Resource.Allocation : num  3 2 NA 1 7 4 6 4 6 6 ...\n $ Mental.Fatigue.Score: num  3.8 5 5.8 2.6 6.9 3.6 7.9 4.4 NA NA ...\n $ Burn.Rate           : num  0.16 0.36 0.49 0.2 0.52 0.29 0.62 0.33 0.56 0.67 ...\n\n\nThe dataset contain 9 variables and 22750 observations.\nFour of the variables are categorical and five are numeric (including one as date)\nLet’s see a Summary for each variable.\n\n\nCode\nsummary(burn)\n\n\n Employee.ID        Date.of.Joining       Gender          Company.Type      \n Length:22750       Length:22750       Length:22750       Length:22750      \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n WFH.Setup.Available  Designation    Resource.Allocation Mental.Fatigue.Score\n Length:22750        Min.   :0.000   Min.   : 1.000      Min.   : 0.000      \n Class :character    1st Qu.:1.000   1st Qu.: 3.000      1st Qu.: 4.600      \n Mode  :character    Median :2.000   Median : 4.000      Median : 5.900      \n                     Mean   :2.179   Mean   : 4.481      Mean   : 5.728      \n                     3rd Qu.:3.000   3rd Qu.: 6.000      3rd Qu.: 7.100      \n                     Max.   :5.000   Max.   :10.000      Max.   :10.000      \n                                     NA's   :1381        NA's   :2117        \n   Burn.Rate    \n Min.   :0.000  \n 1st Qu.:0.310  \n Median :0.450  \n Mean   :0.452  \n 3rd Qu.:0.590  \n Max.   :1.000  \n NA's   :1124   \n\n\nAccording to the source of the data, here is an explanation of each variable:\nEmployee ID: The unique ID allocated for each employee.\nDate of Joining: The date-time when the employee has joined the organization.\nGender: The gender of the employee\nCompany Type: The type of company where the employee is working\nWFH Setup Available: Is the work from home facility available for the employee\nDesignation: The designation of the employee of work in the organization. In the range of [0.0, 5.0] bigger is higher designation.\nResource Allocation: The amount of resource allocated to the employee to work, ie. number of working hours.In the range of [1.0, 10.0] (higher means more resource)\nMental Fatigue Score: The level of fatigue mentally the employee is facing.In the range of [0.0, 10.0] where 0.0 means no fatigue and 10.0 means completely fatigue.\nBurn Rate: The value we need to predict for each employee telling the rate of Bur out while working.In the range of [0.0, 1.0] where the higher the value is more is the burn out.\n\n\nReferences:\nBakker, A. B., & Demerouti, E. (2017). Job demands-resources theory: Taking stock and looking forward. Journal of Occupational Health Psychology, 22(3), 273–285.\nLee, Y., Eissenstat, S. (2017). A longitudinal examination of the causes and effects of burnout based on the job demands-resources model. International Journal for Educational and Vocational Guidance, 18(3), 337–354.\nMaslach, C., & Leiter, M. P. (2016). Understanding the burnout experience: Recent research and its implications for psychiatry. World Psychiatry, 15(2), 103–111.\nWest, C. P., Dyrbye, L. N., Erwin, P., Shanafelt, T. D., (2016). Interventions to promote physician well-being and mitigate burnout: A systematic review and meta-analysis. The Lancet, 388(10057), 2272–228"
  },
  {
    "objectID": "posts/Hw1_thrishul.html",
    "href": "posts/Hw1_thrishul.html",
    "title": "Homework - 1",
    "section": "",
    "text": "First, let’s read in the data from the Excel file:\n\n\nCode\nlibrary(readxl)\nlibrary(tidyverse)\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0     ✔ purrr   1.0.1\n✔ tibble  3.1.8     ✔ dplyr   1.1.0\n✔ tidyr   1.3.0     ✔ stringr 1.5.0\n✔ readr   2.1.4     ✔ forcats 1.0.0\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\nCode\ndf <- read_excel(\"_data/LungCapData.xls\")\nhead(df)\n\n\n# A tibble: 6 × 6\n  LungCap   Age Height Smoke Gender Caesarean\n    <dbl> <dbl>  <dbl> <chr> <chr>  <chr>    \n1    6.48     6   62.1 no    male   no       \n2   10.1     18   74.7 yes   female no       \n3    9.55    16   69.7 no    female yes      \n4   11.1     14   71   no    male   no       \n5    4.8      5   56.9 no    male   no       \n6    6.22    11   58.7 no    female no       \n\n\nThe distribution of LungCap looks as follows:\n\n\nCode\nhist(df$LungCap)\n\n\n\n\n\nThe histogram suggests that the distribution is close to a normal distribution. Most of the observations are close to the mean. Very few observations are close to the margins (0 and 15).\nupdate and comit check\n\n\nCode\n# Subset the data frame by gender\nmale_df <- df[df$Gender == \"male\", ]\nfemale_df <- df[df$Gender == \"female\", ]\n\n# Create separate boxplots for males and females\nboxplot(male_df$LungCap, female_df$LungCap, \n        names = c(\"Male\", \"Female\"),\n        xlab = \"Gender\", ylab = \"Lung Capacity\",\n        main = \"Lung Capacity by Gender\")\n\n\n\n\n\n\n\nCode\nno_smoke <- df[df$Smoke == \"no\",]\nyes_smoke <- df[df$Smoke == \"yes\",]\nmean(no_smoke$LungCap)\n\n\n[1] 7.770188\n\n\nCode\nmean(yes_smoke$LungCap)\n\n\n[1] 8.645455\n\n\n\n\n\n\n\nCode\nage_group_1 <- df[df$Age <= 13, ]\nage_group_2 <- df[df$Age >= 14 & df$Age <= 15, ]\nage_group_3 <- df[df$Age >= 16 & df$Age <= 17, ]\nage_group_4 <- df[df$Age >= 18, ]\npar(mfrow=c(2,2)) # Set up a 2x2 grid of plots\n\nboxplot(LungCap ~ Smoke, data = age_group_1, \n        names = c(\"Non-Smoker\", \"Smoker\"),\n        main = \"Age Group <= 13\")\n\nboxplot(LungCap ~ Smoke, data = age_group_2, \n        names = c(\"Non-Smoker\", \"Smoker\"),\n        main = \"Age Group 14-15\")\n\nboxplot(LungCap ~ Smoke, data = age_group_3, \n        names = c(\"Non-Smoker\", \"Smoker\"),\n        main = \"Age Group 16-17\")\n\nboxplot(LungCap ~ Smoke, data = age_group_4, \n        names = c(\"Non-Smoker\", \"Smoker\"),\n        main = \"Age Group >= 18\")\n\n\n\n\n\n\n\nCode\n# Calculate the mean and standard deviation of Lung Capacity for each age group and smoking status\nagg_data <- aggregate(LungCap ~ Age + Smoke, data = df, \n                      FUN = function(x) c(mean = mean(x), sd = sd(x)))\n\nagg_data\n\n\n   Age Smoke LungCap.mean LungCap.sd\n1    3    no    2.9466923  1.7725478\n2    4    no    2.9416667  1.1691521\n3    5    no    3.4987500  1.4349371\n4    6    no    4.4610000  1.4426914\n5    7    no    4.6202703  1.7044248\n6    8    no    5.2743902  1.5602933\n7    9    no    6.6743750  1.4851993\n8   10    no    6.5861702  1.3697906\n9   11    no    7.4325000  1.5284734\n10  12    no    7.7471311  1.5590134\n11  13    no    8.2700820  1.6003504\n12  14    no    8.7785000  1.4940444\n13  15    no    9.4663636  1.5326404\n14  16    no   10.0577778  1.4230731\n15  17    no   11.0492187  1.5239153\n16  18    no   10.8475000  1.4681731\n17  19    no   11.2585714  1.6228260\n18  10   yes    5.9812500  1.4073283\n19  11   yes    7.5156250  2.1181586\n20  12   yes    6.7464286  0.9939849\n21  13   yes    7.8968750  1.1576174\n22  14   yes    7.8291667  1.7020147\n23  15   yes    8.7666667  1.1875000\n24  16   yes    8.8972222  1.3884819\n25  17   yes    9.7818182  1.1881756\n26  18   yes   10.3903846  1.2926692\n27  19   yes   11.3125000  0.6187184\n\n\n#Question 2 # Let X = number of prior convictions for prisoners at a state prison at which there are 810 prisoners."
  },
  {
    "objectID": "posts/HW1_EmmaNarkewicz.html",
    "href": "posts/HW1_EmmaNarkewicz.html",
    "title": "Homework 1",
    "section": "",
    "text": "First, let’s read in the data from the Excel file:\n\n\nCode\nlibrary(readxl)\ndf <- read_excel(\"_data/LungCapData.xls\")\n\n\nThe distribution of LungCap looks as follows:\n\n\nCode\nhist(df$LungCap)\n\n\n\n\n\nThe histogram suggests that the distribution is close to a normal distribution. Most of the observations are close to the mean. Very few observations are close to the margins (0 and 15).\n##b\nTo compare the distribution of the Lung Capacity with respect to Male & Females, I used ggplot to create a side by side boxplot of Lung Capacity for female and males in the sample, with female lung capacity in red & male lung capacity in blue.\n\n\nCode\n#load libraries\nlibrary(dplyr)\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nCode\nlibrary(ggplot2)\n\n\nggplot(data = df, aes(x= Gender, y = LungCap, fill = Gender)) +\n  geom_boxplot() +  scale_y_continuous(breaks = c(0,2,4,6,8,10,12,14,16)) +\n  labs(title = \"Box Plot - Lung Capacity by Gender\", x = \"Gender\", y = \"Lung Capacity (L)\") \n\n\n\n\n\nThe box-plot above shows that males in the sample had on average a higher lung capacity than female in the sample, with a higher minimum, Q1, median, Q3, & maximum lung capacity. 50% of the lung capacity of females in the sample was between 5.75 L - 9.25 L with a median lung capacity of ~7.75 L. In contrast, 50% of the lung capacity of males in the sample was between 6.5L - 10.5L with a median lung capacity of ~8.25L.\nFrom the size of the boxes & whiskers, it seems that a good amount of the male & female lung capacity is clustered around the median, but to better visualize the distribution, not just the difference between male females, I created a histogram below facet-wrapped by gender.\n\n\nCode\n##Histogram\nggplot(df, aes(x= LungCap, fill = Gender)) + geom_histogram() + facet_wrap(vars(`Gender`)) + labs(title = \"Histogram - Lung Capacity by Gender\", x = \"Lung Capacity (L)\", y = \"Frequency\") \n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nThe histogram also reflects a higher lung capacity for men in the sample than women as seen on the x-axis. It also shows that the lung capacity is somewhat normally distributed overall with most of the observations near the mean, though there are several peaks & dips in the histogram where a fewer or more individuals have a specific lung capacity than would be seen in a normal distribution. Additionally, the histogram for female lung capacity has more data concentrated around the mean, making it taller & pointier than the male lung capacity distribution. The male lung capacity histogram on the right has two modes (seen as peaks) at 7L & 11L on the left & right of the mean, unlike in a true normal distribution.\n##c\nTo compare the mean lung capacity of smokers to non-smokers in the sample, I used the group_by(), select(), & summarize() functions to get a table of the mean lung capacity in L for smokers vs. non-smokers in the sample.\n\n\nCode\n#Mean smokers vs. non-smokers.\n\ndf %>%\n  group_by(`Smoke`) %>%\n  select(`Smoke`, `LungCap`) %>%\n  summarize_all(mean, na.rm = TRUE)\n\n\n# A tibble: 2 × 2\n  Smoke LungCap\n  <chr>   <dbl>\n1 no       7.77\n2 yes      8.65\n\n\nThe mean lung capacity of smokers (Smoke = yes) was 8.65 L compared to a mean lung capacity of 7.77 L for non-smokers (Smoke = no).\nI was not expecting the mean Lung Capacity for smokers in this sample to be higher r than the mean Lung Capacity for non-smokers in the sample. This is because smoking harms lungs & thus is expected to decrease lung capacity.\nHowever, I anticipate that other factors such as age & gender might contribute to this counter-intuitive finding. For example, we saw in the previous question that males in the sample have a higher lung capacity then females. So if more smokers are male, the difference in lung capacity between smokers & non-smokers might be explained by gender more than smoking status.\n##d\nTo examine the relationship between Smoking and Lung Capacity within age groups: “less than or equal to 13”, “14 to 15”, “16 to 17”, and “greater than or equal to 18”, I used the case_when() to recreate a new Age_Range variable corresponding to these age groups.\n\n\nCode\n##Using Case_When to create age_range variable\ndf_by_age <- df %>%\n  mutate(Age_Range = case_when(\n    Age <= 13 ~ \"13 or younger\",\n    Age >= 14 & Age < 16 ~ \"14 to 15\",\n    Age >= 15 & Age < 18 ~ \"16 to 17\",\n    Age >= 16 ~ \"18 or older\")\n)\n\n\nI first wanted to see the relative age of the sample. As seen in the table below, over half the sample is 13 or younger (484), with the least common age group in thh sample being 18 or older (80).\n\n\nCode\n#Counts by age\ntable(select(df_by_age, Age_Range))\n\n\nAge_Range\n13 or younger      14 to 15      16 to 17   18 or older \n          428           120            97            80 \n\n\nThis got me curious, as I don’t know many 13-year-olds or people younger than 13 who smoke. The below table shows for each age range how many people smoke vs not smoke. While 27 individuals who were 13 or younger in the sample smoked, this is dwarfed by the 401 13-year-old or younger individuals who don’t smoke. While the number of 13 or younger individuals who smoke is higher than the number of 18 or older individuals who smoke (27 vs. 15), relative to the entire age-group a much higher proportion of the 18 or older age group smoked (15/80) than in the 13 or younger group (27/428).\n\n\nCode\n#Counts yes or no smoking by age\ntable(select(df_by_age, Age_Range, Smoke))\n\n\n               Smoke\nAge_Range        no yes\n  13 or younger 401  27\n  14 to 15      105  15\n  16 to 17       77  20\n  18 or older    65  15\n\n\nAfter examining the relationship between age & smoking, I then wanted to examine the relationship between age & lung capacity before factoring in smoking status. I would expect that as you go through puberty and become and adult (18+) your lung capacity with increase from before puberty (13 and younger). The table below using group_by(), select(), & summarize_all() follows this expected trend, with mean lung capacity increasing for each age group from 6.41 L for 13 or younger to 10.96 L for 18+ individuals in the sample. The mean lung capacity of 18+ is only slightly higher than the mean lung capacity at 16-17 years-old.\n\n\nCode\n#Mean lung capacity by age group\ndf_by_age %>%\n  group_by(`Age_Range`) %>%\n  select(`Age_Range`, `LungCap`) %>%\n  summarise_all(mean, na.rm = TRUE)\n\n\n# A tibble: 4 × 2\n  Age_Range     LungCap\n  <chr>           <dbl>\n1 13 or younger    6.41\n2 14 to 15         9.05\n3 16 to 17        10.2 \n4 18 or older     11.0 \n\n\nFinally, I once again used the group_by(), select(), and summarise_all() function, grouping by age_range & smoking status & calculating the mean lung capacity for smokers & non smokers in each age range, which I will interpret in 1e.\n\n\nCode\n##Mean lung cap by age_range smoker vs. non-smoker\ndf_by_age %>%\n  group_by(`Smoke`, `Age_Range`) %>%\n  select(`Age_Range`, `LungCap`, `Smoke`) %>%\n  summarise_all(mean, na.rm = TRUE)\n\n\n# A tibble: 8 × 3\n# Groups:   Smoke [2]\n  Smoke Age_Range     LungCap\n  <chr> <chr>           <dbl>\n1 no    13 or younger    6.36\n2 no    14 to 15         9.14\n3 no    16 to 17        10.5 \n4 no    18 or older     11.1 \n5 yes   13 or younger    7.20\n6 yes   14 to 15         8.39\n7 yes   16 to 17         9.38\n8 yes   18 or older     10.5 \n\n\n##e In contrast to 1c, where smokers had a higher mean lung capacity than non-smokers (8.64 L vs 7.77 L), for every age group except for 13 or younger non-smokers had a higher lung capacity than non-smokers.\n\nFor the 13 or younger: non-smoker lung capacity = 6.36L, smoker lung capacity = 7.20 L\nFor 14-15: non-smoker lung capacity = 9.14 L, smoker lung capacity = 8.39 L\nFor 16-17: non-smoker lung capacity = 10.47 L, smoker lung capacity = 9.38 L\nFor 18+: non-smoker lung capacity = 11.07L, smoker lung capacity = 10.51 L\n\nConsidering that in part d it was found that average lung capacity increases with age & that a smaller proportion of younger individuals in the sample smoked than the older students, one possible explanation for the finding in 1c is that the higher mean lung capacity for smokers overall in the sample could be due to a higher age of smokers in the sample, not due to smoking.\nIt is worth noting also that the sample smoking & nonsmoking mean lung capacity are closer to the mean lung capacity of the 13 & younger & 14-15 year old age groups, reflecting the larger number of younger folks in the sample compare.\nFor fun, I calculated the mean age for smokers & non smokers in the sample, and smokers indeed were older with a mean age of 14.8, compared to a mean non-smoker age of 12.03.\n\n\nCode\n#Mean age smoker vs. non-smoker\ndf %>%\n  group_by(`Smoke`) %>%\n  select(`Smoke`, `Age`) %>%\n  summarise_all(mean, na.rm = TRUE)\n\n\n# A tibble: 2 × 2\n  Smoke   Age\n  <chr> <dbl>\n1 no     12.0\n2 yes    14.8\n\n\n#Question 2\n##a\nTo answer these questions I used R more of a calculator, plugging in the frequencies from the HW1 Prior Convictions frequency table to probability equations we learned in class.\nThe probability that a randomly selected inmate has exactly 2 prior convictions is the P(X=2) which is 0.198.\n\n\nCode\n#Calculating P(X=2)\nprob_2_pc = 160/810\nprob_2_pc\n\n\n[1] 0.1975309\n\n\n##b\nThe probability that a randomly selected inmate has fewer than 2 prior convictions is the P(X < 2) which is equal to the P(X=0 or 1) which is equal to P(X=0) + P(X=1) which equals a probability of 0.694.\n\n\nCode\n#Calculating P(X<2)\nprob_0_pc = 128/810\nprob_1_pc = 434/810\nprob_less_2_pc = prob_0_pc + prob_1_pc\nprob_less_2_pc\n\n\n[1] 0.6938272\n\n\n##c\nThe probability that a randomly selected inmate has 2 or fewer prior convictions is the P(X ≤ 2) which is equal to the P(X=0 or 1 or 2) which is equal to P(X=0) + P(X=1) + P(X=2) which equals a probability of 0.891.\n\n\nCode\n#Calculating P(X≤2)\n\nprob_0_pc = 128/810\nprob_1_pc = 434/810\nprob_2_pc = 160/810\nprob_equal_or_less_2pc = prob_0_pc + prob_1_pc + prob_2_pc\nprob_equal_or_less_2pc\n\n\n[1] 0.891358\n\n\n##d The probability that a randomly selected inmate has greater than 2 prior convictions is the P(X >2) which is equal to the P(X=3 or 4) which is equal to P(X=3) + P(X=4), which gives a probability of 0.109.\nBecause probabilities should be cumulative, the probability of having greater than 2 prior convictions & the probability of having 2 or less prior convictions should add up to 1. Therefor, 1 - P(X≤2) should equal P(X >2) which we confirm it does.\n\n\nCode\n#Calculating P(x>2) the first way\nprob_3_pc = 64/810\nprob_3_pc\n\n\n[1] 0.07901235\n\n\nCode\nprob_4_pc = 24/810\nprob_4_pc\n\n\n[1] 0.02962963\n\n\nCode\nprob_greater_2_pc = prob_3_pc + prob_4_pc\nprob_greater_2_pc\n\n\n[1] 0.108642\n\n\nCode\n#Calculating P(x>2) the second way\nsame = 1 - prob_equal_or_less_2pc\nsame\n\n\n[1] 0.108642\n\n\n##e\nThe expected value for the number of prior convictions is the long term mean of the sample which can be calculated with the equation: 𝐸(𝑋)=𝜇=∑𝑥𝑃(𝑥)\nThe expected value for number of prior convictions is 1.286\nThis is not an integer, but means that in the long-term sample mean will be close to 1, which aligns with the frequency table, where 1 is the most frequent number of prior convictions.\n\n\nCode\n#Expected value calc\nexpected_value = (0 * prob_0_pc) + (1 * (prob_1_pc)) + (2 * (prob_2_pc)) + (3* (prob_3_pc)) + (4 * (prob_4_pc))\nexpected_value\n\n\n[1] 1.28642\n\n\nCode\n##Check that mean same\n\n((0*128)+(1*434) + (2*160) + (3*64) + (4*24))/810\n\n\n[1] 1.28642\n\n\n##f\nTo calculate the variance of the sample I used the equation Var(X) = Σx^2p − μ^2, where the mean is the expected value calculated in e.\nThis gives a variance of 0.856 years squared and a standard deviation of 0.925 years.\n\n\nCode\n#Calculating variance\nVariance = (((0^2) * prob_0_pc) + ((1^2)* prob_1_pc) + ((2^2) * prob_2_pc) + ((3^2) * prob_3_pc) + ((4^2) * prob_4_pc)) - (expected_value^2)\nVariance\n\n\n[1] 0.8562353\n\n\nCode\n#Calculating sd from variance\nsd = sqrt(Variance)\nsd\n\n\n[1] 0.9253298"
  },
  {
    "objectID": "posts/AlexisGamez_Project_Proposal.html",
    "href": "posts/AlexisGamez_Project_Proposal.html",
    "title": "Project Proposal",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(readr)\n\nknitr::opts_chunk$set(echo = T)"
  },
  {
    "objectID": "posts/AlexisGamez_Project_Proposal.html#description-and-summary-of-the-data",
    "href": "posts/AlexisGamez_Project_Proposal.html#description-and-summary-of-the-data",
    "title": "Project Proposal",
    "section": "Description and Summary of the Data",
    "text": "Description and Summary of the Data\nThis data set was pulled from the Kaggle online database and it’s description reads as follows, This data set contains a list of video games with sales greater than 100,000 copies along with critic and user ratings.\n\n\nCode\n# reading in our data set\nVideo_Game_Sales <- read_csv(\"_data/final_project/Video_Game_Sales_as_of_Jan_2017.csv\")\nhead(Video_Game_Sales)\n\n\n# A tibble: 6 × 15\n  Name       Platform Year_of_Release Genre Publisher NA_Sales EU_Sales JP_Sales\n  <chr>      <chr>              <dbl> <chr> <chr>        <dbl>    <dbl>    <dbl>\n1 Wii Sports Wii                 2006 Spor… Nintendo      41.4    29.0      3.77\n2 Super Mar… NES                 1985 Plat… Nintendo      29.1     3.58     6.81\n3 Mario Kar… Wii                 2008 Raci… Nintendo      15.7    12.8      3.79\n4 Wii Sport… Wii                 2009 Spor… Nintendo      15.6    11.0      3.28\n5 Pokemon R… G                   1996 Role… Nintendo      11.3     8.89    10.2 \n6 Tetris     G                   1989 Puzz… Nintendo      23.2     2.26     4.22\n# … with 7 more variables: Other_Sales <dbl>, Global_Sales <dbl>,\n#   Critic_Score <dbl>, Critic_Count <dbl>, User_Score <dbl>, User_Count <dbl>,\n#   Rating <chr>\n\n\nWith this updated data set provided by the collector, we are given 15 variables and approximately 17,500 entries. The variables are as follows:\n\nName [game’s name]\nPlatform [platform of game release]\nYear of Release [game’s release date]\nGenre [genre of game]\nPublisher [publisher of game]\nNA Sales [sales in North America in millions]\nEU Sales [sales in Europe in millions]\nJPN Sales [sales in Japan in millions]\nOther Sales [sales in rest of the world in millions]\nGlobal Sales [total worldwide sales in millions]\nCritic Score [aggregate score compiled by Metacritic staff]\nCritic Count [the number of critis used in creating the critic score]\nUser Score [score according to Metacritic subscribers]\nUser Count [number of users who gave the user score]\nRating [ESRB rating for the game]"
  },
  {
    "objectID": "posts/AlexisGamez_Project_Proposal.html#how-was-the-data-collected",
    "href": "posts/AlexisGamez_Project_Proposal.html#how-was-the-data-collected",
    "title": "Project Proposal",
    "section": "How was the data collected?",
    "text": "How was the data collected?\nReferencing the data set’s description once again, it states that, It is a combined web scrape from VGChartz and Metacritic along with manually entered year of release values for most games with a missing year of release.\nThe original code the collector utilized was created by Rush Kirubi, but it’s made apparent that the original set limited the data to only include a subset of video game platforms. Additionally, not all the listed video games have information on Metacritic, so there are a significant amount of missing values under the critic & user scores/counts variables.\nThis provides valuable context concerning Metacritic, the forum utilized by critics and users to rate their favorite games, and the numerous missing values within the data set. Metacritic was established in 1999. As a result, all entries pre-dating early 2000 lack critic and user scores, as it had not been as well established at the time.\n\n\nCode\n# summarizing our data\nsummary(Video_Game_Sales)\n\n\n     Name             Platform         Year_of_Release    Genre          \n Length:17416       Length:17416       Min.   :1976    Length:17416      \n Class :character   Class :character   1st Qu.:2003    Class :character  \n Mode  :character   Mode  :character   Median :2008    Mode  :character  \n                                       Mean   :2007                      \n                                       3rd Qu.:2011                      \n                                       Max.   :2017                      \n                                       NA's   :8                         \n  Publisher            NA_Sales          EU_Sales          JP_Sales       \n Length:17416       Min.   : 0.0000   Min.   : 0.0000   Min.   : 0.00000  \n Class :character   1st Qu.: 0.0000   1st Qu.: 0.0000   1st Qu.: 0.00000  \n Mode  :character   Median : 0.0700   Median : 0.0200   Median : 0.00000  \n                    Mean   : 0.2545   Mean   : 0.1407   Mean   : 0.07502  \n                    3rd Qu.: 0.2300   3rd Qu.: 0.1000   3rd Qu.: 0.03000  \n                    Max.   :41.3600   Max.   :28.9600   Max.   :10.22000  \n                                                                          \n  Other_Sales        Global_Sales      Critic_Score    Critic_Count   \n Min.   : 0.00000   Min.   : 0.0100   Min.   :13.00   Min.   :  3.00  \n 1st Qu.: 0.00000   1st Qu.: 0.0500   1st Qu.:60.00   1st Qu.: 11.00  \n Median : 0.01000   Median : 0.1600   Median :71.00   Median : 21.00  \n Mean   : 0.04591   Mean   : 0.5165   Mean   :68.91   Mean   : 26.19  \n 3rd Qu.: 0.03000   3rd Qu.: 0.4500   3rd Qu.:79.00   3rd Qu.: 36.00  \n Max.   :10.57000   Max.   :82.5400   Max.   :98.00   Max.   :113.00  \n                                      NA's   :9080    NA's   :9080    \n   User_Score      User_Count         Rating         \n Min.   :0.000   Min.   :    4.0   Length:17416      \n 1st Qu.:6.400   1st Qu.:   10.0   Class :character  \n Median :7.500   Median :   25.0   Mode  :character  \n Mean   :7.117   Mean   :  162.7                     \n 3rd Qu.:8.200   3rd Qu.:   81.0                     \n Max.   :9.700   Max.   :10766.0                     \n NA's   :9618    NA's   :9618                        \n\n\nSummarizing our data shows that 9,080 entries lack critic scores and 9,618 of them lack user scores. Even with 9,618 entries omitted, there are still over 7,700 complete entries to analyze and I do not fear that the omission will negatively impact the analysis."
  },
  {
    "objectID": "posts/AlexisGamez_Project_Proposal.html#what-are-the-important-variables-of-interest",
    "href": "posts/AlexisGamez_Project_Proposal.html#what-are-the-important-variables-of-interest",
    "title": "Project Proposal",
    "section": "What are the important variables of interest?",
    "text": "What are the important variables of interest?\nOf the 15 variables provided, 11 will be heavily utilized throughout the scope of this project. 6 are to be considered independent variables and the remaining 5 will be dependent.\nThe 6 independent variables are as follows:\n\nPlatform\nGenre\nPublisher\nRating\nCritic Scores\nUser Scores\n\nThe 5 dependent variables are:\n\nNA Sales\nEU Sales\nJPN Sales\nOther Sales\nGlobal Sales\n\nAs stated previously, of the 6 independent variables, I believe that Genre and Platform will have the most significant impact on commercial success than any other of 4 remaining independent variables. However, I’d also like to add that I believe that the Critic Score variable will have little to no correlation with the commercial success of a video game."
  },
  {
    "objectID": "posts/Rowley_Homework_1.html",
    "href": "posts/Rowley_Homework_1.html",
    "title": "Homework 1",
    "section": "",
    "text": "Question 1a: What does the distribution of LungCap look like?\nFirst, let’s read in the data from the Excel file:\n\n\nCode\nlibrary(readxl)\n\n\nWarning: package 'readxl' was built under R version 4.2.2\n\n\nCode\nLungCapData <- read_excel(\"_data/LungCapData.xls\")\n\n\nThe distribution of LungCap looks as follows:\n\n\nCode\nhist(LungCapData$LungCap)\n\n\n\n\n\nThe histogram suggests that the distribution is close to a normal distribution. Most of the observations are close to the mean. Very few observations are close to the margins (0 and 15).\n\n\nQuestion 1b: Compare the probability distribution of the LungCap with respect to Males and Females. (Hint:make boxplots separated by gender using the boxplot() function)\n\n\nCode\nlibrary(dplyr)\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nCode\nlibrary(magrittr)\nlibrary(ggplot2)\nlibrary(markdown)\nlibrary(ggtext)\n\n\nWarning: package 'ggtext' was built under R version 4.2.2\n\n\nCode\n# generate boxplot:\n\nLungCap_Gender <- LungCapData%>%\n  group_by(LungCapData$Gender)%>%\n  ggplot(aes(x=Gender, y=LungCap)) +\n  geom_point(alpha=.08, size=5) +\n  labs(x=\"Gender\", y=\"LungCap\", title=\"LungCap by Gender\") +\n  theme_light() +\n  geom_boxplot() +\n  theme(axis.text.x=element_markdown(hjust=1))\nLungCap_Gender\n\n\n\n\n\nCode\n# would next like to identify specific values for boxplots...\n\n\nThe distribution of LungCap is higher for males than it is for females. For males, the Q1 value is approximately 6.5, the median value is approximately 8, and the Q3 value is approximately 10. For females, the Q1 value is approximately 5.5, the median value is approximately 7.5, and the Q3 value is approximately 9.\n\n\nQuestion 1c: Compare the mean lung capacities for smokers and non-smokers. Does it make sense?\n\n\nCode\nSmoker_Mean <- LungCapData %>%\n  filter(Smoke==\"yes\")%>%\n  select(Smoke, LungCap)%>%\n  summarize(mean(LungCap, na.rm = TRUE))\nSmoker_Mean\n\n\n# A tibble: 1 × 1\n  `mean(LungCap, na.rm = TRUE)`\n                          <dbl>\n1                          8.65\n\n\nCode\nNonSmoker_Mean <- LungCapData %>%\n  filter(Smoke==\"no\")%>%\n  select(Smoke, LungCap)%>%\n  summarize(mean(LungCap, na.rm = TRUE))\nNonSmoker_Mean\n\n\n# A tibble: 1 × 1\n  `mean(LungCap, na.rm = TRUE)`\n                          <dbl>\n1                          7.77\n\n\nThe mean LungCap for smokers is 8.645, while the mean LungCap for non-smokers is 7.77. This doesn’t seem to make sense!\n\n\nQuestion 1d: Examine the relationship between Smoking and Lung Capacity within age groups: “less than or equal to 13”, “14 to 15”, “16 to 17”, and “greater than or equal to 18”.\n\n\nCode\nSmoker_Age_1 <- LungCapData %>%\n  filter(Smoke==\"yes\")%>%\n  filter(Age<=13)%>%\n  select(Smoke, Age, LungCap)%>%\n  summarize(mean(LungCap, na.rm = TRUE))\nSmoker_Age_1\n\n\n# A tibble: 1 × 1\n  `mean(LungCap, na.rm = TRUE)`\n                          <dbl>\n1                          7.20\n\n\nCode\nSmoker_Age_2 <- LungCapData %>%\n  filter(Smoke==\"yes\")%>%\n  filter(Age==14:15)%>%\n  select(Smoke, Age, LungCap)%>%\n  summarize(mean(LungCap, na.rm = TRUE))\n\n\nWarning in Age == 14:15: longer object length is not a multiple of shorter\nobject length\n\n\nCode\nSmoker_Age_2\n\n\n# A tibble: 1 × 1\n  `mean(LungCap, na.rm = TRUE)`\n                          <dbl>\n1                          8.91\n\n\nCode\nSmoker_Age_3 <- LungCapData %>%\n  filter(Smoke==\"yes\")%>%\n  filter(Age==16:17)%>%\n  select(Smoke, Age, LungCap)%>%\n  summarize(mean(LungCap, na.rm = TRUE))\n\n\nWarning in Age == 16:17: longer object length is not a multiple of shorter\nobject length\n\n\nCode\nSmoker_Age_3\n\n\n# A tibble: 1 × 1\n  `mean(LungCap, na.rm = TRUE)`\n                          <dbl>\n1                          9.60\n\n\nCode\nSmoker_Age_4 <- LungCapData %>%\n  filter(Smoke==\"yes\")%>%\n  filter(Age>=18)%>%\n  select(Smoke, Age, LungCap)%>%\n  summarize(mean(LungCap, na.rm = TRUE))\nSmoker_Age_4\n\n\n# A tibble: 1 × 1\n  `mean(LungCap, na.rm = TRUE)`\n                          <dbl>\n1                          10.5\n\n\nThe mean LungCap value for smokers 13 years or younger is 7.202, whereas it is 8.909 for those ages 14-15. For smokers 16-17, the mean LungCap value is 9.602, and for those 18 years and older, it is 10.513.\n\n\nQuestion 1e: Compare the lung capacities for smokers and non-smokers within each age group. Is your answer different from the one in part c? What could possibly be going on here?\n\n\nCode\nNonSmoker_Age_1 <- LungCapData %>%\n  filter(Smoke==\"no\")%>%\n  filter(Age<=13)%>%\n  select(Smoke, Age, LungCap)%>%\n  summarize(mean(LungCap, na.rm = TRUE))\nNonSmoker_Age_1\n\n\n# A tibble: 1 × 1\n  `mean(LungCap, na.rm = TRUE)`\n                          <dbl>\n1                          6.36\n\n\nCode\nNonSmoker_Age_2 <- LungCapData %>%\n  filter(Smoke==\"no\")%>%\n  filter(Age==14:15)%>%\n  select(Smoke, Age, LungCap)%>%\n  summarize(mean(LungCap, na.rm = TRUE))\nNonSmoker_Age_2\n\n\n# A tibble: 1 × 1\n  `mean(LungCap, na.rm = TRUE)`\n                          <dbl>\n1                          8.84\n\n\nCode\nNonSmoker_Age_3 <- LungCapData %>%\n  filter(Smoke==\"no\")%>%\n  filter(Age==16:17)%>%\n  select(Smoke, Age, LungCap)%>%\n  summarize(mean(LungCap, na.rm = TRUE))\nNonSmoker_Age_3\n\n\n# A tibble: 1 × 1\n  `mean(LungCap, na.rm = TRUE)`\n                          <dbl>\n1                          10.4\n\n\nCode\nNonSmoker_Age_4 <- LungCapData %>%\n  filter(Smoke==\"no\")%>%\n  filter(Age>=18)%>%\n  select(Smoke, Age, LungCap)%>%\n  summarize(mean(LungCap, na.rm = TRUE))\nNonSmoker_Age_4\n\n\n# A tibble: 1 × 1\n  `mean(LungCap, na.rm = TRUE)`\n                          <dbl>\n1                          11.1\n\n\nThe corresponding LungCap mean values for non-smokers are 6.359, 8.844, 10.394, and 11.069. All LungCaps are higher for non-smokers with the exception of those in the 13-and-under age bracket. It would make sense that non-smokers would have higher lung capacities, though it is interesting that the value is lower for the youngest age group. This does, however, correlate with the results to question 1c, which indicated that smokers have higher lung capacities than non-smokers; there could, perhaps, be other extenuating circumstances contributing to these lower rates of capacity, such as health issues, development, or exposure.\n\n\nQuestion 2a: What is the probability that a randomly selected inmate has exactly 2 prior convictions?\n\n\nCode\ninmate <- c(128, 434, 160, 64, 24)\nmean(inmate)\n\n\n[1] 162\n\n\nCode\nsd(inmate)\n\n\n[1] 161.0838\n\n\nCode\n# mean=162\n# sd=161.1\n\nconvictions <- c(0:4)\n\ndata <- tibble(inmate, convictions)\n\ntwo <- 160/summarise(data, sum(inmate))\n  two\n\n\n  sum(inmate)\n1   0.1975309\n\n\nHere, we can see that the probability of an inmate having exactly two prior convictions is 19.8%.\n\n\nQuestion 2b: What is the probability that a randomly selected inmate has fewer than 2 prior convictions?\n\n\nCode\nfewer_than_two <- 128 + 434\nfewer_than_two/summarise(data, sum(inmate))\n\n\n  sum(inmate)\n1   0.6938272\n\n\nHere, we can see that the probability of a randomly selected inmate having fewer than two prior convictions is 69.4%.\n\n\nQuestion 2c: What is the probability that a randomly selected inmate has 2 or fewer prior convictions?\n\n\nCode\ntwo_or_fewer <- 128 + 434 + 160\ntwo_or_fewer/summarise(data, sum(inmate))\n\n\n  sum(inmate)\n1    0.891358\n\n\nHere, we can see that the probability of a randomly selected inmate having two or fewer prior convictions is 89.1%.\n\n\nQuestion 2d: What is the probability that a randomly selected inmate has more than 2 prior convictions?\n\n\nCode\nmore_than_two <- 160 + 64 + 24\nmore_than_two/summarise(data, sum(inmate))\n\n\n  sum(inmate)\n1   0.3061728\n\n\nHere, we can see that the probability of a randomly selected inmate having more than two prior convictions is 30.6%.\n\n\nQuestion 2e: What is the expected value1 for the number of prior convictions?\n\n\nCode\ndata_prob <- transform(data, probability = (inmate/810))\ndata_ev <- transform(data_prob, x = convictions*probability)\n\nEV <- sum(data_ev$x)\nEV\n\n\n[1] 1.28642\n\n\nThe expected value1 for the number of prior convictions is 1.3.\n\n\nQuestion 2f: Calculate the variance and the standard deviation for the Prior Convictions.\n\n\nCode\ninmate <- c(128, 434, 160, 64, 24)\nvar(inmate)\n\n\n[1] 25948\n\n\nCode\nsd(inmate)\n\n\n[1] 161.0838\n\n\nThe variance for the prior convictions is 25948, while the standard deviation is 161."
  },
  {
    "objectID": "posts/HW1_LTucksmith.html",
    "href": "posts/HW1_LTucksmith.html",
    "title": "HW1",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(tidyr)\nknitr::opts_chunk$set(echo = TRUE)\n\n\n\n\nCode\ndf <- read_excel(\"_data/LungCapData.xls\")\n\n\n\n\n\n\nWhat does the distribution of LungCap look like?\n\n\n\nCode\nhist(df$LungCap)\n\n\n\n\n\nThe distribution looks normal, the observations are centered around the mean with minimal outliers.\n\nCompare the probability distribution of the LungCap with respect to Males and Females?\n\n\n\nCode\nlungCapP <- pnorm(df$LungCap, mean(df$LungCap), sd(df$LungCap))\nboxplot(lungCapP~df$Gender)\n\n\n\n\n\nFor both male and female, the probability distribution of the LungCap is similiar. For male, the median line is slightly higher than female, suggesting that their average lungCap is slightly higher for males than females. Also, for male the median is directly in the middle, suggesting that the data isn’t particularly skewed. For female the split appears to have more values fall below the mean than above, telling us that the data skews moreso than for male.\n\nCompare the mean lung capacities for smokers and non-smokers. Does it make sense?\n\n\n\nCode\ndfSmokeLungCap <- df %>% group_by(Smoke) %>% \n    summarise(mean_LungCap=mean(LungCap))\n\nprint(dfSmokeLungCap)\n\n\n# A tibble: 2 × 2\n  Smoke mean_LungCap\n  <chr>        <dbl>\n1 no            7.77\n2 yes           8.65\n\n\nNo, the lungCap average does not make sense. We would expect that the lung capacity for smokers would be lower than it is for non-smokers, but we are seeing the opposite, as the lungCap for smokers is higher than it is for non-smokers.\n\nExamine the relationship between Smoking and Lung Capacity within age groups: “less than or equal to 13”, “14 to 15”, “16 to 17”, and “greater than or equal to 18”.\n\n\n\nCode\ndfAgeRanges <- df %>% \n  mutate(ageRange = case_when(\n    df$Age<=13 ~ \"A\",\n    between(df$Age, 14, 15) ~ \"B\",\n    between(df$Age, 16, 17) ~ \"C\",\n    df$Age>=18 ~ \"D\"\n  ))\n\nprint(dfAgeRanges)\n\n\n# A tibble: 725 × 7\n   LungCap   Age Height Smoke Gender Caesarean ageRange\n     <dbl> <dbl>  <dbl> <chr> <chr>  <chr>     <chr>   \n 1    6.48     6   62.1 no    male   no        A       \n 2   10.1     18   74.7 yes   female no        D       \n 3    9.55    16   69.7 no    female yes       C       \n 4   11.1     14   71   no    male   no        B       \n 5    4.8      5   56.9 no    male   no        A       \n 6    6.22    11   58.7 no    female no        A       \n 7    4.95     8   63.3 no    male   yes       A       \n 8    7.32    11   70.4 no    male   no        A       \n 9    8.88    15   70.5 no    male   no        B       \n10    6.8     11   59.2 no    male   no        A       \n# … with 715 more rows\n\n\n\nCompare the lung capacities for smokers and non-smokers within each age group. Is your answer different from the one in part c. What could possibly be going on here?\n\n\n\nCode\ndfMeanAgeRanges <- dfAgeRanges %>% group_by(ageRange, Smoke) %>% \n    summarise(mean_LungCap=mean(LungCap))\n\n\n`summarise()` has grouped output by 'ageRange'. You can override using the\n`.groups` argument.\n\n\nCode\nprint(dfMeanAgeRanges)\n\n\n# A tibble: 8 × 3\n# Groups:   ageRange [4]\n  ageRange Smoke mean_LungCap\n  <chr>    <chr>        <dbl>\n1 A        no            6.36\n2 A        yes           7.20\n3 B        no            9.14\n4 B        yes           8.39\n5 C        no           10.5 \n6 C        yes           9.38\n7 D        no           11.1 \n8 D        yes          10.5 \n\n\nHere, there is a more varied relationship between smoking and lung capacity due to age as a mitigating variable. Here, the lung capacity for non-smokers is higher than the lung capacity for smokers in youngest age range, but the other age ranges display the opposite relationship. This may be due to the possibility that smoking has a stronger influence on lungCapacity the longer you smoke. So younger folks may have only smoked for a year or so, while folks in the older age ranges have spent many more years smoking. While there still isn’t a clear indirect or direct relationship between smoking and lung capacity with this view, adding the ageRange variable showed that there is more to the relationship than was found in part C.\n\n\n\n\n\nCode\nx <- c(0,1,2,3,4)\nfrequency <- c(128,434,160,64,24)\ndf_2 <- data.frame(x, frequency)\n\n\n\nWhat is the probability that a randomly selected inmate has exactly 2 prior convictions?\n\n\n\nCode\nprob_a = dpois(df_2[3,1], df_2[3,2]/(sum(df_2$frequency)))\nprint(prob_a)\n\n\n[1] 0.01601229\n\n\n\nWhat is the probability that a randomly selected inmate has fewer than 2 prior convictions?\n\n\n\nCode\nprob_b = ppois(df_2[2,1], (df_2[2,2]+df_2[1,2])/(sum(df_2$frequency)))\nprint(prob_b)\n\n\n[1] 0.8463379\n\n\n\nWhat is the probability that a randomly selected inmate has 2 or fewer prior convictions?\n\n\n\nCode\nprob_c = ppois(df_2[3,1], (df_2[3,2]+df_2[2,2]+df_2[1,2])/(sum(df_2$frequency)))\nprint(prob_c)\n\n\n[1] 0.9385585\n\n\n\nWhat is the probability that a randomly selected inmate has more than 2 prior convictions?\n\n\n\nCode\ndf_2d <- df_2[4:5,]\nprob_d = 1 - (ppois(df_2d[2,1],(df_2[4,2]+df_2[5,2])/(sum(df_2$frequency))))\nprint(prob_d)              \n\n\n[1] 1.15223e-07\n\n\n\nWhat is the expected value1 for the number of prior convictions?\n\n\n\nCode\nprobs_e = dpois(df_2$x, df_2$frequency/(sum(df_2$frequency)))\neval = sum(df_2$x*probs_e)\nprint(eval)\n\n\n[1] 0.3458039\n\n\n\nCalculate the variance and the standard deviation for the Prior Convictions.\n\n\n\nCode\nvar_f <- var(rep(df_2$x, df_2$frequency))\nprint(var_f)\n\n\n[1] 0.8572937\n\n\nCode\nsd_f <- sd(rep(df_2$x, df_2$frequency))\nprint(sd_f)\n\n\n[1] 0.9259016"
  },
  {
    "objectID": "posts/Hw2_thrishul.html",
    "href": "posts/Hw2_thrishul.html",
    "title": "Homework - 2",
    "section": "",
    "text": "The distribution of LungCap looks as follows:\n\n\nCode\nhist(df$LungCap)\n\n\nError in df$LungCap: object of type 'closure' is not subsettable\n\n\nThe histogram suggests that the distribution is close to a normal distribution. Most of the observations are close to the mean. Very few observations are close to the margins (0 and 15).\nupdate and comit check\n\n\nCode\n# Subset the data frame by gender\nmale_df <- df[df$Gender == \"male\", ]\n\n\nError in df$Gender: object of type 'closure' is not subsettable\n\n\nCode\nfemale_df <- df[df$Gender == \"female\", ]\n\n\nError in df$Gender: object of type 'closure' is not subsettable\n\n\nCode\n# Create separate boxplots for males and females\nboxplot(male_df$LungCap, female_df$LungCap, \n        names = c(\"Male\", \"Female\"),\n        xlab = \"Gender\", ylab = \"Lung Capacity\",\n        main = \"Lung Capacity by Gender\")\n\n\nError in boxplot(male_df$LungCap, female_df$LungCap, names = c(\"Male\", : object 'male_df' not found\n\n\n\n\nCode\nno_smoke <- df[df$Smoke == \"no\",]\n\n\nError in df$Smoke: object of type 'closure' is not subsettable\n\n\nCode\nyes_smoke <- df[df$Smoke == \"yes\",]\n\n\nError in df$Smoke: object of type 'closure' is not subsettable\n\n\nCode\nmean(no_smoke$LungCap)\n\n\nError in mean(no_smoke$LungCap): object 'no_smoke' not found\n\n\nCode\nmean(yes_smoke$LungCap)\n\n\nError in mean(yes_smoke$LungCap): object 'yes_smoke' not found\n\n\n\n\n\n\n\nCode\nage_group_1 <- df[df$Age <= 13, ]\n\n\nError in df$Age: object of type 'closure' is not subsettable\n\n\nCode\nage_group_2 <- df[df$Age >= 14 & df$Age <= 15, ]\n\n\nError in df$Age: object of type 'closure' is not subsettable\n\n\nCode\nage_group_3 <- df[df$Age >= 16 & df$Age <= 17, ]\n\n\nError in df$Age: object of type 'closure' is not subsettable\n\n\nCode\nage_group_4 <- df[df$Age >= 18, ]\n\n\nError in df$Age: object of type 'closure' is not subsettable\n\n\nCode\npar(mfrow=c(2,2)) # Set up a 2x2 grid of plots\n\nboxplot(LungCap ~ Smoke, data = age_group_1, \n        names = c(\"Non-Smoker\", \"Smoker\"),\n        main = \"Age Group <= 13\")\n\n\nError in eval(m$data, parent.frame()): object 'age_group_1' not found\n\n\nCode\nboxplot(LungCap ~ Smoke, data = age_group_2, \n        names = c(\"Non-Smoker\", \"Smoker\"),\n        main = \"Age Group 14-15\")\n\n\nError in eval(m$data, parent.frame()): object 'age_group_2' not found\n\n\nCode\nboxplot(LungCap ~ Smoke, data = age_group_3, \n        names = c(\"Non-Smoker\", \"Smoker\"),\n        main = \"Age Group 16-17\")\n\n\nError in eval(m$data, parent.frame()): object 'age_group_3' not found\n\n\nCode\nboxplot(LungCap ~ Smoke, data = age_group_4, \n        names = c(\"Non-Smoker\", \"Smoker\"),\n        main = \"Age Group >= 18\")\n\n\nError in eval(m$data, parent.frame()): object 'age_group_4' not found\n\n\n\n\nCode\n# Calculate the mean and standard deviation of Lung Capacity for each age group and smoking status\nagg_data <- aggregate(LungCap ~ Age + Smoke, data = df, \n                      FUN = function(x) c(mean = mean(x), sd = sd(x)))\n\n\nError in model.frame.default(formula = LungCap ~ Age + Smoke, data = df): 'data' must be a data.frame, environment, or list\n\n\nCode\nagg_data\n\n\nError in eval(expr, envir, enclos): object 'agg_data' not found\n\n\n#Question 2 # Let X = number of prior convictions for prisoners at a state prison at which there are 810 prisoners."
  },
  {
    "objectID": "posts/HW1_MiguelCuriel.html",
    "href": "posts/HW1_MiguelCuriel.html",
    "title": "Homework 1",
    "section": "",
    "text": "First, let’s read in the data from the Excel file:\n\n\nCode\nlibrary(readxl)\ndf <- read_excel(\"_data/LungCapData.xls\")\n\n\nThe distribution of LungCap looks as follows:\n\n\nCode\nhist(df$LungCap)\n\n\n\n\n\nThe histogram suggests that the distribution is close to a normal distribution. Most of the observations are close to the mean. Very few observations are close to the margins (0 and 15).\n\n\n\nCompare the probability distribution of the LungCap with respect to Males and Females?\n\n\nCode\nsuppressPackageStartupMessages(library(dplyr))\nboxplot(LungCap~Gender, data=df)\n\n\n\n\n\nThe boxplot suggests that males tend to have a slightly higher lung capacity than females. While the mean of both genders is close to each other (~8), males’ interquartile range is slightly higher (approximately from 6.5 to 10) when compared to the females’ (approximately from 6 to 9).\n\n\n\nCompare the mean lung capacities for smokers and non-smokers. Does it make sense?\n\n\nCode\ndf %>%\n  group_by(Smoke) %>%\n  summarise(mean = mean(LungCap), n = n())\n\n\n# A tibble: 2 × 3\n  Smoke  mean     n\n  <chr> <dbl> <int>\n1 no     7.77   648\n2 yes    8.65    77\n\n\nSmokers have a mean lung capacity of 8.65, versus non-smokers who have a lung capacity of 7.77. These results do not make sense, as we would expect non-smokers to have greater lung capacity.\n\n\n\nExamine the relationship between Smoking and Lung Capacity within age groups: “less than or equal to 13”, “14 to 15”, “16 to 17”, and “greater than or equal to 18”.\n\n\nCode\nage_groups <- df %>% \n  mutate(\n    # Create categories\n    AgeGroup = case_when(\n      Age <= 13            ~ \"0 to 13\",\n      Age == 14 | Age == 15 ~ \"14 to 15\",\n      Age == 16 | Age == 17 ~ \"16 to 17\",\n      Age >= 18             ~ \"18 and above\"\n    ),\n    # Convert to factor\n    AgeGroup = factor(\n      AgeGroup,\n      level = c(\"0 to 13\", \"14 to 15\",\"16 to 17\", \"18 and above\")\n    )\n  )\n\nboxplot(LungCap~AgeGroup, data=age_groups)\n\n\n\n\n\nThe boxplot suggests that the greater the age, the greater the lung capacity. This is especially evident when comparing the lowest age group (0-13) versus the rest of them, but between the two oldest age groups (16-17 vs 18+), this is the least evident. This makes sense as the greatest physical growth usually happens earlier in life - from childhood to puberty - but then this slows down in the late teens and it almost entirely stops during young adulthood.\n\n\n\nCompare the lung capacities for smokers and non-smokers within each age group. Is your answer different from the one in part c. What could possibly be going on here?\n\n\nCode\nlibrary(ggplot2)\n\nage_groups %>% ggplot(aes(x=AgeGroup, y=LungCap, fill=Smoke)) + geom_boxplot()\n\n\n\n\n\nThe answer is different than what I found in 1.C. I previously found that the lung capacity mean for non-smokers was less than the smoking counterpart; however, this new box plot suggests that most non-smoking age groups actually have better lung capacity than smokers. The only age group where this condition isn’t met is in the youngest ages (0-13) so it is likely that this group that is skewing the overall smoker versus non-smoker analysis."
  },
  {
    "objectID": "posts/HW1_MiguelCuriel.html#a-1",
    "href": "posts/HW1_MiguelCuriel.html#a-1",
    "title": "Homework 1",
    "section": "a",
    "text": "a\nWhat is the probability that a randomly selected inmate has exactly 2 prior convictions?\n160/810 = .1975 = 19.75%"
  },
  {
    "objectID": "posts/HW1_MiguelCuriel.html#b-1",
    "href": "posts/HW1_MiguelCuriel.html#b-1",
    "title": "Homework 1",
    "section": "b",
    "text": "b\nWhat is the probability that a randomly selected inmate has fewer than 2 prior convictions?\n(128+434)/810 = 562/810 = .6938 = 69.38%"
  },
  {
    "objectID": "posts/HW1_MiguelCuriel.html#c-1",
    "href": "posts/HW1_MiguelCuriel.html#c-1",
    "title": "Homework 1",
    "section": "c",
    "text": "c\nWhat is the probability that a randomly selected inmate has 2 or fewer prior convictions?\n(128+434+160)/810 = 722/810 = .8914 = 89.14%"
  },
  {
    "objectID": "posts/HW1_MiguelCuriel.html#d-1",
    "href": "posts/HW1_MiguelCuriel.html#d-1",
    "title": "Homework 1",
    "section": "d",
    "text": "d\nWhat is the probability that a randomly selected inmate has more than 2 prior convictions?\n(64+24)/810 = 88/810 = .1086 = 10.86%"
  },
  {
    "objectID": "posts/HW1_MiguelCuriel.html#e-1",
    "href": "posts/HW1_MiguelCuriel.html#e-1",
    "title": "Homework 1",
    "section": "e",
    "text": "e\nWhat is the expected value for the number of prior convictions? (The expected value of a discrete random variable X, symbolized as E(X), is often referred to as the long-term average or mean)\n\n\nCode\n(0*128/810) + (1*434/810) + (2*160/810) + (3*64/810) + (4*24/810) \n\n\n[1] 1.28642"
  },
  {
    "objectID": "posts/HW1_MiguelCuriel.html#f",
    "href": "posts/HW1_MiguelCuriel.html#f",
    "title": "Homework 1",
    "section": "f",
    "text": "f\nCalculate the variance and the standard deviation for the Prior Convictions.\nBelow is the variance:\n\n\nCode\n((0-1.28642)^2 * 0) + ((1-1.28642)^2 * .5358) + ((2-1.28642)^2 * .395) + ((3-1.28642)^2 * .237) + ((4-1.28642)^2 * .1185)\n\n\n[1] 1.813581\n\n\nAnd below is the standard deviation:\n\n\nCode\nsqrt(((0-1.28642)^2 * 0) + ((1-1.28642)^2 * .5358) + ((2-1.28642)^2 * .395) + ((3-1.28642)^2 * .237) + ((4-1.28642)^2 * .1185))\n\n\n[1] 1.346693"
  },
  {
    "objectID": "posts/asch_harwood_final_project_part1.html",
    "href": "posts/asch_harwood_final_project_part1.html",
    "title": "Estimating National Food Waste with State/Local Waste Characterization Studies in the United States",
    "section": "",
    "text": "Code\nlibrary(\"dplyr\")\nlibrary(\"knitr\")\nlibrary(kableExtra)\nlibrary(xtable)\n\n\n\nBackground\nReFED, a national nonprofit that advocates for the reduction of food waste, maintains several models to estimate the amount of wasted food and its greenhouse gas emissions in the United States. Collectively, U.S. residents and businesses throw out roughly 90 million tons of food annually, contributing nearly 5 percent of the total net US greenhouse gas emissions.\nCreating system-level estimates in the food supply chain is notoriously difficult. To produce these estimates, ReFED employs a ‘mass balance’ accounting approach. For each sector, ReFED estimates the value of the total supply of food in US dollars. It then applies a price per lb conversion factor to convert dollars to tons to estimate the total suppy of food in weight. ReFED then draws on academic and private-sector studies to determine ‘surplus rates’–the share of food that is not going to its intended destination. The supply of food is multiplied by these surplus rates to determine the total amount of surplus food in a given place and year.\nA limitation of this approach, however, is that the research to estimate surplus rates is rarely, if ever, repeated at regular intervals. As a result, the lack of year-over-year and geographic variation in surplus rates makes it incredibly difficult to identify systematic changes in the food waste behaviors.\n\n\nProposal\nI propose utilizing state and local waste characterization studies combined with ‘easily observable’ and ‘widely available’ predictors (i.e. food supply, population, population density, GDP, unemployment, food prices, consumer confidence, investment/spending in food waste reduction technologies, knowledge and attitudes about food waste/environmental issues) to build a weighted mixed effects linear regression model. The goal is estimate the share of food waste of total municipal solid waste at the national level in a given year.\nState and local governments periodically conduct inferential waste characterization studies, where they randomly select several 200 - 300 lb samples from landfills and other waste management facilities, and separate the garbage to determine the composition of municipal solid waste in a particular area over a predetermined time. These studies are then used to set waste management budgets, ‘right-size’ landfill capacity, and create/evaluate programs meant to divert recyclable and compostable materials from landfills. However, they are not conducted regularly or consistently (or at all in many places), and, to my knowledge, there are no nationally-representative waste characterization studies.\nNevertheless, I believe there is the potential to creatively use these studies to estimate the share of food waste in landfills at the national-level over time, and, hopefully, to determine if there are any systematic changes in food waste management behavior in the commercial and residential sectors.\n\nResearch Questions\n\nIs it possible to use state and local waste characterization studies to estimate the share of food waste in municipal solid waste at the national-level year over year?\nWhat ‘easily-observable’ and ‘widely-available’ predictors allow us to estimate the share of food waste in the absence of regularly-conducted, national-level samples?\nHow ‘good’ does the model need to be to be “operationally” useful by food businesses, policymakers, and households?\nHow do food waste estimates produced using a bottom-up method proposed here compare to top-down, mass balanced-based approaches?\n\n\n\nHypothesis\nPopulation\nH0: Population is not correlated with percent food waste\nH1: Population is correlated with percent food waste\nFood Supply\nH0: Food supply is not correlated with percent food waste\nH1: Food supply is correlated with percent food waste\nGDP\nH0: GDP growth is not correlated with percent food waste\nH1: GDP growth is positively correlated with percent food waste\nUnemployment\nH0: Unemployment is not correlated with percent food waste\nH1: Unemployment is negatively correlated with percent food waste\nFood Prices\nH0: Food prices are not correlated with percent food waste\nH1: Food prices are negatively correlated with percent food waste\nConsumer Confidence\nH0: Consumer confidence is not correlated with percent food waste\nH1: Consumer confidence is positively correlated with percent food waste\nConsumer Knowledge\nH0: Consumer knowledge/concern about climate change is not correlated with percent food waste\nH1: Consumer knowledge/concern is negatively correlated with percent food waste\nInvestment\nH0: Investment in food waste reduction technologies is not correlated with percent food waste\nH1: Investment in food waste reduction technologies is positively correlated with percent food waste\n\n\nExploratory Data Analysis\nCurrently, no comprehensive aggregate municipal solid waste characterization datasets exisit for the United States in the public domain. To address this, I have compiled roughly 300 waste characterization studies, of which I have parsed and coded roughly 50 to date, based on the following (rough) criteria1. To be eligible to be included in my dataset, each study must be:\n\nconducted in the United States and be representative of the state, county, or local level between the years of 1999 and 2023\ninfer the amount of total food as a share of the total amount of municipal solid waste for an entire year\nreport the number of samples, which need to be between 200 - 300 lbs each\n\n\n\nCode\nwaste <- read.csv(\"/Users/aschharwood/Desktop/intro_quant_spring_2023/603_Spring_2023/posts/wasteCharacterizationStudies_v1.csv\")\nwaste$percent_food <- round(waste$percent_food, digits=4)\ntable <- na.omit(waste) %>%\n  sample_n(10)\nkable(table, caption = \"Waste Characterization Dataset\", format = \"html\") %>%\n  kable_styling(bootstrap_options = \"striped\", full_width = F) %>%\n  row_spec(0:nrow(table), font_size = 12)\n\n\n\n\nWaste Characterization Dataset\n \n  \n    year \n    state \n    geographic_scope \n    geographic_scope_name \n    sector_scope \n    sample_size \n    percent_food \n  \n \n\n  \n    2020 \n    texas \n    city \n    irving \n    residential \n    7 \n    0.1440 \n  \n  \n    2016 \n    washington \n    state \n    washington \n    commercial \n    243 \n    0.1864 \n  \n  \n    2013 \n    california \n    city \n    san_francisco \n    commericial \n    379 \n    0.3389 \n  \n  \n    2018 \n    vermont \n    state \n    vermont \n    commercial \n    86 \n    0.2205 \n  \n  \n    2002 \n    vermont \n    state \n    vermont \n    commercial \n    40 \n    0.2736 \n  \n  \n    2015 \n    rhode island \n    state \n    rhode island \n    commercial \n    106 \n    0.1753 \n  \n  \n    1999 \n    california \n    state \n    california \n    commericial \n    201 \n    0.1426 \n  \n  \n    2021 \n    california \n    state \n    california \n    commerical \n    152 \n    0.0176 \n  \n  \n    2022 \n    wyoming \n    county \n    teton \n    residential \n    61 \n    0.0742 \n  \n  \n    2012 \n    minnesota \n    state \n    minnesota \n    residential \n    180 \n    0.1780 \n  \n\n\n\n\n\n\n\nCode\ncat(\"Summary of Waste Characterization\\n\")\n\n\nSummary of Waste Characterization\n\n\nCode\ncat('\\n')\n\n\nCode\nsummary(waste)\n\n\n      year         state           geographic_scope   geographic_scope_name\n Min.   :1999   Length:76          Length:76          Length:76            \n 1st Qu.:2010   Class :character   Class :character   Class :character     \n Median :2014   Mode  :character   Mode  :character   Mode  :character     \n Mean   :2013                                                              \n 3rd Qu.:2016                                                              \n Max.   :2022                                                              \n                                                                           \n sector_scope        sample_size      percent_food   \n Length:76          Min.   :  7.00   Min.   :0.0176  \n Class :character   1st Qu.: 60.75   1st Qu.:0.1426  \n Mode  :character   Median :108.50   Median :0.1795  \n                    Mean   :121.61   Mean   :0.1839  \n                    3rd Qu.:153.00   3rd Qu.:0.2233  \n                    Max.   :379.00   Max.   :0.3389  \n                    NA's   :48                       \n\n\n\n\nCode\ncat('Summary of Waste Characterization\\n')\n\n\nSummary of Waste Characterization\n\n\nCode\ncat('\\n')\n\n\nCode\nstr(waste)\n\n\n'data.frame':   76 obs. of  7 variables:\n $ year                 : int  2021 2021 2021 2021 2013 2013 1999 1999 2016 2016 ...\n $ state                : chr  \"california\" \"california\" \"california\" \"california\" ...\n $ geographic_scope     : chr  \"state\" \"state\" \"state\" \"state\" ...\n $ geographic_scope_name: chr  \"california\" \"california\" \"california\" \"california\" ...\n $ sector_scope         : chr  \"residential\" \"commercial\" \"commerical\" \"transfer-truck\" ...\n $ sample_size          : int  153 201 152 50 379 251 201 153 77 75 ...\n $ percent_food         : num  0.174 0.1426 0.0176 0.0581 0.3389 ...\n\n\n\n\nCode\n# Create a data frame with the data dictionary\ndata_dictionary <- data.frame(\n  `col_name` = c(\"year\", \"state\", \"geographic_scope\", \"geographic_scope_name\", \"sector_scope\", \"sample_size\", \"percent_food\"),\n  `d_type` = c(\"int\", \"chr\", \"chr\", \"chr\", \"chr\", \"int\", \"dbl\"),\n  description = c(\n    \"The year when the study was conducted\",\n    \"The U.S. state where the study was conducted\",\n    \"The scope of the geographic area covered by the study (e.g., state, county, or city)\",\n    \"The name of the specific geographic area covered by the study (e.g., state name or city name)\",\n    \"The sector scope of the study (e.g., commercial, residential, or transfer-truck)\",\n    \"The number of samples included in the study\",\n    \"The percentage of food waste in the studied area\"\n  )\n)\nkable(data_dictionary)\n\n\n\n\n \n  \n    col_name \n    d_type \n    description \n  \n \n\n  \n    year \n    int \n    The year when the study was conducted \n  \n  \n    state \n    chr \n    The U.S. state where the study was conducted \n  \n  \n    geographic_scope \n    chr \n    The scope of the geographic area covered by the study (e.g., state, county, or city) \n  \n  \n    geographic_scope_name \n    chr \n    The name of the specific geographic area covered by the study (e.g., state name or city name) \n  \n  \n    sector_scope \n    chr \n    The sector scope of the study (e.g., commercial, residential, or transfer-truck) \n  \n  \n    sample_size \n    int \n    The number of samples included in the study \n  \n  \n    percent_food \n    dbl \n    The percentage of food waste in the studied area \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\nFootnotes\n\n\nI recognize that we were encouraged to work with pre-existing datasets. Nevertheless, I view this as an opportunity to prototype a project I believe might have real-world applicability in my professional life.↩︎"
  },
  {
    "objectID": "posts/dacss603hw2_LauraCollazo.html",
    "href": "posts/dacss603hw2_LauraCollazo.html",
    "title": "DACSS 603 Homework 2",
    "section": "",
    "text": "Libraries\n\n\nCode\nlibrary(readxl)\nlibrary(tidyverse)\n\n\n\n\nQuestion 1\n\n\nCode\nsurgical_procedure <- c(\"Bypass\", \"Angiography\")\nsample_size <- c(539, 847)\nmean_wait_time <- c(19, 18)\nstandard_deviation <- c(10, 9)\n\ndata <- data.frame(surgical_procedure, sample_size, mean_wait_time, standard_deviation)\n\ndata\n\n\n  surgical_procedure sample_size mean_wait_time standard_deviation\n1             Bypass         539             19                 10\n2        Angiography         847             18                  9\n\n\nCode\nt.test(data$mean_wait_time, conf.level = 0.9)\n\n\n\n    One Sample t-test\n\ndata:  data$mean_wait_time\nt = 37, df = 1, p-value = 0.0172\nalternative hypothesis: true mean is not equal to 0\n90 percent confidence interval:\n 15.34312 21.65688\nsample estimates:\nmean of x \n     18.5 \n\n\n\n\nQuestion 2\n\n\n\n\n\nQuestion 3\n\n\n\n\n\nQuestion 4\n\n\n\n\n\nQuestion 5\n\n\n\n\n\nQuestion 6\n\n\n\n\n\nQuestion 7"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DACSS 603 Introduction to Quantitative Analysis Spring 2023",
    "section": "",
    "text": "The blog posts here are contributed by students enrolled in DACSS 603, Introduction to Quantitative Analysis.\n\n\n\n\n\n\n\n\n\n\nFinal Project Part 1\n\n\n\n\n\n\n\nfinalpart1\n\n\ntyler tewksbury\n\n\nchess\n\n\n\n\n\n\n\n\n\n\n\nMar 21, 2023\n\n\nTyler Tewksbury\n\n\n\n\n\n\n\n\nThe Pandemic’s Toll on Mental Health: A Look at the Tech Sector (DRAFT)\n\n\n\n\n\n\n\nfinalpart1\n\n\nmental health\n\n\ntech industry\n\n\ncovid-19\n\n\nlayoffs\n\n\n\n\nFinal Project Check In 1\n\n\n\n\n\n\nMar 21, 2023\n\n\nMiguel Curiel\n\n\n\n\n\n\n\n\nFinalPart1\n\n\n\n\n\n\n\nfinalpart1\n\n\nLiam Tucksmith\n\n\ntidyverse\n\n\nreadxl\n\n\nggplot2\n\n\ndplyr\n\n\ntidyr\n\n\njanitor\n\n\n\n\n\n\n\n\n\n\n\nMar 21, 2023\n\n\nLiam Tucksmith\n\n\n\n\n\n\n\n\nMaternal Mortality and Women’s Empowerment: Exploring Non-Medical Factors Associated with Better Outcomes for Mothers Across the Globe\n\n\n\n\n\n\n\nfinalpart1\n\n\nJustine Shakespeare\n\n\nmaternal mortality\n\n\n\n\n\n\n\n\n\n\n\nMar 21, 2023\n\n\nJustine Shakespeare\n\n\n\n\n\n\n\n\nFinal Project Part 1\n\n\n\n\n\n\n\nfinalpart1\n\n\nnyctreecensus\n\n\n\n\nProposal\n\n\n\n\n\n\nMar 21, 2023\n\n\nAlexa Potter\n\n\n\n\n\n\n\n\nHomework 1\n\n\n\n\n\n\n\nhw1\n\n\nchallenge1\n\n\nJerin Jacob\n\n\nLung Capacity Data\n\n\nggplot2\n\n\ntidyverse\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMar 20, 2023\n\n\nJerin Jacob\n\n\n\n\n\n\n\n\nFinal Project Initial Research\n\n\n\n\n\n\n\nfinalpart1\n\n\nabigailbalint\n\n\n\n\n\n\n\n\n\n\n\nMar 20, 2023\n\n\nAbigail Balint\n\n\n\n\n\n\n\n\nFinal Project Checkin\n\n\n\n\n\n\n\nAdithya Parupudi\n\n\nfinalpart1\n\n\n\n\nInvestigating the Etiology of Low Infant Birth Weight: An Exploration of Risk Factors\n\n\n\n\n\n\nMar 20, 2023\n\n\nAdithya Parupudi\n\n\n\n\n\n\n\n\nEstimating National Food Waste with State/Local Waste Characterization Studies in the United States\n\n\n\n\n\n\n\nfinalpart1\n\n\n\n\nFinal Project Part 1: Proposal\n\n\n\n\n\n\nMar 20, 2023\n\n\nAsch Harwood\n\n\n\n\n\n\n\n\nFinal Project - Check point 1\n\n\n\n\n\n\n\nfinalpart1\n\n\nfinal project\n\n\nburnout\n\n\nemployee burnout\n\n\ndescriptives\n\n\nResearch question\n\n\nhyphoteses\n\n\n\n\n\n\n\n\n\n\n\nMar 18, 2023\n\n\nFelix Betanourt\n\n\n\n\n\n\n\n\nProject Proposal\n\n\n\n\n\n\n\nfinalpart1\n\n\n\n\nDACSS 603 Project Proposal\n\n\n\n\n\n\nMar 18, 2023\n\n\nAlexis Gamez\n\n\n\n\n\n\n\n\nFinal Project 603\n\n\n\n\n\n\n\nfinalpart1\n\n\n\n\nFinal project qmd file for 603\n\n\n\n\n\n\nMar 10, 2023\n\n\nJerin Jacob\n\n\n\n\n\n\n\n\nFinal Project Proposal Check-in1\n\n\n\n\n\nInitial draft of research proposal for Final Project\n\n\n\n\n\n\nMar 10, 2023\n\n\nMeredith Derian-Toth\n\n\n\n\n\n\n\n\nFinal Project Check 1\n\n\n\n\n\n\n\nfpc1\n\n\nresearch question\n\n\ndesriptive statistics\n\n\n\n\nFinal Project Check 1\n\n\n\n\n\n\nMar 4, 2023\n\n\nGuanhua Tan\n\n\n\n\n\n\n\n\nHomework 1 Solution\n\n\n\n\n\n\n\nhw1\n\n\ndesriptive statistics\n\n\nprobability\n\n\n\n\nThe first homework on descriptive statistics and probability\n\n\n\n\n\n\nMar 1, 2023\n\n\nRosemary Pang\n\n\n\n\n\n\n\n\nHomework 1\n\n\n\n\n\n\n\nhw1\n\n\ndesriptive statistics\n\n\nprobability\n\n\n\n\nHomework 1\n\n\n\n\n\n\nFeb 28, 2023\n\n\nZhiyuan Zhou\n\n\n\n\n\n\n\n\nHomework 1\n\n\n\n\n\n\n\nhw1\n\n\ndesriptive statistics\n\n\nprobability\n\n\n\n\nHomework 1\n\n\n\n\n\n\nFeb 28, 2023\n\n\nAsch Harwood\n\n\n\n\n\n\n\n\nHomework 1\n\n\n\n\n\n\n\nhw1\n\n\ndesriptive statistics\n\n\nprobability\n\n\n\n\nHomework 1 Submission\n\n\n\n\n\n\nFeb 28, 2023\n\n\nChristine Brydges\n\n\n\n\n\n\n\n\nHomework - 1\n\n\n\n\n\n\n\nhw1\n\n\ndesriptive statistics\n\n\nprobability\n\n\n\n\nHomework assignment 1 - Darron Bunt\n\n\n\n\n\n\nFeb 28, 2023\n\n\nDarron Bunt\n\n\n\n\n\n\n\n\nHomework 1 - Akhilesh Kumar\n\n\n\n\n\n\n\nhw1\n\n\ndesriptive statistics\n\n\nprobability\n\n\n\n\nDACSS_603_Homework 1 on Descriptive Statistics and Probability\n\n\n\n\n\n\nFeb 28, 2023\n\n\nAkhilesh Kumar Meghwal\n\n\n\n\n\n\n\n\nHomework 1\n\n\n\n\n\n\n\nhw1\n\n\ndesriptive statistics\n\n\nprobability\n\n\nemma_narkewicz\n\n\n\n\nEmma Narkewicz’s HW1 Answers\n\n\n\n\n\n\nFeb 28, 2023\n\n\nEmma Narkewicz\n\n\n\n\n\n\n\n\nHw 1 by Kristin Abijaoude\n\n\n\n\n\n\n\nHw1\n\n\nkristin abijaoude\n\n\ndesriptive statistics\n\n\nprobability\n\n\n\n\nLungCap and Prison data HW1\n\n\n\n\n\n\nFeb 27, 2023\n\n\nKristin Abijaoude\n\n\n\n\n\n\n\n\nHomework 1\n\n\n\n\n\n\n\nhw1\n\n\ndesriptive statistics\n\n\nprobability\n\n\n\n\nDACSS_603_Homework 1 on Descriptive Statistics and Probability\n\n\n\n\n\n\nFeb 27, 2023\n\n\nSaisrinivas Ambatipudi\n\n\n\n\n\n\n\n\nHomework1\n\n\n\n\n\n\n\nhw1\n\n\ndesriptive statistics\n\n\nprobability\n\n\n\n\nHW1 course blog qmd file\n\n\n\n\n\n\nFeb 27, 2023\n\n\nRahul Somu\n\n\n\n\n\n\n\n\nHomework 1\n\n\n\n\n\n\n\nhw1\n\n\ndesriptive statistics\n\n\nprobability\n\n\n\n\nhw1\n\n\n\n\n\n\nFeb 27, 2023\n\n\nYoung Soo Choi\n\n\n\n\n\n\n\n\nHomework 1\n\n\n\n\n\n\n\nhw1\n\n\ndesriptive statistics\n\n\nprobability\n\n\n\n\nTemplate of course blog qmd file\n\n\n\n\n\n\nFeb 27, 2023\n\n\nXiaoyan\n\n\n\n\n\n\n\n\nHomework 1\n\n\n\n\n\n\n\nhw1\n\n\nJustine Shakespeare\n\n\ndescriptive statistics\n\n\nprobability\n\n\n\n\nHomework 1 for DACSS 603\n\n\n\n\n\n\nFeb 26, 2023\n\n\nJustine Shakespeare\n\n\n\n\n\n\n\n\nHomework 1\n\n\n\n\n\n\n\nhw1\n\n\ndesriptive statistics\n\n\nprobability\n\n\n\n\nTemplate of course blog qmd file\n\n\n\n\n\n\nFeb 26, 2023\n\n\nCaitlin Rowley\n\n\n\n\n\n\n\n\nHomework 1\n\n\n\n\n\n\n\nhw1\n\n\ndesriptive statistics\n\n\nprobability\n\n\n\n\nDACSS 603\n\n\n\n\n\n\nFeb 25, 2023\n\n\nAlexa Potter\n\n\n\n\n\n\n\n\nHomework 1\n\n\n\n\n\n\n\nhw1\n\n\ndensity\n\n\nprobability distribution\n\n\ndescriptives\n\n\nvisualization\n\n\nggplot2\n\n\n\n\n\n\n\n\n\n\n\nFeb 24, 2023\n\n\nFelix Betanourt\n\n\n\n\n\n\n\n\nHomework1 - EDA of LungCap Data\n\n\n\n\n\n\n\nhw1\n\n\nAdithya Parupudi\n\n\n\n\nHW1 submission\n\n\n\n\n\n\nFeb 23, 2023\n\n\nAdithya Parpudi\n\n\n\n\n\n\n\n\nHomework 1\n\n\n\n\n\n\n\nhw1\n\n\nhomework1\n\n\nabigailbalint\n\n\nlungcap\n\n\nprisoner\n\n\nggplot2\n\n\n\n\n\n\n\n\n\n\n\nFeb 23, 2023\n\n\nAbigail Balint\n\n\n\n\n\n\n\n\nBlog Post #1\n\n\n\n\n\n\n\nhw1\n\n\ndesriptive statistics\n\n\nprobability\n\n\n\n\nDACSS 603 HW#1\n\n\n\n\n\n\nFeb 20, 2023\n\n\nAlexis Gamez\n\n\n\n\n\n\n\n\nHW1\n\n\n\n\n\n\n\nhw1\n\n\nLiam Tucksmith\n\n\nLungCapData\n\n\ntidyverse\n\n\nreadxl\n\n\nggplot2\n\n\ndplyr\n\n\ntidyr\n\n\n\n\n\n\n\n\n\n\n\nFeb 20, 2023\n\n\nLiam Tucksmith\n\n\n\n\n\n\n\n\nHomework 1\n\n\n\n\n\n\n\nhw1\n\n\ndesriptive statistics\n\n\nprobability\n\n\n\n\nProbability and descriptive statistics homework for DACSS 603.\n\n\n\n\n\n\nFeb 20, 2023\n\n\nMiguel Curiel\n\n\n\n\n\n\n\n\nDACSS 603 Homework 1\n\n\n\n\n\n\n\nhw1\n\n\ndesriptive statistics\n\n\nprobability\n\n\n\n\nThis is Homework 1 for DASS 603.\n\n\n\n\n\n\nFeb 19, 2023\n\n\nLaura Collazo\n\n\n\n\n\n\n\n\nHomework_One\n\n\n\n\n\n\n\nhw1\n\n\ndesriptive statistics\n\n\nprobability\n\n\n\n\nTemplate of course blog qmd file\n\n\n\n\n\n\nFeb 5, 2023\n\n\nMeredith Derian-Toth\n\n\n\n\n\n\n\n\nProposal for DACSS 603 Final Project\n\n\n\n\n\n\n\nfinalpart1\n\n\n\n\n\n\n\n\n\n\n\nInvalid Date\n\n\nLaura Collazo\n\n\n\n\n\n\n\n\nHomework 1\n\n\n\n\n\n\n\nhw1\n\n\ndesriptive statistics\n\n\nprobability\n\n\n\n\nHomework 1\n\n\n\n\n\n\nFeb 5, 2023\n\n\nGuanhua Tan\n\n\n\n\n\n\n\n\nHomework - 1\n\n\n\n\n\n\n\nhw1\n\n\ndesriptive statistics\n\n\nprobability\n\n\n\n\nHomework 1\n\n\n\n\n\n\nFeb 5, 2023\n\n\nThrishul\n\n\n\n\n\n\n\n\nHomework - 2\n\n\n\n\n\n\n\nhw2\n\n\ndesriptive statistics\n\n\nprobability\n\n\n\n\nHomework 2\n\n\n\n\n\n\nFeb 5, 2023\n\n\nThrishul\n\n\n\n\n\n\n\n\nDACSS 603 Homework 2\n\n\n\n\n\n\n\nhw2\n\n\ndesriptive statistics\n\n\nprobability\n\n\n\n\nHomework 2 for DASS 603.\n\n\n\n\n\n\nInvalid Date\n\n\nLaura Collazo\n\n\n\n\n\n\nNo matching items"
  }
]