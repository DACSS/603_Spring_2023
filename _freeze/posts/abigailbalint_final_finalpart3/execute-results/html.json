{
  "hash": "fa89d93ca700ae594604b6cf858f6175",
  "result": {
    "markdown": "---\ntitle: \"Final Project (Final Submission)\"\nauthor: \"Abigail Balint\"\ndesription: \"Final project part 3 (final part)\"\ndate: \"05/20/23\"\nformat:\n  html:\n    toc: true\n    code-fold: true\n    code-copy: true\n    code-tools: true\ncategories:\n  - finalpart2\n  - abigailbalint\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(viridis)\nlibrary(car)\nknitr::opts_chunk$set(echo = TRUE)\n```\n:::\n\n\n## Description of data \n\nThe dataset I am using comes from Kaggle https://www.kaggle.com/datasets/kaggle/kaggle-survey-2018 and is a survey titled \"2018 Kaggle Machine Learning & Data Science Survey\" conducted by Kaggle to capture the current state of machine learning and data science usage, mainly at the enterprise and academic level. The dataset contains survey responses from almost 24,000 respondents from varying backgrounds. The survey contains 50 questions, including 9 demographic questions and 41 questions around machine learning and data science. The questions range from platforms and products used, and tools and methodology, barriers to entry, and more. It also asks respondents about their employee experience working in these fields. I believe that the wide array of types of questions used make this dataset a good fit for research, as there are binary and categorical variables to explore but also some that ask for explicit numeric values like what percentage of their work falls to different tasks. Having several different types of questions provide opportunities for multiple types of models to be performed.\n\nThis survey was also run in 2017, 2019, and 2020 on Kaggle as part of an annual competition where users could submit code and analysis using this public data. However, I decided to use the 2018 dataset as my focus because certain questions that I think would be really interesting to analyze were omitted in later years/the survey was shortened overall. This survey was hosted by Kaggle, open to anyone in the industry, for one week in October 2018.\n\n\nReading in the dataset --\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal <- read_csv(\"_data/final_project_data.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: One or more parsing issues, see `problems()` for details\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 23304 Columns: 409\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (347): Q1, Q2, Q3, Q4, Q5, Q6, Q7, Q7_RCSTUD, Q7_RCTECH, Q8, Q9, Q10, Q1...\ndbl  (58): Time from Start to Finish (seconds), Q1_OTHER_TEXT, Q6_OTHER_TEXT...\nlgl   (4): Q28_Part_22, Q29_Part_16, Q38_Part_19, Q38_Part_20\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\nhead(final,10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 10 × 409\n   Time from…¹ Q1    Q1_OT…² Q2    Q3    Q4    Q5    Q6    Q6_OT…³ Q7    Q7_RC…⁴\n         <dbl> <chr>   <dbl> <chr> <chr> <chr> <chr> <chr>   <dbl> <chr> <chr>  \n 1         959 Male       -1 35-39 Chile Doct… Info… Other       1 Acad… Non-st…\n 2        1512 Male       -1 18-21 India Bach… Comp… Stud…      -1 Acad… Non-st…\n 3         848 Male       -1 22-24 Denm… Bach… Engi… Stud…      -1 Acad… Non-st…\n 4        2309 Male       -1 30-34 China Doct… Other Rese…      -1 Acad… Non-st…\n 5        1487 Male       -1 18-21 China Bach… Comp… Stud…      -1 Acad… Non-st…\n 6         790 Male       -1 25-29 China Mast… Engi… Stud…      -1 Acad… Non-st…\n 7        2986 Male       -1 40-44 India Doct… Comp… Other       7 Acad… Non-st…\n 8        1255 Male       -1 18-21 India Some… Engi… Stud…      -1 Acad… Non-st…\n 9         825 Male       -1 25-29 India Bach… Comp… Data…      -1 Acad… Non-st…\n10        1315 Male       -1 18-21 India Bach… Engi… Stud…      -1 Acad… Non-st…\n# … with 398 more variables: Q7_RCSTUDY <dbl>, Q7_RCSTUDN <dbl>,\n#   Q7_RCSTUD2 <dbl>, Q7_RCTECH <chr>, Q7_RCTECH2 <dbl>, Q7_OTHER_TEXT <dbl>,\n#   Q8 <chr>, Q8RC <dbl>, Q9 <chr>, Q10 <chr>, Q11_Part_1 <chr>,\n#   Q11_Part_1RC <dbl>, Q11_Part_1RC2 <chr>, Q11_Part_2 <chr>,\n#   Q11_Part_3 <chr>, Q11_Part_4 <chr>, Q11_Part_5 <chr>, Q11_Part_6 <chr>,\n#   Q11_Part_7 <chr>, Q11_OTHER_TEXT <dbl>, Q12_MULTIPLE_CHOICE <chr>,\n#   Q12_Part_1_TEXT <dbl>, Q12_Part_2_TEXT <dbl>, Q12_Part_3_TEXT <dbl>, …\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfinalrc <- final %>%\n  rename(Percent_Time_Insights = Q34_Part_6) %>%\n  rename(Years_Machine_Learning = Q25) %>%\n  rename(Years_Writing_Code = Q24) %>%\n  rename(Years_Machine_LearningRC = Q25RC) %>%\n  rename(Years_Writing_CodeRC = Q24RC) %>%\n  rename(Percent_Time_GatherData = Q34_Part_1) %>%\n  rename(Percent_Time_Coding = Q23) %>%\n  rename(Percent_Time_CodingRC = Q23RC) %>%\n  rename(AnalyzeDataRC = Q11_Part_1RC) %>%\n  rename(AnalyzeData = Q11_Part_1) %>%\n  rename(Years_In_Role = Q8RC)\n```\n:::\n\n\n## Research Question \n\nUpon doing a cursory search around this data, I see some high level executive-summary style research published about this data set, but I wasn't able to find anything focused on more specific research questions. It was more demographic data of the state of ML and Data Science. I think there is the opportunity to speak more specifically about the state of machine learning and data science, and look deeper at what tools students and employees are using versus what their time is devoted to.\n\nBased on feedback from both parts of the final submissions, I kept my area of focus narrow. There is a huge amount of data within this dataset, but as this project is focused on performing regression modeling, I think the best fit for my main research question is as follows:\n\nHow does an individual’s background, experience, and time in their field/role impact what their day to day looks like?\n\nI used questions from the survey like \"During a typical data science project at work or school, approximately what proportion of your time is devoted to the following?\" as this question supplies exact numbers that I could correlate against demos and more general usage of tools and platforms to see if there is any connection between the work one does and the tools they use.\n\nI am interested in this dataset because a lot of research in my career is in the machine learning space, so I am always interested in contextualizing the employee experience in these areas so that I can better understand the subject of some of my survey research. I also do more general employee engagement research in my career and I think this final is a great opportunity to try my hand at some correlations that would be similar to the ones I would like to eventually run at my job, but have never been able to because I don't have any prior stats knowledge.\n\n\n## Hypothesis\n\nThe hypothesis I would like to test is:\n\nThose with more years of experience in machine learning/coding will spend a larger proportion of their time doing analyzing and decision making, as opposed to those newer to the job will spend more time cleaning data and doing actual coding.\n\nThe below variables are the primary ones I used:\n\nIndependent variable (original name followed by recoded name):\nQ24/Years_Writing_Code, How long have you been writing code to analyze data?\n\nDependent variable:\nQ34_Part_6/Percent_Time_Insights,\tDuring a typical data science project at work or school, approximately what proportion of your time is devoted to the following? (Answers must add up to 100%) - Finding insights in the data and communicating with stakeholders\n\nThe below variables were used as confounding variables to the independent variable, or as alternative dependent variables to test that could give me opposite results to test essentially the second half of my hypothesis statement:\n\n* Confounding variable 1 - Q8/Years_In_Role, How many years of experience do you have in your current role?\n\n* Confounding variable 2 - Q25/Years_Machine_Learning\tFor how many years have you used machine learning methods (at work or in school)?\n\n* Other alternative dependent - Q11_1/AnalyzeData,Select any activities that make up an important part of your role at work: (Select all that apply) - Analyze and understand data to influence product or business decisions\n\n* Other alternative dependent - Q23/Percent_Time_Coding,\tApproximately what percent of your time at work or school is spent actively coding?\n\n* Other alternative dependent -  Q34_Part_1/Percent_Time_GatherData During a typical data science project at work or school, approximately what proportion of your time is devoted to the following? - Gathering data\n\n\n## Descriptive Statistics\n\nI described my dataset at the top of this as well as discussed variables of interest in the Research Question section, but here is a little bit of exploratory code to give a general feel for what the data looks like:\n \n\n \nI can see the data contains mostly younger males, but because of the sample size can really work with lots of demographic combinations.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(finalrc, aes(x = Q1)) +\n  geom_bar() +\n   labs(x=\"Gender\")\n```\n\n::: {.cell-output-display}\n![](abigailbalint_final_finalpart3_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(finalrc, aes(x = Q2)) +\n  geom_bar() +\n  labs(x=\"Age\") +\n  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))\n```\n\n::: {.cell-output-display}\n![](abigailbalint_final_finalpart3_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\nThere is also a range of coding experience in the dataset.\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(finalrc, aes(x = Years_Writing_Code)) +\n  geom_bar() +\n   labs(x=\"Years of coding experience\") +\n  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))\n```\n\n::: {.cell-output-display}\n![](abigailbalint_final_finalpart3_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\nThe data is split between students, tech industry employees, and other industry employees.\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(finalrc, aes(x = Q7)) +\n  geom_bar() +\n   labs(x=\"Industry\") +\n  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))\n```\n\n::: {.cell-output-display}\n![](abigailbalint_final_finalpart3_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\nHere, I made a scatterplot showing where the amount of training from work meets the amount of time spent finding insights instead of cleaning data, coding, etc. I expected this to be much higher for those who received most or all of their training from work, but that isn't the case.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(finalrc, aes(x = Q35_Part_3, y=Percent_Time_Insights)) +\n  geom_point() +\n   labs(x=\"Percentage of machine learning training from work\", y=\"Percentage of project time spent finding insights\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 7559 rows containing missing values (geom_point).\n```\n:::\n\n::: {.cell-output-display}\n![](abigailbalint_final_finalpart3_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n\n\n# Hypothesis Testing\n\n\nHypothesis: Those with more years of experience in machine learning/coding will spend a larger proportion of their time doing analyzing and decision making, as opposed to those newer to the job will spend more time cleaning data and doing actual coding.\n\nSince the variables are in text format in the survey, I recoded the ones needed into a numerical format that gives a corresponding number in ascending order to match the level of experience the respondent reports (i.e, 1 = one year/lowest categorical, ascending from there). \n\n\n::: {.cell}\n\n```{.r .cell-code}\nforplot <- finalrc %>%\n  drop_na(Percent_Time_Insights, Years_Machine_Learning, Years_Writing_Code, Years_Machine_LearningRC, Years_Writing_CodeRC, Percent_Time_GatherData, Percent_Time_Coding, Percent_Time_CodingRC)\nforplot$time <- as.character(forplot$Years_Writing_Code)\nforplot$anpercent <- as.character(forplot$Percent_Time_Insights)\ntable(forplot$time, forplot$anpercent)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n             \n                 0    1   10  100   11   12   13   14   15   16   17   18   19\n  < 1 year     899   22 1141    7    1    5    3    4  331    1    2    8    2\n  1-2 years    986   18 1466    3    1    5    4    3  427    1    4    4    2\n  10-20 years  198    6  300    1    1    1    4    1   91    0    1    1    0\n  20-30 years   63    2   85    0    0    0    0    0   24    0    0    0    0\n  3-5 years    736    6 1056    3    2    4    5    4  349    1    2    9    2\n  30-40 years   20    0   30    0    0    0    0    0    5    0    1    0    0\n  40+ years     17    1   12    1    0    0    0    0    8    0    0    0    0\n  5-10 years   349    9  626    3    0    2    1    0  165    1    1    1    1\n             \n                 2   20   22   23   24   25   27   28    3   30   32   33   34\n  < 1 year      24  544    1    1    1  117    0    1   14  159    0    1    1\n  1-2 years     27  701    0    3    1  117    1    1   23  196    2    1    0\n  10-20 years    7  143    1    0    0   19    0    0    4   53    0    1    1\n  20-30 years    4   50    0    1    0   10    0    0    1   16    0    0    0\n  3-5 years     29  547    1    0    1  110    0    3   22  151    1    0    0\n  30-40 years    0   17    0    0    0    4    0    0    0    5    0    0    0\n  40+ years      0    6    0    0    0    1    0    0    0    2    0    0    0\n  5-10 years    12  325    1    2    0   72    0    2    4   91    0    2    0\n             \n                35   38    4   40   44   45    5   50   55    6   60   65   69\n  < 1 year      20    1    9   45    0    6  461   46    2    8    6    1    1\n  1-2 years     24    0    4   53    0    4  645   33    7    5    7    0    0\n  10-20 years    7    0    4   11    0    1  139    9    1    1    6    1    0\n  20-30 years    1    0    2    3    0    0   30    4    0    0    0    0    0\n  3-5 years     16    1    8   44    2    2  482   38    2    3    6    1    0\n  30-40 years    0    0    1    2    0    0   20    1    0    1    1    0    0\n  40+ years      1    0    1    0    0    0    7    0    0    0    0    0    0\n  5-10 years     4    0    3   29    0    2  243   14    1    0    2    0    0\n             \n                 7   70   75    8   80   85    9   90   94   95\n  < 1 year      11    2    1   24    4    2   15    0    0    1\n  1-2 years     11    3    2   12    1    0    7    2    0    0\n  10-20 years    1    1    1    4    0    0    1    0    0    0\n  20-30 years    1    0    1    1    0    0    2    1    0    0\n  3-5 years     17    1    1   12    1    0    7    0    0    1\n  30-40 years    0    0    0    0    1    0    1    0    0    0\n  40+ years      0    0    0    0    1    0    0    0    0    0\n  5-10 years     5    1    0    4    0    1    2    1    1    0\n```\n:::\n:::\n\n\n\nFor my first test, I run below an anova test with Percent of time finding insights as my dependent variable and Number of years writing code as my independent variable. As the p value is .008 rounded, the test shows that we can reject the null hypothesis that there is no relationship between these two variables, and we can assume a relationship between the percentage of time one spends analyzing data and how many years they have been writing code.\n\nYears_Writing_CodeRC = Amount of years they have been coding\nPercent_Time_Insights = Proportion of time spent analyzing data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanovatest <- aov(Percent_Time_Insights ~ Years_Writing_CodeRC, data=forplot)\nsummary(anovatest)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                        Df  Sum Sq Mean Sq F value  Pr(>F)   \nYears_Writing_CodeRC     1     838   838.2   7.094 0.00774 **\nResiduals            15935 1882765   118.2                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\n\nNow I am fitting a model using the same two variables:\nYears_Writing_CodeRC = Amount of years they have been coding\nPercent_Time_Insights = Proportion of time spent analyzing data\n\nThe p value here is much less than .05 at .008, which makes it significant, however the coefficient does not necessarily strongly support this p value as it is only .14 which would be considered relatively small.\n\n::: {.cell}\n\n```{.r .cell-code}\nfitmodel <- lm(Percent_Time_Insights ~ Years_Writing_CodeRC, data = forplot)\nsummary(fitmodel)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Percent_Time_Insights ~ Years_Writing_CodeRC, data = forplot)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-12.573  -6.700  -1.554   7.591  88.591 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(>|t|)    \n(Intercept)          11.26307    0.16853  66.833  < 2e-16 ***\nYears_Writing_CodeRC  0.14559    0.05466   2.663  0.00774 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 10.87 on 15935 degrees of freedom\nMultiple R-squared:  0.000445,\tAdjusted R-squared:  0.0003823 \nF-statistic: 7.094 on 1 and 15935 DF,  p-value: 0.007741\n```\n:::\n:::\n\n\nPlotting this model:\nYears_Writing_CodeRC = Amount of years they have been coding\nPercent_Time_Insights = Proportion of time spent analyzing data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(Percent_Time_Insights ~ Years_Writing_CodeRC, data = forplot, main = \"Percentage of time analyzing data vs. time in field\")\n```\n\n::: {.cell-output-display}\n![](abigailbalint_final_finalpart3_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\nHere I am filtering out those who say that they have less than 20% percent of time spent on analysis or that they aren't involved in coding so that I can weed out the large number of zero percents.\n\nYears_Writing_CodeRC = Amount of years they have been coding\nPercent_Time_Insights = Proportion of time spent analyzing data\n\n::: {.cell}\n\n```{.r .cell-code}\nforplot2 <- finalrc %>%\n  drop_na(Percent_Time_Insights, Years_Machine_Learning, Years_Writing_Code, Years_Machine_LearningRC, Years_Writing_CodeRC, Percent_Time_GatherData, AnalyzeData, Percent_Time_Coding, Percent_Time_CodingRC) %>%\n  filter(Percent_Time_Insights > 19, Years_Machine_LearningRC < 9, Years_Writing_CodeRC < 10, Percent_Time_GatherData > 19, Percent_Time_CodingRC > 2)\nanovatest2 <- aov(Percent_Time_Insights ~ Years_Writing_CodeRC, data=forplot2)\nsummary(anovatest2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                      Df Sum Sq Mean Sq F value Pr(>F)\nYears_Writing_CodeRC   1     83   83.33   0.966  0.326\nResiduals            569  49102   86.30               \n```\n:::\n:::\n\nThis leaves me with a low sample size to work with, and causes it to be no longer significant and also a negative coefficient, so I'll try a confounding variable added next.\n\nFiltered chart:\n\n::: {.cell}\n\n```{.r .cell-code}\nfitmodel2 <- lm(Years_Writing_CodeRC ~ Percent_Time_Insights , data = forplot2)\nsummary(fitmodel2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Years_Writing_CodeRC ~ Percent_Time_Insights, data = forplot2)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.0928 -1.0928 -0.0928  0.9072  6.0079 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(>|t|)    \n(Intercept)            3.227158   0.181988  17.733   <2e-16 ***\nPercent_Time_Insights -0.006717   0.006836  -0.983    0.326    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.516 on 569 degrees of freedom\nMultiple R-squared:  0.001694,\tAdjusted R-squared:  -6.032e-05 \nF-statistic: 0.9656 on 1 and 569 DF,  p-value: 0.3262\n```\n:::\n\n```{.r .cell-code}\nplot(Percent_Time_Insights ~ Years_Writing_CodeRC, data = forplot2, main = \"Percentage of time analyzing data vs. time in field\")\n```\n\n::: {.cell-output-display}\n![](abigailbalint_final_finalpart3_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\nHere I added Q25 which is amount of years spent using machine learning in their work, and same as previously:\n\nYears_Writing_CodeRC = Amount of years they have been coding\nPercent_Time_Insights = Proportion of time spent analyzing data\nYears_Machine_LearningRC = amount of years spent using machine learning in work\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanovatest3 <- aov(Percent_Time_Insights ~ Years_Writing_CodeRC + Years_Machine_LearningRC, data=forplot)\nsummary(anovatest3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                            Df  Sum Sq Mean Sq F value  Pr(>F)   \nYears_Writing_CodeRC         1     838   838.2   7.097 0.00773 **\nYears_Machine_LearningRC     1     939   938.9   7.950 0.00482 **\nResiduals                15934 1881826   118.1                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\nI can see in this model, amount of years spent using machine learning in their work is the most significant variable. The p value and the coefficient are stronger than the years writing code variable, although still not particularly strong.\n\n::: {.cell}\n\n```{.r .cell-code}\nfitmodel3 <- lm(Percent_Time_Insights ~ Years_Writing_CodeRC + Years_Machine_LearningRC , data = forplot)\nsummary(fitmodel3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Percent_Time_Insights ~ Years_Writing_CodeRC + Years_Machine_LearningRC, \n    data = forplot)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-12.882  -6.842  -1.577   7.511  88.710 \n\nCoefficients:\n                         Estimate Std. Error t value Pr(>|t|)    \n(Intercept)              11.09128    0.17917  61.904  < 2e-16 ***\nYears_Writing_CodeRC      0.08826    0.05831   1.514  0.13012    \nYears_Machine_LearningRC  0.11069    0.03926   2.820  0.00482 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 10.87 on 15934 degrees of freedom\nMultiple R-squared:  0.0009434,\tAdjusted R-squared:  0.000818 \nF-statistic: 7.523 on 2 and 15934 DF,  p-value: 0.0005422\n```\n:::\n:::\n\n\nNext I would like to try Q11 - \"Select any activities that make up an important part of your role at work: Analyze and understand data to influence product or business decisions.\" This is a categorical variable of yes vs no that is similar to the one I fit above but a bit more general. I will use an anova test since my independent variable of time in coding is also categorical. \n\n::: {.cell}\n\n```{.r .cell-code}\nforplot$yearscoding <- as.character(forplot$Years_Writing_CodeRC)\nforplot$analyze <- as.character(forplot$AnalyzeDataRC)\ntable(forplot$yearscoding, forplot$analyze)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   \n       1    2\n  1 1282 2674\n  2 2304 2513\n  3 2115 1574\n  4 1289  694\n  6  683  339\n  7  181  121\n  8   60   50\n  9   34   24\n```\n:::\n\n```{.r .cell-code}\nanova4 <- aov(analyze ~ yearscoding, data=forplot)\nsummary(anova4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n               Df Sum Sq Mean Sq F value Pr(>F)    \nyearscoding     7    222   31.68   134.1 <2e-16 ***\nResiduals   15929   3762    0.24                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\nAgain, despite the strong p value, the model below does not give us a strong coefficient.\n\n::: {.cell}\n\n```{.r .cell-code}\nfitmodel4 <- lm(AnalyzeDataRC ~ Years_Writing_CodeRC , data = forplot)\nsummary(fitmodel4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = AnalyzeDataRC ~ Years_Writing_CodeRC, data = forplot)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.6047 -0.4794  0.3953  0.4580  0.8966 \n\nCoefficients:\n                      Estimate Std. Error t value Pr(>|t|)    \n(Intercept)           1.667357   0.007600  219.39   <2e-16 ***\nYears_Writing_CodeRC -0.062662   0.002465  -25.42   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4902 on 15935 degrees of freedom\nMultiple R-squared:  0.03897,\tAdjusted R-squared:  0.03891 \nF-statistic: 646.2 on 1 and 15935 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\nSince using Q11 gives similar results and is a less detailed variable, I think I will go back to analyzing \"During a typical data science project at work or school, approximately what proportion of your time is devoted to the following?  - Finding insights in the data and communicating with stakeholders\" and add \"How many years of experience do you have in your current role?\" as a confounding variable.\n\nBelow I am adding in Years_In_Role as a confounding variable \"How many years of experience do you have in your current role?\" as amount of time in role could mean that they are relied less on for data collection and cleaning and more analyzing of data. Here my p-values for both variables are very small so I think the confounding variable had an impact. These are also the strongest coefficients I have had in any model. It makes sense that the time in role variable would be a negative coefficient because the less years would mean the more time they would spend doing an entry level task like data collection. \n\n::: {.cell}\n\n```{.r .cell-code}\nfitmodel5 <- lm(Percent_Time_Insights ~ Years_Writing_CodeRC + Years_In_Role, data = forplot)\nsummary(fitmodel5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Percent_Time_Insights ~ Years_Writing_CodeRC + Years_In_Role, \n    data = forplot)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-13.479  -6.862  -1.700   7.345  89.024 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(>|t|)    \n(Intercept)          11.53050    0.18917  60.952  < 2e-16 ***\nYears_Writing_CodeRC  0.23106    0.06203   3.725 0.000196 ***\nYears_In_Role        -0.13099    0.03919  -3.343 0.000832 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 10.89 on 15107 degrees of freedom\n  (827 observations deleted due to missingness)\nMultiple R-squared:  0.001166,\tAdjusted R-squared:  0.001034 \nF-statistic: 8.818 on 2 and 15107 DF,  p-value: 0.0001488\n```\n:::\n:::\n\nOverall, I am seeing that there is a relationship between work done in respondent's roles and the amount of time that they have been coding or in their current role. I wish that there was more numerical data within this dataset that I could use to supplement these findings.\n\nBelow I am plotting the two variables used in my final model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(forplot, aes(x = Years_In_Role, y = Percent_Time_Insights)) +\n  geom_point(color=\"black\") +\n  geom_smooth(method = \"lm\", se = F, color = \"black\") +\n  theme( panel.background = element_rect(fill = \"grey\"),\n    axis.text = element_text(color = \"black\")) +\n  ggtitle(\"Years In Current Role vs. Percent of Time Spent on Insights\") \n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula 'y ~ x'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 827 rows containing non-finite values (stat_smooth).\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 827 rows containing missing values (geom_point).\n```\n:::\n\n::: {.cell-output-display}\n![](abigailbalint_final_finalpart3_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(forplot, aes(x = Years_Writing_CodeRC, y = Percent_Time_Insights)) +\n  geom_point(color=\"black\") +\n  geom_smooth(method = \"lm\", se = F, color = \"black\") +\n  theme( panel.background = element_rect(fill = \"grey\"),\n    axis.text = element_text(color = \"black\"))+\n  ggtitle(\"Years Experience Writing Code vs. Percent of Time Spent on Insights\") \n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](abigailbalint_final_finalpart3_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n\n\n\n# Final Model Comparison/Evaluation and Diagnostics\n\nBelow I am summarizing each model and also finding the AIC/BIC.\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(fitmodel2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Years_Writing_CodeRC ~ Percent_Time_Insights, data = forplot2)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.0928 -1.0928 -0.0928  0.9072  6.0079 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(>|t|)    \n(Intercept)            3.227158   0.181988  17.733   <2e-16 ***\nPercent_Time_Insights -0.006717   0.006836  -0.983    0.326    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.516 on 569 degrees of freedom\nMultiple R-squared:  0.001694,\tAdjusted R-squared:  -6.032e-05 \nF-statistic: 0.9656 on 1 and 569 DF,  p-value: 0.3262\n```\n:::\n\n```{.r .cell-code}\nAIC(fitmodel2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2099.603\n```\n:::\n\n```{.r .cell-code}\nBIC(fitmodel2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2112.646\n```\n:::\n\n```{.r .cell-code}\nsummary(fitmodel3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Percent_Time_Insights ~ Years_Writing_CodeRC + Years_Machine_LearningRC, \n    data = forplot)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-12.882  -6.842  -1.577   7.511  88.710 \n\nCoefficients:\n                         Estimate Std. Error t value Pr(>|t|)    \n(Intercept)              11.09128    0.17917  61.904  < 2e-16 ***\nYears_Writing_CodeRC      0.08826    0.05831   1.514  0.13012    \nYears_Machine_LearningRC  0.11069    0.03926   2.820  0.00482 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 10.87 on 15934 degrees of freedom\nMultiple R-squared:  0.0009434,\tAdjusted R-squared:  0.000818 \nF-statistic: 7.523 on 2 and 15934 DF,  p-value: 0.0005422\n```\n:::\n\n```{.r .cell-code}\nAIC(fitmodel3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 121276.3\n```\n:::\n\n```{.r .cell-code}\nBIC(fitmodel3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 121307\n```\n:::\n\n```{.r .cell-code}\nsummary(fitmodel4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = AnalyzeDataRC ~ Years_Writing_CodeRC, data = forplot)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.6047 -0.4794  0.3953  0.4580  0.8966 \n\nCoefficients:\n                      Estimate Std. Error t value Pr(>|t|)    \n(Intercept)           1.667357   0.007600  219.39   <2e-16 ***\nYears_Writing_CodeRC -0.062662   0.002465  -25.42   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4902 on 15935 degrees of freedom\nMultiple R-squared:  0.03897,\tAdjusted R-squared:  0.03891 \nF-statistic: 646.2 on 1 and 15935 DF,  p-value: < 2.2e-16\n```\n:::\n\n```{.r .cell-code}\nAIC(fitmodel4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 22506.27\n```\n:::\n\n```{.r .cell-code}\nBIC(fitmodel4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 22529.3\n```\n:::\n\n```{.r .cell-code}\nsummary(fitmodel5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Percent_Time_Insights ~ Years_Writing_CodeRC + Years_In_Role, \n    data = forplot)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-13.479  -6.862  -1.700   7.345  89.024 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(>|t|)    \n(Intercept)          11.53050    0.18917  60.952  < 2e-16 ***\nYears_Writing_CodeRC  0.23106    0.06203   3.725 0.000196 ***\nYears_In_Role        -0.13099    0.03919  -3.343 0.000832 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 10.89 on 15107 degrees of freedom\n  (827 observations deleted due to missingness)\nMultiple R-squared:  0.001166,\tAdjusted R-squared:  0.001034 \nF-statistic: 8.818 on 2 and 15107 DF,  p-value: 0.0001488\n```\n:::\n\n```{.r .cell-code}\nAIC(fitmodel5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 115051.7\n```\n:::\n\n```{.r .cell-code}\nBIC(fitmodel5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 115082.2\n```\n:::\n:::\n\n\nHere is how each element ranks in comparison across models:\nAIC/BIC: Model 2 has the lowest AIC/BIC\nAdjusted R squared: Model 4 has the highest adjusted r-squared, but it only has one predictor variable included\nP-Value: Model 4 has the lowest p-value, but again only takes into account one predictor variable\nMultiple R-square: Model 4 has the highest value, indicating the strongest relationship between the variables\nResiduals:Model 2 has the lowest median in the residuals indicating a better fit\n\n\nI think my second to last fitted model (4) is a fine model to use, but in this case I wanted to use a model that had multiple variables included. Since my final model (5) has the same predictor variable as model 4, plus one more variable added, that is the primary model I would explore.\n\nDistributions in the below charts for this model appear normal. The residuals are normally distributed and the Q-Q plot follows a relatively diagonal line. I also checked below for signs of multicollinearity because my final model has two independent variables. The VIF value of 1.2 is not perfect but not very high so I don't think it poses an issue in this model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvif(fitmodel5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nYears_Writing_CodeRC        Years_In_Role \n            1.222315             1.222315 \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(fitted(fitmodel5), resid(fitmodel5))\n```\n\n::: {.cell-output-display}\n![](abigailbalint_final_finalpart3_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(fitmodel5)\n```\n\n::: {.cell-output-display}\n![](abigailbalint_final_finalpart3_files/figure-html/unnamed-chunk-25-1.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](abigailbalint_final_finalpart3_files/figure-html/unnamed-chunk-25-2.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](abigailbalint_final_finalpart3_files/figure-html/unnamed-chunk-25-3.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](abigailbalint_final_finalpart3_files/figure-html/unnamed-chunk-25-4.png){width=672}\n:::\n:::\n\n\n\n\n# Bibliography\n\n\nKaggle, (2018). “2018 Kaggle Machine Learning & Data Science Survey”, Retrieved 21 March 2023 from https://www.kaggle.com/datasets/kaggle/kaggle-survey-2018.\n\nCC BY-SA 4.0 : https://creativecommons.org/licenses/by-sa/4.0/\n:::",
    "supporting": [
      "abigailbalint_final_finalpart3_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}