{
  "hash": "897d7dc1c66f64eddd54a3bc6ae4cac2",
  "result": {
    "markdown": "---\ntitle: \"Final Project Check In\"\nauthor: \"Young Soo Choi\"\ndescription: \"Final Project Check In 2\"\ndate: \"04/20/2023\"\nformat:\n  html:\n    toc: true\n    code-fold: true\n    code-copy: true\n    code-tools: true\ncategories:\n  - finalpart2\n---\n\n\n# Research Problems\n\nAs discussed in check-in 1, my research topics are as follows.\n\"Does the baseball manager's intervention in games improve the team's scoring ability?\"\n\nThe main concepts of the research topic are first \"scoring\". This is a simple concept that does not require a separate operational definition. You just have to find and compare scoring column in the data frame. The next concept is \"intervention in the game.\" This can be defined in various ways. Since the purpose of this study is not to discuss these topics, in order to simplify the research problem, I will define intervention in the game as the concepts of \"bunt\" and \"stolen attempt.\" In a baseball game between a pitcher and a batter, a bunt that sacrifices batter himself to advance a runner and a steal to send another base is a difficult choice for a batter or runner without the manager's instructions, or at least acquiescence. There is also a great deal of discussion about this topic, but in this study, I will briefly summarize it and move on.\n\nTo measure the concept of intervention defined from this perspective, this study defines intervention as the sum of bunt (sacrifice, sh) and steal attempt (sb+cs). In other words, in this study, \"intervention in the game\" is operatively defined as sh+sb+cs.\n\n# Research Design\n\nThis research problem can be approached in various ways. First of all, I can think of a way to simply compare the average score of a team that has a lot of operational intervention and a team that does not. Next, the correlation between the frequency of intervention in the game and the score can be reviewed.\nIn other words, through the t-test, it is possible to examine whether there is a difference between average scores between the two groups and how the correlation between game intervention and scores appears through correlation analysis.\n\nHowever, this is a simple approach that does not take into account the characteristics of baseball. The environment of baseball is different every year. Numerous variables such as the number of participating teams, the level of players, climate, and stadiums change the pattern of scoring every year. From this point of view, it may be more reasonable to select and analyze specific years with similar league environments rather than using all data for analysis.\n\nThe next thing to consider is that each team has a different batting ability involved in baseball's scoring. For example, a team with strong basic offense naturally scores more points than a team with weak basic offense. Therefore, these points need to be considered as well.\n\nFrom this point of view, I will limit the scope of the analysis to a specific year after considering various variables. I will also consider analytical methods that take into account the team's basic offense. Fortunately, there are several ways to get expected scores, and I will use these methods to find the difference between the actual score of a team with a lot of managerial intervention and the expected score and compare it to a team that does not.\n\n# Data Load\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.1     ✔ purrr   1.0.1\n✔ tibble  3.1.8     ✔ dplyr   1.1.0\n✔ tidyr   1.3.0     ✔ stringr 1.5.0\n✔ readr   2.1.4     ✔ forcats 1.0.0\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# loading data\nkbo_df<-read_csv(\"~/R/603_Spring_2023/posts/_data/kbo_df.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nNew names:\nRows: 313 Columns: 28\n── Column specification\n────────────────────────────────────────────────────────\nDelimiter: \",\" chr (1): team dbl (27): ...1, year, game, win, lose, tie,\nrun_scored, run_allowed, batters...\nℹ Use `spec()` to retrieve the full column specification for this data. ℹ\nSpecify the column types or set `show_col_types = FALSE` to quiet this message.\n• `` -> `...1`\n```\n:::\n\n```{.r .cell-code}\nhead(kbo_df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 28\n   ...1  year team    game   win  lose   tie run_s…¹ run_a…² batters   tpa    ab\n  <dbl> <dbl> <chr>  <dbl> <dbl> <dbl> <dbl>   <dbl>   <dbl>   <dbl> <dbl> <dbl>\n1     1  1982 Bears     80    56    24     0     399     318     930  3098  2745\n2     2  1982 Giants    80    31    49     0     353     385     863  3062  2628\n3     3  1982 Lions     80    54    26     0     429     257     887  3043  2647\n4     4  1982 Tigers    80    38    42     0     374     388     873  2990  2665\n5     5  1982 Twins     80    46    34     0     419     350     952  3061  2686\n6     6  1982 Unico…    80    15    65     0     302     574     867  2954  2653\n# … with 16 more variables: hit <dbl>, double <dbl>, triple <dbl>, hr <dbl>,\n#   bb <dbl>, ibb <dbl>, hbp <dbl>, so <dbl>, rbi <dbl>, r <dbl>, sh <dbl>,\n#   sf <dbl>, sb <dbl>, cs <dbl>, gidp <dbl>, e <dbl>, and abbreviated variable\n#   names ¹​run_scored, ²​run_allowed\n```\n:::\n\n```{.r .cell-code}\nkbo_df<-kbo_df[,2:28]\n```\n:::\n\n\n# Simple Analysis\n\n## A Comparison of Average Scores in Two Groups\n\nFirst of all, let's compare the difference in the scores of teams with many manager's interventions and those who don't. To this end, teams with more than average manager intervention and teams that do not are classified by year. According to the previous operational definition, the sum of steal attempts (stolen base(sb) + caught stolen(cs)) and bunt(sacrifice hit, sh) is considered as the frequency of manager intervention, so the average number of manager interventions of each team by year is calculated, and the higher team is classified into the high group and lower team is classified into the lower group.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# making average variables by years\n\n# for sh\n## create an empty data frame to store the results\nsh_df <- data.frame(year = integer(), avr_sh = numeric())\n\n## loop over the years\nfor (i in 1982:2020) {\n  ## filter the data for the current year and calculate the sum of sh variable\n  year_sh <- kbo_df %>% \n    filter(year == i) %>% \n    summarize(year_av_sh = sum(sh)/n()) %>% \n    pull(year_av_sh)\n\n  ## add the result to the data frame\n  sh_df <- rbind(sh_df, data.frame(year = i, avr_sh = year_sh))\n}\n\n# for sb\nsb_df <- data.frame(year = integer(), avr_sb = numeric())\n\nfor (i in 1982:2020) {\n  year_sb <- kbo_df %>% \n    filter(year == i) %>% \n    summarize(year_av_sb = sum(sb)/n()) %>% \n    pull(year_av_sb)\n\n  sb_df <- rbind(sb_df, data.frame(year=i, avr_sb=year_sb))\n}\n\n# for cs\ncs_df <- data.frame(year = integer(), avr_cs = numeric())\n\nfor (i in 1982:2020) {\n  year_cs <- kbo_df %>% \n    filter(year == i) %>% \n    summarize(year_av_cs = sum(cs)/n()) %>% \n    pull(year_av_cs)\n\n\n  cs_df <- rbind(cs_df, data.frame(year=i, avr_cs=year_cs))\n}\n\n# print the results data frame\nsh_df\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   year    avr_sh\n1  1982  36.00000\n2  1983  65.50000\n3  1984  56.83333\n4  1985  78.50000\n5  1986  86.71429\n6  1987  74.42857\n7  1988  78.14286\n8  1989  77.14286\n9  1990  79.71429\n10 1991  81.75000\n11 1992  77.87500\n12 1993  87.25000\n13 1994  88.62500\n14 1995  75.25000\n15 1996  93.25000\n16 1997 101.25000\n17 1998  87.25000\n18 1999  79.87500\n19 2000  64.50000\n20 2001  80.50000\n21 2002  67.00000\n22 2003  94.37500\n23 2004  84.00000\n24 2005  88.00000\n25 2006 100.75000\n26 2007  91.62500\n27 2008  65.12500\n28 2009  69.87500\n29 2010  91.62500\n30 2011  97.75000\n31 2012 102.75000\n32 2013  75.22222\n33 2014  68.11111\n34 2015  83.40000\n35 2016  65.10000\n36 2017  60.00000\n37 2018  44.70000\n38 2019  43.60000\n39 2020  48.60000\n```\n:::\n\n```{.r .cell-code}\nsb_df\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   year    avr_sb\n1  1982 116.50000\n2  1983  83.33333\n3  1984  87.00000\n4  1985 105.16667\n5  1986  91.28571\n6  1987  94.14286\n7  1988 106.14286\n8  1989 138.14286\n9  1990 118.28571\n10 1991 126.87500\n11 1992 105.12500\n12 1993 116.62500\n13 1994 124.25000\n14 1995 126.62500\n15 1996 113.62500\n16 1997 120.75000\n17 1998  99.25000\n18 1999 116.75000\n19 2000  93.37500\n20 2001 107.00000\n21 2002  97.12500\n22 2003  89.25000\n23 2004  84.75000\n24 2005  97.75000\n25 2006  93.12500\n26 2007  95.50000\n27 2008 123.37500\n28 2009 132.00000\n29 2010 139.12500\n30 2011 116.62500\n31 2012 127.75000\n32 2013 129.66667\n33 2014 113.66667\n34 2015 120.20000\n35 2016 105.80000\n36 2017  77.80000\n37 2018  92.80000\n38 2019  98.90000\n39 2020  89.20000\n```\n:::\n\n```{.r .cell-code}\ncs_df\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   year   avr_cs\n1  1982 51.83333\n2  1983 57.83333\n3  1984 56.16667\n4  1985 69.50000\n5  1986 65.85714\n6  1987 59.00000\n7  1988 56.85714\n8  1989 75.85714\n9  1990 71.57143\n10 1991 77.00000\n11 1992 55.87500\n12 1993 64.50000\n13 1994 65.87500\n14 1995 56.25000\n15 1996 65.50000\n16 1997 66.12500\n17 1998 53.50000\n18 1999 53.12500\n19 2000 44.87500\n20 2001 53.87500\n21 2002 50.75000\n22 2003 53.12500\n23 2004 48.62500\n24 2005 43.00000\n25 2006 43.50000\n26 2007 45.75000\n27 2008 55.37500\n28 2009 49.87500\n29 2010 58.75000\n30 2011 56.00000\n31 2012 57.50000\n32 2013 55.77778\n33 2014 48.44444\n34 2015 52.60000\n35 2016 54.70000\n36 2017 40.70000\n37 2018 41.00000\n38 2019 42.30000\n39 2020 37.70000\n```\n:::\n\n```{.r .cell-code}\n# merge those data\nint_df<-merge(merge(sh_df, sb_df, by = \"year\", all = TRUE), cs_df, by=\"year\", all=TRUE)\n\n# left join to original data\ntot_df<-left_join(kbo_df, int_df)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nJoining with `by = join_by(year)`\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# making intervention variables\ntot_df<-tot_df %>%\n  mutate(st_att=sb+cs, inter = sh+st_att, avr_inter=avr_sh+avr_sb+avr_cs)\n\ntot_df[, c('year','team','sh','st_att','inter','avr_inter')]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 313 × 6\n    year team        sh st_att inter avr_inter\n   <dbl> <chr>    <dbl>  <dbl> <dbl>     <dbl>\n 1  1982 Bears       46    167   213      204.\n 2  1982 Giants      41    136   177      204.\n 3  1982 Lions       36    189   225      204.\n 4  1982 Tigers      28    207   235      204.\n 5  1982 Twins       32    194   226      204.\n 6  1982 Unicorns    33    117   150      204.\n 7  1983 Bears       89    105   194      207.\n 8  1983 Giants      58    137   195      207.\n 9  1983 Lions       66    112   178      207.\n10  1983 Tigers      37    222   259      207.\n# … with 303 more rows\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# making intervention type variables\ntot_df<-tot_df %>%\n  mutate(inter_fre=ifelse(inter>avr_inter, \"high\", \"no\"))\ntot_df[,c('year', 'team', 'inter_fre')]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 313 × 3\n    year team     inter_fre\n   <dbl> <chr>    <chr>    \n 1  1982 Bears    high     \n 2  1982 Giants   no       \n 3  1982 Lions    high     \n 4  1982 Tigers   high     \n 5  1982 Twins    high     \n 6  1982 Unicorns no       \n 7  1983 Bears    no       \n 8  1983 Giants   no       \n 9  1983 Lions    no       \n10  1983 Tigers   high     \n# … with 303 more rows\n```\n:::\n:::\n\n\nThe necessary processing has been completed. Let's look at the frequency of groups with high and low interventions by year.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntable(tot_df$inter_fre, tot_df$year)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      \n       1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995\n  high    4    2    3    4    5    4    3    3    4    4    4    4    3    4\n  no      2    4    3    2    2    3    4    4    3    4    4    4    5    4\n      \n       1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009\n  high    5    3    3    6    4    3    4    5    4    5    5    4    4    3\n  no      3    5    5    2    4    5    4    3    4    3    3    4    4    5\n      \n       2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020\n  high    3    3    3    6    6    4    4    6    5    6    4\n  no      5    5    5    3    3    6    6    4    5    4    6\n```\n:::\n\n```{.r .cell-code}\ntable(tot_df$inter_fre)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nhigh   no \n 159  154 \n```\n:::\n:::\n\n\nThe number of high and low groups is almost the same because they are divided into teams that are higher than average and those that are not.\n\nNow, let's compare the average scores between the two groups. (Since the study was a population, the average was simply compared instead of the t-test.)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# comparing average score\ntot_df %>% \n  group_by(inter_fre) %>%\n  summarise(mean_score=mean(run_scored))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 2\n  inter_fre mean_score\n  <chr>          <dbl>\n1 high            595.\n2 no              594.\n```\n:::\n:::\n\n\nThere is little difference in the average score between the two groups. In other words, the analysis classified in this way did not produce meaningful results.\n\n## Raising the criteria for determining a high degree of intervention\n\nSince the previous simple classification did not have much meaning, I further strengthened the criteria for classifying the frequency of intervention. This time, the group that intervened more than 1 standard deviation from the average was divided into a high group, the group that intervened less than 1 standard deviation from the average was divided into a low group, and the rest into a normal group.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# making sd of intervention by each year\nsd_int<- data.frame(year = integer(), sd_i= numeric())\n\nfor (i in 1982:2020) {\n  year_sd <- tot_df %>% \n    filter(year == i) %>% \n    summarize(year_sd_int = sd(inter)) %>% \n    pull(year_sd_int)\n\n  sd_int<- rbind(sd_int, data.frame(year = i, sd_i= year_sd))\n}\n\ntot_df<-left_join(tot_df, sd_int)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nJoining with `by = join_by(year)`\n```\n:::\n\n```{.r .cell-code}\n# making three type variables\ntot_df<-tot_df %>%\n  mutate(inter_fre_sd=ifelse(inter>avr_inter+sd_i, \"high\", \n                               ifelse(inter<avr_inter-sd_i, \"low\", \"normal\")))\n\ntot_df[, c('year','team','run_scored', 'inter_fre_sd')]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 313 × 4\n    year team     run_scored inter_fre_sd\n   <dbl> <chr>         <dbl> <chr>       \n 1  1982 Bears           399 normal      \n 2  1982 Giants          353 normal      \n 3  1982 Lions           429 normal      \n 4  1982 Tigers          374 normal      \n 5  1982 Twins           419 normal      \n 6  1982 Unicorns        302 low         \n 7  1983 Bears           418 normal      \n 8  1983 Giants          370 normal      \n 9  1983 Lions           448 normal      \n10  1983 Tigers          423 high        \n# … with 303 more rows\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntable(tot_df$inter_fre_sd, tot_df$year)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        \n         1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995\n  high      0    2    1    1    1    1    1    2    1    2    1    1    2    1\n  low       1    1    1    1    1    1    2    2    2    2    1    1    1    2\n  normal    5    3    4    4    5    5    4    3    4    4    6    6    5    5\n        \n         1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009\n  high      1    1    1    1    1    1    1    1    2    1    0    2    1    1\n  low       1    2    1    2    2    1    1    2    1    1    1    1    2    1\n  normal    6    5    6    5    5    6    6    5    5    6    7    5    5    6\n        \n         2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020\n  high      1    2    1    1    2    1    2    2    2    0    2\n  low       2    1    0    1    2    1    2    1    1    2    2\n  normal    5    5    7    7    5    8    6    7    7    8    6\n```\n:::\n\n```{.r .cell-code}\ntable(tot_df$inter_fre_sd)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n  high    low normal \n    48     53    212 \n```\n:::\n:::\n\n\nAs a result, a total of 313 team data from 1982 to 2020 were divided into 48 high groups, 53 low groups, and 212 normal groups.\nNow, I compared the average score between these three groups.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# comparing average scores\ntot_df %>% group_by(inter_fre_sd) %>%\n  summarise(mean_sco=mean(run_scored))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 2\n  inter_fre_sd mean_sco\n  <chr>           <dbl>\n1 high             610.\n2 low              596.\n3 normal           591.\n```\n:::\n:::\n\n\nThe team that intervenes a lot shows a high average score. However, even the low intervention team showed higher scoring ability than the average team. It seems that something further analysis is needed.\n\n## Correlation Analysis between Intervention Frequency and Score\n\nNext, beyond a simple average comparison between groups, the correlation between the frequency of game intervention and scores was examined.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# correlation analysis\ncor(tot_df$run_scored, tot_df$inter)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -0.1734817\n```\n:::\n\n```{.r .cell-code}\n# simple regression\nlm_int<-lm(run_scored~inter, tot_df)\nsummary(lm_int)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = run_scored ~ inter, data = tot_df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-334.31  -85.82    2.56   91.53  323.55 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 706.1534    36.5710  19.309  < 2e-16 ***\ninter        -0.4656     0.1499  -3.106  0.00207 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 130.8 on 311 degrees of freedom\nMultiple R-squared:  0.0301,\tAdjusted R-squared:  0.02698 \nF-statistic:  9.65 on 1 and 311 DF,  p-value: 0.002068\n```\n:::\n:::\n\n\nIn this way, there is a negative correlation between game intervention and scoring. Even from the regression equation between the two variables, it can be seen that the coefficient attached to the game intervention variable is negative.\n\nI separated the steal attempt and the bunt and examined it in more detail.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Stolen attempt and bunt separation\ncor(tot_df$run_scored, tot_df$sh)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -0.2197821\n```\n:::\n\n```{.r .cell-code}\ncor(tot_df$run_scored, tot_df$st_att)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -0.0730271\n```\n:::\n\n```{.r .cell-code}\nlm_int_each<-lm(run_scored~sh+st_att, tot_df)\nsummary(lm_int_each)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = run_scored ~ sh + st_att, data = tot_df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-350.17  -81.72    1.41   94.93  310.52 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 711.3843    36.2739  19.611  < 2e-16 ***\nsh           -1.1214     0.2881  -3.892 0.000122 ***\nst_att       -0.1898     0.1812  -1.048 0.295524    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 129.5 on 310 degrees of freedom\nMultiple R-squared:  0.05166,\tAdjusted R-squared:  0.04554 \nF-statistic: 8.444 on 2 and 310 DF,  p-value: 0.0002687\n```\n:::\n:::\n\nBoth steal attempts and bunt variables show a negative correlation with scoring.\n\nWhy are the average comparison and correlation analysis results different?\n\nAs pointed out earlier, there are countless variables that affect baseball's score, and it is likely that the result is that the variable called \"scoring environment,\" which is generally batter-friendly and pitcher-friendly, is not considered. In other words, the difference in average scores that occur by year is not reflected in this simple comparison. For example, if the average score per game in one year is 12 points, and if it is only 8 points in another year, an analysis that ignores these differences will not be valid.\n\nIn consideration of these points, the analysis was conducted in consideration of the scoring environment of baseball.\n\n# Analysis considering scoring environment\n\n## Review Analysis Scope\n\nThrough the boxplot figure, the distribution of scores and game intervention by year was briefly examined.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npar(mfrow=c(1,2))\nboxplot(tot_df$run_scored/tot_df$game~tot_df$year, ylab=\"Score/G\", xlab ='Year')\nboxplot(tot_df$inter/tot_df$game~tot_df$year, ylab=\"Intervention/G\", xlab=\"Year\")\n```\n\n::: {.cell-output-display}\n![](FPchck2_young_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\nThe left is a boxplot diagram showing the distribution of the average score per game and the right is the distribution of the average number of interventions per game.\nAs expected, the year-to-year variation is significant. Scores are generally up and down and intervention is down.\n\nWe looked more closely at how the average score and batting average per game have changed year by year. Here, the batting average is calculated as hit/ab (at bat) as the ratio of hits at bat.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# calculate batting average of each year\n\n# at bat\nab_year<- data.frame(year = integer(), at_bat= numeric())\n\nfor (i in 1982:2020) {\n  year_ab <- tot_df %>% \n    filter(year == i) %>% \n    summarize(year_ab_sum = sum(ab)) %>% \n    pull(year_ab_sum)\n\n  ab_year<- rbind(ab_year, data.frame(year = i, at_bat= year_ab))\n}\n\n# hits\nhit_year<- data.frame(year = integer(), hits= numeric())\n\nfor (i in 1982:2020) {\n  year_hit <- tot_df %>% \n    filter(year == i) %>% \n    summarize(year_hit_sum = sum(hit)) %>% \n    pull(year_hit_sum)\n\n  hit_year<- rbind(hit_year, data.frame(year = i, hits= year_hit))\n}\n\nbatting_average<-merge(ab_year, hit_year, by = \"year\", all = TRUE)\n\nbatting_average<-batting_average%>%\n  mutate(batting_average=hits/at_bat)\n\n# calculate average score of each year\n\n## sum of score\nscore_year<- data.frame(year = integer(), score= numeric())\n\nfor (i in 1982:2020) {\n  year_score <- tot_df %>% \n    filter(year == i) %>% \n    summarize(year_score_sum = sum(run_scored)) %>% \n    pull(year_score_sum)\n\n  score_year<- rbind(score_year, data.frame(year = i, score= year_score))\n}\n\n## total games\ngames_year<- data.frame(year = integer(), gp= numeric())\n\nfor (i in 1982:2020) {\n  year_games <- tot_df %>% \n    filter(year == i) %>% \n    summarize(year_games_sum = sum(game)/2) %>% \n    pull(year_games_sum)\n\n  games_year<- rbind(games_year, data.frame(year = i, gp= year_games))\n}\n\naverage_score<-merge(score_year, games_year, by = \"year\", all = TRUE)\n\naverage_score<-average_score%>%\n  mutate(average_score=score/gp)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\naverage_score[,c(\"year\",\"average_score\")]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   year average_score\n1  1982      9.483333\n2  1983      8.030000\n3  1984      7.666667\n4  1985      8.166667\n5  1986      7.343915\n6  1987      7.994709\n7  1988      8.518519\n8  1989      8.352381\n9  1990      8.301587\n10 1991      8.803571\n11 1992      9.523810\n12 1993      7.359127\n13 1994      8.305556\n14 1995      8.309524\n15 1996      8.140873\n16 1997      8.835317\n17 1998      8.821429\n18 1999     10.765152\n19 2000     10.103383\n20 2001     10.351504\n21 2002      9.270677\n22 2003      9.272556\n23 2004      9.379699\n24 2005      9.178571\n25 2006      7.898810\n26 2007      8.543651\n27 2008      8.972222\n28 2009     10.323308\n29 2010      9.964286\n30 2011      9.063910\n31 2012      8.233083\n32 2013      9.293403\n33 2014     11.243056\n34 2015     10.552778\n35 2016     11.213889\n36 2017     10.669444\n37 2018     11.102778\n38 2019      9.094444\n39 2020     10.327778\n```\n:::\n\n```{.r .cell-code}\nbatting_average[,c(\"year\",\"batting_average\")]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   year batting_average\n1  1982       0.2650399\n2  1983       0.2557265\n3  1984       0.2535147\n4  1985       0.2603929\n5  1986       0.2505728\n6  1987       0.2653134\n7  1988       0.2681318\n8  1989       0.2567079\n9  1990       0.2567293\n10 1991       0.2561911\n11 1992       0.2643017\n12 1993       0.2467434\n13 1994       0.2570741\n14 1995       0.2509807\n15 1996       0.2510156\n16 1997       0.2578578\n17 1998       0.2607412\n18 1999       0.2764104\n19 2000       0.2697075\n20 2001       0.2738850\n21 2002       0.2633735\n22 2003       0.2685470\n23 2004       0.2664191\n24 2005       0.2633025\n25 2006       0.2549982\n26 2007       0.2626301\n27 2008       0.2668192\n28 2009       0.2752146\n29 2010       0.2698236\n30 2011       0.2647216\n31 2012       0.2577346\n32 2013       0.2683662\n33 2014       0.2892902\n34 2015       0.2797730\n35 2016       0.2895784\n36 2017       0.2859668\n37 2018       0.2857736\n38 2019       0.2670202\n39 2020       0.2728060\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npar(mfrow=c(1,2))\nplot(average_score$year, average_score$average_score, xlab=\"Year\", ylab=\"Average Score/G\")\nplot(batting_average$year, batting_average$batting_average, xlab=\"Year\", ylab=\"Batting Average\")\n```\n\n::: {.cell-output-display}\n![](FPchck2_young_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\nIt can also be seen that the league's batting and scoring environment is changing significantly every year.\n\nIn the end, it is judged that choosing an appropriate range is good for achieving more rigorous results. The question now is how to determine the scope.\n\nConsidering that the trend of scoring and batting average has not changed significantly since 2015, and that 10 teams have participated in the KBO League since 2015, the target of the analysis was set from 2015 to 2020.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Filtering\ndf_2015<-tot_df%>%\n  filter(year >= 2015)\n\nhead(df_2015)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 36\n   year team    game   win  lose   tie run_s…¹ run_a…² batters   tpa    ab   hit\n  <dbl> <chr>  <dbl> <dbl> <dbl> <dbl>   <dbl>   <dbl>   <dbl> <dbl> <dbl> <dbl>\n1  2015 Bears    144    79    65     0     807     776    1704  5759  4957  1436\n2  2015 Dinos    144    84    57     3     844     655    1960  5727  4967  1437\n3  2015 Eagles   144    68    76     0     717     800    1899  5713  4850  1316\n4  2015 Giants   144    66    77     1     765     802    1821  5680  4972  1393\n5  2015 Heros    144    78    65     1     904     790    1769  5811  5069  1512\n6  2015 Lande…   144    69    73     2     693     724    1845  5588  4861  1323\n# … with 24 more variables: double <dbl>, triple <dbl>, hr <dbl>, bb <dbl>,\n#   ibb <dbl>, hbp <dbl>, so <dbl>, rbi <dbl>, r <dbl>, sh <dbl>, sf <dbl>,\n#   sb <dbl>, cs <dbl>, gidp <dbl>, e <dbl>, avr_sh <dbl>, avr_sb <dbl>,\n#   avr_cs <dbl>, st_att <dbl>, inter <dbl>, avr_inter <dbl>, inter_fre <chr>,\n#   sd_i <dbl>, inter_fre_sd <chr>, and abbreviated variable names ¹​run_scored,\n#   ²​run_allowed\n```\n:::\n:::\n\n\n## Comparison of average scores by group since 2015\n\nThe average score for each of the three groups classified in the same way as above was compared.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_2015 %>% group_by(inter_fre_sd) %>%\n  summarise(avr_sco=mean(run_scored))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 2\n  inter_fre_sd avr_sco\n  <chr>          <dbl>\n1 high            766.\n2 low             748.\n3 normal          755.\n```\n:::\n:::\n\n\nAlso, the average score of the group, which frequently intervenes in the game, was high.\n\n## Correlation Analysis since 2015\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# correlation of intervention and score\ncor(df_2015$run_scored, df_2015$inter)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.08159777\n```\n:::\n\n```{.r .cell-code}\nlm_2015<-lm(run_scored~inter, df_2015)\nsummary(lm_2015)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = run_scored ~ inter, data = df_2015)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-192.376  -81.702    5.755   65.895  195.249 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 719.7232    58.6681  12.268   <2e-16 ***\ninter         0.1792     0.2874   0.624    0.535    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 92.75 on 58 degrees of freedom\nMultiple R-squared:  0.006658,\tAdjusted R-squared:  -0.01047 \nF-statistic: 0.3888 on 1 and 58 DF,  p-value: 0.5354\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# plot\nplot(df_2015$run_scored~df_2015$inter, xlab=\"Intervention\", ylab=\"Run Scored\")\nabline(lm(run_scored~inter, df_2015),col='red')\n```\n\n::: {.cell-output-display}\n![](FPchck2_young_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\nAlthough it is also weak, there is a positive correlation in which the more interventions there are, the more points scored.\n\nNext, the intervention of the game was subdivided into steal attempts and bunt, and each correlation was examined.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# correlation of sh, steal attemps and score\ncor(df_2015$run_scored, df_2015$sh)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.02183413\n```\n:::\n\n```{.r .cell-code}\ncor(df_2015$run_scored, df_2015$st_att)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.08638145\n```\n:::\n\n```{.r .cell-code}\nlm_2015_sep<-lm(run_scored~sh+st_att, df_2015)\nsummary(lm_2015_sep)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = run_scored ~ sh + st_att, data = df_2015)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-191.266  -80.470    5.174   61.712  194.576 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 719.96961   59.16131  12.170   <2e-16 ***\nsh            0.05624    0.59915   0.094    0.926    \nst_att        0.22720    0.35482   0.640    0.525    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 93.51 on 57 degrees of freedom\nMultiple R-squared:  0.007615,\tAdjusted R-squared:  -0.02721 \nF-statistic: 0.2187 on 2 and 57 DF,  p-value: 0.8042\n```\n:::\n:::\n\nAlthough the explanatory power is low, both steal attempts and bunt show a positive correlation with scoring.\nThese results show a different aspect from the recently accepted perception that \"operation in baseball negatively affects the team's offensive power.\" Is Korean baseball different from American baseball?\nI did some more analysis. First, I conducted a polynomial regression analysis.\n\n## Polynomial regression \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# fitting polynomial regression\nlm_2015_qua<-lm(run_scored~inter+I(inter^2), df_2015)\nsummary(lm_2015_qua)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = run_scored ~ inter + I(inter^2), data = df_2015)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-200.969  -78.462    6.364   59.548  194.162 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 802.998847 222.242294   3.613 0.000641 ***\ninter        -0.643710   2.136729  -0.301 0.764313    \nI(inter^2)    0.001948   0.005011   0.389 0.698944    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 93.43 on 57 degrees of freedom\nMultiple R-squared:  0.009284,\tAdjusted R-squared:  -0.02548 \nF-statistic: 0.2671 on 2 and 57 DF,  p-value: 0.7666\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(df_2015$inter, df_2015$run_scored, xlab=\"Intervention\", ylab=\"Run Scored\")\n\npred <- predict(lm_2015_qua)\nix <- sort(df_2015$inter, index.return=T)$ix\n\nlines(df_2015$inter[ix], pred[ix], col='red', lwd=2)\n```\n\n::: {.cell-output-display}\n![](FPchck2_young_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n:::\n\n\nAlthough the model's explanatory power has increased slightly, the positive correlation between match intervention and scoring continues to appear. (Since it is a quadratic equation, the correlation between scoring and intervention is negative until a specific level of intervention.)\n\n# Analysis using expected score\n\nAs a result of the analysis so far, the results were different from the results of recent studies.\n\nFrom now on, I will analyze the effect of the manager's intervention in the game using the concept of expected scores.\n\nFirst, I will introduce the concept of expected score.\nThe score of baseball is caused by various variables working together. In other words, if the runner gets on base due to hits and walks, and the follow-up batter hits again, the score will be scored. In other words, indicators such as hits and walks and scores have a high correlation, and outs do not.\n\nUsing this concept, a regression model between batting indicators such as hits and walks of the team and scores can be obtained, and expected scores can be obtained by substituting each team's batting indicators into the regression model obtained in this way.\n\nNow, by looking at the difference between the expected score and the actual score obtained by each group divided by the manager's intervention, we can see whether the manager's intervention improves the actual score compared to the team's expected score.\n\nThen, first, the regression equation was obtained.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# fitting regression\nexp_lm<-lm(run_scored~hit+double+triple+hr+bb+ibb+hbp+so+sf+gidp, df_2015)\nsummary(exp_lm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = run_scored ~ hit + double + triple + hr + bb + ibb + \n    hbp + so + sf + gidp, data = df_2015)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-54.750  -9.564   0.773  12.749  33.562 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -413.66438   82.53095  -5.012 7.42e-06 ***\nhit            0.48736    0.05270   9.248 2.53e-12 ***\ndouble         0.32361    0.15117   2.141   0.0373 *  \ntriple         1.10204    0.46735   2.358   0.0224 *  \nhr             0.93490    0.11086   8.433 4.18e-11 ***\nbb             0.45364    0.05571   8.143 1.16e-10 ***\nibb           -0.09291    0.56884  -0.163   0.8709    \nhbp            0.26767    0.16555   1.617   0.1123    \nso            -0.01222    0.04394  -0.278   0.7820    \nsf             0.56138    0.39545   1.420   0.1621    \ngidp          -0.08900    0.25885  -0.344   0.7325    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 19.79 on 49 degrees of freedom\nMultiple R-squared:  0.9618,\tAdjusted R-squared:  0.954 \nF-statistic: 123.4 on 10 and 49 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\nIt is possible to roughly grasp the impact of batting indicators such as hits, doubles, triples, and home runs on scoring.\n\nIt is a little surprising that the intentional base on balls (ibb) has a negative coefficient, but it is natural that the strikeout (so) and the double play (gidp) have a negative coefficient. Because these two variables mean out.\n\nNow, using this model, the expected score for each team was obtained and the difference from the actual score was calculated.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# get expected score\ndf_2015$exp_score<-predict(exp_lm, newdata = df_2015)\ndf_2015<-df_2015 %>%\n  mutate(run_diff=run_scored-exp_score)\ndf_2015[,c(\"year\",\"team\",\"run_scored\",\"exp_score\", \"run_diff\", \"inter_fre_sd\")]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 60 × 6\n    year team    run_scored exp_score run_diff inter_fre_sd\n   <dbl> <chr>        <dbl>     <dbl>    <dbl> <chr>       \n 1  2015 Bears          807      816.    -9.29 normal      \n 2  2015 Dinos          844      837.     7.16 high        \n 3  2015 Eagles         717      726.    -9.24 normal      \n 4  2015 Giants         765      780.   -15.5  normal      \n 5  2015 Heros          904      908.    -3.98 low         \n 6  2015 Landers        693      688.     5.31 normal      \n 7  2015 Lions          897      892.     5.12 normal      \n 8  2015 Tigers         648      626.    22.2  normal      \n 9  2015 Twins          653      678.   -24.9  normal      \n10  2015 Wiz            670      690.   -20.3  normal      \n# … with 50 more rows\n```\n:::\n:::\n\n\nThe average difference between actual and expected scores was examined for each group.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_2015%>%group_by(inter_fre_sd) %>%\n  summarise(run_diff_avr=mean(run_diff))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 2\n  inter_fre_sd run_diff_avr\n  <chr>               <dbl>\n1 high                 3.40\n2 low                  1.75\n3 normal              -1.10\n```\n:::\n:::\n\n\nAs with the previous results, the difference between the actual score and the expected score of the team with frequent intervention is higher.\nIn other words, a team with a lot of manager intervention is scoring more actual points than expected by the team's attack indicators.\n\n## Adjust Descriptive Variables\n\nNext, we adjusted the explanatory variables. The batting indicators included in the model above actually show a fairly high correlation with each other. In other words, a team that batting well is more likely to hit long balls such as doubles and home runs and get walks better.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# check the multicollinearity\npairs(df_2015[,12:19])\n```\n\n::: {.cell-output-display}\n![](FPchck2_young_files/figure-html/unnamed-chunk-27-1.png){width=672}\n:::\n\n```{.r .cell-code}\ncor(df_2015[,12:19])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n              hit      double      triple          hr         bb        ibb\nhit     1.0000000  0.73805947  0.38683193  0.54309756  0.2894128 0.22311500\ndouble  0.7380595  1.00000000  0.28915285  0.46159048  0.1254726 0.22334895\ntriple  0.3868319  0.28915285  1.00000000 -0.01066422  0.2474792 0.09522725\nhr      0.5430976  0.46159048 -0.01066422  1.00000000  0.0922088 0.20661688\nbb      0.2894128  0.12547263  0.24747916  0.09220880  1.0000000 0.23571499\nibb     0.2231150  0.22334895  0.09522725  0.20661688  0.2357150 1.00000000\nhbp     0.1955686  0.15696699  0.01914115  0.38753295 -0.1052230 0.32714658\nso     -0.2481782 -0.08083035 -0.28829988  0.23558753 -0.3059192 0.09115365\n               hbp          so\nhit     0.19556855 -0.24817821\ndouble  0.15696699 -0.08083035\ntriple  0.01914115 -0.28829988\nhr      0.38753295  0.23558753\nbb     -0.10522298 -0.30591922\nibb     0.32714658  0.09115365\nhbp     1.00000000  0.13166728\nso      0.13166728  1.00000000\n```\n:::\n:::\n\n\nIn fact, it can be seen that hits, doubles, triples, and home runs show a significant amount of correlation.\n\nSuch high multicollinearity is likely to distort the results of regression analysis, so it is necessary to select the appropriate variable again as an explanatory variable.\n\n## On-base percentage and Slugging percentage\n\nIn this regard, recent studies have shown the usefulness of the on-base percentage and the slugging percentage. You can simply think of it as how much on-base percentage you get on base alive without being out, and how many bases you get with one hit.\n\nBaseball can score as many bases as possible at a given opportunity while consuming a limited out count (less out), and the on-base percentage and long-base percentage are used as good indicators for evaluating hitting from this point of view\n\nA baseball team can score as many points as possible if it consumes a small out count (less out) and secures as many bases as possible at a given opportunity (long hit, send the ball away). From this point of view, the on-base percentage and slugging percentage are used as good indicators for evaluating battings. In this study, the on-base percentage and the slugging percentage were used as explanatory variables to take this perspective and obtain expected scores.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# OBP = (Hits + Walks + Hit-by-Pitches) / (At-Bats + Walks + Hit-by-Pitches + Sacrifice Flies)\n\ndf_2015<-df_2015 %>%\n  mutate(obp=(hit+bb+ibb+hbp)/(ab+bb+ibb+hbp+sf))\n\n# SLG = (1B + 2B x 2 + 3B x 3 + HR x 4) / AB\ndf_2015<-df_2015%>%\n  mutate(tb=hit-(double+triple+hr)+2*double+3*triple+4*hr)\ndf_2015<-df_2015%>%\n  mutate(slg=tb/ab)\n\ndf_2015[,c(\"year\", \"team\", \"run_scored\", \"obp\", \"slg\")]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 60 × 5\n    year team    run_scored   obp   slg\n   <dbl> <chr>        <dbl> <dbl> <dbl>\n 1  2015 Bears          807 0.373 0.435\n 2  2015 Dinos          844 0.370 0.455\n 3  2015 Eagles         717 0.364 0.405\n 4  2015 Giants         765 0.358 0.446\n 5  2015 Heros          904 0.374 0.486\n 6  2015 Landers        693 0.350 0.410\n 7  2015 Lions          897 0.380 0.469\n 8  2015 Tigers         648 0.328 0.392\n 9  2015 Twins          653 0.341 0.399\n10  2015 Wiz            670 0.348 0.402\n# … with 50 more rows\n```\n:::\n:::\n\n\nFor reference, the trend of on-base percentage and slugging percentage across the league by year since 2015 was also confirmed.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# take a look at obp and slg\nba_2015 <- data.frame(year = integer(), tot_ab= numeric(), \n                      tot_hit=numeric(), tot_bb=numeric(), tot_ibb=numeric(),\n                      tot_hbp=numeric(), tot_sf=numeric(), tot_tb=numeric(),\n                      stringsAsFactors = FALSE)\n\nfor (i in 2015:2020) {\n  year_ab_2015 <- df_2015 %>% \n    filter(year == i) %>% \n    summarize(year_ab_2015 = sum(ab)) %>% \n    pull(year_ab_2015)\n  \n  year_hit_2015 <- df_2015 %>%\n    filter(year == i) %>%\n    summarize(year_hit_2015 = sum(hit)) %>%\n    pull(year_hit_2015)\n  \n  year_bb_2015 <- df_2015 %>%\n    filter(year == i) %>%\n    summarize(year_bb_2015 = sum(bb)) %>%\n    pull(year_bb_2015)\n  \n  year_ibb_2015 <- df_2015 %>%\n    filter(year == i) %>%\n    summarize(year_ibb_2015 = sum(ibb)) %>%\n    pull(year_ibb_2015)\n  \n  year_hbp_2015 <- df_2015 %>%\n    filter(year == i) %>%\n    summarize(year_hbp_2015 = sum(hbp)) %>%\n    pull(year_hbp_2015)\n  \n  year_sf_2015 <- df_2015 %>%\n    filter(year == i) %>%\n    summarize(year_sf_2015 = sum(sf)) %>%\n    pull(year_sf_2015)\n  \n  year_tb_2015 <- df_2015 %>%\n    filter(year == i) %>%\n    summarize(year_tb_2015 = sum(tb)) %>%\n    pull(year_tb_2015)\n\n  ba_2015<- rbind(ba_2015, data.frame(year = i, tot_ab=year_ab_2015,\n                                      tot_hit=year_hit_2015, tot_bb=year_bb_2015,\n                                      tot_ibb=year_ibb_2015, tot_hbp=year_hbp_2015,\n                                      tot_sf=year_sf_2015, tot_tb=year_tb_2015))\n}\n\nba_2015 <- ba_2015 %>%\n  mutate(tot_obp=(tot_hit+tot_bb+tot_ibb+tot_hbp)/(tot_ab+tot_bb+tot_ibb+tot_hbp+tot_sf))\nba_2015<-ba_2015 %>%\n  mutate(tot_slg=tot_tb/tot_ab)\n\nba_2015_os<-select(ba_2015, 1, 9, 10)\n\nba_2015_os\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  year   tot_obp   tot_slg\n1 2015 0.3589008 0.4301378\n2 2016 0.3655517 0.4372514\n3 2017 0.3551946 0.4381766\n4 2018 0.3549076 0.4496014\n5 2019 0.3388575 0.3844904\n6 2020 0.3505034 0.4093399\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(ba_2015_os, aes(x = year)) +\n  geom_line(aes(y = tot_obp, color = \"OBP\")) +\n  geom_line(aes(y = tot_slg, color = \"SLG\")) +\n  scale_color_manual(values = c(\"OBP\" = \"blue\", \"SLG\" = \"red\")) +\n  labs(y = \"\",\n       color = \"\")\n```\n\n::: {.cell-output-display}\n![](FPchck2_young_files/figure-html/unnamed-chunk-30-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# fitting regression model using obp and slg\nexp_os_lm<-lm(run_scored~obp+slg, df_2015)\nsummary(exp_os_lm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = run_scored ~ obp + slg, data = df_2015)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-56.288 -18.876   1.651  19.630  46.770 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  -912.09      80.51 -11.328 3.20e-16 ***\nobp          3019.45     341.62   8.839 2.84e-12 ***\nslg          1411.78     157.31   8.975 1.70e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 25.4 on 57 degrees of freedom\nMultiple R-squared:  0.9268,\tAdjusted R-squared:  0.9242 \nF-statistic: 360.9 on 2 and 57 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\nAs a result of regression analysis, it can be seen that both the on-base percentage and the slugging percentage show a high correlation with scoring. Although only two variables were used in the explanatory power, it shows a high explanatory power that is almost close to the model using many variables.(r-squared: 0.9268)\n\nNow, in the same way as the previous analysis, the expected score using the on-base percentage and the slugging percentage was obtained and compared with the actual score.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# get expected score by obp, slg\ndf_2015$exp_score_os<-predict(exp_os_lm, newdata = df_2015)\ndf_2015<-df_2015 %>%\n  mutate(run_diff_os=run_scored-exp_score_os)\ndf_2015[,c(\"year\",\"team\",\"run_scored\",\"exp_score_os\",\"run_diff_os\",\"inter_fre_sd\")]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 60 × 6\n    year team    run_scored exp_score_os run_diff_os inter_fre_sd\n   <dbl> <chr>        <dbl>        <dbl>       <dbl> <chr>       \n 1  2015 Bears          807         826.     -19.2   normal      \n 2  2015 Dinos          844         847.      -2.75  high        \n 3  2015 Eagles         717         757.     -39.9   normal      \n 4  2015 Giants         765         799.     -34.3   normal      \n 5  2015 Heros          904         903.       0.924 low         \n 6  2015 Landers        693         724.     -31.4   normal      \n 7  2015 Lions          897         898.      -1.34  normal      \n 8  2015 Tigers         648         631.      16.6   normal      \n 9  2015 Twins          653         681.     -27.8   normal      \n10  2015 Wiz            670         706.     -35.8   normal      \n# … with 50 more rows\n```\n:::\n:::\n\n\nUsing this, the average of the difference between the actual score and the expected score by the manager's intervention frequency group was examined.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_2015%>%group_by(inter_fre_sd) %>%\n  summarise(run_diff_os_avr=mean(run_diff_os))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 2\n  inter_fre_sd run_diff_os_avr\n  <chr>                  <dbl>\n1 high                  -3.78 \n2 low                    8.26 \n3 normal                -0.959\n```\n:::\n:::\n\n\nAt last a new result came out.\n\nCompared to the expected score estimated by the on-base percentage and slugging percentage, the actual score of the group with a high degree of intervention in the game was lower than the expected score. The coach's intervention is rather lowering the team's scoring ability!!\n\n# Standardization Analysis\n\nAlthough the analysis period is limited, the annual score distribution is not completely constant. Finally, I examined the effect of manager's intervention with standardized figures considering the scoring environment by year.\n\nLikewise, only the results after 2015 were considered, and only the on-base percentage and the slugging percentage were used as explanatory variables.\n\nSince the average intervention and standard deviation by year have already been obtained, the average and standard deviation of the average score and standard deviation of the average score and the on-base rate by year were obtained,\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# making average and sd of run scored by each year\n\nas_sco_2015 <- data.frame(year = integer(), avr_run= numeric(), sd_run= numeric(),\n                          stringsAsFactors = FALSE)\n\nfor (i in 2015:2020) {\n  year_avr_sco_2015 <- df_2015 %>% \n    filter(year == i) %>% \n    summarize(year_avr_r_2015 = sum(run_scored)/n()) %>% \n    pull(year_avr_r_2015)\n  \n  year_sd_sco_2015 <- df_2015 %>% \n    filter(year == i) %>% \n    summarize(year_sd_r_2015 = sd(run_scored)) %>% \n    pull(year_sd_r_2015)\n\n  as_sco_2015<- rbind(as_sco_2015, data.frame(year = i, avr_run=year_avr_sco_2015,\n                                                sd_run=year_sd_sco_2015))\n}\n\n# making average and sd of obp and slg by each year\n\nos_2015<-data.frame(year = integer(), avr_obp= numeric(), avr_slg=numeric(), \n                    sd_obp=numeric(), sd_slg=numeric(), stringsAsFactors = FALSE)\n\nfor (i in 2015:2020) {\n  year_obp_2015 <- df_2015 %>% \n    filter(year == i) %>% \n    summarize(year_obp_2015 = mean(obp)) %>% \n    pull(year_obp_2015)\n  \n  year_slg_2015 <- df_2015 %>%\n    filter(year == i) %>%\n    summarize(year_slg_2015 = mean(slg)) %>%\n    pull(year_slg_2015)\n  \n  year_obp_sd_2015 <- df_2015 %>%\n    filter(year == i) %>%\n    summarize(year_obp_sd_2015 = sd(obp)) %>%\n    pull(year_obp_sd_2015)\n  \n  year_slg_sd_2015 <- df_2015 %>%\n    filter(year == i) %>%\n    summarize(year_slg_sd_2015 = sd(slg)) %>%\n    pull(year_slg_sd_2015)\n\n  os_2015<- rbind(os_2015, data.frame(year = i, avr_obp=year_obp_2015,\n                                      avr_slg=year_slg_2015, sd_obp=year_obp_sd_2015,\n                                      sd_slg=year_slg_sd_2015))\n}\n\n# left join to original data\ndf_2015<-left_join(left_join(left_join(df_2015, as_sco_2015), ba_2015_os), os_2015)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nJoining with `by = join_by(year)`\nJoining with `by = join_by(year)`\nJoining with `by = join_by(year)`\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# standardization\n\n## runs\ndf_2015<-df_2015%>%\n  mutate(st_run=(run_scored-avr_run)/sd_run) \n## obp\ndf_2015<-df_2015%>%\n  mutate(st_obp=(obp-avr_obp)/sd_obp)\n## slg\ndf_2015<-df_2015 %>%\n  mutate(st_slg=(slg-avr_slg)/sd_slg)\n##intervention\ndf_2015<-df_2015 %>%\n  mutate(st_inter=(inter-avr_inter)/sd_i)\n\ndf_2015[,c(\"year\",\"team\",\"st_run\",\"st_obp\",\"st_slg\",\"st_inter\")]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 60 × 6\n    year team     st_run  st_obp st_slg st_inter\n   <dbl> <chr>     <dbl>   <dbl>  <dbl>    <dbl>\n 1  2015 Bears    0.479   0.839   0.147   -0.707\n 2  2015 Dinos    0.855   0.678   0.760    2.19 \n 3  2015 Eagles  -0.435   0.301  -0.762    0.299\n 4  2015 Giants   0.0528 -0.0110  0.485   -0.676\n 5  2015 Heros    1.46    0.915   1.71    -1.47 \n 6  2015 Landers -0.679  -0.494  -0.603    0.207\n 7  2015 Lions    1.39    1.32    1.18     0.877\n 8  2015 Tigers  -1.14   -1.85   -1.15    -0.372\n 9  2015 Twins   -1.08   -1.05   -0.945   -0.189\n10  2015 Wiz     -0.912  -0.653  -0.830   -0.158\n# … with 50 more rows\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# fitting with standardization data\nst_exp_sco<-lm(st_run~st_obp+st_slg, df_2015)\nsummary(st_exp_sco)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = st_run ~ st_obp + st_slg, data = df_2015)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.79061 -0.16089 -0.00973  0.16722  0.62107 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 1.350e-16  3.914e-02   0.000        1    \nst_obp      5.674e-01  6.228e-02   9.110 1.02e-12 ***\nst_slg      4.477e-01  6.228e-02   7.188 1.55e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3032 on 57 degrees of freedom\nMultiple R-squared:  0.903,\tAdjusted R-squared:  0.8996 \nF-statistic: 265.3 on 2 and 57 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# get expected score using standardization data\ndf_2015$exp_st_sco<-predict(st_exp_sco, newdata = df_2015)\ndf_2015<-df_2015 %>%\n  mutate(st_run_diff=st_run-exp_st_sco)\ndf_2015[,c(\"year\",\"team\",\"exp_st_sco\", \"st_run_diff\", \"inter_fre_sd\")]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 60 × 5\n    year team    exp_st_sco st_run_diff inter_fre_sd\n   <dbl> <chr>        <dbl>       <dbl> <chr>       \n 1  2015 Bears        0.542     -0.0622 normal      \n 2  2015 Dinos        0.725      0.130  high        \n 3  2015 Eagles      -0.170     -0.264  normal      \n 4  2015 Giants       0.211     -0.158  normal      \n 5  2015 Heros        1.29       0.178  low         \n 6  2015 Landers     -0.550     -0.128  normal      \n 7  2015 Lions        1.28       0.118  normal      \n 8  2015 Tigers      -1.56       0.424  normal      \n 9  2015 Twins       -1.02      -0.0680 normal      \n10  2015 Wiz         -0.742     -0.170  normal      \n# … with 50 more rows\n```\n:::\n:::\n\n\n## A Comparison of Standardization Scores in Three Groups\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# comparing three groups\ndf_2015 %>% group_by(inter_fre_sd) %>%\n  summarise(st_r_d=mean(st_run_diff))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 2\n  inter_fre_sd   st_r_d\n  <chr>           <dbl>\n1 high         -0.104  \n2 low           0.0713 \n3 normal        0.00695\n```\n:::\n:::\n\n\nLooking at the results of standardizing and analyzing the variables, it can be seen that the actual score of the group with a lot of manager intervention is lower than the expected score.\n\n## Regression with intervention variable\n\nFinally, I looked at the regression model that included the standardized intervention of manager.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# fitting with intervention\nst_exp_sco_int<-lm(st_run~st_obp+st_slg+st_inter, df_2015)\nsummary(st_exp_sco_int)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = st_run ~ st_obp + st_slg + st_inter, data = df_2015)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.75685 -0.16865 -0.03597  0.20718  0.65370 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  1.289e-16  3.894e-02   0.000    1.000    \nst_obp       5.789e-01  6.264e-02   9.242 7.35e-13 ***\nst_slg       4.356e-01  6.271e-02   6.947 4.24e-09 ***\nst_inter    -5.226e-02  4.158e-02  -1.257    0.214    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3016 on 56 degrees of freedom\nMultiple R-squared:  0.9056,\tAdjusted R-squared:  0.9006 \nF-statistic: 179.2 on 3 and 56 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\nThe slugging percentage and the on-base percentage show a positive correlation with the score, but the coach's intervention shows a negative correlation with the score.\n\n# Finish\n\nWhen the analysis range and explanatory variables are appropriately selected, it can be seen that the manager's intervention and the team's score show a negative correlation. In other words, it is difficult to predict that the manager's involvement in the batting, represented by bunt and steal attempts, will produce such a positive result in the KBO baseball game.\n\n",
    "supporting": [
      "FPchck2_young_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}