{
  "hash": "306bd2f2a5799a28cd1d4115431ba292",
  "result": {
    "markdown": "---\ntitle: \"Homework 4\"\nauthor: \"Darron Bunt\"\ndescription: \"Homework Assignment 4 - Darron Bunt\"\ndate: \"05/07/2023\"\nformat:\n  html:\n    toc: true\n    code-fold: true\n    code-copy: true\n    code-tools: true\ncategories:\n  - hw4\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n:::\n\n```{.r .cell-code}\nlibrary(alr4)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: car\nLoading required package: carData\n\nAttaching package: 'car'\n\nThe following object is masked from 'package:dplyr':\n\n    recode\n\nThe following object is masked from 'package:purrr':\n\n    some\n\nLoading required package: effects\nlattice theme set by effectsTheme()\nSee ?effectsTheme for details.\n```\n:::\n\n```{.r .cell-code}\nlibrary(smss)\nlibrary(ggplot2)\n```\n:::\n\n\n# Question 1 \n\n*For recent data in Jacksonville, Florida, on y = selling price of home (in dollars), x1 = size of home (in square feet), and x2 = lot size (in square feet), the prediction equation is ŷ = −10,536 + 53.8x1 + 2.84x2.*\n\n####  A\n\n**A particular home of 1240 square feet on a lot of 18,000 square feet sold for $145,000. Find the predicted selling price and the residual, and interpret**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Find the predicted selling price and the residual\n# ŷ = −10,536 + 53.8x1 + 2.84x2, where x1 = 1,240 and x2 = 18,000\nPredPrice <- -10536 + (53.8*1240) + (2.84*18000)\nPredPrice\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 107296\n```\n:::\n\n```{.r .cell-code}\n# Calculate the residual - actual selling price - predicted selling price\nActualPrice <- 145000\nResidual <- ActualPrice - PredPrice\nResidual \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 37704\n```\n:::\n:::\n\nThe predicted selling price is $107,296 and the residual is $37,704.\n\nThe actual selling price was more than the model would have predicted.\n\n####  B\n\n**For fixed lot size, how much is the house selling price predicted to increase for each square-foot increase in home size? Why?**\n\nFor a fixed lot size, each square-foot increase is predicted to increase the sale price by $53.80 - the value of x1. \n\nIf we increase the square footage of the example house in question by one square foot, we can observe this difference in the predicted price. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate predicted house price for a 1,241 square foot home\nHouse2 <- -10536 + (53.8*1241) + (2.84*18000)\nHouse2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 107349.8\n```\n:::\n\n```{.r .cell-code}\n# Calculate the difference in predicted price for a 1,241 square foot home vs. a 1,240 square foot home\nHouse2Diff <- House2 - PredPrice\nHouse2Diff\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 53.8\n```\n:::\n:::\n\n####  C\n\n**According to this prediction equation, for fixed home size, how much would lot size need to increase to have the same impact as a one-square-foot increase in home size?**\n\nBased on this prediction equation, every square-foot increase in home size increases the value by $53.80 (the value of x1) and each square-foot increase in lot size increases the price by $2.84 (the value of x2).\n\nIn order to calculate how much lot size would need to increase in order to have the same impact as a one-square-foot increase in home size, we need to see how many times $2.84 goes into $53.80\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Divide $53.80 by $2.84\nHowManyFeet <- 53.80 / 2.84\nHowManyFeet\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 18.94366\n```\n:::\n:::\n\nLot size would need to increase 18.94 square feet in order to have the same impact on predicted selling price as a one square foot increase in home size. \n\n# Question 2\n\n(Data file: salary in alr4 R package).\n\n*The data file concerns salary and other characteristics of all faculty in a small Midwestern college collected in the early 1980s for presentation in legal proceedings for which discrimination against women in salary was at issue. All persons in the data hold tenured or tenure track positions; temporary faculty are not included. The variables include degree, a factor with levels PhD and MS; rank, a factor with levels Asst, Assoc, and Prof; sex, a factor with levels Male and Female; Year, years in current rank; ysdeg, years since highest degree, and salary, academic year salary in dollars.*\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load salary data file\ndata(salary)\n```\n:::\n\n#### A\n\n**Test the hypothesis that the mean salary for men and women is the same, without regard to any other variable but sex. Explain your findings.**\n\nNull hypothesis: That the mean salary for men and women, without regard to any other variable but sex, **is** the same\nAlternative hypothesis: That the mean salary for men and women, without regard to any other variable but sex, **is not** the same.\n\nIn order to test the hypothesis I am going to run a t-test to determine whether the difference in means is statistically significant.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Run a two-sample t-test\nt.test(formula = salary ~ sex, data = salary)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tWelch Two Sample t-test\n\ndata:  salary by sex\nt = 1.7744, df = 21.591, p-value = 0.09009\nalternative hypothesis: true difference in means between group Male and group Female is not equal to 0\n95 percent confidence interval:\n -567.8539 7247.1471\nsample estimates:\n  mean in group Male mean in group Female \n            24696.79             21357.14 \n```\n:::\n:::\n\n\nThe t-test shows that there is indeed a difference between the mean salary for men ($23,696.79) and women ($21,357.14), but with a p-value of 0.09009, we fail to reject the null hypothesis at the 95% confidence level - that is to say, we do not have the evidence that we need to reject the hypothesis that the mean salary for men and women, without regard to any other variable but sex, is the same.\n\n#### B\n\n**Run a multiple linear regression with salary as the outcome variable and everything else as predictors, including sex. Assuming no interactions between sex and the other predictors, obtain a 95% confidence interval for the difference in salary between males and females.**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Run multiple linear regression with salary as outcome variable and everything else (including sex) as predictors\nlm_salary <- lm(salary ~ ., data = salary)\nsummary(lm_salary)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = salary ~ ., data = salary)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4045.2 -1094.7  -361.5   813.2  9193.1 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 15746.05     800.18  19.678  < 2e-16 ***\ndegreePhD    1388.61    1018.75   1.363    0.180    \nrankAssoc    5292.36    1145.40   4.621 3.22e-05 ***\nrankProf    11118.76    1351.77   8.225 1.62e-10 ***\nsexFemale    1166.37     925.57   1.260    0.214    \nyear          476.31      94.91   5.018 8.65e-06 ***\nysdeg        -124.57      77.49  -1.608    0.115    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2398 on 45 degrees of freedom\nMultiple R-squared:  0.855,\tAdjusted R-squared:  0.8357 \nF-statistic: 44.24 on 6 and 45 DF,  p-value: < 2.2e-16\n```\n:::\n\n```{.r .cell-code}\n# Obtain 95% confidence interval for the difference in salary between males and females.\nconfint(lm_salary, \"sexFemale\", level = 0.95)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n              2.5 %   97.5 %\nsexFemale -697.8183 3030.565\n```\n:::\n:::\n\nThe 95% confidence interval for the difference in salary between males and females is (-697.82, 3,030.57).\n\n#### C\n\n**Interpret your finding for each predictor variable; discuss (a) statistical significance, (b) interpretation of the coefficient / slope in relation to the outcome variable and other variables**\n\n* Degree\n  + Controlling for everything else, a professor with a PhD makes $1,388.61 more than a professor with only a master's. The p-value is 0.180, so the result is not statistically significant.\n\n* Rank\n  + The p-values for rankAssoc and rankProf are both less than 0.05, indicating a statistically significant relationship between salary and rank. Controlling for everything else, a professor at the Associate rank makes $5,292.36 more than one at the rank of Assistant, and a full professor makes $11,118.76 more. \n\n* Sex\n  + Controlling for everything else, a female professor makes $1,166 more than a male professor. With a p-value of 0.214, this is not a statistically significant result.\n\n* Year\n  + Year, the years a professor has in their current rank, also had a statistically significant impact on salary. Each additional year of experience added $476.31 in salary.\n\n* Years Since Highest Degree\n  + The result here was not statistically significant but suggests that, when controlling for all other factors, each year that has passed since one obtained their degree results in a $124.57 decrease in salary.\n\nOverall, of the predictor variables considered, rank and year have a statistically significant impact on salary. \n\n#### D\n\n**Change the baseline category for the rank variable. Interpret the coefficients related to rank again.**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Change the baseline category for rank to \"Prof\"\nsalary$rank <- relevel(salary$rank, ref = \"Prof\")\nsummary(lm(salary ~ ., data = salary))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = salary ~ ., data = salary)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4045.2 -1094.7  -361.5   813.2  9193.1 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  26864.81    1375.29  19.534  < 2e-16 ***\ndegreePhD     1388.61    1018.75   1.363    0.180    \nrankAsst    -11118.76    1351.77  -8.225 1.62e-10 ***\nrankAssoc    -5826.40    1012.93  -5.752 7.28e-07 ***\nsexFemale     1166.37     925.57   1.260    0.214    \nyear           476.31      94.91   5.018 8.65e-06 ***\nysdeg         -124.57      77.49  -1.608    0.115    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2398 on 45 degrees of freedom\nMultiple R-squared:  0.855,\tAdjusted R-squared:  0.8357 \nF-statistic: 44.24 on 6 and 45 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Change the baseline category for rank to \"Assoc\"\nsalary$rank <- relevel(salary$rank, ref = \"Assoc\")\nsummary(lm(salary ~ ., data = salary))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = salary ~ ., data = salary)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4045.2 -1094.7  -361.5   813.2  9193.1 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 21038.41    1109.12  18.969  < 2e-16 ***\ndegreePhD    1388.61    1018.75   1.363    0.180    \nrankProf     5826.40    1012.93   5.752 7.28e-07 ***\nrankAsst    -5292.36    1145.40  -4.621 3.22e-05 ***\nsexFemale    1166.37     925.57   1.260    0.214    \nyear          476.31      94.91   5.018 8.65e-06 ***\nysdeg        -124.57      77.49  -1.608    0.115    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2398 on 45 degrees of freedom\nMultiple R-squared:  0.855,\tAdjusted R-squared:  0.8357 \nF-statistic: 44.24 on 6 and 45 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n**Interpret the coefficients related to rank again.**\n\nNo matter which category is the baseline for rank, the results remain statistically significant.\n\n* With professor as the baseline, we that assistant professors are expected to make $11,118.76 less and associate professors $5,826.40 less.\n\n* With associate professor as the baseline, we see that full professors are expected to make $5,826.40 more, while assistant professors are expected to make $5,292.36 less.\n\n* And, as we calculated previously, with assistant as the baseline, a professor at the Associate rank makes $5,292.36 more than one at the rank of Assistant, and a full professor makes $11,118.76 more.\n\nThe numbers always remain the same; it's the same information, just presented in slightly different ways depending on which rank is acting as the baseline variable. \n\n#### E\n\n*Finkelstein (1980), in a discussion of the use of regression in discrimination cases, wrote, “[a] variable may reflect a position or status bestowed by the employer, in which case if there is discrimination in the award of the position or status, the variable may be ‘tainted.’ ” Thus, for example, if discrimination is at work in promotion of faculty to higher ranks, using rank to adjust salaries before comparing the sexes may not be acceptable to the courts.*\n\n**Exclude the variable rank, refit, and summarize how your findings changed, if they did.**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Run multiple linear regression again, but exclude the variable \"rank\"\nlm_salary_NR <- lm(salary ~ degree + sex + year + ysdeg, data = salary)\nsummary(lm_salary_NR)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = salary ~ degree + sex + year + ysdeg, data = salary)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8146.9 -2186.9  -491.5  2279.1 11186.6 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 17183.57    1147.94  14.969  < 2e-16 ***\ndegreePhD   -3299.35    1302.52  -2.533 0.014704 *  \nsexFemale   -1286.54    1313.09  -0.980 0.332209    \nyear          351.97     142.48   2.470 0.017185 *  \nysdeg         339.40      80.62   4.210 0.000114 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3744 on 47 degrees of freedom\nMultiple R-squared:  0.6312,\tAdjusted R-squared:  0.5998 \nF-statistic: 20.11 on 4 and 47 DF,  p-value: 1.048e-09\n```\n:::\n:::\n\n**Summarize how your findings changed, if they did.**\n\n* With rank included as a predictor variable, rank and year had a statistically significant impact on salary. \n\n* With rank excluded, degree, year, and ysdeg had a statistically significant impact on salary\n  + **Degree** \n    - Without the \"rank\" variable, \"degreePhD\" becomes a statistically significant predictor variable. When controlling for all other factors, a PhD (vs. a master's) now results in a $3,299.35 decrease in salary (much different than with rank included, where there was no statistical significance, but a PhD increased salary by $1,388.61).\n  + **Years Since Highest Degree** \n    - Without the \"rank\" variable, \"ysdeg\" (years since receiving one's highest degree) becomes a statistically significant predictor variable. When controlling for all other factors, each year that has passed now results in a $339.40 increase in salary (much different than with rank included, where there was no statistical significance and a decrease). \n  + **Year** \n    - \"year\" remains statistically significant, though the p-value has increased. When controlling for all other factors, each additional year of experience adds $351.97 in salary.\n  + **Sex** \n    - The result for sex was still not statistically significant, but the its impact on salary did change from a positive one to a negative one. \n\n#### F\n\n*Everyone in this dataset was hired the year they earned their highest degree. It is also known that a new Dean was appointed 15 years ago, and everyone in the dataset who earned their highest degree 15 years ago or less than that has been hired by the new Dean. Some people have argued that the new Dean has been making offers that are a lot more generous to newly hired faculty than the previous one and that this might explain some of the variation in Salary.*\n\n**Create a new variable that would allow you to test this hypothesis and run another multiple regression model to test this. Select variables carefully to make sure there is no multicollinearity. Explain why multicollinearity would be a concern in this case and how you avoided it. Do you find support for the hypothesis that the people hired by the new Dean are making higher than those that were not?**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create a new variable that indicates whether the professor was hired by the new dean or not - ysdeg >16 years ago and ysdeg <= 15 years ago\nsalary$newDean <- ifelse(salary$ysdeg <= 15, 0, 1)\n# 0 WAS hired by new Dean; 1 is was NOT hired by new Dean\n```\n:::\n\nMulticollinarity refers to a situation where 2+ variables in a regression model are highly correlated with each other - that is, they are measuring either the same or similar things. If variables that are highly correlated with each other are included in the same regression model, this can lead to unreliable results. \n\nIn our case, newDean is highly correlated with ysdeg - the numerical data from ysdeg was used to create the binary variable newDean (0 if ysdeg is 16+; 1 if ysdeg is 15 or less). Accordingly, when we run our regression analysis, we need to include newDean, but **exclude** ysdeg.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Run regression analysis with newDean included as a predictor variable\nlm_salary_NewDean <- lm(salary ~ degree + rank + sex + year + newDean, data = salary)\nsummary(lm_salary_NewDean)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = salary ~ degree + rank + sex + year + newDean, data = salary)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3403.3 -1387.0  -167.0   528.2  9233.8 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 20464.50     952.41  21.487  < 2e-16 ***\ndegreePhD     818.93     797.48   1.027   0.3100    \nrankProf     6124.28    1028.58   5.954 3.65e-07 ***\nrankAsst    -4972.66     997.17  -4.987 9.61e-06 ***\nsexFemale     907.14     840.54   1.079   0.2862    \nyear          434.85      78.89   5.512 1.65e-06 ***\nnewDean     -2163.46    1072.04  -2.018   0.0496 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2362 on 45 degrees of freedom\nMultiple R-squared:  0.8594,\tAdjusted R-squared:  0.8407 \nF-statistic: 45.86 on 6 and 45 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n**Do you find support for the hypothesis that the people hired by the new Dean are making higher than those that were not?**\n\nYes, there is support for the hypothesis that people hired by the new Dean are making more than those who were not. The p-value is significant at the 5% level (0.0496), and the results suggest that faculty who were not hired by the new Dean make $2,163.46 less, when controlling for other variables. \n\n# Question 3\n\n(Data file: house.selling.price in smss R package)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load data file\ndata(\"house.selling.price\")\n```\n:::\n\n\n#### A\n\n**Using the house.selling.price data, run and report regression results modeling y = selling price (in dollars) in terms of size of home (in square feet) and whether the home is new (1 = yes; 0 = no). In particular, for each variable; discuss statistical significance and interpret the meaning of the coefficient.**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Regression results modeling Size, New as predictor variables for Price\nPrice_SzNew <- lm(Price ~ Size + New, data = house.selling.price)\nsummary(Price_SzNew)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Price ~ Size + New, data = house.selling.price)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-205102  -34374   -5778   18929  163866 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -40230.867  14696.140  -2.738  0.00737 ** \nSize           116.132      8.795  13.204  < 2e-16 ***\nNew          57736.283  18653.041   3.095  0.00257 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 53880 on 97 degrees of freedom\nMultiple R-squared:  0.7226,\tAdjusted R-squared:  0.7169 \nF-statistic: 126.3 on 2 and 97 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n**for each variable; discuss statistical significance and interpret the meaning of the coefficient.**\n\n* Size\n  + Size had a statistically significant impact on selling price; controlling for newness, each additional square foot added $116.13 to the sale price.\n\n* New\n  + New also had a statistically significant impact on selling price; controlling for square footage, a new house sold for $57,736.28 more than houses that were not new.\n\n#### B\n\n**Report and interpret the prediction equation, and form separate equations relating selling price to size for new and for not new homes.**\n\nThe equation would be ŷ = −40,230.867 + 116.132(Size) + 57736.283(New). \n\nIf a house is new: ŷ = −40,230.867 + 116.132(Size) + 57,736.283\nIf a house is not new: ŷ = −40,230.867 + 116.132(Size) \n\nNew/not new is a binary variable, and only new houses see an increase in sale price. \n\n#### C \n\n**Find the predicted selling price for a home of 3000 square feet that is (i) new, (ii) not new.**\n\nNew: ŷ = −40,230.867 + (116.132*3000) + 57,736.283\nNot new: ŷ = −40,230.867 + (116.132*3000)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nNew3000 <- -40230.867 + (116.132*3000) + 57736.283\nNotNew3000 <- -40230.867 + (116.132*3000)\nNew3000\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 365901.4\n```\n:::\n\n```{.r .cell-code}\nNotNew3000\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 308165.1\n```\n:::\n:::\n\nThe predicted selling price for a new 3,000 square foot home is $365,901.40. The predicted selling price for a 3,000 square foot home that is not new is $308,165.10. \n\n#### D \n\n**Fit another model, this time with an interaction term allowing interaction between size and new, and report the regression results**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit a model allowing interaction between size and new\nPrice_SzNewInt <- lm(Price ~ Size + New + Size:New, data = house.selling.price)\nsummary(Price_SzNewInt)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Price ~ Size + New + Size:New, data = house.selling.price)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-175748  -28979   -6260   14693  192519 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -22227.808  15521.110  -1.432  0.15536    \nSize           104.438      9.424  11.082  < 2e-16 ***\nNew         -78527.502  51007.642  -1.540  0.12697    \nSize:New        61.916     21.686   2.855  0.00527 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 52000 on 96 degrees of freedom\nMultiple R-squared:  0.7443,\tAdjusted R-squared:  0.7363 \nF-statistic: 93.15 on 3 and 96 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n#### E \n\n**Report the lines relating the predicted selling price to the size for homes that are (i) new, (ii) not new.**\n\nŷ = −22,227.808 + 104.438(Size) + (-78527.502(New)) + 61.916(Size*New)\n\nNew: −22,227.808 + 104.438(Size) + (-78527.502(New)) + 61.916(Size*New)\n\nNot new: −22,227.808 + 104.438(Size)\n\n#### F \n\n**Find the predicted selling price for a home of 3000 square feet that is (i) new, (ii) not new.**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nNewInt3000 <- -22227.808 + (104.438*3000) -78527.502 + (61.916*3000)\nNotNewInt3000 <- -22227.808 + (104.438*3000)\nNewInt3000\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 398306.7\n```\n:::\n\n```{.r .cell-code}\nNotNewInt3000\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 291086.2\n```\n:::\n:::\n\nThe predicted selling price for a new, 3000 square-foot home is $398,306.70. The predicted selling price for a 3000 square-foot home that is not new is $291,086.20.\n\n#### G \n\n**Find the predicted selling price for a home of 1500 square feet that is (i) new, (ii) not new. Comparing to (F), explain how the difference in predicted selling prices changes as the size of home increases.**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nNewInt1500 <- -22227.808 + (104.438*1500) -78527.502 + (61.916*1500)\nNotNewInt1500 <- -22227.808 + (104.438*1500)\nNewInt1500\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 148775.7\n```\n:::\n\n```{.r .cell-code}\nNotNewInt1500\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 134429.2\n```\n:::\n:::\n\n**Comparing to (F), explain how the difference in predicted selling prices changes as the size of home increases.**\n\n* For 3000 square foot homes:\n  + New: $398,306.70\n  + Not New: $291,086.20\n\n* For 1500 square foot homes:\n  + New: $148,775.70\n  + Not New: $134,429.20\n\nThere is a $107,220.50 difference in sale price for the new/not new 3000 square foot homes but only a $14,346.50 difference in sale price for the new/not new 1500 square foot homes. Given the structure of the prediction equation, this makes a lot of sense - based on the predictive model, a house needs to be roughly 606 feet before it can be sold at a profit. A 1,500 square foot home has only roughly 894 \"money making\" square feet, while the 3000 square foot home has roughly 2394, and each money making square foot available adds 166.354 to the sale price.\n\n#### H\n\n**Do you think the model with interaction or the one without it represents the relationship of size and new to the outcome price? What makes you prefer one model over another?**\n\nI think the model with the interaction more closely represents the relationship of size and newness to the outcome price. The p value for the model with interaction indicated statistical significance; further, the adjusted r squared for the model with interaction (0.7363) was higher than that for the model without (0.7169). ",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}