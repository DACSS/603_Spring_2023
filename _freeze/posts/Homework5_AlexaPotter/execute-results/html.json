{
  "hash": "a16dbc390cfd8e2afa1f9c1ec3746a52",
  "result": {
    "markdown": "---\ntitle: \"Homework 5\"\nauthor: \"Alexa Potter\"\ndescription: \"DACSS 603\"\ndate: \"05/07/2023\"\nformat:\n  html:\n    toc: true\n    code-fold: true\n    code-copy: true\n    code-tools: true\ncategories:\n  - hw5\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(car)\nlibrary(smss)\ndata(\"house.selling.price.2\", package = \"smss\")\ndf <- house.selling.price.2\nlibrary(alr4)\ndata(\"florida\", package = \"alr4\")\ndf <- florida\nlibrary(flexmix)\nlibrary(ggplot2)\nlibrary(stargazer)\n```\n:::\n\n\n\n# Question 1\n\n(Data file: house.selling.price.2 from smss R package)   \n\nFor the house.selling.price.2 data the tables below show a correlation matrix and a model fit using  four predictors of selling price.    \n  \n(Hint 1: You should be able to answer A, B, C just using the tables below, although you should  feel free to load the data in R and work with it if you so choose. They will be consistent with what  you see on the tables.  \n\nHint 2: The p-value of a variable in a simple linear regression is the same p-value one would get  from a Pearson’s correlation (cor.test). The p-value is a function of the magnitude of the correlation  coefficient (the higher the coefficient, the lower the p-value) and of sample size (larger samples  lead to smaller p-values). For the correlations shown in the tables, they are between variables of  the same length.) \nWith these four predictors,   \n\n\n## A \n\nFor backward elimination, which variable would be deleted first? Why?  \n\nBeds would be eliminated first as it has the highest p-value. \n\n## B  \n\nFor forward selection, which variable would be added first? Why?      \n\nSize would be added first because it is the most significant with the highest correlation to price.   \n\n## C  \n\nWhy do you think that BEDS has such a large P-value in the multiple regression model,  even though it has a substantial correlation with PRICE?   \n \nIt may be because with the influence of other variables, beds is not as important to price as new or size is. These then diminish the influence of beds on price when factored together and controlled for.  \n \n## D\n\nUsing software with these four predictors, find the model that would be selected using each  criterion:   \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm_1 <- (lm(P ~ S, data= house.selling.price.2))\n\nlm_2 <- (lm(P ~ S + New, data= house.selling.price.2))\n\nlm_3 <- (lm(P ~ S + Ba + New, data= house.selling.price.2))\n\nlm_4 <- (lm(P ~ S + Be + Ba + New, data= house.selling.price.2))\n\nstargazer(lm_1, lm_2, lm_3, lm_4, type = 'text')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n===================================================================================================================\n                                                          Dependent variable:                                      \n                    -----------------------------------------------------------------------------------------------\n                                                                   P                                               \n                              (1)                     (2)                     (3)                     (4)          \n-------------------------------------------------------------------------------------------------------------------\nS                          75.607***               72.575***               62.263***               64.761***       \n                            (3.865)                 (3.508)                 (4.335)                 (5.630)        \n                                                                                                                   \nBe                                                                                                  -2.766         \n                                                                                                    (3.960)        \n                                                                                                                   \nBa                                                                         20.072***               19.203***       \n                                                                            (5.495)                 (5.650)        \n                                                                                                                   \nNew                                                19.587***               18.371***               18.984***       \n                                                    (3.995)                 (3.761)                 (3.873)        \n                                                                                                                   \nConstant                  -25.194***              -26.089***              -47.992***              -41.795***       \n                            (6.688)                 (5.977)                 (8.209)                (12.104)        \n                                                                                                                   \n-------------------------------------------------------------------------------------------------------------------\nObservations                  93                      93                      93                      93           \nR2                           0.808                   0.848                   0.868                   0.869         \nAdjusted R2                  0.806                   0.845                   0.864                   0.863         \nResidual Std. Error    19.473 (df = 91)        17.395 (df = 90)        16.313 (df = 89)        16.360 (df = 88)    \nF Statistic         382.628*** (df = 1; 91) 251.775*** (df = 2; 90) 195.313*** (df = 3; 89) 145.763*** (df = 4; 88)\n===================================================================================================================\nNote:                                                                                   *p<0.1; **p<0.05; ***p<0.01\n```\n:::\n:::\n\n\n1. R2   \n\nModel 4\n\n2. Adjusted R2   \n\nModel 3\n\n3. PRESS   \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nPRESS <- function(model) {\n    i <- residuals(model)/(1 - lm.influence(model)$hat)\n    sum(i^2)\n}\nPRESS(lm_1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 38203.29\n```\n:::\n\n```{.r .cell-code}\nPRESS(lm_2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 31066\n```\n:::\n\n```{.r .cell-code}\nPRESS(lm_3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 27860.05\n```\n:::\n\n```{.r .cell-code}\nPRESS(lm_4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 28390.22\n```\n:::\n:::\n\nModel 3 \n\n4. AIC   \n\n\n::: {.cell}\n\n```{.r .cell-code}\nAIC(lm_1, k=2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 820.1439\n```\n:::\n\n```{.r .cell-code}\nAIC(lm_2, k=2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 800.1262\n```\n:::\n\n```{.r .cell-code}\nAIC(lm_3, k=2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 789.1366\n```\n:::\n\n```{.r .cell-code}\nAIC(lm_4, k=2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 790.6225\n```\n:::\n:::\n\nModel 3\n\n5. BIC   \n\n\n::: {.cell}\n\n```{.r .cell-code}\nBIC(lm_1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 827.7417\n```\n:::\n\n```{.r .cell-code}\nBIC(lm_2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 810.2566\n```\n:::\n\n```{.r .cell-code}\nBIC(lm_3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 801.7996\n```\n:::\n\n```{.r .cell-code}\nBIC(lm_4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 805.8181\n```\n:::\n:::\n\nModel 3\n\n\n## E  \n\nExplain which model you prefer and why. \n\nThe model diagnostics point to Model 3 (P ~ S + Ba + New) as being the best fit model. This is the best fit model for all the diagnostic tests except for R2. This model has all significant variables except for Beds, which was not significant.    \n\n# Question 2  \n\n(Data file: trees from base R) \n\nFrom the documentation:   \n\n“This data set provides measurements of the diameter, height and volume of timber in 31 felled  black cherry trees. Note that the diameter (in inches) is erroneously labeled Girth in the data. It is  measured at 4 ft 6 in above the ground.”   \n\nTree volume estimation is a big deal, especially in the lumber industry. Use the trees data to build  a basic model of tree volume prediction. In particular, \n\n\n## A  \n\nFit a multiple regression model with the Volume as the outcome and Girth and Height as  the explanatory variables   \n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrees\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Girth Height Volume\n1    8.3     70   10.3\n2    8.6     65   10.3\n3    8.8     63   10.2\n4   10.5     72   16.4\n5   10.7     81   18.8\n6   10.8     83   19.7\n7   11.0     66   15.6\n8   11.0     75   18.2\n9   11.1     80   22.6\n10  11.2     75   19.9\n11  11.3     79   24.2\n12  11.4     76   21.0\n13  11.4     76   21.4\n14  11.7     69   21.3\n15  12.0     75   19.1\n16  12.9     74   22.2\n17  12.9     85   33.8\n18  13.3     86   27.4\n19  13.7     71   25.7\n20  13.8     64   24.9\n21  14.0     78   34.5\n22  14.2     80   31.7\n23  14.5     74   36.3\n24  16.0     72   38.3\n25  16.3     77   42.6\n26  17.3     81   55.4\n27  17.5     82   55.7\n28  17.9     80   58.3\n29  18.0     80   51.5\n30  18.0     80   51.0\n31  20.6     87   77.0\n```\n:::\n\n```{.r .cell-code}\nlm_trees <- lm(Volume ~ Girth + Height, data = trees)\nsummary(lm_trees)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Volume ~ Girth + Height, data = trees)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-6.4065 -2.6493 -0.2876  2.2003  8.4847 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -57.9877     8.6382  -6.713 2.75e-07 ***\nGirth         4.7082     0.2643  17.816  < 2e-16 ***\nHeight        0.3393     0.1302   2.607   0.0145 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.882 on 28 degrees of freedom\nMultiple R-squared:  0.948,\tAdjusted R-squared:  0.9442 \nF-statistic:   255 on 2 and 28 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\n\n\n## B  \n\nRun regression diagnostic plots on the model. Based on the plots, do you think any of the  regression assumptions is violated?   \n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(lm_trees, which = 1)\n```\n\n::: {.cell-output-display}\n![](Homework5_AlexaPotter_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(lm_trees, which = 2)\n```\n\n::: {.cell-output-display}\n![](Homework5_AlexaPotter_files/figure-html/unnamed-chunk-7-2.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(lm_trees, which = 3)\n```\n\n::: {.cell-output-display}\n![](Homework5_AlexaPotter_files/figure-html/unnamed-chunk-7-3.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(lm_trees, which = 4)\n```\n\n::: {.cell-output-display}\n![](Homework5_AlexaPotter_files/figure-html/unnamed-chunk-7-4.png){width=672}\n:::\n:::\n\n\nResiduals vs. Fitted  \n\nThe assumption of linearity seems to be violated here. The graph shows a curve rather than a straight line.   \n\nNormal Q-Q  \n\nThe assumption of normality does appear to not be violated here. The dots generally fall along the line.   \n\nScale-Location \n\nThe assumption of constant variance does not appear violated here. While the line does not appear \"approximately horizontal\", the dots do not have an increasing or decreasing trend.  \n\n\nCook's Distance   \n\nTo calculate the baseline here, it is 4/n. n= number of trees (31). ~ 0.13. The graph displays 3-4 points above this value, meaning the assumption of influential observation is violated.  \n\n::: {.cell}\n\n```{.r .cell-code}\n4/31\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.1290323\n```\n:::\n:::\n\n\n\n\n# Question 3  \n\n(Data file: florida in alr R package)   \n\nIn the 2000 election for U.S. president, the counting of votes in Florida was controversial. In Palm  Beach County in south Florida, for example, voters used a so-called butterfly ballot. Some believe  that the layout of the ballot caused some voters to cast votes for Buchanan when their intended  choice was Gore.    \n\nThe data has variables for the number of votes for each candidate—Gore, Bush, and Buchanan.   \n\n\n## A  \n\nRun a simple linear regression model where the Buchanan vote is the outcome and the  Bush vote is the explanatory variable. Produce the regression diagnostic plots. Is Palm Beach  County an outlier based on the diagnostic plots? Why or why not?     \n\n\n::: {.cell}\n\n```{.r .cell-code}\nflorida\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n               Gore   Bush Buchanan\nALACHUA       47300  34062      262\nBAKER          2392   5610       73\nBAY           18850  38637      248\nBRADFORD       3072   5413       65\nBREVARD       97318 115185      570\nBROWARD      386518 177279      789\nCALHOUN        2155   2873       90\nCHARLOTTE     29641  35419      182\nCITRUS        25501  29744      270\nCLAY          14630  41745      186\nCOLLIER       29905  60426      122\nCOLUMBIA       7047  10964       89\nDADE         328702 289456      561\nDE SOTO        3322   4256       36\nDIXIE          1825   2698       29\nDUVAL        107680 152082      650\nESCAMBIA      40958  73029      504\nFLAGLER       13891  12608       83\nFRANKLIN       2042   2448       33\nGADSDEN        9565   4750       39\nGILCHRIST      1910   3300       29\nGLADES         1420   1840        9\nGULF           2389   3546       71\nHAMILTON       1718   2153       24\nHARDEE         2341   3764       30\nHENDRY         3239   4743       22\nHERNANDO      32644  30646      242\nHIGHLANDS     14152  20196       99\nHILLSBOROUGH 166581 176967      836\nHOLMES         2154   4985       76\nINDIAN RIVER  19769  28627      105\nJACKSON        6868   9138      102\nJEFFERSON      3038   2481       29\nLAFAYETTE       788   1669       10\nLAKE          36555  49963      289\nLEE           73560 106141      305\nLEON          61425  39053      282\nLEVY           5403   6860       67\nLIBERTY        1011   1316       39\nMADISON        3011   3038       29\nMANATEE       49169  57948      272\nMARION        44648  55135      563\nMARTIN        26619  33864      108\nMONROE        16483  16059       47\nNASSAU         6952  16404       90\nOKALOOSA      16924  52043      267\nOKEECHOBEE     4588   5058       43\nORANGE       140115 134476      446\nOSCEOLA       28177  26216      145\nPALM BEACH   268945 152846     3407\nPASCO         69550  68581      570\nPINELLAS     199660 184312     1010\nPOLK          74977  90101      538\nPUTNAM        12091  13439      147\nST. JOHNS     19482  39497      229\nST. LUCIE     41559  34705      124\nSANTA ROSA    12795  36248      311\nSARASOTA      72854  83100      305\nSEMINOLE      58888  75293      194\nSUMTER         9634  12126      114\nSUWANNEE       4084   8014      108\nTAYLOR         2647   4051       27\nUNION          1399   2326       26\nVOLUSIA       97063  82214      396\nWAKULLA        3835   4511       46\nWALTON         5637  12176      120\nWASHINGTON     2796   4983       88\n```\n:::\n\n```{.r .cell-code}\nlm_florida <- lm(Buchanan ~ Bush, data = florida)\nsummary(lm_florida)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Buchanan ~ Bush, data = florida)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-907.50  -46.10  -29.19   12.26 2610.19 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 4.529e+01  5.448e+01   0.831    0.409    \nBush        4.917e-03  7.644e-04   6.432 1.73e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 353.9 on 65 degrees of freedom\nMultiple R-squared:  0.3889,\tAdjusted R-squared:  0.3795 \nF-statistic: 41.37 on 1 and 65 DF,  p-value: 1.727e-08\n```\n:::\n\n```{.r .cell-code}\nplot(lm_florida,which=1)\n```\n\n::: {.cell-output-display}\n![](Homework5_AlexaPotter_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(lm_florida,which=2)\n```\n\n::: {.cell-output-display}\n![](Homework5_AlexaPotter_files/figure-html/unnamed-chunk-9-2.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(lm_florida,which=3)\n```\n\n::: {.cell-output-display}\n![](Homework5_AlexaPotter_files/figure-html/unnamed-chunk-9-3.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(lm_florida,which=4)\n```\n\n::: {.cell-output-display}\n![](Homework5_AlexaPotter_files/figure-html/unnamed-chunk-9-4.png){width=672}\n:::\n:::\n\n\nPalm Beach does appear to be an outlier in all the diagnostic plots as it is furthest away from the red baselines. In the Cook's distance plot, the 4/n is 4/67 = 0.0597, which both Dade and Palm Beach exceed. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n4/67\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.05970149\n```\n:::\n:::\n\n\n\n## B  \n\nTake the log of both variables (Bush vote and Buchanan Vote) and repeat the analysis in  (A.) Does your findings change?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm_floridalog <- lm((log(Buchanan)) ~ (log(Bush)), data = florida)\nsummary(lm_floridalog)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = (log(Buchanan)) ~ (log(Bush)), data = florida)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.96075 -0.25949  0.01282  0.23826  1.66564 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -2.57712    0.38919  -6.622 8.04e-09 ***\nlog(Bush)    0.75772    0.03936  19.251  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4673 on 65 degrees of freedom\nMultiple R-squared:  0.8508,\tAdjusted R-squared:  0.8485 \nF-statistic: 370.6 on 1 and 65 DF,  p-value: < 2.2e-16\n```\n:::\n\n```{.r .cell-code}\nplot(lm_floridalog,which=1)\n```\n\n::: {.cell-output-display}\n![](Homework5_AlexaPotter_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(lm_floridalog,which=2)\n```\n\n::: {.cell-output-display}\n![](Homework5_AlexaPotter_files/figure-html/unnamed-chunk-11-2.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(lm_floridalog,which=3)\n```\n\n::: {.cell-output-display}\n![](Homework5_AlexaPotter_files/figure-html/unnamed-chunk-11-3.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(lm_floridalog,which=4)\n```\n\n::: {.cell-output-display}\n![](Homework5_AlexaPotter_files/figure-html/unnamed-chunk-11-4.png){width=672}\n:::\n:::\n\n\nThe results here are similar, but less drastic in difference when it comes to Palm Beach. In the Cook's Distance plot, it's also now apparent that other counties also violate the assumption. \n",
    "supporting": [
      "Homework5_AlexaPotter_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}