{
  "hash": "770f0abe7118a50b6a56481e1accbb3f",
  "result": {
    "markdown": "---\ntitle: \"DACSS 603 Homework 4\"\nauthor: \"Laura Collazo\"\ndescription: \"Homework 4 for DACSS 603\"\ndate: \"04/18/2023\"\nformat:\n  html:\n    toc: true\n    code-fold: true\n    code-copy: true\n    code-tools: true\ncategories:\n  - hw4\n  - regression\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(alr4)\nlibrary(smss)\n```\n:::\n\n\n# Question 1\n\nFor this question the prediction equation is `Price = -10,536 + 53.8HomeSize + 2.84LotSize`.\n\n## a\n\nWhen HomeSize = 1240 and LotSize= 18,000, the predicted Price is:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsum(-10,536 + (53.8*1240) + (2.84*1800))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 72350\n```\n:::\n:::\n\n\nSince this home actually sold for $145,000, the residual is:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsum(72350-145000)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -72650\n```\n:::\n:::\n\n\n## b\n\nWhen the lot size remains fixed, the price is predicted to increase $53.80 for every one-square foot increase in size.\n\n## c\n\nGiven this same equation, if home size remains fixed, the lot size would need to increase by the below in order to have the same impact on price as a one-square foot increase in home size:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsum(53.8/2.84)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 18.94366\n```\n:::\n:::\n\n\n# Question 2 \n\nThis question uses the \"salary\" data from the alr4 package to examine salary and characteristics of faculty in the early 1980s at a small Mid-West college. \n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(\"salary\")\n```\n:::\n\n\n## a\n\nThe below tests the hypothesis that mean salary for men and women is the same.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_2a <- lm(salary ~ sex, data = salary)\n\nsummary(fit_2a)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = salary ~ sex, data = salary)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8602.8 -4296.6  -100.8  3513.1 16687.9 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    24697        938  26.330   <2e-16 ***\nsexFemale      -3340       1808  -1.847   0.0706 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5782 on 50 degrees of freedom\nMultiple R-squared:  0.0639,\tAdjusted R-squared:  0.04518 \nF-statistic: 3.413 on 1 and 50 DF,  p-value: 0.0706\n```\n:::\n:::\n\nThis model does not allow the null hypothesis to be rejected as the p-value is not less than 0.05. The adjusted R-squared is also low and indicates this model explains only 4.52% of the variation between `salary` and `sex`. This model also shows that being female results in being paid $3,340 less per year than male faculty.\n\n## b\n\nThe below model adds in `degree`, `rank`, `year`, and `ysdeg` as additional predictors to the regression model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_2b <- lm(salary ~ sex + degree + rank + year + ysdeg, data = salary)\n\nsummary(fit_2b)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = salary ~ sex + degree + rank + year + ysdeg, data = salary)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4045.2 -1094.7  -361.5   813.2  9193.1 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 15746.05     800.18  19.678  < 2e-16 ***\nsexFemale    1166.37     925.57   1.260    0.214    \ndegreePhD    1388.61    1018.75   1.363    0.180    \nrankAssoc    5292.36    1145.40   4.621 3.22e-05 ***\nrankProf    11118.76    1351.77   8.225 1.62e-10 ***\nyear          476.31      94.91   5.018 8.65e-06 ***\nysdeg        -124.57      77.49  -1.608    0.115    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2398 on 45 degrees of freedom\nMultiple R-squared:  0.855,\tAdjusted R-squared:  0.8357 \nF-statistic: 44.24 on 6 and 45 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\nThe 95% confidence interval for the difference in salary between males and females is below.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nconfint(fit_2b)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                 2.5 %      97.5 %\n(Intercept) 14134.4059 17357.68946\nsexFemale    -697.8183  3030.56452\ndegreePhD    -663.2482  3440.47485\nrankAssoc    2985.4107  7599.31080\nrankProf     8396.1546 13841.37340\nyear          285.1433   667.47476\nysdeg        -280.6397    31.49105\n```\n:::\n:::\n\n\n## c\n\nThis section interprets the findings for each predictor variable in the above model.\n\n### sex \n\nThe variable `sex` is not statistically significant in this model. It indicates that when all predictors are held constant, females are paid $1,166.37 more per year more than males.\n\n### degree\n\nThe variable `degree` is not statistically significant in this model. It indicates that when all predictors are held constant, those with a PhD earn $1,388.61 more than those with a Master's.\n\n### rank\n\nThe variable `rank` is statistically significant in this model. It indicates that when all predictors are held constant, faculty with a title of Assoc earn $5,292.36 more per year than those with a title of Asst and those with a title of Prof earn $11,118.76 more per year than those with a title of Prof.\n\n### year\n\nThe variable `year` is statistically significant in this model. It indicates that when all predictors are held constant, for every year increase in faculty's current rank, salary increases by $476.31.\n\n### ysdeg\n\nThe variable `ysdeg` is not statistically significant in this model. It indicates that when all predictors are held constant, for every year increase since the highest degree was earned, salary decreases by -$124.57.\n\n## d\n\nBelow the model is updated so that the baseline category for `rank` is \"Prof.\"\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsalary$rank <- relevel(salary$rank, ref = \"Prof\")\n\nfit_2d <- lm(salary ~ sex + degree + rank + year + ysdeg, data = salary)\n\nsummary(fit_2d)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = salary ~ sex + degree + rank + year + ysdeg, data = salary)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4045.2 -1094.7  -361.5   813.2  9193.1 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  26864.81    1375.29  19.534  < 2e-16 ***\nsexFemale     1166.37     925.57   1.260    0.214    \ndegreePhD     1388.61    1018.75   1.363    0.180    \nrankAsst    -11118.76    1351.77  -8.225 1.62e-10 ***\nrankAssoc    -5826.40    1012.93  -5.752 7.28e-07 ***\nyear           476.31      94.91   5.018 8.65e-06 ***\nysdeg         -124.57      77.49  -1.608    0.115    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2398 on 45 degrees of freedom\nMultiple R-squared:  0.855,\tAdjusted R-squared:  0.8357 \nF-statistic: 44.24 on 6 and 45 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\nThis change to the model does not affect its fit or the coefficients. Notice that rankAsst shows a decrease of -$11,118.76 in salary whereas in the previous model rankProf was an increase of $11,118.76 in salary.\n\n## e\n\nThis next model removes the variable `rank` from the model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_2e <- lm(salary ~ sex + degree + year + ysdeg, data = salary)\n\nsummary(fit_2e)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = salary ~ sex + degree + year + ysdeg, data = salary)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8146.9 -2186.9  -491.5  2279.1 11186.6 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 17183.57    1147.94  14.969  < 2e-16 ***\nsexFemale   -1286.54    1313.09  -0.980 0.332209    \ndegreePhD   -3299.35    1302.52  -2.533 0.014704 *  \nyear          351.97     142.48   2.470 0.017185 *  \nysdeg         339.40      80.62   4.210 0.000114 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3744 on 47 degrees of freedom\nMultiple R-squared:  0.6312,\tAdjusted R-squared:  0.5998 \nF-statistic: 20.11 on 4 and 47 DF,  p-value: 1.048e-09\n```\n:::\n:::\n\nRemoving `rank` leads to `ysdeg` and `degree` now being statistically significant in the model. However, the adjusted R-square is lower than in the previous 2 models and the residual standard error is greater making this model not the best fit.  \n\n## f\n\nThis final model creates a new variable `new_hire` using `ysdeg`. Those who were hired within 15 years or less were coded as 1 and everyone else 0. To avoid multicollinearity, the variable year was removed from the model. This is because it's possible the years in faculty's current rank are the same as years since the highest degree was earned (or in other words, years since hired). \n\n\n::: {.cell}\n\n```{.r .cell-code}\nsalary$new_hire <- ifelse(salary$ysdeg <= 15, 1, 0)\n\nfit_2f <- lm(salary ~ sex + degree + new_hire, data = salary)\n\nsummary(fit_2f)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = salary ~ sex + degree + new_hire, data = salary)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8260.4 -3557.7  -462.6  3563.2 12098.5 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    28663       1155  24.821  < 2e-16 ***\nsexFemale      -2716       1433  -1.896    0.064 .  \ndegreePhD      -1227       1372  -0.895    0.375    \nnew_hire       -7418       1306  -5.679 7.74e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4558 on 48 degrees of freedom\nMultiple R-squared:  0.4416,\tAdjusted R-squared:  0.4067 \nF-statistic: 12.65 on 3 and 48 DF,  p-value: 3.231e-06\n```\n:::\n:::\n\nThis model shows the null hypothesis should be rejected and indicates that faculty hired by the new dean are actually making a lower salary than those who were hired more than 15 years ago. \n\n# Question 3\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(\"house.selling.price\")\n```\n:::\n\n\nThis questions uses the dataset house.selling.price from the package smss. \n\n## a\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_3a <- lm(Price ~ Size + New, data = house.selling.price)\n\nsummary(fit_3a)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Price ~ Size + New, data = house.selling.price)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-205102  -34374   -5778   18929  163866 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -40230.867  14696.140  -2.738  0.00737 ** \nSize           116.132      8.795  13.204  < 2e-16 ***\nNew          57736.283  18653.041   3.095  0.00257 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 53880 on 97 degrees of freedom\nMultiple R-squared:  0.7226,\tAdjusted R-squared:  0.7169 \nF-statistic: 126.3 on 2 and 97 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\nThis first model examines how the size of a house and being new or not influences price. It reveals the variables are statistically significant. Furthermore, we learn that a 1 unit change in size leads to a $116.13 increase in price and when a house is new, it will cost $57,736.28 more than a house that is old when the size is held constant. \n\n## b\n\nThe equation for the predicted selling price when the home is new is: `price = -40230.867 + 116.132Size + 57736.283New`\n\n\n::: {.cell}\n\n:::\n\n\n## c\n\nThe predicted selling price for a home of 3000 square feed that is new is below.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_new <- data.frame(Size = 3000, New = 1)\n\npredict(fit_3a, newdata = df_new)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       1 \n365900.2 \n```\n:::\n:::\n\n\nThe predicted selling price for a home of 3000 square feed that is not new is below.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_not_new <- data.frame(Size = 3000, New = 0)\n\npredict(fit_3a, newdata = df_not_new)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       1 \n308163.9 \n```\n:::\n:::\n\n\n## d\n\nThe next model includes an interaction term between size and new.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_3d <- lm(Price ~ Size * New, data = house.selling.price)\n\nsummary(fit_3d)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Price ~ Size * New, data = house.selling.price)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-175748  -28979   -6260   14693  192519 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -22227.808  15521.110  -1.432  0.15536    \nSize           104.438      9.424  11.082  < 2e-16 ***\nNew         -78527.502  51007.642  -1.540  0.12697    \nSize:New        61.916     21.686   2.855  0.00527 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 52000 on 96 degrees of freedom\nMultiple R-squared:  0.7443,\tAdjusted R-squared:  0.7363 \nF-statistic: 93.15 on 3 and 96 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\n## e\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(house.selling.price,aes(y=Price,x=Size,color=factor(New)))+\n  geom_point()+\n  stat_smooth(method=\"lm\",se=TRUE)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](dacss603hw4_LauraCollazo_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\n## f\n\nThe predicted selling price, using the model with interaction terms, for a home of 3000 square feed that is new is below.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npredict(fit_3d, newdata = df_new)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       1 \n398307.5 \n```\n:::\n:::\n\n\nThe predicted selling price, using the model with interaction terms, for a home of 3000 square feed that is not new is below.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npredict(fit_3d, newdata = df_not_new)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       1 \n291087.4 \n```\n:::\n:::\n\n\n## g\n\n\nThe predicted selling price, using the model with interaction terms, for a home of 1500 square feed that is new is below.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_new <- data.frame(Size = 1500, New = 1)\n\npredict(fit_3d, newdata = df_new)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       1 \n148776.1 \n```\n:::\n:::\n\n\nThe predicted selling price, using the model with interaction terms, for a home of 1500 square feed that is not new is below.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_not_new <- data.frame(Size = 1500, New = 0)\n\npredict(fit_3d, newdata = df_not_new)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       1 \n134429.8 \n```\n:::\n:::\n\n\nIn comparing the predictions for part F and G, it can be observed that the difference in selling price between a new and not new home increases as the the size of the home increases.\n\n## h\n\nI believe the model with the interaction term best represents the relationship of size and new to the outcome price. I've come to this conclusion as the model with the interaction term has a higher adjusted R-squared and lower residual standard error than the model without the interaction term.\n\n\n",
    "supporting": [
      "dacss603hw4_LauraCollazo_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}