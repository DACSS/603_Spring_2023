{
  "hash": "d51874d71af2dea5a108c7e0ec9c5f14",
  "result": {
    "markdown": "---\ntitle: \"Blog Post #2\"\nauthor: \"Alexis Gamez\"\ndescription: \"DACSS 603 HW#2\"\ndate: \"03/26/2023\"\nformat:\n  html:\n    toc: true\n    code-fold: true\n    code-copy: true\n    code-tools: true\ncategories:\n  - hw2\n  - probability distributions\n  - hypothesis testing\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\nknitr::opts_chunk$set(echo = TRUE)\n```\n:::\n\n\n# Question 1\n\n**The time between the date a patient was recommended for heart surgery and the surgery date for cardiac patients in Ontario was collected by the Cardiac Care Network (“Wait Times Data Guide,” Ministry of Health and Long-Term Care, Ontario, Canada, 2006). The sample mean and sample standard deviation for wait times (in days) of patients for two cardiac procedures are given in the accompanying table. Assume that the sample is representative of the Ontario population**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nProcedure <- c('Bypass', 'Angiography')\nSample <- c(539,847)\nMean_WT <- c(19,18)\nSD <- c(10,9)\n\nProcedure_df <- data.frame(Procedure, Sample, Mean_WT, SD)\n\nprint(Procedure_df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    Procedure Sample Mean_WT SD\n1      Bypass    539      19 10\n2 Angiography    847      18  9\n```\n:::\n:::\n\n\n**Construct the 90% confidence interval to estimate the actual mean wait time for each of the two procedures. Is the confidence interval narrower for angiography or bypass surgery?**\n\nStandard Error is calculated using the following equation.\n\n*SE = SD/sqrt(sample size)*\n\nOur first step will be to use this equation to calculate the standard error for both procedures and afterwards, set the confidence interval to 90%.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nSE_By <- 10/sqrt(539)\nSE_An <- 9/sqrt(847)\n\nConf_Int <- 0.90\n```\n:::\n\n\nNow that we have our standard error, we designate the tail area of our confidence interval using the following equation.\n\n*Tail Area = (1 - Confidence Interval)/2*\n\nWith that Tail Area calculated we can use all our new found variables to construct the confidence interval values we're looking for. We use the student t distribution function to calculate the t-scores for each procedure. From there, we can take into account all our new found values to calculate the confidence intervals.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntail <- (1-Conf_Int)/2\n\nt_By <- qt(p = 1-tail, df = 539-1)\nt_An <- qt(p = 1-tail, df = 847-1)\n\nCI_By <- c(19 - t_By * SE_By,\n       19 + t_By * SE_By)\n\nCI_An <- c(18 - t_An * SE_An,\n        18 + t_An * SE_An)\n\nCI <- c('X1', 'X2')\nBypass <- c(CI_By)\nAngiography <- c(CI_An)\n\nCI_df <- data.frame(CI, Bypass, Angiography)\n\nprint(CI_df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  CI   Bypass Angiography\n1 X1 18.29029    17.49078\n2 X2 19.70971    18.50922\n```\n:::\n:::\n\n\nFrom our visualization here we can see that the confidence interval for the Angiography procedure is more narrow than that for the Bypass procedure.\n\n# Question 2\n\n**A survey of 1031 adult Americans was carried out by the National Center for Public Policy. Assume that the sample is representative of adult Americans. Among those surveyed, 567 believed that college education is essential for success. Find the point estimate, p, of the proportion of all adult Americans who believe that a college education is essential for success. Construct and interpret a 95% confidence interval for p.**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nSurvey <- c('Adults')\nSample <- c(1031)\nEssential <- (567)\nOther <- (1031-567)\n\nSurvey_df <- data.frame(Survey, Sample, Essential, Other)\n\nprint(Survey_df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  Survey Sample Essential Other\n1 Adults   1031       567   464\n```\n:::\n:::\n\n\nThankfully, we can simply run a `prop.test` to construct the 95% confidence interval while simultaneously calculating our point estimate.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprop.test(Essential, Sample, conf.level = 0.95)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\t1-sample proportions test with continuity correction\n\ndata:  Essential out of Sample, null probability 0.5\nX-squared = 10.091, df = 1, p-value = 0.00149\nalternative hypothesis: true p is not equal to 0.5\n95 percent confidence interval:\n 0.5189682 0.5805580\nsample estimates:\n        p \n0.5499515 \n```\n:::\n:::\n\n\nWe can see that the point estimate of the proportion of all adult Americans who believe that a college education is essential for success is located at the 54.99% point in our data frame.\n\nThe results from our test also shows us that 95% of calculated confidence intervals would reflect the true percentage of the sample that believe college education is essential between 51.89-58.05% of the time. \n\n# Question 3\n\n**Suppose that the financial aid office of UMass Amherst seeks to estimate the mean cost of textbooks per semester for students. The estimate will be useful if it is within $5 of the true population mean (i.e. they want the confidence interval to have a length of $10 or less). The financial aid office is pretty sure that the amount spent on books varies widely, with most values between $30 and $200. They think that the population standard deviation is about a quarter of this range (in other words, you can assume they know the population standard deviation). Assuming the significance level to be 5%, what should be the size of the sample**\n\nBreaking it down, we need to calculate the sample size(n) using the z-value for a significance level of 5%. Knowing this we can use the Confidence Interval equation that utilizes z-value and restructure it to calculate the n value we seek.\n\n*Confidence Interval = (X bar) ± (z × s/sqrt(n))*\n\nRestructured turns into:\n\n*n = ((z x Standard Deviation)/Margin of Error)^2*\n\nBefore we can calculate n, we need to find the corresponding z-value and standard deviation. We already know that the z-value of 95% confidence interval is 1.96 and we can use the range and estimate provided to calculate a relatively accurate standard deviation.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nz <- 1.96\n\nSD <- (200-30)/4\n```\n:::\n\n\nWith these calculated, we can plug the values back in to our n equation to receive the necessary sample size.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn <- ((z*SD)/5)^2\nprint(n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 277.5556\n```\n:::\n:::\n\n\nAccording to our calculations, the required sample size would be 278 students.\n\n# Question 4\n\n**According to a union agreement, the mean income for all senior-level workers in a large service company equals $500 per week. A representative of a women's group decides to analyze whether the mean income μ for female employees matches this norm. For a random sample of nine female employees, ȳ = $410 and s = 90**\n\n## A)\n\n**Test whether the mean income of female employees differs from $500 per week. Include assumptions, hypotheses, test statistic, and P-value. Interpret the result.**\n\nAssumptions:\n\n* The sample provided is randomly selected and representative of the population\n* Population is normally distributed\n* The variance of both populations are equal\n\nNull Hypothesis(H0): μ = 500 \n\nAlternative Hypothesis(HA): μ ≠ 500\n\nt-test Formula:\n*t = (Y bar - μ)/(Standard Deviation/sqrt(n))*\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt <- (410-500)/(90/sqrt(9))\nt\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -3\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\np <- 2*pt(t, 9-1)\np\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.01707168\n```\n:::\n:::\n\n\nThe test statistic and p-value we receive are equal to -3 and 0.0171 respectively. Because our p-value < 0.05, we are able to reject the null hypothesis meaning that the mean income of female employees differs from $500 per week. \n\n## B)\n\n**Report the P-value for Ha: μ < 500. Interpret.**\n\nHere we're being asked to calculate a one sided p-value where the alternative hypothesis is that μ < 500. In order to calculate said p-value, we must specify within our function that we will be look at the lower tail of the data.\n\nH0: μ >= 500 \n\nHA: μ < 500 \n\n\n::: {.cell}\n\n```{.r .cell-code}\np1 <- pt(t, 9-1, lower.tail = T)\np1\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.008535841\n```\n:::\n:::\n\n\nBeing provided such a small p-value tells us that we are able to reject the null hypothesis and embrace the alternative that mean female income within the population is less than $500 per week.\n\n## C)\n\n**Report and interpret the P-value for Ha: μ > 500.**\n*(Hint: The P-values for the two possible one-sided tests must sum to 1.)*\n\nHere, we'll be functionally doing the same thing as in part b, but instead of using the lower tail we'll be focusing on the upper. Under these circumstances, we'll be adopting the following hypothesis.\n\nH0: μ =< 500 \n\nHA: μ > 500 \n\n\n::: {.cell}\n\n```{.r .cell-code}\np2 <- pt(t, 9-1, lower.tail = F)\np2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.9914642\n```\n:::\n:::\n\n\nIn this case, we receive a p-value > 0.05 meaning that we fail to reject the null and that the mean female income within the population is not greater than $500.\n\n# Question 5\n\n**Jones and Smith separately conduct studies to test H0: μ = 500 against Ha: μ ≠ 500, each with n = 1000. Jones gets ȳ = 519.5, with se = 10.0. Smith gets ȳ = 519.7, with se = 10.0.**\n\n## A)\n\n**Show that t = 1.95 and P-value = 0.051 for Jones. Show that t = 1.97 and P-value = 0.049 for Smith.**\n\nt-test Formula:\n*t = (Y bar - μ)/Standard Error*\n\n### Jones\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntJones <- (519.5-500)/10\ntJones\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1.95\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npJones <- 2*pt(tJones, 1000-1, lower.tail = F)\npJones\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.05145555\n```\n:::\n:::\n\n\n### Smith\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntSmith <- (519.7-500)/10\ntSmith\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1.97\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npSmith <- 2*pt(tSmith, 1000-1, lower.tail = F)\npSmith\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.04911426\n```\n:::\n:::\n\n\n## B)\n\n**Using α = 0.05, for each study indicate whether the result is “statistically significant.”**\n\nAlpha(α) is the level at which a result is considered statistically significant or not. \n\nWith our significance level defined, we know that `pJones`, sitting at  0.051, would not be considered statistically significant and we fail to reject the null (μ = 500). On the other hand, `pSmith` (0.049)\nwould be considered statistically significant resulting in our ability to reject the null (μ ≠ 500).\n\n## C)\n\n**Using this example, explain the misleading aspects of reporting the result of a test as “P ≤ 0.05” versus “P > 0.05,” or as “reject H0” versus “Do not reject H0,” without reporting the actual P-value.**\n\nStatistical significance is something that must be well defined prior to the gathering and analyzing data. The term holds weight in the credibility of research and analysis and without it being clearly defined, it's uncertain whether or not the work that was done truly holds up and proves anything. Not reporting the actual P-values could lead to confusion and misinterpretation down the road. This makes it important to begin every varying analysis with the a clear definition of hypothesis and significance level.\n\n# Question 6\n\n**A school nurse wants to determine whether age is a factor in whether children choose a healthy snack after school. She conducts a survey of 300 middle school students, with the results below. Test at α = 0.05 the claim that the proportion who choose a healthy snack differs by grade level. What is the null hypothesis? Which test should we use? What is the conclusion?**\n\nn = 300\n\nα = 0.05\n\nH0: The proportion of students who choose a healthy snack *is not* affected by grade level. \n\nHA: The proportion of students who choose a healthy snack *is* affected by grade level.\n\nThe variables that we'll be utilizing in this analysis are both categorical, meaning we'll complete our analysis using a Chi-Squared test. We can start out by reading in the data we've received, in matrix form so that it's suited for the the Chi-Squared function.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nGrade_df <- matrix(c(31, 43, 51, 69, 57, 49), nrow = 2, byrow = TRUE)\n\n# Row and column names\nrownames(Grade_df) <- c(\"Healthy snack\", \"Unhealthy snack\")\ncolnames(Grade_df) <- c(\"6th grade\", \"7th grade\", \"8th grade\")\n\nprint(Grade_df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                6th grade 7th grade 8th grade\nHealthy snack          31        43        51\nUnhealthy snack        69        57        49\n```\n:::\n:::\n\n\nWith our matrix defined, we can plug it into the `chisq.test()` function.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchisq.test(Grade_df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tPearson's Chi-squared test\n\ndata:  Grade_df\nX-squared = 8.3383, df = 2, p-value = 0.01547\n```\n:::\n:::\n\n\nGiven our significance level is set to 0.05, the p-value we've received from our analysis shows that our results are indeed statistically significant meaning we can reject the null. Under these circumstances, the proportion of students who choose a healthy snack *is* affected by grade level.\n\n# Question 7\n\n**Per-pupil costs (in thousands of dollars) for cyber charter school tuition for school districts in three areas are shown. Test the claim that there is a difference in means for the three areas, using an appropriate test. What is the null hypothesis? Which test should we use? What is the conclusion?**\n\nH0: The 3 districts have *equal* average tuition\n\nHA: The 3 districts have *non-equal* average tuition\n\nIn this case, because we are comparing 3 separate mean values, we will be using an Anova test. The first step would be to read in our data into a data frame reflective of the figure we were provided.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nArea1 <- c(6.2, 9.3, 6.8, 6.1, 6.7, 7.5)\nArea2 <- c(7.5, 8.2, 8.5, 8.2, 7.0, 9.3)\nArea3 <- c(5.8, 6.4, 5.6, 7.1, 3.0, 3.5)\n\nArea_df <- data.frame(Area1, Area2, Area3)\nArea_anova_df <- pivot_longer(Area_df, c(Area1, Area2, Area3), names_to = \"Area\", values_to = \"tuition\")\n\nprint(Area_anova_df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 18 × 2\n   Area  tuition\n   <chr>   <dbl>\n 1 Area1     6.2\n 2 Area2     7.5\n 3 Area3     5.8\n 4 Area1     9.3\n 5 Area2     8.2\n 6 Area3     6.4\n 7 Area1     6.8\n 8 Area2     8.5\n 9 Area3     5.6\n10 Area1     6.1\n11 Area2     8.2\n12 Area3     7.1\n13 Area1     6.7\n14 Area2     7  \n15 Area3     3  \n16 Area1     7.5\n17 Area2     9.3\n18 Area3     3.5\n```\n:::\n:::\n\n\nWith the last function in the code chunk above, we've created a data frame capable of being utilized in the Anova function `aov()`. We can use this function to test the hypothesis we've previously defined.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nArea_aov <- aov(tuition ~ Area, data = Area_anova_df)\nsummary(Area_aov)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n            Df Sum Sq Mean Sq F value  Pr(>F)   \nArea         2  25.66  12.832   8.176 0.00397 **\nResiduals   15  23.54   1.569                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\nOur new p-value is equal to 0.00397. Given that result, we are capable of rejecting the null up to a significance level of 0.01 or α = 0.01 meaning that mean tuition varies in at least one of the 3 schools.  \n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}