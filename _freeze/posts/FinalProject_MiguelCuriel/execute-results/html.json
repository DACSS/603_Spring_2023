{
  "hash": "20825b84549ddedc94de774a6d95ebe0",
  "result": {
    "markdown": "---\ntitle: \"Final Project Write Up\"\nauthor: \"Miguel Curiel\"\ndescription: \"Mental Health Among Workers in the Tech Industry\"\ndate: \"05/20/2023\"\nformat:\n  html:\n    toc: true\n    code-fold: true\n    code-copy: true\n    code-tools: true\ncategories:\n  - final project\n  - mental health\n  - tech industry\n---\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# load neccesary packages\nlibrary(tidyverse) # used for elementary data wrangling and visualization\nlibrary(naniar) # used for missing values visualization\nlibrary(summarytools) # used for table summarizing descriptive statistics\nlibrary(corrplot) # used for correlation plots\nlibrary(ggridges) # used for joint plots\nlibrary(boot) # used for the PRESS statistic\nlibrary(knitr) # used for table with statistics\n```\n:::\n\n\n# Introduction\n\nThis project is part of University of Massachusetts (UMass) Amherst Data Analytics and Computational Social Science (DACSS) Master's program. Specifically, this is a final project for the Introduction to Quantitative Analysis class and will focus on **analyzing the state of mental health among workers in the technology industry** - aka tech - which has been one of the highest employers in the twenty-first century. Not only that, but it has been praised for having some of the happiest workers[^1] [^2].\n\n[^1]: Fox, M. (2016, November 11). *Why Are Tech Workers So Satisfied With Their Jobs?* Retrieved March 17, 2023, from https://www.forbes.com/sites/meimeifox/2016/11/11/why-are-tech-workers-so-satisfied-with-their-jobs/?sh=4eac1918a059\n\n[^2]: Wronski, L., & Cohen, J. (2019, November 4). *This is the industry sector that has some of the happiest workers in America*. Retrieved March 17, 2023, from https://www.cnbc.com/2019/11/04/this-is-the-industry-that-has-some-of-the-happiness-workers-in-america.html\n\nWhat has made the tech industry so appealing? A case study on Google published in the International Journal of Corporate Social Responsibility in 2017[^3] points to several elements that make high-tech unique, such as having a distinct culture proposition, aligning individual behaviors to company-wide goals, having managers be coaches rather than bosses, and being able to interact with people from other cultures.\n\n[^3]: Kim, K. T. (2017). GOOGLE: A reflection of culture, leader, and management. *International Journal of Corporate Social Responsibility*, *2*(10). https://doi.org/10.1186/s40991-017-0021-0\n\nEvidently, Google is one-in-a-million tech company, but there are certainly commonalities shared with smaller new tech (startup) companies. Culture Amp, a company focused on surveying employees in startups, elaborated an analysis based on their results from 2015-2020 surveys[^4] and mention that elements such as an open and honest two-way communication, workplace flexibility, and fair division of workload, are what make new tech companies valued.\n\n[^4]: McPherson, J. (n.d.). *Tech company cultures are not all the same*. Culture Amp. Retrieved March 17, 2023, from https://www.cultureamp.com/blog/tech-company-culture\n\nHowever, the previous data omits the downsides of such cultures. Besides the multiple blog posts and news articles one can find talking about burnout[^5], the darker side of tech also includes (but is not limited to) ageism[^6], gender inequality[^7] [^8], and even migration issues[^9] [^10].\n\n[^5]: Goncharov, A. (2023, March 13). *How I burnt out in FAANG, but my job was not the problem*. Blog.Goncharov.ai. Retrieved March 17, 2023, from https://blog.goncharov.ai/how-i-burnt-out-in-faang-but-my-job-was-not-the-problem\n\n[^6]: Rosales, A., & Jakob, S. (2021). Perceptions of age in contemporary tech. *Sciendo*, *42*(1), 79-91. https://doi.org/10.2478/nor-2021-0021\n\n[^7]: Mickey, E. L. (2021). The Organization of Networking and Gender Inequality in the New Economy: Evidence from the Tech Industry. *Work & Occupations*, *49*(4), 383-420. https://doi.org/10.1177/07308884221102134\n\n[^8]: Hardey, M. (2020). *The Culture of Women in Tech : An Unsuitable Job for a Woman* (1st ed.). Emerald Publishing.\n\n[^9]: Banerjee, P., & Rinc√≥n, L. (2019). Trouble in Tech Paradise. *Journal of Water Resources Planning & Management*, *145*(4), 24-29. https://doi.org/10.1177/1536504219854714\n\n[^10]: Matloff, N. (2013). Immigration and the tech industry: As a labour shortage remedy, for innovation, or for cost savings? *Migration Letters*, *10*(2), 210-227. ISSN: 1741-8984 Online ISSN: 1741-8992\n\nAdditionally, a survey lead by Blind in 2021[^11] found that, out of 2400 workers in tech, 64% said their mental health is worse after the pandemic. What's more, layoffs by the thousands, plummeting stock prices, and generalized revaluation of an entire industry's value, are just few words that can describe what has happened to tech in 2022 and 2023. An industry that once employed over 5 million people in the US alone[^12] and had nearly 700 billion dollars in funding worldwide[^13] has now laid off over 300 thousand people[^14] and nearly halved in funding.\n\n[^11]: Blind (2021, January 29). *Deteriorating Mental Health In The Workplace*. Retrieved March 17, 2023, from https://www.teamblind.com/blog/index.php/2021/01/29/deteriorating-mental-health-in-the-workplace/\n\n[^12]: The United States Bureau of Labor and Statistics via CompTIA (2023, March 3). *Cyberstates 2021: The Definitive Guide to the Tech Industry and Workforce*. Retrieved March 17, 2023, from https://www.comptia.org/content/tech-jobs-report\n\n[^13]: Crunchbase News. (2023, January 5). *Global VC Funding on a Slide since Q4 2022*. Retrieved March 17, 2023, from https://news.crunchbase.com/venture/global-vc-funding-slide-q4-2022\n\n[^14]: Layoffs.fyi. (n.d.). *Layoffs.fyi - Tracking all tech startup layoffs since COVID-19*. https://layoffs.fyi\n\n------------------------------------------------------------------------\n\n# Research Question\n\nIt is reasonable to hypothesize that the aforementioned events will take a toll on the workers of this industry, but what has been the actual mental health state of the actors involved?\n\n::: callout-tip\n## Research Question\n\nWhat is the trend in mental health issues among workers in the technology industry from 2017 to 2021, as measured by survey data, and what factors may contribute to these changes?\n:::\n\n------------------------------------------------------------------------\n\n# Hypotheses\n\nBased on the present research question, on previous studies, and on feedback received throughout this course, I have removed two null hypotheses (which were the counterpart of the alternative hypotheses). This has been enacted to strengthen the argument made in the analysis. Additionally, the independent variables have been reduced (leaving the rest of the variables as possible confounders).\n\n::: callout-tip\n## Hypotheses\n\n-   H1: There has been an increase in the prevalence of mental health issues among workers in the technology industry from 2017 to 2021.\n\n-   H2: The presence of mental health issues among workers in the technology industry from 2017 to 2021 is related to level of support provided by the employer.\n:::\n\n------------------------------------------------------------------------\n\n# Descriptive Statistics\n\nTo analyze the state of mental health and the contributing factors, I will rely on data provided by the Open Sourcing Mental Health (OSMH), specifically using their Mental Health in Tech Survey.\n\nOSMH[^15] is a non-profit dedicated to raising awareness, educating, and providing resources to support mental wellness in the tech and open source communities. It began operations in 2013 and since 2014 it has conducted and published an annual or bi-annual survey analyzing several mental health indicators.\n\n[^15]: Open Sourcing Mental Health (n.d.). *About OSMH*. Retrieved March 18, 2023, from https://osmhhelp.org/about/about-osmi.html\n\nAs of May 19, 2023, the 2022 survey has not yet been published. Therefore, this analysis employs historical data, specifically utilizing surveys conducted from 2017 through 2021. All datasets are publicly available on OSMH's [website](https://osmhhelp.org/research.html) or on [Kaggle](https://www.kaggle.com/osmihelp/datasets).\n\nBelow you can find the offline (Microsoft Excel) and online (R) preprocessing steps taken, as well as a snippet of the resulting dataframe. It is worth noting that the preprocessing includes converting certain variables (such as number of employees) to ordinal variables as well as creating an important net-new variable (which will be explained later on).\n\n::: {.callout-note collapse=\"true\"}\n## Offline edits made on the raw files\n\n-   A \"year\" column was added to differentiate between both files.\n\n-   Data pertaining to insurance information (e.g., \"Does you company provide a mental health insurance plan?\") was removed because in the 2019 it was optional and was, therefore, almost entirely blank.\n\n-   Both files contained columns pertaining to the mental disorder each respondent may or may not have. However, these columns were inconsistent and could not be interpreted without making assumptions which may lead to an incorrect interpretation of the data. For that reason, these columns were removed.\n\n-   The raw data files followed a title case naming convention (e.g., \"Does your employer provide mental health resources?\"). All column names were changed to a snake_case format (e.g., \"employer_provides_mental_health_resources\").\n\n-   The rest of the columns and data therein contained is left as is.\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## ONLINE EDITS MADE ON THE CONSOLIDATED FILE\n\n# temporarily set working directory to read in data\nsetwd(\"/Users/macuriels/Documents/Umass/umass_dacss_quantitativeanalysis/posts/_data\")\n\n# read in consolidated file with 2017-2021 data\ndf <- read_csv(\"mhit.csv\")\n\n# create new dataframe with columns of interest\ndf <- df |>\n  select(\n    year\n    ,has_mental_disorder\n    ,age\n    ,gender\n    ,willingness_to_share_with_friends\n    ,number_of_employees\n    ,company_provides_mhcare\n    ,easy_to_leave_for_mhcare\n    ,comfortable_talking_to_supervisor\n    ,employer_mh_importance\n    ,employer_offers_mhresources\n  )\n  \n  \n# leave only responses of interest within the dependent variable\ndf <- subset(df, has_mental_disorder %in% c(\"Yes\", \"No\"))\n\n# treating inconsistent gender naming conventions\ndf$gender <- ifelse(grepl(\"female\", df$gender, ignore.case = TRUE), \"NonMale\" \n                    ,ifelse(grepl(\"male\", df$gender, ignore.case = TRUE), \"Male\"\n                           ,\"NonMale\"))\n\n# order company size by employee count\ndf$number_of_employees <- factor(df$number_of_employees\n                                 , levels=c(\n                                   \"1-5\"\n                                   ,\"6-25\"\n                                   ,\"26-100\"\n                                   ,\"100-500\"\n                                   ,\"500-1000\"\n                                   ,\"More than 1000\"))\n\n# convert dependent variable to a factor\ndf$has_mental_disorder <- factor(df$has_mental_disorder)\n\n# convert some columns to numeric\ndf$age <- as.numeric(df$age)\ndf$willingness_to_share_with_friends <- as.numeric(df$willingness_to_share_with_friends)\n\n# remove respondents under 18\ndf <- df[df$age > 18,]\n\n# remove respondents over 90\ndf <- df[df$age < 90,]\n\n# remove rows with missing values\ndf <- df[complete.cases(df),]\n\n# remove columns with missing values\ndf <- df[,colSums(is.na(df)) == 0]\n\n# remove \"I don't know\" and \"Not eligible for coverage\" in column of interest\ndf <- subset(df, company_provides_mhcare != \"I don't know\" & company_provides_mhcare != \"Not eligible for coverage\")\n\n# remove \"I don't know\" from column of interest\ndf <- subset(df, employer_offers_mhresources != \"I don't know\")\n\n# temp calculation for employer_mh_importance variable\ndf$employer_mh_importance_calc <- as.numeric(df$employer_mh_importance) * 2\n\n# temp calculation for comfortable_talking_to_supervisor variable\n## use ifelse() to recode the values of the column\ndf$comfortable_talking_to_supervisor_calc <- as.numeric(ifelse(df$comfortable_talking_to_supervisor == \"Yes\", 1, ifelse(df$comfortable_talking_to_supervisor == \"No\", 0, 0.5))) * 20\n\n# temp calculation for employer_offers_mhresources variable\n## use ifelse() to recode the values of the column\ndf$employer_offers_mhresources_calc <- as.numeric(ifelse(df$employer_offers_mhresources == \"Yes\", 1, 0)) * 20\n\n# temp calculation for easy_to_leave_for_mhcare variable\n## convert easy to leave for mental health care to numerical categories\ndf$easy_to_leave_for_mhcare_calc <- as.numeric(\n  factor(\n    df$easy_to_leave_for_mhcare\n    ,levels = c(\n      \"Very easy\"\n      ,\"Somewhat easy\"\n      ,\"Neither easy nor difficult\"\n      ,\"I don't know\"\n      ,\"Somewhat difficult\"\n      ,\"Difficult\"\n      )\n    , labels = c(\n      20\n      ,15\n      ,10\n      ,10\n      ,5\n      ,0)))\n\n# temp calculation for company_provides_mhcare variable\ndf$company_provides_mhcare_calc <- as.numeric(ifelse(df$company_provides_mhcare == \"Yes\", 1, 0)) * 20\n  \n# create new dependent column\ndf$mh_support_factors <- rowSums(df[, c(\n  'employer_mh_importance_calc'\n  ,'easy_to_leave_for_mhcare_calc'\n  ,'company_provides_mhcare_calc'\n  ,'employer_offers_mhresources_calc'\n  ,'comfortable_talking_to_supervisor_calc'\n  )], na.rm = TRUE)\n\n# Remove temp columns that end in \"_calc\"\ndf <- select(df, -ends_with(\"_calc\"))\n\n# export resulting dataframe to csv\nwrite.csv(df, file = \"df.csv\")\n\n# Generate a random sample of the dataframe\nsample_df <- df %>% sample_n(5)\n\n# print a preview of the table using kable()\nsample_df %>%\n  head(5) %>%\n  kable()\n```\n\n::: {.cell-output-display}\n| year|has_mental_disorder | age|gender  | willingness_to_share_with_friends|number_of_employees |company_provides_mhcare |easy_to_leave_for_mhcare   |comfortable_talking_to_supervisor | employer_mh_importance|employer_offers_mhresources | mh_support_factors|\n|----:|:-------------------|---:|:-------|---------------------------------:|:-------------------|:-----------------------|:--------------------------|:---------------------------------|----------------------:|:---------------------------|------------------:|\n| 2020|Yes                 |  59|Male    |                                 9|26-100              |Yes                     |Neither easy nor difficult |Maybe                             |                      6|Yes                         |                 65|\n| 2019|No                  |  36|Male    |                                 8|More than 1000      |Yes                     |Very easy                  |Yes                               |                      8|Yes                         |                 77|\n| 2017|No                  |  32|Male    |                                 7|26-100              |No                      |Somewhat easy              |No                                |                      6|No                          |                 14|\n| 2018|Yes                 |  27|NonMale |                                 8|6-25                |Yes                     |Neither easy nor difficult |Maybe                             |                      3|No                          |                 39|\n| 2017|Yes                 |  38|Male    |                                10|More than 1000      |Yes                     |Very easy                  |Yes                               |                      4|No                          |                 49|\n:::\n:::\n\n\nTo close this section, below we will use the `dfSummary` function from the `summarytools` library to recap the distribution of responses across all columns of the dataframe:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## SUMMARY OF THE RESULTING DATAFRAME\ndfSummary(df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nData Frame Summary  \ndf  \nDimensions: 682 x 12  \nDuplicates: 0  \n\n---------------------------------------------------------------------------------------------------------------------------------------\nNo   Variable                            Stats / Values                 Freqs (% of Valid)   Graph                 Valid      Missing  \n---- ----------------------------------- ------------------------------ -------------------- --------------------- ---------- ---------\n1    year                                Mean (sd) : 2018.2 (1.3)       2017 : 284 (41.6%)   IIIIIIII              682        0        \n     [numeric]                           min < med < max:               2018 : 157 (23.0%)   IIII                  (100.0%)   (0.0%)   \n                                         2017 < 2018 < 2021             2019 : 129 (18.9%)   III                                       \n                                         IQR (CV) : 2 (0)               2020 :  55 ( 8.1%)   I                                         \n                                                                        2021 :  57 ( 8.4%)   I                                         \n\n2    has_mental_disorder                 1. No                          253 (37.1%)          IIIIIII               682        0        \n     [factor]                            2. Yes                         429 (62.9%)          IIIIIIIIIIII          (100.0%)   (0.0%)   \n\n3    age                                 Mean (sd) : 34.8 (8)           45 distinct values       :                 682        0        \n     [numeric]                           min < med < max:                                        : . .             (100.0%)   (0.0%)   \n                                         19 < 34 < 63                                          . : : :                                 \n                                         IQR (CV) : 11 (0.2)                                   : : : : : .                             \n                                                                                             : : : : : : : .                           \n\n4    gender                              1. Male                        358 (52.5%)          IIIIIIIIII            682        0        \n     [character]                         2. NonMale                     324 (47.5%)          IIIIIIIII             (100.0%)   (0.0%)   \n\n5    willingness_to_share_with_friends   Mean (sd) : 7 (2.7)            11 distinct values                     :   682        0        \n     [numeric]                           min < med < max:                                                  :   :   (100.0%)   (0.0%)   \n                                         0 < 8 < 10                                                  .   : : : :                       \n                                         IQR (CV) : 4 (0.4)                                          : . : : : :                       \n                                                                                             : : : : : : : : : :                       \n\n6    number_of_employees                 1. 1-5                          18 ( 2.6%)                                682        0        \n     [factor]                            2. 6-25                         91 (13.3%)          II                    (100.0%)   (0.0%)   \n                                         3. 26-100                      116 (17.0%)          III                                       \n                                         4. 100-500                     170 (24.9%)          IIII                                      \n                                         5. 500-1000                     53 ( 7.8%)          I                                         \n                                         6. More than 1000              234 (34.3%)          IIIIII                                    \n\n7    company_provides_mhcare             1. No                          139 (20.4%)          IIII                  682        0        \n     [character]                         2. Not eligible for coverage    35 ( 5.1%)          I                     (100.0%)   (0.0%)   \n                                         3. Yes                         508 (74.5%)          IIIIIIIIIIIIII                            \n\n8    easy_to_leave_for_mhcare            1. Difficult                    62 ( 9.1%)          I                     682        0        \n     [character]                         2. I don't know                102 (15.0%)          II                    (100.0%)   (0.0%)   \n                                         3. Neither easy nor difficul    82 (12.0%)          II                                        \n                                         4. Somewhat difficult           71 (10.4%)          II                                        \n                                         5. Somewhat easy               203 (29.8%)          IIIII                                     \n                                         6. Very easy                   162 (23.8%)          IIII                                      \n\n9    comfortable_talking_to_supervisor   1. Maybe                       202 (29.6%)          IIIII                 682        0        \n     [character]                         2. No                          197 (28.9%)          IIIII                 (100.0%)   (0.0%)   \n                                         3. Yes                         283 (41.5%)          IIIIIIII                                  \n\n10   employer_mh_importance              Mean (sd) : 5.2 (2.6)          11 distinct values           :             682        0        \n     [numeric]                           min < med < max:                                            :   .         (100.0%)   (0.0%)   \n                                         0 < 5 < 10                                          .       : . : :                           \n                                         IQR (CV) : 4 (0.5)                                  : : : : : : : :                           \n                                                                                             : : : : : : : : : :                       \n\n11   employer_offers_mhresources         1. No                          329 (48.2%)          IIIIIIIII             682        0        \n     [character]                         2. Yes                         353 (51.8%)          IIIIIIIIII            (100.0%)   (0.0%)   \n\n12   mh_support_factors                  Mean (sd) : 49.5 (22.2)        82 distinct values                 :       682        0        \n     [numeric]                           min < med < max:                                              : : :       (100.0%)   (0.0%)   \n                                         1 < 53 < 83                                             . . . : : :                           \n                                         IQR (CV) : 38 (0.4)                                 . . : : : : : :                           \n                                                                                             : : : : : : : : .                         \n---------------------------------------------------------------------------------------------------------------------------------------\n```\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n# Exploratory Data Analysis\n\nIn the following section, plots will be included to further explore and describe the dataset.\n\nStarting off with a plot visualizing the dependent variable distribution, we can see that we are dealing with a binary (categorical) variable where participants indicate whether they have mental disorders or not - and approximately 67% of them say they do have a mental disorder.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# bar plot of dependent variable\nggplot(data = data.frame(Category = names(table(df$has_mental_disorder))\n                         , Count = as.numeric(table(df$has_mental_disorder)))\n       , aes(x = Category, y = Count)) +\n  geom_bar(stat = \"identity\") +\n  labs(title = \"Participants with Mental Disorders\")\n```\n\n::: {.cell-output-display}\n![](FinalProject_MiguelCuriel_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\nNow we will visualize some of the main variables of interest. The first graph will show the number of responses by year divided by participants' mental health status. From the graph we can see that the responses decrease significantly year-over-year, but it also seems there are always more people that indicate they have mental disorders versus those that don't.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# create a contingency table of the data\ncont_tbl <- table(df$has_mental_disorder, df$year)\n\n# create a stacked bar chart\nbarplot(cont_tbl, beside = FALSE, legend.text = rownames(cont_tbl),\n        main = \"Mental Disorders by Year\",\n        xlab = \"Year\", ylab = \"Count\")\n```\n\n::: {.cell-output-display}\n![](FinalProject_MiguelCuriel_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\nThe plot below includes a variable that was not included in the survey, but rather was created in the preprocessing of the data. It is a variable called `mh_support_factors`, which is on a scale from 0-100, is created by adding five variables from the original surveys, and greater numbers indicate that participants believe their employers provide better mental health support (e.g., they provide mental health insurance, they feel supported by their managers, etcetera). The resulting distribution seems to be somewhat flat, with hints of it being bimodal becausea there is a spike at the lower end of the distribution and then another spik at the higher end of the distribution.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data = data.frame(Category = names(table(df$mh_support_factors))\n                         , Count = as.numeric(table(df$mh_support_factors)))\n       , aes(x = Category, y = Count)) +\n  geom_bar(stat = \"identity\") +\n  labs(title = \"Mental Health Support provided by the Employer\"\n       ,x = 'Level of Support') +\n  scale_x_discrete(breaks = seq(0, 100, 10))\n```\n\n::: {.cell-output-display}\n![](FinalProject_MiguelCuriel_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\nAnother interesting thing to observe is the age distribution. From the graphic below we can see that most respondents are in their mid-twenties to late-thirties (which makes sense as this industry is relatively new, it is usually associated with younger people, plus there are records of ageism in said industry).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# create a histogram of the \"age\" column\nhist(df$age\n     ,breaks = 100\n     ,xlab = \"Age\"\n     ,ylab = \"Frequency\"\n     ,main = \"Age Distribution\")\n```\n\n::: {.cell-output-display}\n![](FinalProject_MiguelCuriel_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\nLastly, we will plot the remaining variables of interest: gender, number of employees, and willingness to share their mental health status with friends. During the preprocessing, gender was divided into male and non-male (to capture sexism relationships) and we can see that their are slightly more males than non-males in the sample. From the number of employees, most respondents work at large enterprises (with more than 1000 employees). And from the willingness to share with friends, most respondents are highly willing (7-10 on a scale of 0-10) to share about their mental health status.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_long <- gather(df\n                  ,key = \"question\"\n                  ,value = \"response\"\n                  ,gender\n                  ,number_of_employees\n                  ,willingness_to_share_with_friends\n                  )\n\nggplot(df_long, aes(x = response, fill = question)) +\n  geom_bar() +\n  facet_wrap(~ question, scales = \"free_x\") +\n  labs(title = \"Remaining Variables of Interest\", x = \"Responses\", y = \"Count\") +\n  theme(strip.text = element_text(size = 6, face = \"bold\")\n        , strip.background = element_blank()\n        , panel.spacing = unit(0.2, \"cm\")\n        , axis.text.x = element_text(angle = 45, hjust = 1)) + \n  theme(axis.text = element_text(size = 6)) +\n  guides(fill = \"none\")\n```\n\n::: {.cell-output-display}\n![](FinalProject_MiguelCuriel_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n# Hypotheses Testing\n\nThe previous section already alluded to the variables of interest, which are as follows:\n\n::: callout-tip\n## Main Variables\n\n-   **DEPENDENT VARIABLE**\n\n    -   **has_mental_disorder:** Do you currently have a mental health disorder?\n\n-   **INDEPENDENT VARIABLES**\n\n    -   **year (for h1)**: In what year was the survey conducted?\n    -   **mh_support_factors (for h2):** A numerical variable (discrete) with values ranging from 0 to 100, where greater numbers indicate that participants perceive their employers provide more mental health support.\n:::\n\n::: callout-tip\n## Confounder Variables\n\n-   **CONFOUNDER VARIABLES**\n\n    -   **age:** What is your age?\n\n    -   **gender:** What is your gender?\n\n    -   **willingness_to_share_with_friends:** How willing would you be to share with friends and family that you have a mental illness?\n\n    -   **number_of_employees:** How many employees does your company or organization have?\n:::\n\n## Testing H1\n\nTo answer the first research question - whether there has been an increase in mental health disorders throughout the years - we can run a Chi-squared test of independence. This will allow us to test whether there is an association between two variables (year and mental disorders) in the population.\n\nThe test is conducted by comparing the observed frequencies of the data to the expected frequencies and it assumes that data is independent and that the expected frequencies are not too small (as a rule of thumb, no cell of the contingency table should have less than 5 observations).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# print contingency table\nprint_table <- function(var1, var2, annotation) {\n  cat(paste0(annotation, \"\\n\"))\n  print(table(df$has_mental_disorder, df$year))\n}\n\nprint_table(var1, var2, \"Contingency Table\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nContingency Table\n     \n      2017 2018 2019 2020 2021\n  No   106   44   45   30   28\n  Yes  178  113   84   25   29\n```\n:::\n\n```{.r .cell-code}\n# perform a chi-squared test of independence\nchisq.test(cont_tbl)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tPearson's Chi-squared test\n\ndata:  cont_tbl\nX-squared = 16.522, df = 4, p-value = 0.002393\n```\n:::\n:::\n\n\nThe results of the Chi-squared test indicate a statistically significant association between the two variables - year and mental disorders. **This suggests that the prevalence of mental disorders among mental health workers varies significantly across different years.**\n\nWhat's interesting is that some years show a higher proportion of mental disorders, while other years have a higher proportion of individuals without mental disorders. While the test does not provide information on the direction or nature of this variation, it does imply that the observed variation is unlikely due to chance alone.\n\n## Testing H2\n\nThe second hypothesis does not pertain to mental health over the years; rather, it seeks to inquire whether the level of mental health support provided by employers is associated to mental disorders. Since we are dealing with a binary categorical variable (mental disorders = yes/no) and a numerical discrete variable (mental health support factors= 0-100), a logistic regression model can help test this hypothesis.\n\nA logistic regression uses the logistic function to estimate the probability of the binary response variable taking on a certain value given the values of the predictor variables. Additionally, we first experiment the model's performance with a single predictor variable, and we will then include control variables to compare the models.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# transform no/yes to 0/1\ndf$has_mental_disorder <- ifelse(df$has_mental_disorder == \"Yes\", 1, 0)\n\n# simple log model\nlog_simple <- glm(has_mental_disorder ~ mh_support_factors\n                  ,data = df\n                  ,family = binomial(link=\"logit\"))\n\n# print model summary\nsummary(log_simple)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = has_mental_disorder ~ mh_support_factors, family = binomial(link = \"logit\"), \n    data = df)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-1.5242  -1.3455   0.8951   0.9653   1.1136  \n\nCoefficients:\n                   Estimate Std. Error z value Pr(>|z|)  \n(Intercept)        0.144042   0.190507   0.756    0.450  \nmh_support_factors 0.007832   0.003564   2.198    0.028 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 899.52  on 681  degrees of freedom\nResidual deviance: 894.68  on 680  degrees of freedom\nAIC: 898.68\n\nNumber of Fisher Scoring iterations: 4\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# create a new column with the count of each combination of x and y values\ndf <- df %>%\n  group_by(mh_support_factors, has_mental_disorder) %>%\n  mutate(count = n()) %>%\n  ungroup()\n\n# create the plot with the logistic regression line and data points\nggplot(df, aes(x = mh_support_factors, y = has_mental_disorder, size = count)) +\n  geom_point() +\n  scale_size_area(max_size = 10) +  # adjust the maximum size of the points\n  stat_smooth(method = \"glm\", method.args = list(family=\"binomial\")) +\n  xlab(\"Mental health support factors in tech\") +\n  ylab(\"Presence of mental disorder\") +\n  guides(size=FALSE)\n```\n\n::: {.cell-output-display}\n![](FinalProject_MiguelCuriel_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\nThe associated p-value (.028) suggests that there is a statistically significant association between the level of mental health support provided by employers and the presence of mental health issues among the individuals in the dataset. This **suggests that the level of mental health support provided by employers has a meaningful impact on the likelihood of individuals experiencing mental health issues**.\n\nHowever, from the plot, we do not see the expected sigmoidal relationship. This could not be due to missing data (because there is none), and it is unlikely that it is due to outliers (because there are not many), therefore this most likely suggests that there is either a nonlinear relationship or that there might be interaction effects.\n\n------------------------------------------------------------------------\n\n# Model Comparisons\n\nTo see whether interaction effects play a role in the previous relationships, I developed a new model which includes also includes the following dependent variables: gender, whether participants are willing to share their mental health status with friends, and the number of employees of a company.\n\nBelow is the code used to generate the enhanced model and its summary.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlog_interaction <- glm(has_mental_disorder ~ mh_support_factors *  gender  + willingness_to_share_with_friends + number_of_employees + age\n             ,data = df\n             ,family = binomial(link=\"logit\"))\n\nsummary(log_interaction)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = has_mental_disorder ~ mh_support_factors * gender + \n    willingness_to_share_with_friends + number_of_employees + \n    age, family = binomial(link = \"logit\"), data = df)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-1.9660  -1.1905   0.7204   0.9397   1.5584  \n\nCoefficients:\n                                   Estimate Std. Error z value Pr(>|z|)    \n(Intercept)                       -1.015686   0.672170  -1.511    0.131    \nmh_support_factors                -0.001631   0.005096  -0.320    0.749    \ngenderNonMale                      0.492817   0.414279   1.190    0.234    \nwillingness_to_share_with_friends  0.174225   0.031983   5.447 5.11e-08 ***\nnumber_of_employees6-25            0.617222   0.546092   1.130    0.258    \nnumber_of_employees26-100          0.219476   0.533643   0.411    0.681    \nnumber_of_employees100-500         0.718551   0.528643   1.359    0.174    \nnumber_of_employees500-1000        0.197141   0.578709   0.341    0.733    \nnumber_of_employeesMore than 1000  0.717553   0.523203   1.371    0.170    \nage                               -0.011886   0.010522  -1.130    0.259    \nmh_support_factors:genderNonMale   0.002874   0.007669   0.375    0.708    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 899.52  on 681  degrees of freedom\nResidual deviance: 841.26  on 671  degrees of freedom\nAIC: 863.26\n\nNumber of Fisher Scoring iterations: 4\n```\n:::\n:::\n\n\nWith the above model we can see that the original explanatory variable (`mh_support_factors`) ceases to be statistically significant. In actuality, with this new model, most variables are irrelevant - all but willingness to share with friends. This suggests that there is a strong relationship between the willingness to talk about one's mental health and the presence of mental disorders.\n\nNow we will run some additional metrics to compare both models.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# function to calculate mean of the PRESS statistic\nmean_delta <- sapply(list(log_simple, log_interaction), function(model) {\n  cv.glm(df, model, K = nrow(df))$delta[1]\n})\n\n# create a data frame with the metrics\nmetrics_df <- data.frame(\n  Model = c(\"Simple Logistic Regression\", \"Logistic Regression w/Interactions\"),\n  AIC = c(AIC(log_simple), AIC(log_interaction)),\n  BIC = c(BIC(log_simple), BIC(log_interaction)),\n  PRESS = mean_delta\n)\n\n# print the table using kable()\nkable(metrics_df, caption = \"Model Evaluation Metrics\")\n```\n\n::: {.cell-output-display}\nTable: Model Evaluation Metrics\n\n|Model                              |      AIC|      BIC|     PRESS|\n|:----------------------------------|--------:|--------:|---------:|\n|Simple Logistic Regression         | 898.6769| 907.7270| 0.2330125|\n|Logistic Regression w/Interactions | 863.2633| 913.0386| 0.2211524|\n:::\n:::\n\n\nAs we can see, the statistics suggest that no model is ideal (i.e., the numbers are high) and when it is a mixed bag when it comes to determining which model is better. The adjusted R-squared was not added as it yielded null results, which is likely due to there being multicollinearity among the predictors.\n\nFrom the statistics used, the Akaike Information Criterion (AIC) and the Bayesian Information Criterion (BIC) measure goodness of fit, and the Predicted Residual Sum of Squares (PRESS) measures the ability to predict on new data. In all cases, lower numbers are better, and **the model with interactions performed better on the AIC and the PRESS statistic, but the model without interaction performed better on the BIC statistic**. This suggests that the model without interaction has a better balance between fit and complexity (which makes sense as it is simpler) while the model with interactions has a better performance between fit and predictive performance.\n\nAs with any modeling decision, choosing among them depends on the use case. If we wanted to have better predictions, the model with interactions would be the way to go (in real life, this makes sense, as mental health is nuanced and is influenced by multiple factors). On the other hand, if we want to pave the way for future research and communicate findings in a simple way, the model without interactions could be a better choice (we could say, for example, that there is a strong relationship between company policies and mental disorders, but that further research is entailed).\n\n------------------------------------------------------------------------\n\n# Diagnostics\n\nGiven the previous situation - choosing between a simpler model or a more complex one - I opt to diagnose the model without interactions.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# generate diagnostic plots\npar(mfrow = c(2, 2))\nplot(log_simple)\n```\n\n::: {.cell-output-display}\n![](FinalProject_MiguelCuriel_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\nFrom the plots we can conclude that:\n\n-   Residuals vs Fitted: Even though there is a slight pattern in the data (as denoted by the curvature of the red line), we can say it is reasonably linear. This suggests that the model is capturing most - but not all - of the relationship.\n\n-   Normal Q-Q: The data points mostly depart from the dotted line, which would be a violation of the assumption of normality and could be due to various reasons, including heavy tails in the distribution or non-linear relationships.\n\n-   Scale-Location: The red line forms roughly a red line, meaning there is no heteroscedasticity and the assumption is constant variance is likely not violated.\n\n-   Residuals vs Leverage: Even though the data somewhat strays away from the red line, it does not seem to cross the dotted line. This suggests that there are no notable outliers in the data.\n\n------------------------------------------------------------------------\n\n# Conclusion\n\nThe results for both hypotheses were statistically significant, meaning that **1) mental disorders among workers in tech have varied significantly over the years and 2) the level of support provided by employers seems to play an important role in the presence of mental health issues among workers in tech.**\n\nThat said, I advise caution before jumping to any conclusions. For starters, the underlying dataset is not of the highest quality - it is distributed online with seemingly little control over the sampling, most responses admit open-field text which requires additional cleansing and assumptions, and responses have steadily decreased over the years which may or may not influence the quality of the data being received.\n\nRelated to making assumptions of the data, an important net-new variable was created based on already dubious data. If the quality of the underlying data is debatable, it is likely the end result is equally debatable. Furthermore, the net-new variable was created using arbitrary scores which is also worth thinking about.\n\nLastly, on the modeling side, the decision was to use a logistic regression model, but the topic at hand is mental health which is nuanced in nature and can hardly be classified on a binary basis. Even though the model was statistically significant, a more realistic approach would be to rely on multiple predictor variables (including expert opinions on a diagnosis, not only self-reported measures) and on varying degrees of mental disorders as the outcome variable.\n",
    "supporting": [
      "FinalProject_MiguelCuriel_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}