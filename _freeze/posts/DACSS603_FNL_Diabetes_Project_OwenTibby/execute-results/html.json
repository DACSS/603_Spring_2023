{
  "hash": "229e608a2c0a76e2de4874254ad64c1f",
  "result": {
    "markdown": "---\ntitle: \"Final Project - Diabetes and General Health\"\nauthor: \"Owen Tibby\"\neditor: visual\noutput: html\n---\n\n\n\n\n### **Introduction:**\n\nDiabetes, particularly type 2 diabetes, is a widespread chronic disease in the United States, impacting the health of millions and placing a significant financial strain on the US economy (Xie Z, Nikolayeva O, Luo J, Li D., 2019). Recently becoming aware of the risks associated with consuming too much sugary food, I am passionate about promoting overall health awareness among everyday people.\n\nXie et al. utilized the diabetes data set obtained from the 2014 Behavioral Risk Factor Surveillance System, which offers a wide array of observations associated with multiple significant variables.\n\nThis research project aims to further explore the relationship between general health and various socio-economic and demographic factors, such as income, education, and gender.\n\n**Note: For a summary of this project's findings, please see link to poster:** [Poster link](https://www.canva.com/design/DAFhgdSVFaI/R02Fl8Rh4JIHe7a4STCHKw/view?utm_content=DAFhgdSVFaI&utm_campaign=designshare&utm_medium=link&utm_source=publishsharelink){.uri}\n\n#### Research Questions:\n\nResearch Question: How do demographic factors compare to health indicators in predicting the risk of type II diabetes and general health?\n\nHypothesis A: Among adults aged 30 and above, health factors are slightly more effective than demographic factors in predicting the occurrence of diabetes.\n\nHypothesis B: Demographic factors play a significantly larger role than health indicators in predicting general health.\n\n#### Variables:\n\nDiabetes: Indicates whether the individual has diabetes or not.\n\nGenHlth: Represents the self-reported general health status of the individual, rescaled to a range of 1 (poor health) to 5 (excellent health).\n\nHighBP: Indicates whether the individual has been diagnosed with high blood pressure or not.\n\nHighChol: Indicates whether the individual has been diagnosed with high cholesterol or not.\n\nCholCheck: Represents whether the individual has undergone cholesterol checks or screenings in the past 5 years.\n\nBMI: Stands for Body Mass Index, a measure of body fat based on height and weight.\n\nSmoker: Indicates whether the individual has smoked more than 100 cigarettes in their lifetime or not.\n\nStroke: Represents whether the individual has had a stroke or not.\n\nHeartDiseaseorAttack: Indicates whether the individual has a history of heart disease or heart attacks.\n\nPhysActivity: Indicates whether the individual reported engaging in any level of physical activity outside of their regular job or household activities in the past 30 days.\n\nHvyAlcoholConsump: Indicates whether the individual consumes alcohol heavily. For men, it means consuming more than 14 alcoholic drinks per week, and for women, it means consuming more than 7 drinks per week.\n\nNoDocbcCost: Indicates whether the individual has avoided visiting the doctor due to cost constraints.\n\nMentHlth_low: Refers to the mental health status or conditions of the individual. It represents the number of poor mental health days the individual experienced in the past 30 days.\n\nPhysHlth_low: Indicates the physical health status or conditions of the individual. It represents the number of days per month the individual's physical health was poor.\n\nSex: Represents the biological sex of the individual. 0 indicates female, and 1 indicates male.\n\nAge: Refers to the age group of the individual. Group 1 represents individuals aged 18-24 years old, and group 13 represents individuals aged 80 or older.\n\nEducation: Represents the educational attainment or level of the individual. The scale ranges from 1 (never attended any level of school beyond kindergarten) to 6 (college, 4 years or more).\n\nIncome: Indicates the income level or range of the individual. The scale ranges from 1 (less than \\$10,000 per annum) to 8 (greater than \\$75,000 per annum).\n\nDiet: Refers to the dietary habits or patterns of the individual, specifically whether they consume fruits or vegetables at least once a day. The scale ranges from 0 (consumes neither fruits nor vegetables) to 3 (consumes both fruits and vegetables).\n\n#### Strategy\n\nThis research project aims to investigate two main dependent variables: *diabetes* and *general health*. The goal is to develop models for predicting both variables and evaluate their performance using various metrics.\n\nFor predicting both variables, three models will be fitted: Ordinal Logistic Regression, Random Forest classification, and Logistic Regression.\n\nThe evaluation metrics for these models will include sensitivity, accuracy, AIC (Akaike Information Criterion), and confusion matrices. The prediction accuracy for both general health and diabetes will be compared to determine which models provide better predictions for each dependent variable.\n\n### Section 1: Data Preprocessing & Wrangling\n\n#### Reading in Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndiabetes<- read_csv(\"_data/diabetes_012.csv\", \n    col_types = cols(DiffWalk = col_skip()))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Renaming Columns\ndiabetes <- diabetes %>% \n  rename(Diabetes = Diabetes_012, MentHlth_low = MentHlth, PhysHlth_low = PhysHlth)\n\n\n#Re-factoring Diabetes & General Health\ndiabetes$GenHlth<- as.numeric(ifelse(diabetes$GenHlth == \"1\", 5, ifelse(diabetes$GenHlth == \"2\", 4, ifelse(diabetes$GenHlth== \"3\", 3, ifelse(diabetes$GenHlth== \"4\", 2, ifelse(diabetes$GenHlth == \"5\", 1, \"N/A\"))))))\n\ndiabetes$GenHlth <- diabetes$GenHlth %>% as.factor()\ndiabetes$Diabetes <-  diabetes$Diabetes %>% as.factor()\n\n#Merging 'Fruits' and 'Veggies' into one column called Diet\n\ndiabetes <-  diabetes %>%\n  mutate(Diet= as.numeric(ifelse(Fruits + Veggies == 2, 3,ifelse(Fruits == 1 & Veggies==0, 2, ifelse(Veggies==1 & Fruits ==0, 1, \"0\")))))\n\n# diabetes <- diabetes[,-c(\"Fruits\", \"Veggies\" )]\ndiabetes <- diabetes[, !(colnames(diabetes) %in% c(\"Fruits\", \"Veggies\"))]\n```\n:::\n\n\n### Section 2: Exploratory Data Analysis\n\nBelow are pie charts illustrating the proportion and distribution of diabetes categories, general health and the age groups of the respondents.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Summarize the data to get the count of records in each category\nsummary_data <- diabetes %>%\n  count(Diabetes) %>%\n  mutate(Percentage = prop.table(n) * 100,\n         Total = sum(n)) %>% \n  mutate(Diabetes = case_when(\n    Diabetes == 0 ~ \"Non-diabetic\",\n    Diabetes == 1 ~ \"Prediabetic\",\n    Diabetes == 2 ~ \"Diabetic\"))\n\n# Create the pie chart of Diabetes Categories\nplot1 <- ggplot(summary_data, aes(x = \"\", y = n, fill = Diabetes)) +\n  geom_bar(stat = \"identity\", width = 1) +\n  coord_polar(\"y\", start = 0) +\n  theme_void() +\n  labs(title = \" Distribution of Diabetes Categories\") +\n  geom_text(aes(label = paste0(round(Percentage) ,\"%\")),\n            position = position_stack(vjust = 0.5), color = \"white\")\n\nplot1\n```\n\n::: {.cell-output-display}\n![](DACSS603_FNL_Diabetes_Project_OwenTibby_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary_data <- diabetes %>%\n  count(GenHlth) %>%\n  mutate(Percentage = prop.table(n) * 100,\n         Total = sum(n)) %>% \n  mutate(GenHlth = case_when(\n    GenHlth == 1 ~ \"1-Poor\",\n    GenHlth == 2 ~ \"2-Below Aveage\",\n    GenHlth == 3 ~ \"3-Average\", \n     GenHlth == 4 ~ \"4-Good\",\n     GenHlth == 5 ~ \"5-Excellent\")\n    )\n\n# Create the pie chart to show General Health Distribution\nplot2 <- ggplot(summary_data, aes(x = \"\", y = n, fill = GenHlth)) +\n  geom_bar(stat = \"identity\", width = 1) +\n  coord_polar(\"y\", start = 0) +\n  theme_void() +\n  labs(title = \"Distribution of Self-Reported General Health\" , fill= \"General Health\") +\n  geom_text(aes(label = paste0(round(Percentage) ,\"%\")),\n            position = position_stack(vjust = 0.5), color = \"white\")\nplot2\n```\n\n::: {.cell-output-display}\n![](DACSS603_FNL_Diabetes_Project_OwenTibby_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary_data <- diabetes %>%\n  count(Age) %>%\n  mutate(Percentage = prop.table(n) * 100,\n         Total = sum(n), Age=factor(Age) )%>% \n            mutate(Age = case_when(\n              Age == 1 ~ \"18-24\",\n              Age == 2 ~ \"25-29\",\n              Age == 3 ~ \"30-34\",\n              Age == 4 ~ \"35-39\", \n              Age == 5 ~ \"40-44\",\n              Age == 6 ~ \"45-49\",\n              Age == 7~ \"50-54\",\n              Age == 8 ~ \"55-59\",\n              Age == 9 ~ \"60-64\",\n              Age == 10 ~ \"65-69\",\n              Age == 11 ~ \"70-74\",\n              Age == 12 ~ \"75-79\",\n              Age == 13 ~ \"80-99\"))\n\n\n\n# Create the pie chart to show Age Distribution\nplot3 <- ggplot(summary_data, aes(x = \"\", y = n, fill = Age)) +\n  geom_bar(stat = \"identity\", width = 1) +\n  coord_polar(\"y\", start = 0) +\n  theme_void() +\n  labs(title = \"Distribution of Age groups\" , fill= \"Age\") +\n  geom_text(aes(label = paste0(round(Percentage) ,\"%\")),\n            position = position_stack(vjust = 0.5), color = \"white\")\nplot3\n```\n\n::: {.cell-output-display}\n![](DACSS603_FNL_Diabetes_Project_OwenTibby_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Plot the correlation matrix for people with diabetes and pre-diabetes\n\n# Create correlation matrix\ncorrelation_matrix <- cor(diabetes %>% mutate(GenHlth=as.numeric(GenHlth), Diabetes = as.numeric(Diabetes)))\n\n# Melt correlation matrix into long format for ggplot2\nmelted_correlation <- melt(correlation_matrix)\n\n# Create heat map with ggplot2\nggplot(data = melted_correlation, aes(x = Var1, y = Var2, fill = value)) +\n  geom_tile() +\n  scale_fill_gradient2(low = \"darkred\", mid = \"white\", high = \"darkgreen\", midpoint = 0) +\n  theme_minimal() +\n  labs(x= \"\", y=\"\")+\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) #+\n```\n\n::: {.cell-output-display}\n![](DACSS603_FNL_Diabetes_Project_OwenTibby_files/figure-html/Correlation Plot-1.png){width=672}\n:::\n\n```{.r .cell-code}\n  #labs(title = \"Correlation Matrix\")\n```\n:::\n\n\n#### Splitting the Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create a data partition for cross-validation\nset.seed(123)\npartition <- createDataPartition(diabetes$Diabetes, p = 0.8, list = FALSE)\n\n# Split the data into training and validation sets\ntrain <- diabetes[partition, ]\nvalid <- diabetes[-partition, ]\n```\n:::\n\n\n### Section 3: Modelling for Diabetes\n\n#### Random Forest\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndemographic_factors <- c(\"Sex\", \"Income\", \"Education\", \"Age\", \"NoDocbcCost\")\n\nhealth_indicators <- c(\"GenHlth\", \"BMI\",  \"Smoker\", \"HighBP\", \"HighChol\", \"Stroke\" , \"HeartDiseaseorAttack\" ,  \"HvyAlcoholConsump\" ,\"Diet\") \n\nboth <- c(demographic_factors, health_indicators)\nresponse <- \"Diabetes\"\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndiab_rf_dem <-  train(x = train[,demographic_factors ], y =train[[response]], method = \"rf\", trControl = trainControl(method = \"cv\", number = 5), ntree=20)\n\ndiab_rf_hlth <- diab_rf_hlth <- train(x = train[,health_indicators ], y = train[[response]], method = \"rf\", trControl = trainControl(method = \"cv\", number = 5), ntree= 20)\n\ndiab_rf_both <- train(x = train[,both ], y = train[[response]], method = \"rf\", trControl = trainControl(method = \"cv\", number = 5), ntree= 20)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nactual <- factor(valid$Diabetes)\n\n# Make predictions on the validation set\npredictions_rf_dem <- predict(diab_rf_dem, newdata = valid[, demographic_factors]) %>%  as.factor\n\n# Make predictions on the validation set\npredictions_rf_hlth <- predict(diab_rf_hlth, newdata = valid[, health_indicators]) %>%  as.factor\n\n# Make predictions on the validation set\npredictions_rf_both <- predict(diab_rf_both, newdata = valid[, both]) %>%  as.factor\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Print the confusion matrix and accuracy of the model\ncat(\"Demogrpahic Variables in RF\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nDemogrpahic Variables in RF\n```\n:::\n\n```{.r .cell-code}\nconfusionMatrix(predictions_rf_dem, actual)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction     0     1     2\n         0 42734   926  7067\n         1     0     0     0\n         2     6     0     2\n\nOverall Statistics\n                                          \n               Accuracy : 0.8423          \n                 95% CI : (0.8391, 0.8455)\n    No Information Rate : 0.8424          \n    P-Value [Acc > NIR] : 0.5224          \n                                          \n                  Kappa : 2e-04           \n                                          \n Mcnemar's Test P-Value : NA              \n\nStatistics by Class:\n\n                      Class: 0 Class: 1  Class: 2\nSensitivity          0.9998596  0.00000 2.829e-04\nSpecificity          0.0002502  1.00000 9.999e-01\nPos Pred Value       0.8424311      NaN 2.500e-01\nNeg Pred Value       0.2500000  0.98175 8.607e-01\nPrevalence           0.8424165  0.01825 1.393e-01\nDetection Rate       0.8422982  0.00000 3.942e-05\nDetection Prevalence 0.9998423  0.00000 1.577e-04\nBalanced Accuracy    0.5000549  0.50000 5.001e-01\n```\n:::\n\n```{.r .cell-code}\ncat(\"Health Variables in RF\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nHealth Variables in RF\n```\n:::\n\n```{.r .cell-code}\nconfusionMatrix(predictions_rf_hlth, actual)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction     0     1     2\n         0 42333   894  6393\n         1     0     0     0\n         2   407    32   676\n\nOverall Statistics\n                                          \n               Accuracy : 0.8477          \n                 95% CI : (0.8446, 0.8508)\n    No Information Rate : 0.8424          \n    P-Value [Acc > NIR] : 0.0005092       \n                                          \n                  Kappa : 0.1199          \n                                          \n Mcnemar's Test P-Value : < 2.2e-16       \n\nStatistics by Class:\n\n                     Class: 0 Class: 1 Class: 2\nSensitivity           0.99048  0.00000  0.09563\nSpecificity           0.08856  1.00000  0.98995\nPos Pred Value        0.85314      NaN  0.60628\nNeg Pred Value        0.63498  0.98175  0.87116\nPrevalence            0.84242  0.01825  0.13933\nDetection Rate        0.83439  0.00000  0.01332\nDetection Prevalence  0.97802  0.00000  0.02198\nBalanced Accuracy     0.53952  0.50000  0.54279\n```\n:::\n\n```{.r .cell-code}\ncat(\"Demogrpahic & Health Variables in RF\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nDemogrpahic & Health Variables in RF\n```\n:::\n\n```{.r .cell-code}\nconfusionMatrix(predictions_rf_both, actual)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction     0     1     2\n         0 42355   894  6381\n         1     0     0     0\n         2   385    32   688\n\nOverall Statistics\n                                          \n               Accuracy : 0.8484          \n                 95% CI : (0.8452, 0.8515)\n    No Information Rate : 0.8424          \n    P-Value [Acc > NIR] : 0.0001062       \n                                          \n                  Kappa : 0.1231          \n                                          \n Mcnemar's Test P-Value : < 2.2e-16       \n\nStatistics by Class:\n\n                     Class: 0 Class: 1 Class: 2\nSensitivity           0.99099  0.00000  0.09733\nSpecificity           0.09006  1.00000  0.99045\nPos Pred Value        0.85342      NaN  0.62262\nNeg Pred Value        0.65158  0.98175  0.87143\nPrevalence            0.84242  0.01825  0.13933\nDetection Rate        0.83483  0.00000  0.01356\nDetection Prevalence  0.97822  0.00000  0.02178\nBalanced Accuracy     0.54052  0.50000  0.54389\n```\n:::\n:::\n\n\n#### Ordinal Logistic Regression\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit ordinal logistic regression model for diabetes prediction using demographic factors\ndiab_olm_dem <- polr(Diabetes ~ Income*Education + Age + Sex + NoDocbcCost, data = train)\n\n# Print the model summary\nsummary(diab_olm_dem)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCall:\npolr(formula = Diabetes ~ Income * Education + Age + Sex + NoDocbcCost, \n    data = train)\n\nCoefficients:\n                    Value Std. Error t value\nIncome           -0.09324   0.013429  -6.944\nEducation        -0.07608   0.015310  -4.969\nAge               0.17403   0.002332  74.641\nSex               0.33003   0.012819  25.746\nNoDocbcCost       0.34023   0.021590  15.759\nIncome:Education -0.01385   0.002734  -5.066\n\nIntercepts:\n    Value   Std. Error t value\n0|1  2.0392  0.0739    27.5941\n1|2  2.1931  0.0739    29.6681\n\nResidual Deviance: 186572.36 \nAIC: 186588.36 \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndiab_olm_hth <- polr(Diabetes~ GenHlth + BMI + Smoker+ HighBP + HighChol + Stroke + HeartDiseaseorAttack + HvyAlcoholConsump + Diet, data = train)\n\nsummary(diab_olm_hth)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCall:\npolr(formula = Diabetes ~ GenHlth + BMI + Smoker + HighBP + HighChol + \n    Stroke + HeartDiseaseorAttack + HvyAlcoholConsump + Diet, \n    data = train)\n\nCoefficients:\n                        Value Std. Error t value\nGenHlth2             -0.18150  0.0263103  -6.899\nGenHlth3             -0.66263  0.0250488 -26.454\nGenHlth4             -1.37753  0.0270188 -50.984\nGenHlth5             -2.06058  0.0385455 -53.458\nBMI                   0.05136  0.0009145  56.161\nSmoker                0.04533  0.0136497   3.321\nHighBP                0.92404  0.0149636  61.753\nHighChol              0.66858  0.0141728  47.173\nStroke                0.26567  0.0267760   9.922\nHeartDiseaseorAttack  0.40902  0.0188064  21.749\nHvyAlcoholConsump    -0.81188  0.0390895 -20.770\nDiet                 -0.01702  0.0058222  -2.924\n\nIntercepts:\n    Value    Std. Error t value \n0|1   3.2094   0.0417    76.9570\n1|2   3.3839   0.0418    80.9461\n\nResidual Deviance: 165914.43 \nAIC: 165942.43 \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndiab_olm_both <- polr(Diabetes~ Income*Education + Age + Sex + NoDocbcCost + GenHlth+ BMI + Smoker+ HighBP + HighChol + Stroke + HeartDiseaseorAttack + HvyAlcoholConsump + Diet, data = train)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Predictions using demographic indicators with OLM\npredictions_olm_dem <- predict(diab_olm_dem, newdata= valid)\n\n\n# Predictions using health indicators with OLM\npredictions_olm_hlth <- predict(diab_olm_hth, newdata= valid)\n\n# Predictions using health indicators with both\npredictions_olm_both <- predict(diab_olm_both, newdata= valid)\n\n# Extract the response variable from the training data\nactual <- valid$Diabetes\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Confusion matrix for demographic variables\n\ncat(\"Demographic Variables in Ordinal logistic model\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nDemographic Variables in Ordinal logistic model\n```\n:::\n\n```{.r .cell-code}\nconfusionMatrix(predictions_olm_dem, actual)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction     0     1     2\n         0 42689   925  7049\n         1     0     0     0\n         2    51     1    20\n\nOverall Statistics\n                                         \n               Accuracy : 0.8418         \n                 95% CI : (0.8386, 0.845)\n    No Information Rate : 0.8424         \n    P-Value [Acc > NIR] : 0.6499         \n                                         \n                  Kappa : 0.0024         \n                                         \n Mcnemar's Test P-Value : <2e-16         \n\nStatistics by Class:\n\n                     Class: 0 Class: 1  Class: 2\nSensitivity          0.998807  0.00000 0.0028293\nSpecificity          0.002627  1.00000 0.9988091\nPos Pred Value       0.842607      NaN 0.2777778\nNeg Pred Value       0.291667  0.98175 0.8608649\nPrevalence           0.842416  0.01825 0.1393318\nDetection Rate       0.841411  0.00000 0.0003942\nDetection Prevalence 0.998581  0.00000 0.0014191\nBalanced Accuracy    0.500717  0.50000 0.5008192\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Confusion matrix for health indicators\n\ncat(\"Health Variables in Ordinal logistic model\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nHealth Variables in Ordinal logistic model\n```\n:::\n\n```{.r .cell-code}\nconfusionMatrix(predictions_olm_hlth, actual)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction     0     1     2\n         0 41876   872  5984\n         1     0     0     0\n         2   864    54  1085\n\nOverall Statistics\n                                          \n               Accuracy : 0.8468          \n                 95% CI : (0.8436, 0.8499)\n    No Information Rate : 0.8424          \n    P-Value [Acc > NIR] : 0.003513        \n                                          \n                  Kappa : 0.1733          \n                                          \n Mcnemar's Test P-Value : < 2.2e-16       \n\nStatistics by Class:\n\n                     Class: 0 Class: 1 Class: 2\nSensitivity            0.9798  0.00000  0.15349\nSpecificity            0.1425  1.00000  0.97898\nPos Pred Value         0.8593      NaN  0.54169\nNeg Pred Value         0.5686  0.98175  0.87721\nPrevalence             0.8424  0.01825  0.13933\nDetection Rate         0.8254  0.00000  0.02139\nDetection Prevalence   0.9605  0.00000  0.03948\nBalanced Accuracy      0.5611  0.50000  0.56623\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Confusion matrix for health indicators\ncat(\"Demographic & health Variables in Ordinal logistic model\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nDemographic & health Variables in Ordinal logistic model\n```\n:::\n\n```{.r .cell-code}\nconfusionMatrix(predictions_olm_both, actual)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction     0     1     2\n         0 41749   862  5910\n         1     0     0     0\n         2   991    64  1159\n\nOverall Statistics\n                                          \n               Accuracy : 0.8457          \n                 95% CI : (0.8426, 0.8489)\n    No Information Rate : 0.8424          \n    P-Value [Acc > NIR] : 0.02041         \n                                          \n                  Kappa : 0.1806          \n                                          \n Mcnemar's Test P-Value : < 2e-16         \n\nStatistics by Class:\n\n                     Class: 0 Class: 1 Class: 2\nSensitivity            0.9768  0.00000  0.16396\nSpecificity            0.1530  1.00000  0.97584\nPos Pred Value         0.8604      NaN  0.52349\nNeg Pred Value         0.5524  0.98175  0.87820\nPrevalence             0.8424  0.01825  0.13933\nDetection Rate         0.8229  0.00000  0.02284\nDetection Prevalence   0.9564  0.00000  0.04364\nBalanced Accuracy      0.5649  0.50000  0.56990\n```\n:::\n:::\n\n\n#### Logistic Regression\n\nNote: The diabetes data was subsequently recoded to merge individuals classified as pre-diabetic and non-diabetic, creating two distinct classes. A value of 0 was assigned to those who were non-diabetic or pre-diabetic, while a value of 2 was assigned to those classified as diabetic.\n\nThis re-coding process sets the stage for logistic regression analysis, aiming to evaluate how it compares to the sensitivity of the ordinal logistic model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#count of prediabetics\ncat( \"Number of pre-diabetics: \", length(diabetes$Diabetes[diabetes$Diabetes == \"1\"]))\n\n#Merging pre-diabetics with non-diabetics\ndiabetes_binary <- diabetes\ndiabetes_binary$Diabetes[diabetes_binary$Diabetes == \"1\"] <- 0\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#count of prediabetics\ncat( \"Number of pre-diabetics: \", length(diabetes$Diabetes[diabetes$Diabetes == \"1\"]))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nNumber of pre-diabetics:  4631\n```\n:::\n\n```{.r .cell-code}\n#Merging pre-diabetics with non-diabetics\ndiabetes_binary <- diabetes\ndiabetes_binary$Diabetes[diabetes_binary$Diabetes == \"1\"] <- 2\n```\n:::\n\n\n```         \n```\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndemographic_factors <- c(\"Sex\", \"Income\", \"Education\", \"Age\", \"NoDocbcCost\")\n\nhealth_indicators <- c(\"GenHlth\", \"BMI\",  \"Smoker\", \"HighBP\", \"HighChol\", \"Stroke\" , \"HeartDiseaseorAttack\" ,  \"HvyAlcoholConsump\" ,\"Diet\") \n\nboth <- c(demographic_factors, health_indicators)\n\n#Merging pre-diabetics with non-diabetics\ndiabetes_binary <- diabetes\ndiabetes_binary$Diabetes[diabetes_binary$Diabetes == \"1\"] <- 2\n\n\n# Create a data partition for cross-validation\nset.seed(123)\npartition <- createDataPartition(diabetes_binary$Diabetes, p = 0.8, list = FALSE)\n\n# Split the data into training and validation sets\ntrain2 <- diabetes_binary[partition, ]\nvalid2 <- diabetes_binary[-partition, ]\n\n\n# LR models\ndiab_lr_dem <-  multinom(Diabetes ~  Income*Education + Age + Sex + NoDocbcCost, data = train2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# weights:  8 (7 variable)\ninitial  value 140670.754559 \niter  10 value 81880.470998\nfinal  value 81875.856658 \nconverged\n```\n:::\n\n```{.r .cell-code}\ndiab_lr_hlth <-  multinom(Diabetes ~ GenHlth + BMI + HighBP + HighChol + Stroke + HeartDiseaseorAttack + HvyAlcoholConsump + Diet, data = train2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# weights:  13 (12 variable)\ninitial  value 140670.754559 \niter  10 value 81796.759194\niter  20 value 71657.874488\nfinal  value 71657.844798 \nconverged\n```\n:::\n\n```{.r .cell-code}\ndiab_lr_both <- multinom(Diabetes ~ Income*Education + Age + Sex + NoDocbcCost + GenHlth +BMI + HighBP + HighChol + Stroke + HeartDiseaseorAttack + HvyAlcoholConsump + Diet, data = train2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# weights:  19 (18 variable)\ninitial  value 140670.754559 \niter  10 value 75778.902970\niter  20 value 74308.882164\nfinal  value 70218.660619 \nconverged\n```\n:::\n\n```{.r .cell-code}\nactual <- factor(valid2$Diabetes)\n\n# Make predictions on the validation set\npredictions_lr_dem <- predict(diab_lr_dem, newdata = valid2[, demographic_factors]) %>%  as.factor\n\n# Make predictions on the validation set\npredictions_lr_hlth <- predict(diab_lr_hlth, newdata = valid2[, health_indicators]) %>%  as.factor\n\n# Make predictions on the validation set\npredictions_lr_both <- predict(diab_lr_both, newdata = valid2[, both]) %>%  as.factor\n\n\n# Print the confusion matrix and accuracy of the model\n\ncat(\"Demographic Variables in  logistic regression model\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nDemographic Variables in  logistic regression model\n```\n:::\n\n```{.r .cell-code}\nconfusionMatrix(predictions_lr_dem, actual)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction     0     2\n         0 42659  7960\n         2    81    35\n                                          \n               Accuracy : 0.8415          \n                 95% CI : (0.8383, 0.8447)\n    No Information Rate : 0.8424          \n    P-Value [Acc > NIR] : 0.7148          \n                                          \n                  Kappa : 0.0041          \n                                          \n Mcnemar's Test P-Value : <2e-16          \n                                          \n            Sensitivity : 0.998105        \n            Specificity : 0.004378        \n         Pos Pred Value : 0.842747        \n         Neg Pred Value : 0.301724        \n             Prevalence : 0.842416        \n         Detection Rate : 0.840820        \n   Detection Prevalence : 0.997714        \n      Balanced Accuracy : 0.501241        \n                                          \n       'Positive' Class : 0               \n                                          \n```\n:::\n\n```{.r .cell-code}\ncat(\"Health Variables in  logistic regression model\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nHealth Variables in  logistic regression model\n```\n:::\n\n```{.r .cell-code}\nconfusionMatrix(predictions_lr_hlth, actual)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction     0     2\n         0 41694  6637\n         2  1046  1358\n                                          \n               Accuracy : 0.8486          \n                 95% CI : (0.8454, 0.8517)\n    No Information Rate : 0.8424          \n    P-Value [Acc > NIR] : 6.819e-05       \n                                          \n                  Kappa : 0.2031          \n                                          \n Mcnemar's Test P-Value : < 2.2e-16       \n                                          \n            Sensitivity : 0.9755          \n            Specificity : 0.1699          \n         Pos Pred Value : 0.8627          \n         Neg Pred Value : 0.5649          \n             Prevalence : 0.8424          \n         Detection Rate : 0.8218          \n   Detection Prevalence : 0.9526          \n      Balanced Accuracy : 0.5727          \n                                          \n       'Positive' Class : 0               \n                                          \n```\n:::\n\n```{.r .cell-code}\ncat(\"Demographic & health Variables in  logistic regression model\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nDemographic & health Variables in  logistic regression model\n```\n:::\n\n```{.r .cell-code}\nconfusionMatrix(predictions_lr_both, actual)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction     0     2\n         0 41544  6540\n         2  1196  1455\n                                          \n               Accuracy : 0.8475          \n                 95% CI : (0.8444, 0.8506)\n    No Information Rate : 0.8424          \n    P-Value [Acc > NIR] : 0.0007823       \n                                          \n                  Kappa : 0.2115          \n                                          \n Mcnemar's Test P-Value : < 2.2e-16       \n                                          \n            Sensitivity : 0.9720          \n            Specificity : 0.1820          \n         Pos Pred Value : 0.8640          \n         Neg Pred Value : 0.5488          \n             Prevalence : 0.8424          \n         Detection Rate : 0.8188          \n   Detection Prevalence : 0.9477          \n      Balanced Accuracy : 0.5770          \n                                          \n       'Positive' Class : 0               \n                                          \n```\n:::\n:::\n\n\n### Section 4: Model Comparison (Diabetes)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_names <- c(\"Demographic Variables\", \"Health Variables\", \"Both Dem. & Hlth\")\nAIC_values_olm <- c(AIC(diab_olm_dem), AIC(diab_olm_hth), AIC(diab_olm_both))\n# BIC_values_olm <- c(BIC(diab_olm_dem), BIC(diab_olm_hth), BIC(diab_olm_both))\n\n# Plotting AIC values\nbarplot(AIC_values_olm, names.arg = model_names, ylab = \"AIC\", main = \"Ordinal Logistic Regression Model: AIC Comparison (Diabetes)\", col = c(\"darkblue\", \"blue\", \"lightblue\"))\n```\n\n::: {.cell-output-display}\n![](DACSS603_FNL_Diabetes_Project_OwenTibby_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n\n```{.r .cell-code}\nAIC_values_lr <- c(AIC(diab_lr_dem), AIC(diab_lr_hlth), AIC(diab_lr_both))\n\n# Plotting AIC values\nbarplot(AIC_values_lr, names.arg = model_names, ylab = \"AIC\", main = \"Logistic Regression Model: AIC Comparison (Diabetes)\", col = c(\"darkred\", \"red\", \"pink\"))\n```\n\n::: {.cell-output-display}\n![](DACSS603_FNL_Diabetes_Project_OwenTibby_files/figure-html/unnamed-chunk-8-2.png){width=672}\n:::\n:::\n\n\n### Section 5: Modelling for General Health\n\n#### Random Forest\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#### Random Forest\n\ndemographic_factors <- c(\"Sex\", \"Income\", \"Education\", \"Age\", \"NoDocbcCost\")\n\nhealth_indicators <- c( \"Diabetes\" ,\"BMI\",  \"Smoker\", \"HighBP\", \"HighChol\", \"Stroke\" , \"HeartDiseaseorAttack\" ,  \"HvyAlcoholConsump\" ,\"Diet\") \n\nboth <- c(demographic_factors, health_indicators)\n\n\nresponse <- \"GenHlth\"\n\ngen_rf_dem <- train(x = train[,demographic_factors ], y =train[[response]], method = \"rf\", trControl = trainControl(method = \"cv\", number = 5), ntree=15)\n\ngen_rf_hlth <- train(x = train[,health_indicators ], y = train[[response]], method = \"rf\", trControl = trainControl(method = \"cv\", number = 5), ntree= 15)\n\ngen_rf_both <- train(x = train[,both ], y = train[[response]], method = \"rf\", trControl = trainControl(method = \"cv\", number = 5), ntree= 15)\n\n# Predictions\n\nvalid$GenHlth <- valid$GenHlth %>% as.factor\nactual_gen <- (valid$GenHlth) %>% as.factor()\n\n# Make predictions on the validation set using demographic factors\npredictions_gen_rf_dem <- predict(gen_rf_dem, newdata = valid[, demographic_factors]) %>%   as.factor()\n\n# Make predictions on the validation set using health factors\npredictions_gen_rf_hlth <- predict(gen_rf_hlth, newdata = valid[, health_indicators]) %>% as.factor()\n\n# Make predictions on the validation set using health factors\npredictions_gen_rf_both <- predict(gen_rf_both, newdata = valid[, both]) %>% as.factor()\n\n\n#predictions_gen_rf_dem <- factor(predictions_gen_rf_dem, levels = levels(actual_gen))\n\n\n#predictions_gen_rf_both <- factor(predictions_gen_rf_both, levels = levels(actual_gen))\n\n# Print the confusion matrix and accuracy of the model\nconfusionMatrix(predictions_gen_rf_dem, actual_gen)\nconfusionMatrix(predictions_gen_rf_hlth, actual_gen)\n\n\nconfusionMatrix(predictions_gen_rf_both, actual_gen)\n```\n:::\n\n\n#### Ordinal Logistic Model\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndiabetes$GenHlth <- diabetes$GenHlth %>% as.factor()\n\n\n# Split the data into training and validation sets\ntrain <- diabetes[partition, ]\nvalid <- diabetes[-partition, ]\n\n# Fit ordinal logistic regression model for diabetes prediction using demographic factors\ngen_olm_dem <- polr(GenHlth ~ Income*Education + Age + Sex + NoDocbcCost, data = train)\n\n# Print the model summary\nsummary(gen_olm_dem)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCall:\npolr(formula = GenHlth ~ Income * Education + Age + Sex + NoDocbcCost, \n    data = train)\n\nCoefficients:\n                     Value Std. Error t value\nIncome            0.247518   0.009676  25.582\nEducation         0.268930   0.011905  22.590\nAge              -0.074559   0.001367 -54.551\nSex              -0.175646   0.008252 -21.285\nNoDocbcCost      -0.787298   0.015327 -51.368\nIncome:Education  0.003006   0.001949   1.542\n\nIntercepts:\n    Value    Std. Error t value \n1|2  -1.1290   0.0569   -19.8344\n2|3   0.4422   0.0570     7.7600\n3|4   2.1254   0.0574    36.9993\n4|5   3.9489   0.0575    68.6786\n\nResidual Deviance: 546445.71 \nAIC: 546465.71 \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#OLR model\ngen_olm_hth <- polr(GenHlth~ Diabetes + BMI + Smoker+ HighBP + HighChol + Stroke + HeartDiseaseorAttack + HvyAlcoholConsump + Diet, data = train)\n\nsummary(gen_olm_hth)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCall:\npolr(formula = GenHlth ~ Diabetes + BMI + Smoker + HighBP + HighChol + \n    Stroke + HeartDiseaseorAttack + HvyAlcoholConsump + Diet, \n    data = train)\n\nCoefficients:\n                       Value Std. Error t value\nDiabetes1            -0.6437  0.0305433  -21.08\nDiabetes2            -0.9534  0.0127099  -75.01\nBMI                  -0.0492  0.0006732  -73.08\nSmoker               -0.4205  0.0083976  -50.07\nHighBP               -0.6254  0.0091414  -68.41\nHighChol             -0.2767  0.0087734  -31.54\nStroke               -0.9755  0.0217750  -44.80\nHeartDiseaseorAttack -0.9949  0.0150702  -66.02\nHvyAlcoholConsump     0.2017  0.0178414   11.31\nDiet                  0.1523  0.0036542   41.68\n\nIntercepts:\n    Value     Std. Error t value  \n1|2   -5.4235    0.0255  -212.4224\n2|3   -3.7883    0.0233  -162.9228\n3|4   -2.0268    0.0220   -92.0342\n4|5   -0.1318    0.0216    -6.0947\n\nResidual Deviance: 533054.80 \nAIC: 533082.80 \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ngen_olm_both <- polr(GenHlth~ Diabetes +BMI + Smoker+ HighBP + HighChol + Stroke + HeartDiseaseorAttack + HvyAlcoholConsump + Diet + Income*Education + Age + Sex + NoDocbcCost\n, data = train)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Predictions using demographic indicators with OLM\npredictions_olm_dem_gen <- predict(gen_olm_dem, newdata= valid)\n\n\n# Predictions using health indicators with OLM\npredictions_olm_hlth_gen <- predict(gen_olm_hth, newdata= valid)\n\n\n# Predictions using health indicators with OLM\npredictions_olm_both_gen <- predict(gen_olm_both, newdata= valid)\n\n# Extract the response variable from the training data\nactual_gen_olm <- valid$GenHlth\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Confusion matrix for demographic variables\nconfusionMatrix(predictions_olm_dem_gen, actual_gen_olm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction     1     2     3     4     5\n         1    19    14     8     6     1\n         2   334   470   366   155    57\n         3  1669  3784  6356  4563  1640\n         4   489  2069  8264 12994  7285\n         5     0     5    38    92    57\n\nOverall Statistics\n                                          \n               Accuracy : 0.3922          \n                 95% CI : (0.3879, 0.3964)\n    No Information Rate : 0.351           \n    P-Value [Acc > NIR] : < 2.2e-16       \n                                          \n                  Kappa : 0.1002          \n                                          \n Mcnemar's Test P-Value : < 2.2e-16       \n\nStatistics by Class:\n\n                      Class: 1 Class: 2 Class: 3 Class: 4 Class: 5\nSensitivity          0.0075667 0.074109   0.4228   0.7296 0.006305\nSpecificity          0.9993986 0.979456   0.6735   0.4501 0.996762\nPos Pred Value       0.3958333 0.340087   0.3529   0.4178 0.296875\nNeg Pred Value       0.9508355 0.881020   0.7349   0.7547 0.822270\nPrevalence           0.0494925 0.125002   0.2963   0.3510 0.178181\nDetection Rate       0.0003745 0.009264   0.1253   0.2561 0.001123\nDetection Prevalence 0.0009461 0.027240   0.3550   0.6130 0.003784\nBalanced Accuracy    0.5034827 0.526783   0.5482   0.5898 0.501534\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Confusion matrix for health indicators\nconfusionMatrix(predictions_olm_hlth_gen, actual_gen_olm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction     1     2     3     4     5\n         1   152   145    81    32     5\n         2   439   763   627   220    41\n         3  1245  3275  6124  4099   938\n         4   667  2144  8141 13291  7845\n         5     8    15    59   168   211\n\nOverall Statistics\n                                          \n               Accuracy : 0.4049          \n                 95% CI : (0.4006, 0.4092)\n    No Information Rate : 0.351           \n    P-Value [Acc > NIR] : < 2.2e-16       \n                                          \n                  Kappa : 0.1238          \n                                          \n Mcnemar's Test P-Value : < 2.2e-16       \n\nStatistics by Class:\n\n                     Class: 1 Class: 2 Class: 3 Class: 4 Class: 5\nSensitivity          0.060534  0.12031   0.4074   0.7463 0.023341\nSpecificity          0.994546  0.97011   0.7323   0.4291 0.994004\nPos Pred Value       0.366265  0.36507   0.3905   0.4142 0.457701\nNeg Pred Value       0.953120  0.88531   0.7459   0.7577 0.824382\nPrevalence           0.049492  0.12500   0.2963   0.3510 0.178181\nDetection Rate       0.002996  0.01504   0.1207   0.2620 0.004159\nDetection Prevalence 0.008180  0.04119   0.3091   0.6325 0.009086\nBalanced Accuracy    0.527540  0.54521   0.5699   0.5877 0.508672\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Confusion matrix for both indicators\nconfusionMatrix(predictions_olm_both_gen, actual_gen_olm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction     1     2     3     4     5\n         1   251   228    98    28     9\n         2   698  1089   828   236    68\n         3  1211  3582  6898  4285  1135\n         4   339  1414  7017 12406  6639\n         5    12    29   191   855  1189\n\nOverall Statistics\n                                         \n               Accuracy : 0.4303         \n                 95% CI : (0.426, 0.4347)\n    No Information Rate : 0.351          \n    P-Value [Acc > NIR] : < 2.2e-16      \n                                         \n                  Kappa : 0.1766         \n                                         \n Mcnemar's Test P-Value : < 2.2e-16      \n\nStatistics by Class:\n\n                     Class: 1 Class: 2 Class: 3 Class: 4 Class: 5\nSensitivity          0.099960  0.17171   0.4589   0.6966  0.13153\nSpecificity          0.992473  0.95878   0.7139   0.5320  0.97393\nPos Pred Value       0.408795  0.37307   0.4031   0.4460  0.52241\nNeg Pred Value       0.954909  0.89014   0.7581   0.7642  0.83799\nPrevalence           0.049492  0.12500   0.2963   0.3510  0.17818\nDetection Rate       0.004947  0.02146   0.1360   0.2445  0.02344\nDetection Prevalence 0.012102  0.05753   0.3373   0.5482  0.04486\nBalanced Accuracy    0.546216  0.56524   0.5864   0.6143  0.55273\n```\n:::\n:::\n\n\n### Section 6: Model Comparison Part 2 (General Health)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_names <- c(\"Demographic Variables\", \"Health Variables\", \"Both Dem. & Hlth\")\nAIC_values_olm_gen <- c(AIC(gen_olm_dem), AIC(gen_olm_hth), AIC(gen_olm_both))\n\n# Plotting AIC values\nbarplot(AIC_values_olm_gen, names.arg = model_names, ylab = \"AIC\", main = \"Ordinal Logistic Regression Model: AIC Comparison (General Health)\", col = c(\"darkgreen\", \"green\", \"lightgreen\"))\n```\n\n::: {.cell-output-display}\n![](DACSS603_FNL_Diabetes_Project_OwenTibby_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n### **Section 7: Summary of Findings**\n\nDiabetes\n\n-   Contrary to the primary hypothesis, demographic variables alone demonstrate very limited effectiveness in predicting diabetes. In contrast, health indicators exhibit superior predictive capability for diabetes. When combining demographic variables with health indicators, there are only slight improvements in model accuracy and sensitivity compared to models fitted solely with health variables.\n\n-   Comparing the predictive performance of different models for diabetes and general health, the ordinal logistic regression model outperformed the random forest and logistic regression models.\n\n-   Logistic regression models (Fig.5) exhibited a lower AIC across all groups of variables after recoding the response variable, but sensitivity did not improve.\n\nGeneral Health\n\n-   Demographic variables were more effective at predicting general health than classifying the presence of diabetes.\n\n-   In all models, including the random forest model, demographic variables such as age, sex, income, and education provided close predictions of general health for individuals. It is worth noting that the random forest model was less likely to classify respondents as having excellent health, typically predicting on a scale of 1-4\n\n-   This behavior may be attributed to the mismatch in sample size between the classes and the random forest model needing to sample across a wide number of trees to determine the most likely outcome. As a result, the predictions leaned towards good health but not excellent health, which aligns with the tendency of respondents to report higher general health ratings for themselves.\n\n### **Section 8: Conclusion**\n\nFitting additional variables has minimal impact on accuracy and the true-positive rate. Health indicators alone are sufficient for predicting diabetes, as demographic variables, whether considered individually or in combination with health indicators, do not contribute significantly to predictive power.\n\nWhile health indicators alone may be suitable for diabetes prediction (despite a relatively low 15% sensitivity rate), it is important to acknowledge that the data relies on self-reports, which may introduce response bias or rating inflation.\n\nThe findings did not substantially support the secondary hypothesis. For predicting general health, regression with a continuous outcome variable and metrics like root mean squared error could have provided a better measure of model performance. However, this aspect was beyond the scope of the project.\n\nThe correlation matrix reveals a moderate relationship between demographic variables (such as income and age) and certain key health indicators. Although this relationship exists, it is not strong enough for demographic variables to predict (either diabetes or general health) well in the absence of health factors.\n",
    "supporting": [
      "DACSS603_FNL_Diabetes_Project_OwenTibby_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}