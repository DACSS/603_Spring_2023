{
  "hash": "92466279f556b35b3fe40d12d2b477af",
  "result": {
    "markdown": "---\ntitle: \"Homework 4\"\nauthor: \"Asch Harwood\"\ndescription: \"Homework 4, Intro to Quant\"\ndate: \"4/25/2023\"\nformat:\n  html:\n    toc: true\n    code-fold: true\n    code-copy: true\n    code-tools: true\ncategories:\n  - hw4\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(\"dplyr\")\nlibrary(\"knitr\")\nlibrary(kableExtra)\nlibrary(xtable)\nlibrary(ggplot2)\nlibrary(GGally)\nlibrary(lme4)\nlibrary(car)\nlibrary(dplyr)\nlibrary(alr4)\nlibrary(stargazer)\nlibrary(smss)\n```\n:::\n\n\n# Question 1\n\n### A\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx1 <-  1240 #house size\nx2 <- 18000 #lot size\ny_observed <- 145000\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# find predicted selling price\ny_hat <- (-10536) + (53.8*x1) + (2.84*x2)\nresidual <- y_observed - y_hat\ncat('Predict sale price: $',  y_hat)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nPredict sale price: $ 107296\n```\n:::\n\n```{.r .cell-code}\ncat('\\n')\n```\n\n```{.r .cell-code}\ncat('Residual: $', residual)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nResidual: $ 37704\n```\n:::\n\n```{.r .cell-code}\ncat('\\n')\n```\n\n```{.r .cell-code}\ncat('The predicted sale price of', y_hat, 'dollars is', residual, 'dollars less than the actual observed house price of', y_observed, '.')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nThe predicted sale price of 107296 dollars is 37704 dollars less than the actual observed house price of 145000 .\n```\n:::\n:::\n\n\n### B\n\nHolding the lot size fixed, each unit increase in square footage increases the house value by 53.8 dollars, which is the coefficient.\n\n### C\n\nThe lot size would need to increase by 19.94 square feet to increase the home value by 53.8 dollars.\n\n# Question 2\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(salary)\n```\n:::\n\n\n### A\n\nWe cannot reject the null hypothesis that there is a difference between the mean male and female salary at the 0.05 significance level given the observed p-value of 0.09. The 95 percent confidence interval supports this conclusion because it contains zero.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data = salary, aes(x=salary, fill=sex)) + \n  geom_histogram(bins=5)\n```\n\n::: {.cell-output-display}\n![](asch_harwood_hw_4_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmale_salaries <- salary[salary$sex == \"Male\",]$salary\nfemale_salaries <- salary[salary$sex == \"Female\",]$salary\nt.test(male_salaries, female_salaries)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tWelch Two Sample t-test\n\ndata:  male_salaries and female_salaries\nt = 1.7744, df = 21.591, p-value = 0.09009\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -567.8539 7247.1471\nsample estimates:\nmean of x mean of y \n 24696.79  21357.14 \n```\n:::\n:::\n\n\n### B\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(salary)\nfit <- lm(salary ~ rank + sex + year + ysdeg + degree, data = salary)\nsex_ci <- confint(fit)[\"sexFemale\", ]\ncat('sexFemale confidence interval: ', sex_ci)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nsexFemale confidence interval:  -697.8183 3030.565\n```\n:::\n:::\n\n\n### C\n\nIntercept: The intercept of \\$15,746.05 refers to when all coefficients are zero, which can be interpreted as the 'base' salary. In this case, our base reference professor is a male, assistant professor with zero years of experience and 0 years since graduation.\n\nrankAssoc: Holding all else equal, associate professors make \\$5,292.36 more than assistant professors. This finding is statistically significant, which means we can reject the null hypothesis that there is no different in salary between associate and assistant professors.\n\nrankProf: Holding all else equal, professors make \\$11,118.76 more than assistant professors. This finding is statistically significant, which means we can reject the null hypothesis that there is no different in salary between professors and assistant professors.\n\nsexFemale: Holding all else equal, female professors make \\$1,166.37 more than male professors. This finding is NOT statistically significant, which means we cannot reject the null hypothesis that there is no difference in salary between male and female professors.\n\nyear: Holding all else equal, for each year increase in years in current position, salary increases by \\$476.31. This finding is statistically significant, which means we can reject the null hypothesis that an increase in years does not increase salary.\n\nysdeg: Holding all else equal, for each year increase in years since degree, salary decreases by \\$124.57. This finding is NOT statistically significant, which means we cannot reject the null hypothesis that a change in years in position does not have a corresponding change in salary.\n\ndegreePhD: Holding all else equal, professors with PhD's make \\$1,388 more than those with masters degrees. This is NOT statistically significant.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = salary ~ rank + sex + year + ysdeg + degree, data = salary)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4045.2 -1094.7  -361.5   813.2  9193.1 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 15746.05     800.18  19.678  < 2e-16 ***\nrankAssoc    5292.36    1145.40   4.621 3.22e-05 ***\nrankProf    11118.76    1351.77   8.225 1.62e-10 ***\nsexFemale    1166.37     925.57   1.260    0.214    \nyear          476.31      94.91   5.018 8.65e-06 ***\nysdeg        -124.57      77.49  -1.608    0.115    \ndegreePhD    1388.61    1018.75   1.363    0.180    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2398 on 45 degrees of freedom\nMultiple R-squared:  0.855,\tAdjusted R-squared:  0.8357 \nF-statistic: 44.24 on 6 and 45 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\n### D\n\nrankAsst: Holding all else equal, associate professors make \\$11,118.76 less than a professor. This finding is statistically significant.\n\nrankAssoc: Holding all else equal, assistant professors make \\$5,826.40 less than a professor. This finding is statistically significant.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsalary$rank <- relevel(salary$rank, ref=\"Prof\")\nfit <- lm(salary ~ rank + sex + year + ysdeg + degree, data = salary)\nsummary(fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = salary ~ rank + sex + year + ysdeg + degree, data = salary)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4045.2 -1094.7  -361.5   813.2  9193.1 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  26864.81    1375.29  19.534  < 2e-16 ***\nrankAsst    -11118.76    1351.77  -8.225 1.62e-10 ***\nrankAssoc    -5826.40    1012.93  -5.752 7.28e-07 ***\nsexFemale     1166.37     925.57   1.260    0.214    \nyear           476.31      94.91   5.018 8.65e-06 ***\nysdeg         -124.57      77.49  -1.608    0.115    \ndegreePhD     1388.61    1018.75   1.363    0.180    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2398 on 45 degrees of freedom\nMultiple R-squared:  0.855,\tAdjusted R-squared:  0.8357 \nF-statistic: 44.24 on 6 and 45 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\n### E\n\nBy excluding rank:\n\n-   the model as a whole is less 'useful'. R-squared has gone down from 86 to 63, as has the adjusted r-squared, even though we have simplified the model. This means the model without rank has less 'explanatory' power. We also see an increase in the residual standard error.\n\n-   sexFemale in the new model is now correlated with a decreased salary of \\$1,286.54 compared to the original model's increase of \\$1,166.37. Sex is still not statistically significant.\n\n-   There is a slight decrease in the coefficient for year.\n\n-   In the new model, an increase in one year in number of years since degree is associated with a \\$339.40 increase in salary, compared to the \\$124.57 reduction from the previous model. This finding is statistically significant.\n\n-   In the new model, having a phd is associated with a decline in salary by \\$3,299.35 compared to the \\$1,388.61 bump in the original model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_no_rank <- lm(salary ~ sex + year + ysdeg + degree, data = salary)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create a side-by-side table of the models using stargazer\nstargazer(fit, fit_no_rank,type = \"text\",\n          title = \"Professor Salary Regression\",\n          align = TRUE,\n          column.labels = c(\"M1:AllVari\", \"M2:NoRank\"),\n          ci = TRUE, # Show confidence intervals\n          digits = 2) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nProfessor Salary Regression\n==================================================================\n                                 Dependent variable:              \n                    ----------------------------------------------\n                                        salary                    \n                          M1:AllVari              M2:NoRank       \n                              (1)                    (2)          \n------------------------------------------------------------------\nrankAsst                 -11,118.76***                            \n                    (-13,768.19, -8,469.34)                       \n                                                                  \nrankAssoc                -5,826.40***                             \n                    (-7,811.72, -3,841.09)                        \n                                                                  \nsexFemale                  1,166.37               -1,286.54       \n                      (-647.71, 2,980.45)   (-3,860.15, 1,287.06) \n                                                                  \nyear                       476.31***               351.97**       \n                       (290.28, 662.34)        (72.71, 631.23)    \n                                                                  \nysdeg                       -124.57               339.40***       \n                       (-276.44, 27.30)        (181.38, 497.41)   \n                                                                  \ndegreePhD                  1,388.61              -3,299.35**      \n                      (-608.09, 3,385.32)    (-5,852.24, -746.46) \n                                                                  \nConstant                 26,864.81***            17,183.57***     \n                    (24,169.30, 29,560.33)  (14,933.65, 19,433.50)\n                                                                  \n------------------------------------------------------------------\nObservations                  52                      52          \nR2                           0.86                    0.63         \nAdjusted R2                  0.84                    0.60         \nResidual Std. Error   2,398.42 (df = 45)      3,743.50 (df = 47)  \nF Statistic          44.24*** (df = 6; 45)  20.11*** (df = 4; 47) \n==================================================================\nNote:                                  *p<0.1; **p<0.05; ***p<0.01\n```\n:::\n:::\n\n\n### F\n\nTo prevent multicollinearity, I excluded `ys_deg` from the model. A pair plot visual inspection suggests that ys_deg is correlated with years. Without a visual inspection, we already know it is correlated with `dean_selected` because `dean_selected` is derived from `ys_deg`. We want to remove multicollinearity because it can influence other coefficients in the model, possibly obscuring the true relationship between the independent and dependent variable.\n\nThere is evidence to suggest that the dean is preferentially rewarding staff he has hired. Holding all else equal, those hired by the dean earn \\$2,160 more than those who were not. This number is statistically significant.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#add dean selection\nsalary$dean_selected <- ifelse(salary$ysdeg<=15, 1, 0)\n\n#dropping ysdeg b/c correlated with dean_selected\nx_no_y <- subset(salary, select = -c(salary, ysdeg))\n#pairs(x_no_y)\n\n# not including ys_deg b/c correlation with dean_selected and year\nfit_dean <- lm(salary ~ degree + rank + sex + dean_selected + year, data = salary)\nsummary(fit_dean)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = salary ~ degree + rank + sex + dean_selected + year, \n    data = salary)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3403.3 -1387.0  -167.0   528.2  9233.8 \n\nCoefficients:\n               Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    24425.32    1107.52  22.054  < 2e-16 ***\ndegreePhD        818.93     797.48   1.027   0.3100    \nrankAsst      -11096.95    1191.00  -9.317 4.54e-12 ***\nrankAssoc      -6124.28    1028.58  -5.954 3.65e-07 ***\nsexFemale        907.14     840.54   1.079   0.2862    \ndean_selected   2163.46    1072.04   2.018   0.0496 *  \nyear             434.85      78.89   5.512 1.65e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2362 on 45 degrees of freedom\nMultiple R-squared:  0.8594,\tAdjusted R-squared:  0.8407 \nF-statistic: 45.86 on 6 and 45 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nvif(fit_dean)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                  GVIF Df GVIF^(1/(2*Df))\ndegree        1.341872  1        1.158392\nrank          2.964200  2        1.312130\nsex           1.295820  1        1.138341\ndean_selected 2.678486  1        1.636608\nyear          1.726209  1        1.313853\n```\n:::\n:::\n\n\n# Question 3\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(\"house.selling.price\")\nhouse.selling.price$New <- as.factor(house.selling.price$New)\n```\n:::\n\n\n### A\n\nSize: Holding all else equal, a one square foot increase in house size adds \\$116 dollars to its sale price. This finding is statistically significant.\n\nNew: Holding all else equal, a new house sells for \\$57,736 more than an 'old' house. This finding is also statistically significant.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit <- lm(Price ~ Size + New, data = house.selling.price)\nsummary(fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Price ~ Size + New, data = house.selling.price)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-205102  -34374   -5778   18929  163866 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -40230.867  14696.140  -2.738  0.00737 ** \nSize           116.132      8.795  13.204  < 2e-16 ***\nNew1         57736.283  18653.041   3.095  0.00257 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 53880 on 97 degrees of freedom\nMultiple R-squared:  0.7226,\tAdjusted R-squared:  0.7169 \nF-statistic: 126.3 on 2 and 97 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\n### B\n\n**Combined Model**\n\n`price = -40230.867 + 116.132*x_size + 57736.283*x_new`\n\nIn this model, our price prediction is based on our intercept to -40,230.867 plus 116.132 multiplied by the house square footage plus \\$57,736 if the house is new.\n\n**New House Model**\n\n`price_new_house = 116.132*x_size + 17505.42`\n\n**Old House Model**\n\n`price_old_house = 116.132*x_size - 40230.867`\n\n\n::: {.cell}\n\n```{.r .cell-code}\n-40230.867 + 57736.283\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 17505.42\n```\n:::\n:::\n\n\n### C\n\nFind the predicted selling price for a home of 3000 square feet that is (i) new, (ii) not new.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# house size\nx_size <- 3000\n\n# new model\nprice_new_house <- 116.132*x_size + 17505.42\n\n#old house model\nprice_old_house = 116.132*x_size - 40230.867\n\ncat('New house estimate: ', price_new_house)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nNew house estimate:  365901.4\n```\n:::\n\n```{.r .cell-code}\ncat('\\n')\n```\n\n```{.r .cell-code}\ncat('Old house estimate: ', price_old_house)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nOld house estimate:  308165.1\n```\n:::\n:::\n\n\n### D\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit <- lm(Price ~ Size + New + Size*New, data = house.selling.price)\nsummary(fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Price ~ Size + New + Size * New, data = house.selling.price)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-175748  -28979   -6260   14693  192519 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -22227.808  15521.110  -1.432  0.15536    \nSize           104.438      9.424  11.082  < 2e-16 ***\nNew1        -78527.502  51007.642  -1.540  0.12697    \nSize:New1       61.916     21.686   2.855  0.00527 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 52000 on 96 degrees of freedom\nMultiple R-squared:  0.7443,\tAdjusted R-squared:  0.7363 \nF-statistic: 93.15 on 3 and 96 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\n### E\n\nNew1: Coefficient of \\$-78,537. Compared to old houses, new houses with zero square feet would sell for \\$78,527, which is not possible. This result, however, is NOT statistically significant.\n\nSize:New1: For every unit increase in size, new homes sale price will increase by 61 dollars more than an old home. This coefficient is statistically significant.\n\n### F\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnew_house <- data.frame(Size = 3000, New = 1)\nnew_house$New <- as.factor(new_house$New)\nnew_house_predicted_price <- as.numeric(predict(fit, newdata = new_house))\n\n\nold_house <- data.frame(Size = 3000, New = 0)\nold_house$New <- as.factor(old_house$New)\nold_house_predicted_price <- as.numeric(predict(fit, newdata = old_house))\n\ncat('New house predicted price: ', new_house_predicted_price)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nNew house predicted price:  398307.5\n```\n:::\n\n```{.r .cell-code}\ncat('\\n')\n```\n\n```{.r .cell-code}\ncat('Old house predicted price: ', old_house_predicted_price)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nOld house predicted price:  291087.4\n```\n:::\n:::\n\n\n### G\n\nGiven the use of our interaction term, which says that as homes increase in square footage, new homes will increase by \\$61 per square foot more than old homes. Therefore as a result, as houses get larger, the price difference between new and old homes will also get larger.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnew_house <- data.frame(Size = 1500, New = 1)\nnew_house$New <- as.factor(new_house$New)\nnew_house_predicted_price <- as.numeric(predict(fit, newdata = new_house))\n\n\nold_house <- data.frame(Size = 1500, New = 0)\nold_house$New <- as.factor(old_house$New)\nold_house_predicted_price <- as.numeric(predict(fit, newdata = old_house))\n\ncat('New house predicted price: ', new_house_predicted_price)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nNew house predicted price:  148776.1\n```\n:::\n\n```{.r .cell-code}\ncat('\\n')\n```\n\n```{.r .cell-code}\ncat('Old house predicted price: ', old_house_predicted_price)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nOld house predicted price:  134429.8\n```\n:::\n:::\n\n\n### H\n\nI prefer the model with the interaction term. While only slightly stronger in terms of its R-Squared, the model and the interaction term are simple enough to be easily interpreted. I also prefer it because 'New' by itself is not statistically significant. I feel the New variable is not 'specific' enough about what it refers to and thus not actually that useful in understanding home prices. What constitutes a new house? What happens if there is an old house that has been remodeled or has an addition?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_interaction <- lm(Price ~ Size + New + Size*New, data = house.selling.price)\nfit_no_interaction <- lm(Price ~ Size + New, data = house.selling.price)\n\nstargazer(fit_interaction, fit_no_interaction,type = \"text\",\n          title = \"New vs Old Home Prices\",\n          align = TRUE,\n          column.labels = c(\"M1:wInteraction\", \"M2:NoInteraction\"),\n          ci = TRUE, # Show confidence intervals\n          digits = 2) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nNew vs Old Home Prices\n=====================================================================\n                                   Dependent variable:               \n                    -------------------------------------------------\n                                          Price                      \n                        M1:wInteraction          M2:NoInteraction    \n                              (1)                      (2)           \n---------------------------------------------------------------------\nSize                       104.44***                116.13***        \n                        (85.97, 122.91)          (98.89, 133.37)     \n                                                                     \nNew1                       -78,527.50              57,736.28***      \n                    (-178,500.60, 21,445.64)  (21,176.99, 94,295.57) \n                                                                     \nSize:New1                   61.92***                                 \n                        (19.41, 104.42)                              \n                                                                     \nConstant                   -22,227.81             -40,230.87***      \n                     (-52,648.62, 8,193.01)  (-69,034.77, -11,426.96)\n                                                                     \n---------------------------------------------------------------------\nObservations                  100                      100           \nR2                            0.74                     0.72          \nAdjusted R2                   0.74                     0.72          \nResidual Std. Error   51,998.11 (df = 96)      53,880.95 (df = 97)   \nF Statistic          93.15*** (df = 3; 96)    126.34*** (df = 2; 97) \n=====================================================================\nNote:                                     *p<0.1; **p<0.05; ***p<0.01\n```\n:::\n:::\n",
    "supporting": [
      "asch_harwood_hw_4_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}