{
  "hash": "99ae4a153a916ff02f26b9dff416d001",
  "result": {
    "markdown": "---\ntitle: \"Homework 4\"\nauthor: \"Emma Narkewicz\"\ndescription: \"Emma Narkewicz HW4\"\ndate: \"05/01/2023\"\nformat:\n  html:\n    toc: true\n    code-fold: true\n    code-copy: true\n    code-tools: true\ncategories:\n  - hw4\n  - linear regression\n  - emma_narkewicz\neditor: \n  markdown: \n    wrap: 72\n---\n\n\n# Question 1\n\nFor recent data in Jacksonville, Florida, on y = selling price of home\n(in dollars), x1 = size of home (in square feet), and x2 = lot size (in\nsquare feet), the prediction equation is ŷ = −10,536 + 53.8x1 + 2.84x2.\n\n## A\n\nA particular home of 1240 square feet on a lot of 18,000 square feet\nsold for \\$145,000. Find the predicted selling price and the residual,\nand interpret.\n\nTo solve for the predicted price, I plugged in x1 = 1,240 & x2 = 18,000\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Predicted Price\npp <- -10536 + (53.8 * 1240) + (2.84 * 18000)  \npp\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 107296\n```\n:::\n:::\n\n\nFrom the equation, the predicted selling price of the house is \\$107,296\n\nThe residual can be calculated using the equation:\n\nResidual = (actual y-value) - (predicted y value)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Residual\n\nR = 145000 - 107296\nR\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 37704\n```\n:::\n:::\n\n\nThe residual of positive \\$37,704 indicates that the house sold for more\nthan the model predicted, meaning the model under-predicted the selling\nprice.\n\n## B\n\nFor fixed lot size, how much is the house selling price predicted to\nincrease for each square- foot increase in home size? Why?\n\nBased on the prediction equation for a fixed lot size (x2), the price of\nthe house is expected to increase \\$53.8 dollars for each square foot of\nhouse size. This is because with a fixed lot size (x2) t the 53.8x1 in\nthe prediction equation explains the increase in house price per each\nsquare foot of house size\n\nŷ = −10,536 + 53.8x1 + 2.84x2.\n\n## C\n\nAccording to this prediction equation, for fixed home size, how much\nwould lot size need to increase to have the same impact as a\none-square-foot increase in home size?\n\nHome size = x1 = 1 Lot size = x2\n\n53.81 (x1) = 2.84x2 53.8 = 2.84x2\n\n\n::: {.cell}\n\n```{.r .cell-code}\n53.8/2.84\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 18.94366\n```\n:::\n:::\n\n\nBased on the prediction equation, the lot size would need to increase by\n18.94 square feet to have the same impact as a 1-square-foot increase in\nhome size.\n\n# Question 2\n\n(Data file: salary in alr4 R package). The data file concerns salary and\nother characteristics of all faculty in a small Midwestern college\ncollected in the early 1980s for presentation in legal proceedings for\nwhich discrimination against women in salary was at issue. All persons\nin the data hold tenured or tenure track positions; temporary faculty\nare not included. The variables include degree, a factor with levels PhD\nand MS; rank, a factor with levels Asst, Assoc, and Prof; sex, a factor\nwith levels Male and Female; Year, years in current rank; ysdeg, years\nsince highest degree, and salary, academic year salary in dollars.\n\n## A {#a-1}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(alr4)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: car\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: carData\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: effects\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nlattice theme set by effectsTheme()\nSee ?effectsTheme for details.\n```\n:::\n\n```{.r .cell-code}\nhead(salary)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   degree rank    sex year ysdeg salary\n1 Masters Prof   Male   25    35  36350\n2 Masters Prof   Male   13    22  35350\n3 Masters Prof   Male   10    23  28200\n4 Masters Prof Female    7    27  26775\n5     PhD Prof   Male   19    30  33696\n6 Masters Prof   Male   16    21  28516\n```\n:::\n\n```{.r .cell-code}\nsummary(salary)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     degree      rank        sex          year            ysdeg      \n Masters:34   Asst :18   Male  :38   Min.   : 0.000   Min.   : 1.00  \n PhD    :18   Assoc:14   Female:14   1st Qu.: 3.000   1st Qu.: 6.75  \n              Prof :20               Median : 7.000   Median :15.50  \n                                     Mean   : 7.481   Mean   :16.12  \n                                     3rd Qu.:11.000   3rd Qu.:23.25  \n                                     Max.   :25.000   Max.   :35.00  \n     salary     \n Min.   :15000  \n 1st Qu.:18247  \n Median :23719  \n Mean   :23798  \n 3rd Qu.:27258  \n Max.   :38045  \n```\n:::\n:::\n\n\nTest the hypothesis that the mean salary for men and women is the same,\nwithout regard to any other variable but sex. Explain your findings.\n\nTo test the hypothesis if the mean salary for men and women is the same,\nI created a linear regression model for salary with only sex as the\nexplanatory variable.\n\nThe null hypothesis is that mean salary men and women is the same - H0:\nμm = μw\n\nThe alternative hypothesis is that the mean salary of men and women is\nnot the same - Ha: μm ≠ μw\n\n\n::: {.cell}\n\n```{.r .cell-code}\n##Hypothesis testing with linear regression only\nsummary(lm(salary ~ sex, data = salary))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = salary ~ sex, data = salary)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8602.8 -4296.6  -100.8  3513.1 16687.9 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    24697        938  26.330   <2e-16 ***\nsexFemale      -3340       1808  -1.847   0.0706 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5782 on 50 degrees of freedom\nMultiple R-squared:  0.0639,\tAdjusted R-squared:  0.04518 \nF-statistic: 3.413 on 1 and 50 DF,  p-value: 0.0706\n```\n:::\n:::\n\n\nThe resulting coefficient for the sexFemale explanatory variable is\n-3340, suggesting Female staff make on average \\$3,340 less than Male\nprofessors. In the linear regression model, sexFemale has a p-value of\n0.0706 meaning at the 0.05 level we fail to reject the null hypothesis\nthat there is no difference in the mean salaries for men and women. We\ncould however reject the null hypothesis at the 0.1 significance level.\n\n## B\n\nRun a multiple linear regression with salary as the outcome variable and\neverything else as predictors, including sex. Assuming no interactions\nbetween sex and the other predictors, obtain a 95% confidence interval\nfor the difference in salary between males and females.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n##95% confidence interval\nlm(salary ~ degree + rank + sex + ysdeg + year, data = salary) |> confint()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                 2.5 %      97.5 %\n(Intercept) 14134.4059 17357.68946\ndegreePhD    -663.2482  3440.47485\nrankAssoc    2985.4107  7599.31080\nrankProf     8396.1546 13841.37340\nsexFemale    -697.8183  3030.56452\nysdeg        -280.6397    31.49105\nyear          285.1433   667.47476\n```\n:::\n:::\n\n\nThe 95% confidence interval for the sexFemale is (-663, 3340) which can\nbe interpreted as women making between \\$663 less or \\$3340 more than\ntheir male colleagues.\n\nCompared to to the coefficient of -3340 in the model with only sex as an\nexplanatory variable, this suggests that controlling for rank, degree,\nyears since degree, and years of experience explains some of the\ndifference between male and female salaries.\n\n## C\n\nInterpret your finding for each predictor variable; discuss (a)\nstatistical significance, (b) interpretation of the coefficient / slope\nin relation to the outcome variable and other variables\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary (lm(salary ~ degree + rank + sex + ysdeg + year, data = salary))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = salary ~ degree + rank + sex + ysdeg + year, data = salary)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4045.2 -1094.7  -361.5   813.2  9193.1 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 15746.05     800.18  19.678  < 2e-16 ***\ndegreePhD    1388.61    1018.75   1.363    0.180    \nrankAssoc    5292.36    1145.40   4.621 3.22e-05 ***\nrankProf    11118.76    1351.77   8.225 1.62e-10 ***\nsexFemale    1166.37     925.57   1.260    0.214    \nysdeg        -124.57      77.49  -1.608    0.115    \nyear          476.31      94.91   5.018 8.65e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2398 on 45 degrees of freedom\nMultiple R-squared:  0.855,\tAdjusted R-squared:  0.8357 \nF-statistic: 44.24 on 6 and 45 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\n-   degree PhD has a p=value of 0.180, meaning it is not statistically\n    significant at the 0.1 or 0.05 level. It has a positive coefficient\n    of 1388.61 suggesting that that having a PhD increases a person's\n    salary by \\$1388 over having a Master's degree. This is the 3rd\n    largest coefficient of any of the explanatory variables in the\n    model.\n\n-   rankAssoc has as p-value of 3.22 \\* e\\^-05, meaning it a\n    statistically significant explanatory variable at the 0.001 level.\n    It has a positive coefficient of 5293.36 suggesting that being an\n    associate professor results in \\$5292 larger salary than an\n    Assistant professor. This is the 2nd largest coefficient of any of\n    the explanatory variables in the model.\n\n-   rankProf has a p-value of 1.62 \\* e\\^-10, meaning it is a\n    statistically significant explanatory variable at the 0.001 level.\n    It has a positive coefficient of 11,118, suggesting that having a\n    rank of full professorship results in a salary of \\$11,118 more than\n    an Assistant professor. This is the largest coefficient of any of\n    the explanatory variables in the model, suggesting it is responsible\n    for the largest change in salary of any variable in the model.\n\n-   sexFemale has a p-value of 0.214, meaning it is not statistically\n    significant at the 0.1 or 0.05 level. The coefficient of 1166\n    suggests that being female increases salary by \\$1166, which is\n    surprising given the well-known phenomenon of the wage gap.\n\n-   ysdeg has a p-value of 0.115, meaning it is not statistically\n    significant at the 0.1 or 0.05 level. The coefficient of -124\n    suggests that every year since getting a degree, an individual's\n    salary decreases by \\$124.\n\n-   year has a p-value of 8.65 \\* e\\^-06, meaning it is statistically\n    significant at the 0.001 level. The coefficient of 476 suggests that\n    that every year someone is in their job as a professor, their salary\n    increases by \\$476.\n\n## D\n\nChange the baseline category for the rank variable. Interpret the\ncoefficients related to rank again.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Relevel \nsalary$rank <- relevel(salary$rank, ref = 'Prof')\nsummary (lm(salary ~ degree + rank + sex + ysdeg + year, data = salary))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = salary ~ degree + rank + sex + ysdeg + year, data = salary)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4045.2 -1094.7  -361.5   813.2  9193.1 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  26864.81    1375.29  19.534  < 2e-16 ***\ndegreePhD     1388.61    1018.75   1.363    0.180    \nrankAsst    -11118.76    1351.77  -8.225 1.62e-10 ***\nrankAssoc    -5826.40    1012.93  -5.752 7.28e-07 ***\nsexFemale     1166.37     925.57   1.260    0.214    \nysdeg         -124.57      77.49  -1.608    0.115    \nyear           476.31      94.91   5.018 8.65e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2398 on 45 degrees of freedom\nMultiple R-squared:  0.855,\tAdjusted R-squared:  0.8357 \nF-statistic: 44.24 on 6 and 45 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\nAfter re-leveling the rank to Prof instead of Assistant professor and\nre-running the linear regression model, rankAsst now has a coefficient\nof -11118 and rankAssociate has a coefficient of -5826. This means an\nAssistant professor makes \\$11,118 less than a full professsor and a an\nAssociate professor makes \\$5,826 less than a full professors. These are\nthe same coefficients for the rankProf and RankAssoc in the previous\nmodel, expect negative, as they now represent the distance from the top\nrank (professor) as opposed to the lowest rank (assistant).\n\n## E\n\nFinkelstein (1980), in a discussion of the use of regression in\ndiscrimination cases, wrote, \"[a](#a-1) variable may reflect a position\nor status bestowed by the employer, in which case if there is\ndiscrimination in the award of the position or status, the variable may\nbe 'tainted.'\" Thus, for example, if discrimination is at work in\npromotion of faculty to higher ranks, using rank to adjust salaries\nbefore comparing the sexes may not be acceptable to the courts.\n\nExclude the variable rank, refit, and summarize how your findings\nchanged, if they did.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Rerun model excluding rank\nsummary (lm(salary ~ degree + sex + ysdeg + year, data = salary))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = salary ~ degree + sex + ysdeg + year, data = salary)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8146.9 -2186.9  -491.5  2279.1 11186.6 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 17183.57    1147.94  14.969  < 2e-16 ***\ndegreePhD   -3299.35    1302.52  -2.533 0.014704 *  \nsexFemale   -1286.54    1313.09  -0.980 0.332209    \nysdeg         339.40      80.62   4.210 0.000114 ***\nyear          351.97     142.48   2.470 0.017185 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3744 on 47 degrees of freedom\nMultiple R-squared:  0.6312,\tAdjusted R-squared:  0.5998 \nF-statistic: 20.11 on 4 and 47 DF,  p-value: 1.048e-09\n```\n:::\n:::\n\n\nRerunning the model excluding rank changes the coefficient of sexFemale\nto negative -1286, from previously being positive +1166. However, with a\np-value of 0.332 the explanatory variable of sexFemale is still not\nstatistically significant at any level after removing rank.\n\n## F\n\nEveryone in this data set was hired the year they earned their highest\ndegree. It is also known that a new Dean was appointed 15 years ago, and\neveryone in the data set who earned their highest degree 15 years ago or\nless than that has been hired by the new Dean. Some people have argued\nthat the new Dean has been making offers that are a lot more generous to\nnewly hired faculty than the previous one and that this might explain\nsome of the variation in Salary.\n\nCreate a new variable that would allow you to test this hypothesis and\nrun another multiple regression model to test this. Select variables\ncarefully to make sure there is no multicollinearity. Explain why\nmulticollinearity would be a concern in this case and how you avoided\nit. Do you find support for the hypothesis that the people hired by the\nnew Dean are making higher than those that were not?\n\nI created a new variable \"New_Dean\" where anyone who earned their\nhighest degree (ysdeg) over 15 years ago are coded as a 0 & anyone who\nearned their highest degree (ysdeg) 15 or less years ago coded as a 1.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#recreating new variable\nsalary_Dean <- salary %>%\n  mutate(New_Dean = case_when(\n    ysdeg > 15 ~ \"0\",\n    ysdeg <= 15 ~ \"1\"))\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in salary %>% mutate(New_Dean = case_when(ysdeg > 15 ~ \"0\", ysdeg <= : could not find function \"%>%\"\n```\n:::\n\n```{.r .cell-code}\nsalary_Dean\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in eval(expr, envir, enclos): object 'salary_Dean' not found\n```\n:::\n:::\n\n\nMulticollinearity occurs when one explanatory variable is predicted by\nanother variable in the model to a substantial degree. This can be\ncaused by an explanatory variable is a combination of another variable\nin the model or there are two almost identical variables in the model.\n\nTo avoid multicollinearity in this model while testing if being hired by\nthe New Dean results in a higher salary, I will not include ysdeg in the\nlinear regression model. This is because the New Dean explanatory\nvariable was created from the ysdeg model, meaning that they are likely\nsubstantially correlated.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n##Testing New Dean Hypothesis after removing ysdeg\nsummary (lm(salary ~ degree + rank + sex + New_Dean + year, data = salary_Dean))\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in is.data.frame(data): object 'salary_Dean' not found\n```\n:::\n:::\n\n\nAccording to the linear regression model, having been hired by the New\nDean does result in a higher salary of \\$2,163, as indicated by the\ncoefficient to this variable. Furthermore, the New Dean explanatory\nvariable is just barely statistically significant at the 0.05 level with\na p-value of 0.0496.\n\n# Question 3\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Load data\nlibrary(smss)\ndata(\"house.selling.price\")\nhead(house.selling.price)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  case Taxes Beds Baths New  Price Size\n1    1  3104    4     2   0 279900 2048\n2    2  1173    2     1   0 146500  912\n3    3  3076    4     2   0 237700 1654\n4    4  1608    3     2   0 200000 2068\n5    5  1454    3     3   0 159900 1477\n6    6  2997    3     2   1 499900 3153\n```\n:::\n\n```{.r .cell-code}\nsummary(house.selling.price)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      case            Taxes           Beds       Baths           New      \n Min.   :  1.00   Min.   :  20   Min.   :2   Min.   :1.00   Min.   :0.00  \n 1st Qu.: 25.75   1st Qu.:1178   1st Qu.:3   1st Qu.:2.00   1st Qu.:0.00  \n Median : 50.50   Median :1614   Median :3   Median :2.00   Median :0.00  \n Mean   : 50.50   Mean   :1908   Mean   :3   Mean   :1.96   Mean   :0.11  \n 3rd Qu.: 75.25   3rd Qu.:2238   3rd Qu.:3   3rd Qu.:2.00   3rd Qu.:0.00  \n Max.   :100.00   Max.   :6627   Max.   :5   Max.   :4.00   Max.   :1.00  \n     Price             Size     \n Min.   : 21000   Min.   : 580  \n 1st Qu.: 93225   1st Qu.:1215  \n Median :132600   Median :1474  \n Mean   :155331   Mean   :1629  \n 3rd Qu.:169625   3rd Qu.:1865  \n Max.   :587000   Max.   :4050  \n```\n:::\n:::\n\n\n## A\n\nUsing the house.selling.price data, run and report regression results\nmodeling y = selling price (in dollars) in terms of size of home (in\nsquare feet) and whether the home is new (1 = yes; 0 = no). In\nparticular, for each variable; discuss statistical significance and\ninterpret the meaning of the coefficient.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#linear regression model y = selling price, explanatory variables = Size & New\nsummary(lm(Price ~ Size + New, data = house.selling.price))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Price ~ Size + New, data = house.selling.price)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-205102  -34374   -5778   18929  163866 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -40230.867  14696.140  -2.738  0.00737 ** \nSize           116.132      8.795  13.204  < 2e-16 ***\nNew          57736.283  18653.041   3.095  0.00257 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 53880 on 97 degrees of freedom\nMultiple R-squared:  0.7226,\tAdjusted R-squared:  0.7169 \nF-statistic: 126.3 on 2 and 97 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\n-   *Size* of a house statistically significant at the 0.0001 level with\n    a p-value less than 2 \\* e\\^-16. The coefficient of the Size\n    variable is 116 suggesting that for every square-foot the size of a\n    house increases, the predicted price increases by \\$116.\n\n-   *New* The newness of a house is statistically significant at the\n    0.05 level with a p-value of 0.00257. The coefficient of 57735\n    suggests that the predicted price of a new house is \\$57736.283 more\n    than a house than is not new.\n\n## B\n\nReport and interpret the prediction equation, and form separate\nequations relating selling price to size for new and for not new homes.\n\nY = -40230.867 + 116.132(x1) + 57726.263(x2)\n\nwhere x1 = size of house in square feet, x2 = if a house is new (1 =\nyes, 0 = no)\n\nThis prediction equation can be interpreted that the predicted price of\na house in \\$ can be calculated by multiplying the size of the house in\nsquare feet by \\~ \\$116, subtracting the intercept of -\\$40,230 from the\nprice, and adding \\$57,726 if the house is new.\n\nSeperate equations for the selling price for new and not new houses can\nbe generated by subbing in x2 =1 for new houses and x2 =0 for not new\nhouses and calculating the resulting equation\n\nYnew house = -40230.867 + 116.132(x1) + 57726.263(1) = -40,230.867 +\n57,726.263 + 116.132 (x1) *Ynew house = 17495.4 + 116.132(x1)* *where x1\n= size of house in square-feet*\n\nThis equation can be interpreted as the Predicted Price of a new house\nin dollars can be calculated from \\$17;495 + \\$116 for every square foot\nin size the house is.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#substraction of intercepts\n57726.263 - 40230.867\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 17495.4\n```\n:::\n:::\n\n\nYnot new = -40230.867 + 116.132(x1) + 57726.263(0) = -40230.867 +\n116.132(x1) + 0\n\n\\*Ynotnew = -40230.867 + 116.132(x1) \\*\\* *where x1 = size of house in\nsquare-feet*\n\nThis equation can be interpreted as the price of a not-new house in\ndollars is calculated as \\$116 for every square-foot a house increases\nin size, minus \\$40,230.\n\n## C\n\nFind the predicted selling price for a home of 3000 square feet that is\n(i) new, (ii) not new.\n\ni.  for a new house where x1 = 3000 Y = 17495.4 + 116.132(x1) Y =\n    17495.4 + 116.132 (3000)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Arithmitic\n116.132 * 3000\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 348396\n```\n:::\n\n```{.r .cell-code}\n348396 + 17495.4 \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 365891.4\n```\n:::\n:::\n\n\nY = 17495.4 + 34896 Y = 365891.4 *The predicted price of a new house\nwith a size of 3000 square feet is \\$365,891.4*\n\nii. For a non-new house where x1 = 3000 Y = -40230.867 + 116.132(x1) Y =\n    = -40230.867 + 116.132(3000)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Arithmetic\n116.132 * 3000\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 348396\n```\n:::\n\n```{.r .cell-code}\n348396 - 40230.867\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 308165.1\n```\n:::\n:::\n\n\n    Y = -40230.867 + 348396\n    Y = 308165.1\n\n*The predicted price of a not new house with a size of 3000 square feet\nis \\$308,165.1*\n\n## D\n\nFit another model, this time with an interaction term allowing\ninteraction between size and new, and report the regression results\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#linear regression model y = selling price, explanatory variables = Interaction Size * New\nsummary(lm(Price ~ Size * New, data = house.selling.price))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Price ~ Size * New, data = house.selling.price)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-175748  -28979   -6260   14693  192519 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -22227.808  15521.110  -1.432  0.15536    \nSize           104.438      9.424  11.082  < 2e-16 ***\nNew         -78527.502  51007.642  -1.540  0.12697    \nSize:New        61.916     21.686   2.855  0.00527 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 52000 on 96 degrees of freedom\nMultiple R-squared:  0.7443,\tAdjusted R-squared:  0.7363 \nF-statistic: 93.15 on 3 and 96 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\nIn the model with the interaction between Size \\* New, the Adjusted\nR-squared of the model is 0.7363 as opposed to the model with Size & New\nas explanatory variables without an interaction, which had an adjusted\nR-squared of 0.7169. In the interaction model:\n\n-   *Size* has a p-value of less than 2\\*e-\\^16, being statistically\n    significant at the 0.05 level. The coefficient of 104.438 suggest\n    that the price of the house increases \\$104 for every square foot a\n    house increases in size\n\n-   *New* has a p-value of 0.12697, not being statistically significant\n    at the 0.05 or 0.1 levels. The coefficient of -78527.502 suggests\n    that if a house is new, regardless of size, the predicted price of\n    the house decreases by \\$78527. In the previous model without the\n    interaction between new & size, new had a positive coefficient and\n    was statistically significant.\n\n-   *Size x New* has a p-value of 0.00527, which is statistically\n    significant at the 0.01 level. This suggests there is a interaction\n    between the newness of a house and the size of a house. The\n    coefficient of 61.916 suggests the predicted price of only new\n    houses increases by \\$61.9 for each square foot the size of the\n    house increases.\n\nWritten out as an equation for predicted price, where x1 = size of house\nin square feet & x2 = newness of house\n\n*Y = -22227.808 + 104.438(x1) - 78527.502(x2) + 61.916(x1)(x2)*\n\n## E\n\nReport the lines relating the predicted selling price to the size for\nhomes that are (i) new, (ii) not new.\n\n-   \n\n    (i) new, x2 = 1. Plugging that into the prediction equation: Y =\n        -22227.808 + 104.438(x1) - 78527.502(x2) + 61.916(x1)(x2) Y =\n        -22227.808 + 104.438(x1) - 78527.502(1) + 61.916(x1)(1) Y =\n        -22227.808 + 104.438(x1) - 78527.502 + 61.916(x1)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Arithmetic\n-22227.808 -78527.502\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -100755.3\n```\n:::\n\n```{.r .cell-code}\n104.438 + 61.916\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 166.354\n```\n:::\n:::\n\n\n*Ynew = -100755.3 + 166.354(x1)*\n\n-   \n\n    (ii) not new, x2 = 0. Plugging that into the prediction equation: Y\n         = -22227.808 + 104.438(x1) - 78527.502(0) + 61.916(x1)(0) Y =\n         -22227.808 + 104.438(x1) - 0 + 0 *Ynotnew = -22227.808 +\n         104.438(x1)*\n\n## F\n\nFind the predicted selling price for a home of 3000 square feet that is\n(i) new, (ii) not new.\n\n-   \n\n    (i) new, x1 = 3000 square feet Ynew = -100755.3 + 166.354(x1) Ynew =\n        -100755.3 + 166.354(3000)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n166.354 * 3000 \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 499062\n```\n:::\n:::\n\n\nYnew = -100755.3 + 499062\n\n\n::: {.cell}\n\n```{.r .cell-code}\n-100755.3 + 499062\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 398306.7\n```\n:::\n:::\n\n\nYnew = 398306.7 *The predicted selling price of a new house 3000 square\nfeet in size is \\$398306.7*\n\n-   \n\n    (ii) not new, x1 = 3000 square feet Ynotnew = -22227.808 +\n         104.438(x1) Ynotnew = -22227.808 + 104.438(3000)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n104.438 * 3000\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 313314\n```\n:::\n:::\n\n\nYnotnew = -22227.808 + 313314\n\n\n::: {.cell}\n\n```{.r .cell-code}\n-22227.808 + 313314\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 291086.2\n```\n:::\n:::\n\n\nYnotnew = 291086.2 *The predicted selling price of a not new house 3000\nsquare feet in size is \\$291,086.2*\n\n## G\n\nFind the predicted selling price for a home of 1500 square feet that is\n(i) new, (ii) not new. Comparing to (F), explain how the difference in\npredicted selling prices changes as the size of home increases.\n\n-   \n\n    (i) new, x1 = 1500 square feet Ynew = -100755.3 + 166.354(x1) Ynew =\n        -100755.3 + 166.354(1500)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n166.354 * 1500\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 249531\n```\n:::\n:::\n\n\nYnew = -100755.3 + 249531\n\n\n::: {.cell}\n\n```{.r .cell-code}\n-100755.3 + 249531\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 148775.7\n```\n:::\n:::\n\n\nYnew = 148775.7\n\n*The predicted selling price of a new house 1500 square feet in size is\n\\$148,775.7*\n\n-   \n\n    (ii) not new, x1 = 1500 square feet Ynotnew = -22227.808 +\n         104.438(x1) Ynotnew = -22227.808 + 104.438(1500)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n 104.438 * 1500\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 156657\n```\n:::\n:::\n\n\nYnotnew = -22227.808 + 156657\n\n\n::: {.cell}\n\n```{.r .cell-code}\n-22227.808 + 156657\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 134429.2\n```\n:::\n:::\n\n\nYnotnew = 134429.2 *The predicted selling price of a not new house 1500\nsquare feet in size is \\$ 134429.2*\n\n-   Difference in prices new & not new by size\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Difference new, not new x1 = 3000 square feet\n398306.7 - 291086.2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 107220.5\n```\n:::\n\n```{.r .cell-code}\n##Difference new, not new x1 = 1500 square feet\n 148775.7 - 134429.2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 14346.5\n```\n:::\n\n```{.r .cell-code}\n#Division \n107220.5/14346.5\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 7.473635\n```\n:::\n:::\n\n\nThe difference between the price of a new & not house 3000 feet in size\nis \\$107,220.5\n\nThe difference between the price of a new & not new house 1500 feet in\nsize is \\$14,346.5\n\nA house that is 3000 square feet in size is twice the size of a house\n1500 square feet in size, the difference between a new & not new houses\nis 7.473635x more for a house that is 3000 square feet than a house that\nis 15000 square feet in size. This suggests that the larger the size of\na house the more influence the newness of a house has on price.\n\n## H\n\nDo you think the model with interaction or the one without it represents\nthe relationship of size and new to the outcome price? What makes you\nprefer one model over another?\n\nBased on the statistical significance of the interaction between\nNew:Size at the 0.001 level & the higher Adjusted R-Squared of the model\nwith the interaction term 0.7363) than the adjusted R-squared of the\nmodel without the interaction term (0.7169) both make me prefer the\nmodel with the interacction term over the other interms of best\nrepresenting the relationship of size and new to the outcome price.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}