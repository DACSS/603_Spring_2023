{
  "hash": "3255458b5e555485af32fdf67eb3da4a",
  "result": {
    "markdown": "---\ntitle: \"HW4\"\nauthor: \"Liam Tucksmith\"\ndesription: \"HW4\"\ndate: \"05/12/2023\"\nformat:\n  html:\n    toc: true\n    code-fold: true\n    code-copy: true\n    code-tools: true\ncategories:\n  - hw4\n  - Liam Tucksmith\n\neditor_options: \n  markdown: \n    wrap: 72\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(smss)\nlibrary(alr4)\nknitr::opts_chunk$set(echo = TRUE)\n```\n:::\n\n1.  For recent data in Jacksonville, Florida, on y = selling price of\n    home (in dollars), x1 = size of home(in square feet), and x2 = lot\n    size (in square feet), the prediction equation is y = ???10,536 +\n    53.8x1 + 2.84x2.\n\nA. A particular home of 1240 square feet on a lot of 18,000 square feet\nsold for \\$145,000. Find the predicted selling price and the residual,\nand interpret.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx1 <- 1240\nx2 <- 18000\ny <- 145000\n\npredicted <- (-10536 + 53.8*(x1) + 2.84*(x2))\nresidual <- y - predicted\nprint(predicted)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 107296\n```\n:::\n\n```{.r .cell-code}\nprint(residual)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 37704\n```\n:::\n:::\n\n\nThe predicted value is lower than the actual value, indicating that the\nequation is undervaluing the homes.\n\nB. For fixed lot size, how much is the house selling price predicted to\nincrease for each square- foot increase in home size? Why?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx1 <- 1240\nx2 <- 18000\ny <- 145000\n\nfixed_price <- (-10536 + 53.8*(x1) + 2.84*(x2))\n\nx1 <- 1241\nfixed_price_sqft_inc <- (-10536 + 53.8*(x1) + 2.84*(x2))\n\nprint(fixed_price_sqft_inc - fixed_price)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 53.8\n```\n:::\n:::\n\n\nUsing the numbers from part A, we can see that a 1 sqft increase results\nin a \\$53.80 predicted sell price increase when the lot size is fixed.\n\nC. According to this prediction equation, for fixed home size, how much\nwould lot size need to increase to have the same impact as a\none-square-foot increase in home size?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhome_size_inc <- fixed_price_sqft_inc - fixed_price\n\nx1 <- 1240\nx2 <- 18000\ny <- 145000\n\nfixed_price_c <- (-10536 + 53.8*(x1) + 2.84*(x2))\n\nlot_inc_pred <- fixed_price_c + home_size_inc\npart1 <- (-10536 + 53.8*(x1))\n```\n:::\n\n\npart1 + 2.84*((x2)+z) = lot_inc_pred (lot_inc_pred - part1)=\n(((x2)+z)*2.84)/2.84 (lot_inc_pred - part1)/2.84 = (x2)+z\n\n\n::: {.cell}\n\n```{.r .cell-code}\nz <- (lot_inc_pred - part1)/2.84 - x2\nprint(z)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 18.94366\n```\n:::\n:::\n\n\nTo have an impact of a 1 sqft increase in home size, lot size would have\nto increase by 18.9 sqft.\n\n2 (Data file: salary in alr4 R package). The data file concerns salary\nand other characteristics of all faculty in a small Midwestern college\ncollected in the early 1980s for presentation in legal proceedings for\nwhich discrimination against women in salary was at issue. All persons\nin the data hold tenured or tenure track positions; temporary faculty\nare not included. The variables include degree, a factor with levels PhD\nand MS; rank, a factor with levels Asst, Assoc, and Prof; sex, a factor\nwith levels Male and Female; Year, years in current rank; ysdeg, years\nsince highest degree, and salary, academic year salary in dollars.\n\nA. Test the hypothesis that the mean salary for men and women is the\nsame, without regard to any other variable but sex. Explain your\nfindings.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(lm(salary ~ sex, data = salary))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = salary ~ sex, data = salary)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8602.8 -4296.6  -100.8  3513.1 16687.9 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    24697        938  26.330   <2e-16 ***\nsexFemale      -3340       1808  -1.847   0.0706 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5782 on 50 degrees of freedom\nMultiple R-squared:  0.0639,\tAdjusted R-squared:  0.04518 \nF-statistic: 3.413 on 1 and 50 DF,  p-value: 0.0706\n```\n:::\n:::\n\n\nOn average, the women make \\$3340 less than the men. The p-value of 0.07\nindicates that this relationship is not statistically significant at the\n.05 level.\n\nB. Run a multiple linear regression with salary as the outcome variable\nand everything else as predictors, including sex. Assuming no\ninteractions between sex and the other predictors, obtain a 95%\nconfidence interval for the difference in salary between males and\nfemales.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(lm(salary ~ ., data = salary))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = salary ~ ., data = salary)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4045.2 -1094.7  -361.5   813.2  9193.1 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 15746.05     800.18  19.678  < 2e-16 ***\ndegreePhD    1388.61    1018.75   1.363    0.180    \nrankAssoc    5292.36    1145.40   4.621 3.22e-05 ***\nrankProf    11118.76    1351.77   8.225 1.62e-10 ***\nsexFemale    1166.37     925.57   1.260    0.214    \nyear          476.31      94.91   5.018 8.65e-06 ***\nysdeg        -124.57      77.49  -1.608    0.115    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2398 on 45 degrees of freedom\nMultiple R-squared:  0.855,\tAdjusted R-squared:  0.8357 \nF-statistic: 44.24 on 6 and 45 DF,  p-value: < 2.2e-16\n```\n:::\n\n```{.r .cell-code}\nconfint(lm(salary ~ ., data = salary))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                 2.5 %      97.5 %\n(Intercept) 14134.4059 17357.68946\ndegreePhD    -663.2482  3440.47485\nrankAssoc    2985.4107  7599.31080\nrankProf     8396.1546 13841.37340\nsexFemale    -697.8183  3030.56452\nyear          285.1433   667.47476\nysdeg        -280.6397    31.49105\n```\n:::\n:::\n\n\nC. Interpret your finding for each predictor variable; discuss (a)\nstatistical significance, (b) interpretation of the coefficient / slope\nin relation to the outcome variable and other variables\n\ndegreePhD - Not statistically significant. The coefficient of \\$1388\nsuggests that the faculty with phDs have, on avergage, a salary \\$1388\nhigher than faculty with masters.\n\nrankAssoc - Statistically significant. The coefficient of \\$5292\nsuggests that the faculty with associate rank have, on avergage, a\nsalary \\$5292 higher than faculty with assistant rank.\n\nrankProf - Statistically significant. The coefficient of \\$11118\nsuggests that the faculty with phDs have, on avergage, a salary \\$11118\nhigher than faculty with assistant rank.\n\nsexFemale - Not statistically significant. The coefficient of \\$1166\nsuggests that the female faculty have, on avergage, a salary \\$1166\nhigher than male faculty.\n\nyear - Statistically significant. The coefficient of \\$476 suggests that\nthe faculty gain \\$476 in salary each additional year worked.\n\nysdeg - Not statistically significant. The coefficient of -\\$124\nsuggests that the faculty with phDs have, on avergage, a salary -\\$124\nlower with each passing year since high school graduation.\n\nD. Change the baseline category for the rank variable. Interpret the\ncoefficients related to rank again.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsalary$rank <- relevel(salary$rank, ref = 'Prof')\nsummary(lm(salary ~ ., data = salary))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = salary ~ ., data = salary)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4045.2 -1094.7  -361.5   813.2  9193.1 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  26864.81    1375.29  19.534  < 2e-16 ***\ndegreePhD     1388.61    1018.75   1.363    0.180    \nrankAsst    -11118.76    1351.77  -8.225 1.62e-10 ***\nrankAssoc    -5826.40    1012.93  -5.752 7.28e-07 ***\nsexFemale     1166.37     925.57   1.260    0.214    \nyear           476.31      94.91   5.018 8.65e-06 ***\nysdeg         -124.57      77.49  -1.608    0.115    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2398 on 45 degrees of freedom\nMultiple R-squared:  0.855,\tAdjusted R-squared:  0.8357 \nF-statistic: 44.24 on 6 and 45 DF,  p-value: < 2.2e-16\n```\n:::\n\n```{.r .cell-code}\nconfint(lm(salary ~ ., data = salary))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                  2.5 %      97.5 %\n(Intercept)  24094.8394 29634.78404\ndegreePhD     -663.2482  3440.47485\nrankAsst    -13841.3734 -8396.15463\nrankAssoc    -7866.5550 -3786.25144\nsexFemale     -697.8183  3030.56452\nyear           285.1433   667.47476\nysdeg         -280.6397    31.49105\n```\n:::\n:::\n\n\nNothing changed, the model displays the same information, just with\ndifferent variables. Here, the coefficients tell us that assistant\nfaculty members make \\$11118 less than professors, and associate faculty\nmembers make \\$7866 less than professors.\n\nE. Finkelstein (1980), in a discussion of the use of regression in\ndiscrimination cases, wrote, \"\\[a\\] variable may reflect a position or\nstatus bestowed by the employer, in which case if there is\ndiscrimination in the award of the position or status, the variable may\nbe 'tainted.' \" Thus, for example, if discrimination is at work in\npromotion of faculty to higher ranks, using rank to adjust salaries\nbefore comparing the sexes may not be acceptable to the courts. Exclude\nthe variable rank, refit, and summarize how your findings changed, if\nthey did.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(lm(salary ~ . -rank, data = salary))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = salary ~ . - rank, data = salary)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8146.9 -2186.9  -491.5  2279.1 11186.6 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 17183.57    1147.94  14.969  < 2e-16 ***\ndegreePhD   -3299.35    1302.52  -2.533 0.014704 *  \nsexFemale   -1286.54    1313.09  -0.980 0.332209    \nyear          351.97     142.48   2.470 0.017185 *  \nysdeg         339.40      80.62   4.210 0.000114 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3744 on 47 degrees of freedom\nMultiple R-squared:  0.6312,\tAdjusted R-squared:  0.5998 \nF-statistic: 20.11 on 4 and 47 DF,  p-value: 1.048e-09\n```\n:::\n:::\n\n\nThe sex coefficient flipped to show that females make -\\$1286 less than\nmales, but it's still not statistically signigicant.\n\nF. Everyone in this dataset was hired the year they earned their highest\ndegree. It is also known that a new Dean was appointed 15 years ago, and\neveryone in the dataset who earned their highest degree 15 years ago or\nless than that has been hired by the new Dean. Some people have argued\nthat the new Dean has been making offers that are a lot more generous to\nnewly hired faculty than the previous one and that this might explain\nsome of the variation in Salary.\n\nCreate a new variable that would allow you to test this hypothesis and\nrun another multiple regression model to test this. Select variables\ncarefully to make sure there is no multicollinearity. Explain why\nmulticollinearity would be a concern in this case and how you avoided\nit. Do you find support for the hypothesis that the people hired by the\nnew Dean are making higher than those that were not?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsalary$yrs_since_dean <- ifelse(salary$ysdeg <= 15, 1, 0)\ncor.test(salary$yrs_since_dean, salary$ysdeg)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tPearson's product-moment correlation\n\ndata:  salary$yrs_since_dean and salary$ysdeg\nt = -11.101, df = 50, p-value = 4.263e-15\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.9074548 -0.7411040\nsample estimates:\n       cor \n-0.8434239 \n```\n:::\n\n```{.r .cell-code}\nsummary(lm(salary ~ . -ysdeg, data = salary))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = salary ~ . - ysdeg, data = salary)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3403.3 -1387.0  -167.0   528.2  9233.8 \n\nCoefficients:\n                Estimate Std. Error t value Pr(>|t|)    \n(Intercept)     24425.32    1107.52  22.054  < 2e-16 ***\ndegreePhD         818.93     797.48   1.027   0.3100    \nrankAsst       -11096.95    1191.00  -9.317 4.54e-12 ***\nrankAssoc       -6124.28    1028.58  -5.954 3.65e-07 ***\nsexFemale         907.14     840.54   1.079   0.2862    \nyear              434.85      78.89   5.512 1.65e-06 ***\nyrs_since_dean   2163.46    1072.04   2.018   0.0496 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2362 on 45 degrees of freedom\nMultiple R-squared:  0.8594,\tAdjusted R-squared:  0.8407 \nF-statistic: 45.86 on 6 and 45 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\n3.  Looking at the yrs_since_dean variable, the p-value is statistically\n    significant and the positive coefficient, both supporting the\n    hypothesis that the dean has been offering higher salaries to newer\n    faculty.\n\n(Data file: house.selling.price in smss R package)\n\nA. Using the house.selling.price data, run and report regression results\nmodeling y = selling price (in dollars) in terms of size of home (in\nsquare feet) and whether the home is new (1 = yes; 0 = no). In\nparticular, for each variable; discuss statistical significance and\ninterpret the meaning of the coefficient.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(\"house.selling.price\")\nsummary(lm(Price ~ Size + New, data = house.selling.price))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Price ~ Size + New, data = house.selling.price)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-205102  -34374   -5778   18929  163866 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -40230.867  14696.140  -2.738  0.00737 ** \nSize           116.132      8.795  13.204  < 2e-16 ***\nNew          57736.283  18653.041   3.095  0.00257 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 53880 on 97 degrees of freedom\nMultiple R-squared:  0.7226,\tAdjusted R-squared:  0.7169 \nF-statistic: 126.3 on 2 and 97 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\nBoth Size and New are statistically significant in this model, and both\nhave positive coefficients. For New, this indicates that new houses are,\non average, \\$57736 more expensive than non-new. And for Size, a 1 sqft\nincrease in size indicates a \\$116 increase in sell price.\n\nB. Report and interpret the prediction equation, and form separate\nequations relating selling price to size for new and for not new homes.\n\nselling price prediction = -40230 + 116(size) + 57736(new)\n\nThe prediction equation indicates that while controlling for size and\nwhether or not the size of the car is new, the prediction on average is\n\\$40230 lower than the actual selling price.\n\nNew: selling price prediction = -40230 + 116(size) + 57736\n\nNot new: selling price prediction = -40230 + 116(size)\n\nC. Find the predicted selling price for a home of 3000 square feet that\nis (i) new, (ii) not new.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnew_prediction <- -40230 + 116*(3000) + 57736\nnot_new_prediction <- -40230 + 116*(3000)\n\nprint(new_prediction)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 365506\n```\n:::\n\n```{.r .cell-code}\nprint(not_new_prediction)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 307770\n```\n:::\n:::\n\n\nD. Fit another model, this time with an interaction term allowing\ninteraction between size and new, and report the regression results\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(lm(Price ~ Size + New + (Size * New), data = house.selling.price))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Price ~ Size + New + (Size * New), data = house.selling.price)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-175748  -28979   -6260   14693  192519 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -22227.808  15521.110  -1.432  0.15536    \nSize           104.438      9.424  11.082  < 2e-16 ***\nNew         -78527.502  51007.642  -1.540  0.12697    \nSize:New        61.916     21.686   2.855  0.00527 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 52000 on 96 degrees of freedom\nMultiple R-squared:  0.7443,\tAdjusted R-squared:  0.7363 \nF-statistic: 93.15 on 3 and 96 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\nE. Report the lines relating the predicted selling price to the size for\nhomes that are (i) new, (ii) not new.\n\nNew: selling price prediction = -22228 + 104(size) - 78528 + 62(size) =\n-100756 + 168(size)\n\nNot new: selling price prediction = -22228 + 104(size)\n\nF. Find the predicted selling price for a home of 3000 square feet that\nis (i) new, (ii) not new.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnew_prediction <- -100756 + 168*(3000)\nnot_new_prediction <- 22228 + 104*(3000)\n\nprint(new_prediction)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 403244\n```\n:::\n\n```{.r .cell-code}\nprint(not_new_prediction)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 334228\n```\n:::\n:::\n\n\nG. Find the predicted selling price for a home of 1500 square feet that\nis (i) new, (ii) not new.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnew_prediction <- -100756 + 168*(1500)\nnot_new_prediction <- 22228 + 104*(1500)\n\nprint(new_prediction)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 151244\n```\n:::\n\n```{.r .cell-code}\nprint(not_new_prediction)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 178228\n```\n:::\n:::\n\n\nComparing to (F), explain how the difference in predicted selling prices\nchanges as the size of home increases.\n\nAs the size of the home increase, the not new homes increase in price at\na lower rate than the new homes. This is shown by the not new homes\nbeing predicted as more selling for more on average than the new homes\nfor the 1500 sqft home, and the opposite being true for the 3000 sqft\nhome predictions.\n\nH. Do you think the model with interaction or the one without it\nrepresents the relationship of size and new to the outcome price? What\nmakes you prefer one model over another?\n\nI prefer the model without the interaction term, because Size and New\nare both statistically significant and therefore all the variables in\nthe model are statistically significant, which isn't the case for the\nmodel with the interaction term.",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}