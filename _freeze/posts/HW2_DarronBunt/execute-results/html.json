{
  "hash": "fced6453e0570c033e7351cc0fb10d5d",
  "result": {
    "markdown": "---\ntitle: \"Homework 2\"\nauthor: \"Darron Bunt\"\ndescription: \"Homework Assignment 2 - Darron Bunt\"\ndate: \"04/16/2023\"\nformat:\n  html:\n    toc: true\n    code-fold: true\n    code-copy: true\n    code-tools: true\ncategories:\n  - hw2\n  - hypothesistesting\n  - confidenceintervals\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'tidyverse' was built under R version 4.2.2\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'ggplot2' was built under R version 4.2.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'tibble' was built under R version 4.2.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'tidyr' was built under R version 4.2.2\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'readr' was built under R version 4.2.2\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'purrr' was built under R version 4.2.2\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'dplyr' was built under R version 4.2.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'stringr' was built under R version 4.2.2\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'forcats' was built under R version 4.2.2\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'lubridate' was built under R version 4.2.2\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.1     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n:::\n:::\n\n\n\n# Question 1\n\n*The time between the date a patient was recommended for heart surgery and the surgery date*\n*for cardiac patients in Ontario was collected by the Cardiac Care Network (“Wait Times Data*\n*Guide,” Ministry of Health and Long-Term Care, Ontario, Canada, 2006). The sample mean*\n*and sample standard deviation for wait times (in days) of patients for two cardiac* *procedures are given in the accompanying table. Assume that the sample is representative of* *the Ontario population*\n\n*Construct the 90% confidence interval to estimate the actual mean wait time for each of the two procedures. Is the confidence interval narrower for angiography or bypass surgery?*\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Create the data frame that matches the table that was provided.\n\nWaitTimes <- data.frame (\"Surgical Procedure\" = c(\"Bypass\", \"Angiography\"),\n                  \"Sample Size\" = c(539, 847),\n                  \"Mean Wait Time\" = c(19, 18),\n                  \"Standard Deviation\" = c(10,9)\n                  )\nWaitTimes\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  Surgical.Procedure Sample.Size Mean.Wait.Time Standard.Deviation\n1             Bypass         539             19                 10\n2        Angiography         847             18                  9\n```\n:::\n:::\n\n####  Part 1\n*Construct the 90% confidence interval to estimate the actual mean wait time for the two procedures*\n\nFormula for Confidence Interval = (X bar) +/- (t x s/sqrt(n))\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# For Bypass - \n\n#x-bar = mean wait time = 19\nsmean_bypass <- 19 \n\n# standard deviation = 10\nssd_bypass <- 10\n\n# sample size = 539\nn_bypass <- 539\n\n# standard error = standard deviation / sqrt(sample size) => 10/sqrt(539)\nsterror_bypass <- 10/sqrt(539) \nsterror_bypass\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.4307305\n```\n:::\n\n```{.r .cell-code}\n# confidence level = 0.9\ncl_bypass <- 0.1 \n\n# calculate t score that corresponds to confidence level/sample size\nt_score_bypass <- qt(1-cl_bypass/2, n_bypass-1)\nt_score_bypass\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1.647691\n```\n:::\n\n```{.r .cell-code}\n#calculating the 90% confidence interval for bypass\n\nCI_bypass <- c(smean_bypass - (t_score_bypass * sterror_bypass), smean_bypass + (t_score_bypass * sterror_bypass))\nCI_bypass\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 18.29029 19.70971\n```\n:::\n:::\n\n\nThe 90% Confidence Interval for Bypass is 18.3 to 19.7 days.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# For Angiography - \n\n#x-bar = mean wait time = 18\nsmean_angio <- 18 \n\n# standard deviation = 9\nssd_angio <- 9\n\n# sample size = 847\nn_angio <- 847\n\n# standard error = standard deviation / sqrt(sample size) => 9/sqrt(847)\nsterror_angio <- 9/sqrt(847) \nsterror_angio\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.3092437\n```\n:::\n\n```{.r .cell-code}\n# confidence level = 0.9\ncl_angio <- 0.1 \n\n# calculate t score that corresponds to confidence level/sample size\nt_score_angio <- qt(1-cl_angio/2, n_angio-1)\nt_score_angio\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1.646657\n```\n:::\n\n```{.r .cell-code}\n#Calculating the 90% confidence interval for angio\n\nCI_angio <- c(smean_angio - (t_score_angio * sterror_angio), smean_angio + (t_score_angio * sterror_angio))\nCI_angio\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 17.49078 18.50922\n```\n:::\n:::\n\nThe 90% Confidence Interval for Angiography is 17.5 to 18.5 days.\n\n####  Part 2\n\n*Is the confidence interval narrower for angiography or bypass surgery?*\n\n90% CI for Bypass: 18.3 to 19.7 days - this is 1.4 days.\n90% CI for Angiography: 17.5 to 18.5 days - this is 1 day.\n\nThe CI is narrower for Angiography.\n\n# Question 2\n\n*A survey of 1,031 adult Americans was carried out by the National Center for Public*\n*Policy. Assume that the sample is representative of adult Americans. Among those surveyed, 567 believed that college education is essential for success. Find the point estimate, p, of the proportion of all adult Americans who believe that a college education is essential for success.*\n\n*Construct and interpret a 95% confidence interval for p.*\n\n#### Part 1 - \n\n*Find the point estimate (p) of the proportion of all adult Americans who believe that a college education is essential for success.*\n\nThe point estimate (p) is the proportion observed in this sample and is equal to the number of respondents who believe a college education is essential for success (567) divided by the total number of respondents (1,031)\n\n\n::: {.cell}\n\n```{.r .cell-code}\np_CollegeEd <- 567/1031\np_CollegeEd\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.5499515\n```\n:::\n:::\n\np = 0.55 - approximately 55% of the sampled adult Americans believe that a college education is essential for success. \n\n#### Part 2 - \n\n*Construct and interpret a 95% confidence interval for p.*\n\nWe learned about prop.test() in Tutorial 5 - the Z-Test of Proportions with Continuity Correction. Similar to a t-test, it is suited for tests about proportions. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# to perform prop.test() we require three main arguments: x, n, and p\n\n#x = vector of counts of successes = 567\nx_CollegeEd <- 567\n\n#n = vector of counts of trials = 1031\nn_CollegeEd <- 1031\n\n#p = vector of probabilities of success = p_CollegeEd calculated above\n\nprop.test(x_CollegeEd, n_CollegeEd, p_CollegeEd)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\t1-sample proportions test without continuity correction\n\ndata:  x_CollegeEd out of n_CollegeEd, null probability p_CollegeEd\nX-squared = 6.9637e-30, df = 1, p-value = 1\nalternative hypothesis: true p is not equal to 0.5499515\n95 percent confidence interval:\n 0.5194543 0.5800778\nsample estimates:\n        p \n0.5499515 \n```\n:::\n:::\n\nBased on the prop.test results, the 95% Confidence Interval for the proportion of all adult Americans who believe that a college education is essential for success is 0.52 - 0.58 (or 52% to 58%)\n\nWe can be 95% confident that the true population proportion falls within this range - if we were to take many random samples of the same size from the population and calculate the confidence intervals for each sample, 95% of these intervals would contain the true population proportion.\n\n# Question 3\n\n*Suppose that the financial aid office of UMass Amherst seeks to estimate the mean cost*\n*of textbooks per semester for students. The estimate will be useful if it is within $5 of the true population mean (i.e. they want the confidence interval to have a length of $10 or less).*\n\n*The financial aid office is pretty sure that the amount spent on books varies widely, with* *most values between $30 and $200. They think that the population standard deviation is about a quarter of this range (in other words, you can assume they know the population standard deviation).*\n\n*Assuming the significance level to be 5%, what should be the size of the sample?*\n\nIf:\nMargin of Error = z* (standard deviation / square root of n)\n\nThen we can rearrange the formula in order to solve for n:\nn = ((z*sd)/MoE)^2\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# find value for z-score  \nz_Amherst <- qnorm(0.975)\nz_Amherst\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1.959964\n```\n:::\n\n```{.r .cell-code}\n# find value for standard deviation\n\n# Most values betweeen $30-200 => range of 170\nrange_Amherst <- 200-30\n\n# They think population standard deviation is about a quarter of this range => 170/4\nsd_Amherst <- range_Amherst/4\nsd_Amherst\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 42.5\n```\n:::\n\n```{.r .cell-code}\n#Margin of Error = 5\nMOE_Amherst <- 5\n\n# Solving for n\n# n = ((z*sd)/MoE)^2\n\nn_Amherst <- ((z_Amherst*sd_Amherst)/MOE_Amherst)^2\nn_Amherst\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 277.5454\n```\n:::\n:::\n\nWe round up, so the sample size should be 278.\n\n# Question 4\n\n*According to a union agreement, the mean income for all senior-level workers in a large*\n*service company equals $500 per week. A representative of a women’s group decides to analyze* *whether the mean income μ for female employees matches this norm. For a random sample of* *nine female employees, ȳ = $410 and s = 90*\n\n*A. Test whether the mean income of female employees differs from $500 per week. Include*\n*assumptions, hypotheses, test statistic, and P-value. Interpret the result.*\n*B. Report the P-value for Ha: μ < 500. Interpret.*\n*C. Report and interpret the P-value for Ha: μ > 500.*\n*(Hint: The P-values for the two possible one-sided tests must sum to 1.*\n\n#### Part A\n\n*A. Test whether the mean income of female employees differs from $500 per week. Include*\n*assumptions, hypotheses, test statistic, and P-value. Interpret the result*\n\nIn order to test this, we are going to need to do a one-sample t-test.\n\n**Assumptions** of a one-sample t-test:\n* normality: that the population distribution is normal\n* independence: that the observations in our sample are generated independently of one another.\n\n**Hypotheses:**\n\nOur null hypotheisis is that the mean income of female employees does not differ from $500 per week. \n\nThe alternative hypothesis is that the mean income of female employees DOES differ from $500 per week.\n\nNow we need to calculate the **test statistic** (t-score)\n\nt = (m - μ) / (s / sqrt(n))\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# t = (m - μ) / (s / sqrt(n)), where:\n\n# m = sample mean (female employees) \nsamplemean_Union <- 410\n\n# μ = population mean (reported for all employees)\npopulationmean_Union <- 500\n\n# s = sample standard deviation (given - 90)\nsamplesd_Union <- 90\n\n# n = sample size (given - 9 female employees)\nsamplen_Union <- 9\n\nt_Union <- (samplemean_Union - populationmean_Union) / ((samplesd_Union) / (sqrt(samplen_Union)))\nt_Union\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -3\n```\n:::\n:::\n\n\nThe t-score is -3.\n\nNow we need the **P-value**\n\nThe P-value is the probability of obtaining test results at least as extreme as the result actually observed, under the assumption that the null hypothesis is correct.\n\nTo find the p-value, we can use pt() in R. This requires the calculated t-statistic and the degrees of freedom. In a one-sample t-test, the degrees of freedom are n-1 (where n is the sample size).\n\nSo in this case, the **degrees of freedom** are 9-1, or 8.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# find p-value\npvalueTwoTail_Union <- 2*pt(q=t_Union, df=8, lower.tail=TRUE)\npvalueTwoTail_Union\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.01707168\n```\n:::\n:::\n\nThe p-value is 0.017\n\n**Interpreting the result:**\nThe p-value is less than 0.05, so accordingly we can reject the hypothesis that the . This suggests that the true mean salary of female workers is **not** equal to $500.\n\n#### Part B\n\n*B. Report the P-value for Ha: μ < 500. Interpret.*\n\nNull hypothesis is that mean income for female workers is greater than 500. The alternative hypothesis that the mean income for female workers is less than $500.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# find lower tail of p-value\npvalueLowerTail_Union <- pt(q=t_Union, df=8, lower.tail=TRUE)\npvalueLowerTail_Union\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.008535841\n```\n:::\n:::\n\n**Interpreting the result:**\nThe p-value is less than 0.05, so accordingly we can reject the null hypothesis. This suggests that the true mean salary of female workers is less than $500.\n\n#### Part C\n\n*C. Report and interpret the P-value for Ha: μ > 500.*\n\nNull hypothesis is that mean income for female workers is less than 500. The alternative hypothesis that the mean income for female workers is greater than $500.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# find upper tail of p-value\npvalueUpperTail_Union <- pt(q=t_Union, df=8, lower.tail=FALSE)\npvalueUpperTail_Union\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.9914642\n```\n:::\n:::\n\n**Interpreting the result:**\nThe p-value is greater than 0.05, so we fail to reject the null hypothesis that the mean income for female workers is less than 500. This suggests that the true mean salary of female workers is less than $500.\n\n# Question 5\n\n*5. Jones and Smith separately conduct studies to test H0: μ = 500 against Ha: μ ≠ 500, each*\n*with n = 1000. Jones gets ȳ = 519.5, with se = 10.0. Smith gets ȳ = 519.7,*\n*with se = 10.0.*\n\n*A. Show that t = 1.95 and P-value = 0.051 for Jones. Show that t = 1.97 and P-value = 0.049*\n*for Smith.*\n\n*B. Using α = 0.05, for each study indicate whether the result is “statistically significant.”*\n\n*C. Using this example, explain the misleading aspects of reporting the result of a test as “P ≤ 0.05” versus “P > 0.05,” or as “reject H0” versus “Do not reject H0,” without reporting the actual P-value.*\n\n#### Part A\n\n*A. Show that t = 1.95 and P-value = 0.051 for Jones.* \n*Show that t = 1.97 and P-value = 0.049 for Smith.*\n\nFirst we'll confirm the t scores. The equation for calculating t score when you have the standard error is:\nt = (ȳ - μ) / se\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# t = (ȳ - μ) / se\n\n# ȳ = \ny_Jones <- 519.5\ny_Smith <- 519.7\n\n# μ = (from hypothesis)\npopulationmean_JonesSmith <- 500\n\n# se = (given)\nse_Jones <- 10.0\nse_Smith <- 10.0\n\n# n - (given)\nn_JonesSmith <- 1000\n\nt_Jones <- (y_Jones - populationmean_JonesSmith) / se_Jones\nt_Jones\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1.95\n```\n:::\n\n```{.r .cell-code}\nt_Smith <- (y_Smith - populationmean_JonesSmith) / se_Smith\nt_Smith\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1.97\n```\n:::\n:::\n\n\nThis confirms that the respective t scores for Jones and Smith are 1.95 and 1.97. \n\nNow we'll calculate the p-values. Both t-scores are positive, so we are going to look at the upper tail. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n#find p-values\np_Jones <- 2*pt(q=t_Jones, df=999, lower.tail=FALSE)\np_Jones\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.05145555\n```\n:::\n\n```{.r .cell-code}\np_Smith <- 2*pt(q=t_Smith, df=999, lower.tail=FALSE)\np_Smith\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.04911426\n```\n:::\n:::\n\n This confirms that the p-values for Jones and Smith are 0.051 and 0.049 respectively.\n \n#### Part B\n\n*B. Using α = 0.05, for each study indicate whether the result is “statistically significant.”*\n\nFor Jones' study, the p-value of 0.051 is greater than α = 0.05, therefore Jones' study is not statistically significant.\n\nFor Smith's study, the p-value of 0.049 is less than α = 0.05, therefore Smith's study is statistically significant.\n\n#### Part C \n\n*C. Using this example, explain the misleading aspects of reporting the result of a test as “P ≤ 0.05” versus “P > 0.05,” or as “reject H0” versus “Do not reject H0,” without reporting the actual P-value.*\n\nIf only p ≤ 0.05 or p > 0.05 was reported (or similarly, only whether or not we can reject the null hypothesis) and not the actual p-values, we lose a lot of context. In the case of these two studies, the difference in Jones' and Smith's p-values are 0.002 apart, but that made the difference between one result having statistical significance at the α = 0.05 level and the other not. \n\n# Question 6\n\n*A school nurse wants to determine whether age is a factor in whether children choose a*\n*healthy snack after school. She conducts a survey of 300 middle school students, with the results below. Test at α = 0.05 the claim that the proportion who choose a healthy snack differs by grade level.* \n\n*What is the null hypothesis? Which test should we use? What is the conclusion?*\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Replicate the data as a table\nHealthySnack <- matrix(c(31, 43, 51, 69, 57, 49), nrow=2, byrow=TRUE)\ncolnames(HealthySnack) <- c('Grade 6', 'Grade 7', 'Grade 8')\nrownames(HealthySnack) <- c('Healthy', 'Unhealthy')\nHealthySnack <- as.table(HealthySnack)\nHealthySnack\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          Grade 6 Grade 7 Grade 8\nHealthy        31      43      51\nUnhealthy      69      57      49\n```\n:::\n:::\n\n*What is the null hypothesis?*\n\nWe are interested in the effect of **grade level** on **snack choice**.\n\nThe null hypothesis is that grade level does not impact whether students choose a healthy or unhealthy snack. \n\nThe alternative hypothesis is that grade level does impact whether students choose a healthy or unhealthy snack.\n\n*Which test should we use?*\n\nWe should use the χ2 test of independence (or association), aka the chi-square test of independence/association, which is used to determine whether there is a significant association between two categorical variables.\n\n*What is the conclusion?*\n\nWe now need to compare the observed frequencies to the expected frequencies that would be observed if the variables were independent. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# chi-square test to compare snack choice and grade level\nchisq.test(HealthySnack)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tPearson's Chi-squared test\n\ndata:  HealthySnack\nX-squared = 8.3383, df = 2, p-value = 0.01547\n```\n:::\n:::\n\nWe are testing at α = 0.05 and the p-value is smaller than 0.05, which indicates that we can reject the null hypothesis that grade level does not impact snack choice; there is a relationship between grade level and choice of snack. \n\n# Question 7\n\n*Per-pupil costs (in thousands of dollars) for cyber charter school tuition for school*\n*districts in three areas are shown.*\n\n*Test the claim that there is a difference in means for the three areas, using an appropriate* *test. What is the null hypothesis? Which test should we use? What is the conclusion?*\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Replicating the data\nArea <- c(rep(\"Area_1\", 6), rep(\"Area_2\", 6), rep(\"Area_3\", 6))\nCost <- c(6.2, 9.3, 6.8, 6.1, 6.7, 7.5, 7.5, 8.2, 8.5, 8.2, 7.0, 9.3, 5.8, 6.4, 5.6, 7.1, 3.0, 3.5)\n\nCyberCharterCost <- data.frame(Area,Cost)\nCyberCharterCost\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     Area Cost\n1  Area_1  6.2\n2  Area_1  9.3\n3  Area_1  6.8\n4  Area_1  6.1\n5  Area_1  6.7\n6  Area_1  7.5\n7  Area_2  7.5\n8  Area_2  8.2\n9  Area_2  8.5\n10 Area_2  8.2\n11 Area_2  7.0\n12 Area_2  9.3\n13 Area_3  5.8\n14 Area_3  6.4\n15 Area_3  5.6\n16 Area_3  7.1\n17 Area_3  3.0\n18 Area_3  3.5\n```\n:::\n:::\n\n*What is the null hypothesis?*\n\nThe null hypothesis is that there is no difference in means for the three areas.\nThe alternative hypothesis is that there is a difference in means for the three areas.\n\n*Which test should we use?*\n\nWe should use **ANOVA**, specifically a one-way ANOVA. ANOVA is used to investigate differences in means, and a one-way ANOVA is used when we have several different groups of observations and are interested in finding out whethter those groups differ in terms of some outcome variable of interest.\n\nIn this case we are interested in whether Area 1, 2, and 3 differ in terms of per-pupil costs for cyber charter school tuition. \n\n*Test the claim that there is a difference in means for the three areas*\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Running ANOVA in R uses aov()\n# formula => argument to specify the outcome variable and the grouping variable \n# data => the data frame that stores those variables\n# NOTE: Make sure the dependent variable is continuous and the independent variable is categorical.\n\nCyberCharterANOVA <- aov(formula = Cost ~ Area, data = CyberCharterCost)\nsummary(CyberCharterANOVA)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n            Df Sum Sq Mean Sq F value  Pr(>F)   \nArea         2  25.66  12.832   8.176 0.00397 **\nResiduals   15  23.54   1.569                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n*What is the conclusion?*\n\nThe p-value of 0.00397 is less than α = 0.05, which means that we reject the null hypothesis that there is no difference in the means for the three areas. There does indeed appear to be a difference in the per-pupil cost for cyber charter school tuition by area. \n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}