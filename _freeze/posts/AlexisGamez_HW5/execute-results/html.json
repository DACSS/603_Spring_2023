{
  "hash": "b2b5fad61ef8425490a3a81bff2c47d5",
  "result": {
    "markdown": "---\ntitle: \"Blog Post #5\"\nauthor: \"Alexis Gamez\"\ndescription: \"DACSS 603 HW#5\"\ndate: \"05/13/2023\"\nformat:\n  html:\n    toc: true\n    code-fold: true\n    code-copy: true\n    code-tools: true\ncategories:\n  - hw5\n  - correlation\n  - regressional analysis\n  - transformations\n---\n\n::: {.cell}\n\n```{.r .cell-code}\n# setup\nlibrary(tidyverse)\nlibrary(alr4)\nlibrary(smss)\nlibrary(stargazer)\nlibrary(MPV)\n\nknitr::opts_chunk$set(echo = TRUE)\n```\n:::\n\n\n# Question 1\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# loading data\ndata(\"house.selling.price.2\")\n```\n:::\n\n\n*For the house.selling.price.2 data the tables below show a correlation matrix and a model fit using four predictors of selling price.*\n\n## A)\n\n**For backward elimination, which variable would be deleted first? Why?**\n\nUsing backward elimination, I would delete the `Beds` variable first. The point of backward elimination is to fit a model using all possible variables provided and 1 by 1 eliminating the least significant variables from said model. In this case, the `Beds` variable is the least significant in the model with a p-value of 0.487.\n\n## B)\n\n**For forward selection, which variable would be added first? Why?**\n\nForward selection works opposite to backward elimination where we start with an empty model and 1 by 1 add variables according to their significance level. Under these circumstances, I would add the `Size` variable first, as it is the most significant, with a p-value of 0.\n\n## C)\n\n**Why do you think that BEDS has such a large P-value in the multiple regression model, even though it has a substantial correlation with PRICE?**\n\nIf there is 1 thing we've learned this semester, it's that correlation does not dictate causation. So while both are strongly correlated, it appears that the significance of the `Beds` variable within the model diminishes with the addition of the other variables. In other words, the effect of `Beds` on `Price` is not as significant in comparison to the effect of the other variables on `Price`. \n\n## D)\n\n**Using software with these four predictors, find the model that would be selected using each criterion:**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(house.selling.price.2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       P                S              Be              Ba       \n Min.   : 17.50   Min.   :0.40   Min.   :1.000   Min.   :1.000  \n 1st Qu.: 72.90   1st Qu.:1.33   1st Qu.:3.000   1st Qu.:2.000  \n Median : 96.00   Median :1.57   Median :3.000   Median :2.000  \n Mean   : 99.53   Mean   :1.65   Mean   :3.183   Mean   :1.957  \n 3rd Qu.:115.00   3rd Qu.:1.98   3rd Qu.:4.000   3rd Qu.:2.000  \n Max.   :309.40   Max.   :3.85   Max.   :5.000   Max.   :3.000  \n      New        \n Min.   :0.0000  \n 1st Qu.:0.0000  \n Median :0.0000  \n Mean   :0.3011  \n 3rd Qu.:1.0000  \n Max.   :1.0000  \n```\n:::\n:::\n\n\nFor this question, I'll be utilizing stargazer to visualize the results to answer parts 1 & 2.\n\n::: {.cell}\n\n```{.r .cell-code}\nfit1 <- (lm(P ~ S, data= house.selling.price.2))\n\nfit2 <- (lm(P ~ S + New, data= house.selling.price.2))\n\nfit3 <- (lm(P ~ S + Ba + New, data= house.selling.price.2))\n\nfit4 <- (lm(P ~ S + Be + Ba + New, data= house.selling.price.2))\n\nstargazer(fit1, fit2, fit3, fit4, type = 'text')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n===================================================================================================================\n                                                          Dependent variable:                                      \n                    -----------------------------------------------------------------------------------------------\n                                                                   P                                               \n                              (1)                     (2)                     (3)                     (4)          \n-------------------------------------------------------------------------------------------------------------------\nS                          75.607***               72.575***               62.263***               64.761***       \n                            (3.865)                 (3.508)                 (4.335)                 (5.630)        \n                                                                                                                   \nBe                                                                                                  -2.766         \n                                                                                                    (3.960)        \n                                                                                                                   \nBa                                                                         20.072***               19.203***       \n                                                                            (5.495)                 (5.650)        \n                                                                                                                   \nNew                                                19.587***               18.371***               18.984***       \n                                                    (3.995)                 (3.761)                 (3.873)        \n                                                                                                                   \nConstant                  -25.194***              -26.089***              -47.992***              -41.795***       \n                            (6.688)                 (5.977)                 (8.209)                (12.104)        \n                                                                                                                   \n-------------------------------------------------------------------------------------------------------------------\nObservations                  93                      93                      93                      93           \nR2                           0.808                   0.848                   0.868                   0.869         \nAdjusted R2                  0.806                   0.845                   0.864                   0.863         \nResidual Std. Error    19.473 (df = 91)        17.395 (df = 90)        16.313 (df = 89)        16.360 (df = 88)    \nF Statistic         382.628*** (df = 1; 91) 251.775*** (df = 2; 90) 195.313*** (df = 3; 89) 145.763*** (df = 4; 88)\n===================================================================================================================\nNote:                                                                                   *p<0.1; **p<0.05; ***p<0.01\n```\n:::\n:::\n\n\n### 1. R^2\n\nThe best model according to this criteria would be model 4, as its R^2 value is the closest to 1 (0.869).\n\n### 2. Adjusted R^2\n\nThe best model according to this criteria would be model 3, as its adjusted R^2 value is the closest to 1 (0.864).\n\n### 3. PRESS\n\nModel 1\n\n::: {.cell}\n\n```{.r .cell-code}\nPRESS(fit1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 38203.29\n```\n:::\n:::\n\n\nModel 2\n\n::: {.cell}\n\n```{.r .cell-code}\nPRESS(fit2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 31066\n```\n:::\n:::\n\n\nModel 3\n\n::: {.cell}\n\n```{.r .cell-code}\nPRESS(fit3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 27860.05\n```\n:::\n:::\n\n\nModel 4\n\n::: {.cell}\n\n```{.r .cell-code}\nPRESS(fit4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 28390.22\n```\n:::\n:::\n\n\nKnowing that a lower PRESS value indicates a better fit model, I would select model 3 according to this criteria. \n\n### 4. AIC\n\nModel 1\n\n::: {.cell}\n\n```{.r .cell-code}\nAIC(fit1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 820.1439\n```\n:::\n:::\n\n\nModel 2\n\n::: {.cell}\n\n```{.r .cell-code}\nAIC(fit2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 800.1262\n```\n:::\n:::\n\n\nModel 3\n\n::: {.cell}\n\n```{.r .cell-code}\nAIC(fit3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 789.1366\n```\n:::\n:::\n\n\nModel 4\n\n::: {.cell}\n\n```{.r .cell-code}\nAIC(fit4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 790.6225\n```\n:::\n:::\n\n\nSimilar to the PRESS criteria, the lower the returned AIC value, the better the model fits. Again, under these circumstances I would select model 3 as the best fit.\n\n### 5. BIC\n\nModel 1\n\n::: {.cell}\n\n```{.r .cell-code}\nBIC(fit1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 827.7417\n```\n:::\n:::\n\n\nModel 2\n\n::: {.cell}\n\n```{.r .cell-code}\nBIC(fit2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 810.2566\n```\n:::\n:::\n\n\nModel 3\n\n::: {.cell}\n\n```{.r .cell-code}\nBIC(fit3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 801.7996\n```\n:::\n:::\n\n\nModel 4\n\n::: {.cell}\n\n```{.r .cell-code}\nBIC(fit4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 805.8181\n```\n:::\n:::\n\n\nIdentical to AIC, the lowest BIC value indicates the best fit model. Once again, model 3 would be the best fit under these circumstances.\n\n## E)\n\n**Explain which model you prefer and why.**\n\nThe only models proven to be significant through previous criterion are models 3 & 4. Even then, model 4 was only proven to be significant according to it's R^2 value and I would argue that the more significant value to consider would be the adjusted R^2. Thus, if I were to select 1 of these 2 models, I would select model 3 as the best fit model, especially when considering the criterion previously calculated.\n\n# Question 2\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# loading data\ndata(\"trees\")\n```\n:::\n\n\n**Tree volume estimation is a big deal, especially in the lumber industry. Use the trees data to build a basic model of tree volume prediction. In particular,**\n\n## A)\n\n**Fit a multiple regression model with the Volume as the outcome and Girth and Height as the explanatory variables.**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(trees)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     Girth           Height       Volume     \n Min.   : 8.30   Min.   :63   Min.   :10.20  \n 1st Qu.:11.05   1st Qu.:72   1st Qu.:19.40  \n Median :12.90   Median :76   Median :24.20  \n Mean   :13.25   Mean   :76   Mean   :30.17  \n 3rd Qu.:15.25   3rd Qu.:80   3rd Qu.:37.30  \n Max.   :20.60   Max.   :87   Max.   :77.00  \n```\n:::\n:::\n\n\nWith the data loaded, I'll fit the model below:\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_t <- lm(Volume ~ Girth + Height, data = trees)\n\nsummary(fit_t)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Volume ~ Girth + Height, data = trees)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-6.4065 -2.6493 -0.2876  2.2003  8.4847 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -57.9877     8.6382  -6.713 2.75e-07 ***\nGirth         4.7082     0.2643  17.816  < 2e-16 ***\nHeight        0.3393     0.1302   2.607   0.0145 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.882 on 28 degrees of freedom\nMultiple R-squared:  0.948,\tAdjusted R-squared:  0.9442 \nF-statistic:   255 on 2 and 28 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\n## B)\n\n**Run regression diagnostic plots on the model. Based on the plots, do you think any of the regression assumptions is violated?**\n\n\n::: {.cell}\n\n```{.r .cell-code}\npar(mfrow = c(2, 3)); plot(fit_t, which = 1:6)\n```\n\n::: {.cell-output-display}\n![](AlexisGamez_HW5_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\nImmediately, it's apparent that at least a couple of regression assumptions are violated throughout the 6 diagnostic plots. Most noteworthy, are the Residuals vs Fitted, Scale-Location and Cook's Distance plots. It's obvious that the for the 1st plot that the linearity assumption is violated. Similarly, the lack of a steady horizontal trend in the Scale-Location plot indicates a violation of the constant variance assumption. Lastly, it's apparent in the Cook's distance plot that the 31st observation, which is also an extreme outlier, holds significantly more weight within the model than any other telling me that the significance of all observations is skewed and not well fit.\n\n# Question 3\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# loading data\ndata(\"florida\")\n```\n:::\n\n\n**In the 2000 election for U.S. president, the counting of votes in Florida was controversial. In Palm Beach County in south Florida, for example, voters used a so-called butterfly ballot. Some believe that the layout of the ballot caused some voters to cast votes for Buchanan when their intended choice was Gore.**\n\n## A)\n\n**Run a simple linear regression model where the Buchanan vote is the outcome and the Bush vote is the explanatory variable. Produce the regression diagnostic plots. Is Palm Beach County an outlier based on the diagnostic plots? Why or why not?**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(florida)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      Gore             Bush           Buchanan     \n Min.   :   788   Min.   :  1316   Min.   :   9.0  \n 1st Qu.:  3055   1st Qu.:  4746   1st Qu.:  46.5  \n Median : 14152   Median : 20196   Median : 114.0  \n Mean   : 43341   Mean   : 43356   Mean   : 258.5  \n 3rd Qu.: 45974   3rd Qu.: 56542   3rd Qu.: 285.5  \n Max.   :386518   Max.   :289456   Max.   :3407.0  \n```\n:::\n:::\n\n\nWith the data loaded, I've fit & visualized the requested model below:\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_f <- lm(Buchanan ~ Bush, data = florida)\n\npar(mfrow = c(2, 3)); plot(fit_f, which = 1:6)\n```\n\n::: {.cell-output-display}\n![](AlexisGamez_HW5_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n:::\n\n\nWith the model fit and the diagnostic plots created, it's extremely apparent that Palm Beach is indeed an outlier and an extreme one at that. In all plots, Palm Beach is shown to deviate entirely from any trend that might have been present among the other polling stations. For example, within the Residuals vs Fitted plot, the linearity assumption is relatively sound until one takes into consideration the Palm Beach and Dade sites. Both are blatant violations of said assumption and would lead any reasonable data scientist to believe that some sort of tampering/manipulation was involved.\n\n## B)\n\n**Take the log of both variables (Bush vote and Buchanan Vote) and repeat the analysis in (A.) Does your findings change?**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_logf <- lm(log(Buchanan) ~ log(Bush), data = florida)\n\npar(mfrow = c(2, 3)); plot(fit_logf, which = 1:6)\n```\n\n::: {.cell-output-display}\n![](AlexisGamez_HW5_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n:::\n\n\nWhile logging both the `Buchanan` & `Bush` variables seems to lessen the impact of the Palm Beach observation on the model, I would argue that the new results are still not significant enough to change my findings. I  would still consider Palm Beach an outlier.\n",
    "supporting": [
      "AlexisGamez_HW5_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}