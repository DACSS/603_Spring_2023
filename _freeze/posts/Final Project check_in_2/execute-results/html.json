{
  "hash": "33d177290bf1e8690b2f62e8bae70a64",
  "result": {
    "markdown": "---\ntitle: \"Final Project check-in 2\"\nauthor: \"Diana Rinker\"\ndescription: \"Final project DACSS 603\"\ndate: \"4/17/2023\"\nformat:\n  html:\n    toc: true\n    code-fold: true\n    code-copy: true\n    code-tools: true\neditor: \n  markdown: \n    wrap: 72\n---\n\n\n## DACSS 603, spring 2023\n\n## Final Project check-in 2, Diana Rinker.\n\n# Online engagement\n\nIt is well known that online engagement with the web resource is a\nhighly valuable metric and is driving site revenue. However, engagement\nand popularity might also be associated with other factors, that\nwebsties are trying to avoid, such as online violence, inappropriate\nbehavior and misinformation. This research project is exploring how\nthese factos impact readers' engagement in social media conversations\nand what are main forces of site popularity.\n\nTo do that I will use the data from an online blog on the news website.\nThe author of this blog is posting articles about interpersonal\nrelationships every work day (Mon- Fri). The posts are formulated as a\nletter from a reader with the situation and a question about\nrelationships. The author gives an advice about the situation. Website\nreaders are free to comment under each post, but cannot make their own\nposts.\n\nAll post methadata and comments are public. They are saved by the\nwebsite and available for the analysis. Using this data set, I will\nexplore how readers' engagement connected with blogs's author\nengagement, site comments', web source of readers and negative behaviors\nonline.\n\nMy research question is: Does the authors engagement in the conversation\naround the post makes readers more engaged and promotes positive\ninteractions among them?\n\n**DV:** My dependent construct is **\"user's engagement**\", I will\nmeasure users' engagement at the level of individual post, using the\nfollowing metrics:\n\n1.  Page views\n2.  Page visits (one visit can contain a few views, if the person visits\n    other pages on the site)\n3.  Unique users. One person can visit the same page a few times (it is\n    calculated for all time since the page was posted).\n4.  Number of votes: \"thums up\" or \"thumbs down\"\n5.  Number of comments\n6.  Exit rate or \"bounces\". When the visitor is coming to the page and\n    then leaving, i.e. not opening other pages on this website.\n\nL2 - page readers \\* Reveal letter \\* Reveal comments\n\n**IV:** My main independent variable is **Blog's author engagement.** I\nwill measure authors engagement as the factor variable, with the\nfollowing levels:\n\nA. Unspecified comment\n\nB. Featured comment\n\nC. Engagement in conversation\n\nTo control for **confounders,** I will also measure the follwing\nvariables:\n\n1.  Topic of the post (\"post tag\"), categorical variable.\n\n2.  Source of the readers, also categorical variable.\n\n3.  Mood of the conversation , derivative continuous variable calculated\n    as the ratio of \"likes\" to \"dislikes\".\n\n4.  Blocked and flagged comments.\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'dplyr'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ tibble  3.1.8     ✔ purrr   1.0.1\n✔ tidyr   1.3.0     ✔ stringr 1.5.0\n✔ readr   2.1.4     ✔ forcats 1.0.0\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n```\n:::\n:::\n\n\n# Data\n\nTo answer my research question I will use two datasets. the first data\nset has information about all comments associated with each post by post\nID. The second data set is analytics data for the web bage. It contains\none post per row and variables describe each post as a whole without\nbreaking down to the comment level.\n\nIn this project I will analyze posts for January 2021 - February 2023.\n\nFirst, I will load the data set with the comment level data:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngetwd()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"C:/Users/Diana/OneDrive - University Of Massachusetts Medical School/Documents/R/R working directory/DACSS/603/603_Spring_2023/posts\"\n```\n:::\n\n```{.r .cell-code}\nraw <- as_tibble (read_csv(\"C:\\\\Users\\\\Diana\\\\OneDrive - University Of Massachusetts Medical School\\\\Documents\\\\R\\\\R working directory\\\\DACSS\\\\603\\\\my study files for dacss603\\\\globe\\\\ data.2021.plus.csv\"))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 105136 Columns: 17\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (6): content, user_name, display_name, image_url, email, approved\ndbl  (7): message_id, post_id, user_id, parent, absolute_likes, absolute_dis...\nlgl  (3): email_verified, created_at, private_profile\ndttm (1): written_at\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\ncomments.data<-raw \ncolnames (comments.data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"content\"           \"message_id\"        \"post_id\"          \n [4] \"user_id\"           \"user_name\"         \"display_name\"     \n [7] \"image_url\"         \"email\"             \"email_verified\"   \n[10] \"created_at\"        \"private_profile\"   \"approved\"         \n[13] \"written_at\"        \"parent\"            \"absolute_likes\"   \n[16] \"absolute_dislikes\" \"comment.year\"     \n```\n:::\n\n```{.r .cell-code}\nhead(comments.data$written_at)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"2021-01-01 08:28:44 UTC\" \"2021-01-01 08:57:08 UTC\"\n[3] \"2021-01-01 10:36:58 UTC\" \"2021-01-01 11:13:13 UTC\"\n[5] \"2021-01-01 12:27:44 UTC\" \"2021-01-01 12:51:48 UTC\"\n```\n:::\n\n```{.r .cell-code}\ncomments.data <-comments.data%>%\n              mutate(com.year = format(written_at,format = \"%Y\" ))\nrange(comments.data$com.year)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"2021\" \"2023\"\n```\n:::\n\n```{.r .cell-code}\ndim(comments.data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 105136     18\n```\n:::\n:::\n\n\nSecond, loadng post-level data :\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmerged <- as_tibble (read_csv(\"C:\\\\Users\\\\Diana\\\\OneDrive - University Of Massachusetts Medical School\\\\Documents\\\\R\\\\R working directory\\\\DACSS\\\\603\\\\my study files for dacss603\\\\globe\\\\data.merged.csv\"))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 535 Columns: 23\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (3): Letter, Exit rate, post.month\ndbl  (18): Page views, Search + amp referral visits, Direct (non-email) refe...\nnum   (1): Visits when post was on LL HP\ndate  (1): post.date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\n# colnames(merged)\n# str(merged)\n```\n:::\n\n\n\\# Variable description\n\nTo begin, I will review available variables and evaluate whether it is a\ngood measure for this study.\n\n# Engagement (DV) metrics:\n\n### Page views\n\nThis is the most general engagement metric, representing how many views\nthe post received. Views do not distinguish repeated views by the same\nperson.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# str(merged)\nmerged$post.month <-as.numeric(merged$post.month)\nmerged$year_month <- paste0(merged$post.year, \"-\", sprintf(\"%02d\", merged$post.month))\n\nggplot( data=merged, mapping=aes(y=`Page views`, x=merged$year_month))+\n          geom_boxplot()+\n  labs(title=\"Number of post wiews per month\", x=\"Month\", y=\"Number of vews\")+ \n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Use of `merged$year_month` is discouraged.\nℹ Use `year_month` instead.\n```\n:::\n\n::: {.cell-output-display}\n![](Final-Project-check_in_2_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\nFrom this graph we can see that the numbers of views is increased over\ntime. To get a better understanding of it, lets review other metrics.\n\n### Page visits and unique users\n\nViews - represent the number of times page was viewed by all users at\nall times. \nVisit - is an instance of a user engaging with bdc website.\nThere can be many visits by the same viewer. Once th user is leaving the\nwebsite, the visit is over. \nTo count unique viewers, we can use \"Uniques\" variable. It tells us how many unique users saw the post.\n\nThe relationship will always be that Unique < Visits < Views, so we will plot them together:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# str(merged)\nggplot(merged, aes(x =post.date )) +\n     geom_bar(aes(y = `Page views`, fill = \"Page views\"), stat = \"identity\", position = \"dodge\", width = 0.6) +\n     geom_bar(aes(y = Visits, fill = \"Visits\"), stat = \"identity\", position = \"dodge\", width = 0.6) +\n     geom_bar(aes(y = Uniques, fill = \"Unique users\"), stat = \"identity\", position = \"dodge\", width = 0.6)    +\n     labs(title = \"Views, visits and unique users per month\", x = \"Post.date\", y = \"Value\") + \n     theme(axis.text.x = element_text(angle = 45, hjust = 1))\n```\n\n::: {.cell-output-display}\n![](Final-Project-check_in_2_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\nThis graph also shows increase in all three  metrics in 2022-2023. To see how these metrics crrespond to each other,  I will calculate \"visits ratio\" and \"unique.ratio\".\n\n### Pagevisit and unique ratios: \n\"visits ratio\"  isnumber of visits per total vies. this metric telss us how offten the page being re-viewed. The lower the ratio means more people viwed page more than once during their visit. \n\n\"unique ratio\" - number of unique users per total views is telling uys how often unique viewers re-visited the page. Lower ratio indicate more views by the same individual. \n\nBoth ratios are always in the range of 0 - 1. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n  merged <- merged %>%\n     mutate(uniques.ratio = Uniques / `Page views`)%>%\n      mutate(visits.ratio = Visits / `Page views`)\n# str(merged)\n\n     ggplot(merged, aes( y = uniques.ratio, x =post.date, )) +\n          geom_point(color =\"green\" )    +\n          labs(title = \"Unique.ratio per post \", x = \"Post.date\", y = \"Value\") + \n          theme(axis.text.x = element_text(angle = 45, hjust = 1))  \n```\n\n::: {.cell-output-display}\n![](Final-Project-check_in_2_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n\n```{.r .cell-code}\n      ggplot(merged, aes( y = visits.ratio, x =post.date, )) +\n          geom_point(color =\"blue\" )    +\n          labs(title = \"Unique.ratio per post \", x = \"Post.date\", y = \"Value\") + \n          theme(axis.text.x = element_text(angle = 45, hjust = 1))\n```\n\n::: {.cell-output-display}\n![](Final-Project-check_in_2_files/figure-html/unnamed-chunk-6-2.png){width=672}\n:::\n:::\n\nFrom the two  graphs below we can see that the two variables are distributed very similarly. \n\nIf we plot them against each other and calculate their correlation, we can see that they highly correlated especially in higher values. \n\n::: {.cell}\n\n```{.r .cell-code}\n      plot(merged$uniques.ratio, merged$visits.ratio)\n```\n\n::: {.cell-output-display}\n![](Final-Project-check_in_2_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n\n```{.r .cell-code}\ncorrelation <- cor(merged$uniques.ratio, merged$visits.ratio)\ncorrelation\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.915789\n```\n:::\n:::\n\n\nDensity of the distribution also showing that there are more posts that are visited once and by unique users, i.w post is read once by each user. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# DENSITY DISTRIBUTION HERE \n```\n:::\n\n\n### Exit rate\n\nThis variable is measuring how many people visited the page and then left the website after the first view. We can also see consistent increase of this value, similar to the trend seen before: over time, there are more of less engaged users. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# str(merged)\nmerged$`Exit rate` <- as.numeric(sub(\"%\", \"\", merged$`Exit rate`)) / 100\nggplot(merged, mapping = aes(x=year_month , y=`Exit rate`, fill=year_month ))+\n  geom_boxplot() +\n  labs(title = \"distribution of `Exit rate` per post \", y = \"Exit rate\" , x=\"Month\")+ \n     theme(axis.text.x = element_text(angle = 45, hjust = 1))\n```\n\n::: {.cell-output-display}\n![](Final-Project-check_in_2_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n### Number of comments\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# merged$year_month \nggplot(merged, mapping = aes(x=year_month , y=n.comments, fill=year_month ))+\n  geom_boxplot() +\n  labs(title = \"distribution of comments per post \", y = \"Number of comments\" )+\n  scale_y_continuous(breaks = seq (from=0, to= 10000, by= 100)) + \n     theme(axis.text.x = element_text(angle = 45, hjust = 1))\n```\n\n::: {.cell-output-display}\n![](Final-Project-check_in_2_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\nIt is interesting to mention that overal trend of comments is different from Views, visits and uniques trend. While the first tree seemded to increase over time, this variable overall decreased.  It si important to note, that commenting on the platform  requires logging in from a user, which is an indicator of engagement. \nIt is also more likely that the user who logged in would return to the post (=add views or visits while not changing \"uniques\" count). If that assumption holds, an increase of first three variables (vies, visits and uniques) is consistent with decrease of comments. \n\n\n\n##Independent variables (IV):\n\n#### Authors comments\n\nTo identify, how much the author of the bblog is engaged in the post, I\nwill create an additional variable derived from a user_name field.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# str(merged)\ncomments.data$user_name<-  ifelse (is.na(comments.data$user_name), 0, comments.data$user_name)\ncomments.data$author<-  ifelse (comments.data$user_name==\"MeredithGoldstein\", 1, 0)\n\ncomments.grouped <-comments.data %>%\n  group_by(post_id)%>%\n  summarize(n.comments=n(),\n            author.sum = sum(author))\n\n# dim(comments.grouped )\n# colnames(comments.grouped )\n# class(comments.grouped$author.sum)\n\n# Comments data contains rows that dont actually reporesent posts, and were crearted by web support team for troubleshooting. I need to remove these rows. They typically have very low number of comments\ncomments.grouped <-comments.grouped %>%\nfilter(n.comments >100)  # removing invalid posts created by the  website management team.\n\ncomments.grouped <-comments.grouped %>%\n  select(post_id, author.sum)\n dim(comments.grouped)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 535   2\n```\n:::\n\n```{.r .cell-code}\n#adding author.sum to main data set: \nmerged <- merge( merged , comments.grouped, by = \"post_id\", all = TRUE)\n\nggplot(merged, mapping = aes(x=year_month , y=author.sum, fill=year_month ))+\n  geom_boxplot() +\n  labs(title = \"distribution of Author's comments by months\", y = \"Author's comments\" , x=\"Month\")+ \n     theme(axis.text.x = element_text(angle = 45, hjust = 1))\n```\n\n::: {.cell-output-display}\n![](Final-Project-check_in_2_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n### Mood of the post.\n\nThis is a numerical variable, calculated as percentage of \"thumbs up\"\nfrom all likes (both \"thumbs up\" and \"thumbs down\").\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(merged, mapping = aes(x=year_month , y=pct.positive, fill=year_month ))+\n  geom_boxplot() +\n  labs(title = \"distribution of Mood per post \", y = \"Mood\" , x=\"Month\")+ \n     theme(axis.text.x = element_text(angle = 45, hjust = 1))\n```\n\n::: {.cell-output-display}\n![](Final-Project-check_in_2_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\n### Blocked comments per post.\n\nNow I will visualize amount of blocked comments per post:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(merged, mapping = aes(x=year_month , y=blocked.sum, fill=year_month ))+\n  geom_boxplot() +\n  labs(title = \"Number Blocked comments  per post \", y = \"Number of blocked comments per post\" , x=\"Month\")+ \n     theme(axis.text.x = element_text(angle = 45, hjust = 1))\n```\n\n::: {.cell-output-display}\n![](Final-Project-check_in_2_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\n### Referral sources:\n\nThe web analytics provides information on where the viewers are coming\nfrom to the LL page. There are 5 sources of referrals, each\ncorresponding with a variable in the data set.\n\n```         \n        \"Search + amp referral visits\"\n        \"Direct (non-email) referral visits\"\n        \"Other website referral visits\"\n        \"Social referral visits\"\n        \"BDC referral visits\"\n        \"Visits when post was on LL HP\" \n```\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmerged<-merged%>%\n  rename(google =\"Search + amp referral visits\",\n         direct =\"Direct (non-email) referral visits\",\n         other.web = \"Other website referral visits\",\n          social= \"Social referral visits\",\n          bdc= \"BDC referral visits\",\n          ll= \"Visits when post was on LL HP\" )\n\nggplot(merged, mapping=aes(x=post.date))+\n  geom_point(aes(y=google), color=\"red\")+\n  geom_point(aes(y=direct), color=\"green\")+\n  geom_point(aes(y=other.web), color=\"yellow\")+\n  geom_point(aes(y=social), color=\"purple\")+\n  geom_point(aes(y=bdc), color=\"blue\")+\n  geom_point(aes(y=ll), color=\"pink\")  +\n  labs(title = \"referral sources per post \", y = \"Number of referrals\" , x=\"Post\")+ \n     theme(axis.text.x = element_text(angle = 45, hjust = 1))\n```\n\n::: {.cell-output-display}\n![](Final-Project-check_in_2_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\n# Analysis\n\nFirst, I will use \"page views\" as dependent variable and regress it\nagainst all other independent variable:\n\n##Page views as DV\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncolnames(merged)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"post_id\"          \"post.date\"        \"Letter\"           \"Page views\"      \n [5] \"google\"           \"direct\"           \"Visits\"           \"Uniques\"         \n [9] \"other.web\"        \"social\"           \"bdc\"              \"ll\"              \n[13] \"Exits\"            \"Exit rate\"        \"dup\"              \"n.comments\"      \n[17] \"post.year\"        \"post.month\"       \"post.likes\"       \"post.dislikes\"   \n[21] \"post.total.likes\" \"blocked.sum\"      \"pct.positive\"     \"year_month\"      \n[25] \"uniques.ratio\"    \"visits.ratio\"     \"author.sum\"      \n```\n:::\n\n```{.r .cell-code}\nsummary(lm(`Page views` ~ pct.positive+author.sum +uniques.ratio +visits.ratio +blocked.sum, data = merged))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = `Page views` ~ pct.positive + author.sum + uniques.ratio + \n    visits.ratio + blocked.sum, data = merged)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-11546  -6721  -3063   2498  74246 \n\nCoefficients:\n               Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   -67321.44   26343.73  -2.556   0.0109 *  \npct.positive    -179.29      85.70  -2.092   0.0369 *  \nauthor.sum       347.56     572.72   0.607   0.5442    \nuniques.ratio 101424.19   21505.45   4.716 3.08e-06 ***\nvisits.ratio   29959.75   42945.44   0.698   0.4857    \nblocked.sum       18.90      76.92   0.246   0.8060    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 10810 on 529 degrees of freedom\nMultiple R-squared:  0.2642,\tAdjusted R-squared:  0.2573 \nF-statistic:    38 on 5 and 529 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\n## Number of comments as DV\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncolnames(merged)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"post_id\"          \"post.date\"        \"Letter\"           \"Page views\"      \n [5] \"google\"           \"direct\"           \"Visits\"           \"Uniques\"         \n [9] \"other.web\"        \"social\"           \"bdc\"              \"ll\"              \n[13] \"Exits\"            \"Exit rate\"        \"dup\"              \"n.comments\"      \n[17] \"post.year\"        \"post.month\"       \"post.likes\"       \"post.dislikes\"   \n[21] \"post.total.likes\" \"blocked.sum\"      \"pct.positive\"     \"year_month\"      \n[25] \"uniques.ratio\"    \"visits.ratio\"     \"author.sum\"      \n```\n:::\n\n```{.r .cell-code}\nsummary(lm(n.comments ~ pct.positive+author.sum +uniques.ratio +visits.ratio +blocked.sum, data = merged))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = n.comments ~ pct.positive + author.sum + uniques.ratio + \n    visits.ratio + blocked.sum, data = merged)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-105.433  -32.240   -8.202   26.545  173.418 \n\nCoefficients:\n               Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    582.4699   116.2216   5.012 7.37e-07 ***\npct.positive     0.4952     0.3781   1.310  0.19088    \nauthor.sum       1.9454     2.5267   0.770  0.44169    \nuniques.ratio   24.7694    94.8764   0.261  0.79414    \nvisits.ratio  -511.3328   189.4639  -2.699  0.00718 ** \nblocked.sum      0.8087     0.3394   2.383  0.01752 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 47.69 on 529 degrees of freedom\nMultiple R-squared:  0.09471,\tAdjusted R-squared:  0.08615 \nF-statistic: 11.07 on 5 and 529 DF,  p-value: 3.727e-10\n```\n:::\n:::\n\n\n## Exit rate as DV\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncolnames(merged)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"post_id\"          \"post.date\"        \"Letter\"           \"Page views\"      \n [5] \"google\"           \"direct\"           \"Visits\"           \"Uniques\"         \n [9] \"other.web\"        \"social\"           \"bdc\"              \"ll\"              \n[13] \"Exits\"            \"Exit rate\"        \"dup\"              \"n.comments\"      \n[17] \"post.year\"        \"post.month\"       \"post.likes\"       \"post.dislikes\"   \n[21] \"post.total.likes\" \"blocked.sum\"      \"pct.positive\"     \"year_month\"      \n[25] \"uniques.ratio\"    \"visits.ratio\"     \"author.sum\"      \n```\n:::\n\n```{.r .cell-code}\nsummary(lm(`Exit rate`~ pct.positive+author.sum +uniques.ratio +visits.ratio +blocked.sum, data = merged))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = `Exit rate` ~ pct.positive + author.sum + uniques.ratio + \n    visits.ratio + blocked.sum, data = merged)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.26645 -0.03047 -0.00203  0.03163  0.19748 \n\nCoefficients:\n                Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   -2.574e-02  1.199e-01  -0.215 0.830117    \npct.positive  -6.219e-04  3.900e-04  -1.594 0.111451    \nauthor.sum    -1.530e-03  2.607e-03  -0.587 0.557434    \nuniques.ratio  3.395e-01  9.788e-02   3.469 0.000565 ***\nvisits.ratio   6.602e-01  1.955e-01   3.378 0.000784 ***\nblocked.sum   -2.326e-05  3.501e-04  -0.066 0.947055    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.0492 on 529 degrees of freedom\nMultiple R-squared:  0.3615,\tAdjusted R-squared:  0.3555 \nF-statistic: 59.91 on 5 and 529 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\n##Page views as DV\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncolnames(merged)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"post_id\"          \"post.date\"        \"Letter\"           \"Page views\"      \n [5] \"google\"           \"direct\"           \"Visits\"           \"Uniques\"         \n [9] \"other.web\"        \"social\"           \"bdc\"              \"ll\"              \n[13] \"Exits\"            \"Exit rate\"        \"dup\"              \"n.comments\"      \n[17] \"post.year\"        \"post.month\"       \"post.likes\"       \"post.dislikes\"   \n[21] \"post.total.likes\" \"blocked.sum\"      \"pct.positive\"     \"year_month\"      \n[25] \"uniques.ratio\"    \"visits.ratio\"     \"author.sum\"      \n```\n:::\n\n```{.r .cell-code}\nsummary(lm(google~ ll, data = merged))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = google ~ ll, data = merged)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n -7239  -5812  -4602   1914  68444 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 9323.5592  1417.8372   6.576 1.16e-10 ***\nll            -0.8107     0.4195  -1.932   0.0538 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9787 on 533 degrees of freedom\nMultiple R-squared:  0.006957,\tAdjusted R-squared:  0.005094 \nF-statistic: 3.734 on 1 and 533 DF,  p-value: 0.05385\n```\n:::\n\n```{.r .cell-code}\nsummary(lm(google~ n.comments, data = merged))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = google ~ n.comments, data = merged)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n -6571  -5556  -4849   2034  68886 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 8042.721   1712.249   4.697 3.36e-06 ***\nn.comments    -6.847      8.514  -0.804    0.422    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9815 on 533 degrees of freedom\nMultiple R-squared:  0.001212,\tAdjusted R-squared:  -0.000662 \nF-statistic: 0.6467 on 1 and 533 DF,  p-value: 0.4216\n```\n:::\n\n```{.r .cell-code}\nsummary(lm(google~ Uniques, data = merged))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = google ~ Uniques, data = merged)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-12233.0  -1177.6    488.3   1804.8   7093.0 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -8.807e+03  2.186e+02  -40.29   <2e-16 ***\nUniques      8.524e-01  1.026e-02   83.09   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2629 on 533 degrees of freedom\nMultiple R-squared:  0.9283,\tAdjusted R-squared:  0.9282 \nF-statistic:  6904 on 1 and 533 DF,  p-value: < 2.2e-16\n```\n:::\n\n```{.r .cell-code}\nsummary(lm(google~ Uniques + n.comments +ll, data = merged))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = google ~ Uniques + n.comments + ll, data = merged)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-11790.8  -1238.5    425.3   1689.8   6964.7 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -6.915e+03  5.472e+02 -12.637   <2e-16 ***\nUniques      8.511e-01  1.015e-02  83.843   <2e-16 ***\nn.comments  -4.789e+00  2.371e+00  -2.020   0.0439 *  \nll          -2.899e-01  1.173e-01  -2.472   0.0138 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2598 on 531 degrees of freedom\nMultiple R-squared:  0.9303,\tAdjusted R-squared:  0.9299 \nF-statistic:  2361 on 3 and 531 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\n### Blocked comments and Post mood:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(blocked.sum ~ mood.score, data= grouped )\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in eval(m$data, eframe): object 'grouped' not found\n```\n:::\n\n```{.r .cell-code}\nsummary(grouped)  \n```\n\n::: {.cell-output .cell-output-error}\n```\nError in summary(grouped): object 'grouped' not found\n```\n:::\n\n```{.r .cell-code}\nfit <- lm(blocked.sum ~ mood.score, data = grouped)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in is.data.frame(data): object 'grouped' not found\n```\n:::\n\n```{.r .cell-code}\nsum(is.na(grouped$mood.score))\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in eval(expr, envir, enclos): object 'grouped' not found\n```\n:::\n\n```{.r .cell-code}\nsummary(fit)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in summary(fit): object 'fit' not found\n```\n:::\n:::\n\n\n### \n\nThis variable indicates the date of the comment. Using the range of the\ndates per post, I can estimate how long each post was in active\ndiscussion.\n\n\n::: {.cell}\n\n:::\n\n\n### Second wave causes:\n\nSome posts demonstrate increased amount of views, coming from search\nengines. These views are coming 2-3 days after the post date (ADD DATA\nHERE ).\n\nWe are interested to find out, what characteristics of the post (prior\nto it being picked up by google), correlate with its appearance on\ngoogle news.\n\nNumber of comments within 1st 10 hours from the post -\\> google wave\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#  calculating number of comments within first 10 hours \n\n# date and time of the post \npost.date  <-comments.data %>%\n  group_by(post_id)%>%\n  arrange(written_at)%>%\n  summarize(post.dt = first(written_at), \n            n.coms =n())%>%\n  filter (n.coms>100)%>%\n  select(post_id, post.dt, n.coms)%>%\narrange(desc(post_id))\nhead(post.date )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 3\n   post_id post.dt             n.coms\n     <dbl> <dttm>               <int>\n1 27071003 2021-01-04 09:06:25    267\n2 27070997 2021-01-05 08:58:15    207\n3 27070991 2021-01-06 09:08:59    266\n4 27070985 2021-01-07 09:07:15    372\n5 27070979 2021-01-08 09:00:33    319\n6 27070973 2021-01-11 09:04:02    267\n```\n:::\n\n```{.r .cell-code}\n# Calculating age of the post \ncomments.data.1 <- merge( comments.data , post.date , by = \"post_id\", all = TRUE)\ncomments.data.1 <-comments.data.1 %>%\n  mutate (age = difftime(  written_at,post.dt, units = \"hours\"), \n          early = ifelse(age<10, 1, 0))\n\nearly.coms  <-comments.data.1 %>%\n  group_by(post_id)%>%\n  arrange(written_at)%>%\n  summarize(early.sum = sum(early), \n            n.coms =n())%>%\n  filter (n.coms>100)%>%\n  select(post_id, early.sum)%>%\narrange(desc(post_id))\n\n# Adding number of early comments to merged dataset:\nmerged.1 <- merge( merged, early.coms , by = \"post_id\", all = TRUE)\n```\n:::\n\n\nNow, as I calculated number of early comments for all posts, I can see\nif that number correlated with google referrals\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmerged.2<-merged.1 %>%\n  filter(google>10000)\n\ncorrelation.2 <- cor(merged.2$early.sum, merged.2$google)\ncorrelation.2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.2736053\n```\n:::\n\n```{.r .cell-code}\nplot(merged.2$early.sum, merged.2$google)\n```\n\n::: {.cell-output-display}\n![](Final-Project-check_in_2_files/figure-html/unnamed-chunk-22-1.png){width=672}\n:::\n\n```{.r .cell-code}\nsummary(lm(google ~early.sum, data=merged.2))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = google ~ early.sum, data = merged.2)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-15035  -6141  -2482   3559  54900 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)   \n(Intercept)  5908.84    5265.21   1.122  0.26406   \nearly.sum      94.56      30.73   3.077  0.00261 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 10600 on 117 degrees of freedom\nMultiple R-squared:  0.07486,\tAdjusted R-squared:  0.06695 \nF-statistic: 9.467 on 1 and 117 DF,  p-value: 0.002605\n```\n:::\n:::\n\n\nWe can see significant connection between early comments and google\nreferrals above 10000 visits. Howeve, R\\^2 is low in this model, whic\nsuggests that there are other factors that are not considered in this\nmodel. I will explore how days of the week and time of the post\ncontribute to this relationship.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# calculating day of the week for the post: \n\n# Calculating age of the post \nlibrary(lubridate)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'lubridate'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n```\n:::\n\n```{.r .cell-code}\ncomments.data.1 <-comments.data.1 %>%\n  mutate (weekday = wday(post.dt, label = TRUE), \n          weekend = ifelse(weekday ==\"Fri\" | weekday == \"Sat\", 1, 0))\n  \n\n# class(week.days$weekday)\n# levels(week.days$weekday) \n# \n# week.days$weekend\n\nweekdays <-comments.data.1 %>%\n  group_by(post_id)%>%\n  arrange(written_at)%>%\n  summarize(post.weekday = first(weekday), \n            post.weekend =first(weekend),\n            n.coms =n())%>%\n  filter (n.coms>100)%>%\n  select(post_id, post.weekday,post.weekend )%>%\narrange(desc(post_id))\n\n\n# Adding number of early comments to merged dataset:\nmerged.weekdays <- merge( merged.2, weekdays , by = \"post_id\", all = TRUE)\ncolnames(merged.weekdays)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"post_id\"          \"post.date\"        \"Letter\"           \"Page views\"      \n [5] \"google\"           \"direct\"           \"Visits\"           \"Uniques\"         \n [9] \"other.web\"        \"social\"           \"bdc\"              \"ll\"              \n[13] \"Exits\"            \"Exit rate\"        \"dup\"              \"n.comments\"      \n[17] \"post.year\"        \"post.month\"       \"post.likes\"       \"post.dislikes\"   \n[21] \"post.total.likes\" \"blocked.sum\"      \"pct.positive\"     \"year_month\"      \n[25] \"uniques.ratio\"    \"visits.ratio\"     \"author.sum\"       \"early.sum\"       \n[29] \"post.weekday\"     \"post.weekend\"    \n```\n:::\n\n```{.r .cell-code}\nlevels(merged.weekdays$post.weekday)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Sun\" \"Mon\" \"Tue\" \"Wed\" \"Thu\" \"Fri\" \"Sat\"\n```\n:::\n:::\n\n\n### Adding IV to the model\n\nNow, as I have necessary variables to run a regression, I will build the\nmodel again with more independent variables:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmerged.2<-merged.1 %>%\n  filter(google>10000)\n\n# correlation.2 <- cor(merged.weekdays$early.sum, merged.weekdays$google)\n# correlation.2\n plot(merged.weekdays$post.weekday ,   merged.weekdays$google)\n```\n\n::: {.cell-output-display}\n![](Final-Project-check_in_2_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n\n```{.r .cell-code}\nsummary(lm(google ~early.sum +post.weekday , data=merged.weekdays))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = google ~ early.sum + post.weekday, data = merged.weekdays)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-18530  -5883  -2023   3440  51408 \n\nCoefficients:\n               Estimate Std. Error t value Pr(>|t|)   \n(Intercept)     5821.61    5305.78   1.097  0.27488   \nearly.sum         94.64      31.02   3.051  0.00285 **\npost.weekday.L   906.01    2276.75   0.398  0.69143   \npost.weekday.Q -1337.72    2227.77  -0.600  0.54939   \npost.weekday.C  -949.90    2158.89  -0.440  0.66078   \npost.weekday^4  3976.83    2097.13   1.896  0.06047 . \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 10580 on 113 degrees of freedom\n  (416 observations deleted due to missingness)\nMultiple R-squared:  0.1089,\tAdjusted R-squared:  0.06948 \nF-statistic: 2.762 on 5 and 113 DF,  p-value: 0.02158\n```\n:::\n\n```{.r .cell-code}\ntable(merged.weekdays$post.weekday)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nSun Mon Tue Wed Thu Fri Sat \n  0  96 112 111 110 106   0 \n```\n:::\n\n```{.r .cell-code}\nggplot (merged.weekdays, mapping =aes(x=early.sum, y=google, color =post.weekday))+\n  geom_point( ) +\n  geom_smooth(method=\"lm\")+\n  labs(title = \"Google referrals and early comments\", y = \"Google referrals\" , x=\"Early comments\")+ \n     theme(axis.text.x = element_text(angle = 45, hjust = 1))+\n  facet_wrap(~post.weekday)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 416 rows containing non-finite values (`stat_smooth()`).\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 416 rows containing missing values (`geom_point()`).\n```\n:::\n\n::: {.cell-output-display}\n![](Final-Project-check_in_2_files/figure-html/unnamed-chunk-24-2.png){width=672}\n:::\n\n```{.r .cell-code}\n# ggplot(merged, mapping=aes(x=post.date))+\n#   geom_point(aes(y=google), color=\"red\")+\n#   geom_point(aes(y=direct), color=\"green\")+\n#   geom_point(aes(y=other.web), color=\"yellow\")+\n#   geom_point(aes(y=social), color=\"purple\")+\n#   geom_point(aes(y=bdc), color=\"blue\")+\n#   geom_point(aes(y=ll), color=\"pink\")  +\n#   labs(title = \"referral sources per post \", y = \"Number of referrals\" , x=\"Post\")+ \n#      theme(axis.text.x = element_text(angle = 45, hjust = 1))\n```\n:::\n",
    "supporting": [
      "Final-Project-check_in_2_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}