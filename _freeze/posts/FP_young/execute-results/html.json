{
  "hash": "c36d562e9409d240a9ace6c814cd77be",
  "result": {
    "markdown": "---\ntitle: \"The effect of a manager's intervention in the game on the team's scoring ability in the KBO League\"\nauthor: \"Young Soo Choi\"\ndescription: \"Final Project\"\ndate: \"05/22/2023\"\nformat:\n  html:\n    toc: true\n    code-fold: true\n    code-copy: true\n    code-tools: true\ncategories:\n  - final project\n---\n\n\n# Intro\n\n## Research Problems\n\nThe debate about the role of a manager in baseball games has always been a hot potato. In the case of the United States, MLB(Major League Baseball), various quantitative analyses have been conducted on this topic since the famous Moneyball(2004, Lewis, M.), and most studies conclude that the role of the coach in the team's victory or defeat is not significant.\n\nThen, what is the case in Korea? Baseball is also prevalent in Korea as the most popular professional sport, and quantitative analysis has been conducted on these topics along with the activation of data analysis techniques over the past decade. However, the number is not large, but if you look at representative studies, there is a result of studying the difference in team performance according to the manager's tendency.(Lee, Kim, and Lee, 2007)\n\nIf so, what is the relationship between the specific manager's behavior and the team's performance, other than the relationship between the manager's tendency and performance? More specifically, does the team's performance improve if the manager intervenes a lot in the game? Unfortunately, it was difficult to find a study on these problems targeting KBO(Korean Baseball Organization) league in Korea.\n\nWith this awareness of the problem, this study aims to check whether the manager's intervention improves the team's performance in baseball games in Korean professional baseball(KBO league). In other words, the research question is, **\"What is the relationship between the manager's intervention and the team's performance in the KBO League?\"**\n\n## Major Concepts\n\nBefore review the problem, let's look at some important concepts. First of all, baseball's team performance is divided into wins and losses, and of course, the more wins, the better. And the victory of the game is given to the team that scores more points, so the team's performance is more advantageous the more points they score and allow fewer runs. In addition, the manager of baseball directs the overall game, such as setting the team's batting order and replacing pitchers at an appropriate time, and in terms of offense, he can directly intervene in the game through various operations such as bunt and steal direction. Finally, the KBO League is a Korean professional baseball league that started with six teams in 1982, and 10 teams have been participating since 2015. Currently, each team plays 144 games in a season, with a total of 720 games.\n\n## Hypothesis and Research Design\n\nBased on the research problems and major concepts discussed above, the hypothesis of this study was established as follows.\n\n**Ha-1: In the KBO League, teams with a lot of managers' intervention in games have higher scoring ability than teams that do not.**\n\n*(High Group Average Score \\> Normal Group Average Score \\> Low Group Average Score)*\n\n**Ha-2: In the KBO League, the more the manager intervenes in the game, the higher the team's scoring ability.**\n\n*(In the regression model of scoring and intervention, regression coefficient for intervention \\> 0)*\n\n**Hb-1: In the KBO League, the difference between the actual score and the expected score of the team with a lot of intervention in the game will be greater than that of the team that does not.**\n\n*(The difference between the actual score and the expected score of high group \\> The difference between the actual score and the expected score of normal group \\> The difference between the actual score and the expected score of low group)*\n\n**Hb-2: In the KBO League, the more interventions there are in the game, the greater the difference between actual scores and expected scores.**\n\n*(In the regression model of the difference between the actual score and the expected score and intervention, regression coefficient for intervention \\> 0)*\n\nSince baseball games are quite complex, I would like to verify research problems in various ways. Therefore, hypotheses were also defined in four forms as above.\n\nFor Ha-1, teams will be classified according to the frequency of game intervention and the average of which groups have a high average score will be compared. For Ha-2, we will conduct a regression analysis on how the team's average score moves as the game intervention increases.\n\nFor Hb, we will use the concept of expected score. Expected score refers to the expected score considering the team's basic offensive power, and an expected score generation formula can be obtained through regression analysis using batting indicators such as batting average and slugging rate. From this point of view, the manager's intervention can confirm whether the team's actual score is higher or lower than the team's expected score.\n\nHb-1 will classify groups according to the frequency of intervention in the game, such as Ha-1, and compare the average of the expected scores of the teams in each group with the actual scores. Like Ha-2, Hb-2 will be analyzed the difference between the team's actual score and the expected score depending on the degree of intervention in the game using regression.\n\n# Looking at the Data\n\n## Operational Definition\n\nUntil now, the concept of manager's intervention in the game has been used. But how can we measure this. In fact, it is a subject that allows for extensive research on this alone. However, in this study, to simplify the analysis, I would like to operatively define it so that existing data can be used as it is. In other words, the team's annual bunt(sacrifice hit, sh) and steal attempts(steal, st + stolen caught, sc) are defined as the manager's intervention in the game.\n\n## Data Load\n\nBefore the full-fledged analysis, I would like to set the scope of the study first. Baseball shows quite different aspects from time to time, especially the average score showing quite differently from time to time. In particular, the KBO League has continued to expand its teams, and the proportion of stadiums used and foreign players has been determined every year. Considering this, only data after 2015 when the 10-team system was established will be used.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nSys.setenv(LANG = \"en\")\n\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'tidyverse' was built under R version 4.2.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'ggplot2' was built under R version 4.2.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'tibble' was built under R version 4.2.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'dplyr' was built under R version 4.2.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n:::\n\n```{.r .cell-code}\n# loading data\nkbo_df<-read_csv(\"~/R/603_Spring_2023/posts/_data/kbo_df.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nNew names:\nRows: 313 Columns: 28\n── Column specification\n────────────────────────────────────────────────────────\nDelimiter: \",\" chr (1): team dbl (27): ...1, year, game, win, lose, tie,\nrun_scored, run_allowed, batters...\nℹ Use `spec()` to retrieve the full column specification for this data. ℹ\nSpecify the column types or set `show_col_types = FALSE` to quiet this message.\n• `` -> `...1`\n```\n:::\n\n```{.r .cell-code}\nkbo_df<-kbo_df[254:313,2:28]\nhead(kbo_df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 27\n   year team   game   win  lose   tie run_scored run_allowed batters   tpa    ab\n  <dbl> <chr> <dbl> <dbl> <dbl> <dbl>      <dbl>       <dbl>   <dbl> <dbl> <dbl>\n1  2015 Bears   144    79    65     0        807         776    1704  5759  4957\n2  2015 Dinos   144    84    57     3        844         655    1960  5727  4967\n3  2015 Eagl…   144    68    76     0        717         800    1899  5713  4850\n4  2015 Gian…   144    66    77     1        765         802    1821  5680  4972\n5  2015 Heros   144    78    65     1        904         790    1769  5811  5069\n6  2015 Land…   144    69    73     2        693         724    1845  5588  4861\n# ℹ 16 more variables: hit <dbl>, double <dbl>, triple <dbl>, hr <dbl>,\n#   bb <dbl>, ibb <dbl>, hbp <dbl>, so <dbl>, rbi <dbl>, r <dbl>, sh <dbl>,\n#   sf <dbl>, sb <dbl>, cs <dbl>, gidp <dbl>, e <dbl>\n```\n:::\n:::\n\n\n## Looking at the average intervention by year\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# making average variables by years\n\n# for sh\n## create an empty data frame to store the results\nsh_df <- data.frame(year = integer(), avr_sh = numeric())\n\n## loop over the years\nfor (i in 2015:2020) {\n  ## filter the data for the current year and calculate the sum of sh variable\n  year_sh <- kbo_df %>% \n    filter(year == i) %>% \n    summarize(year_av_sh = sum(sh)/n()) %>% \n    pull(year_av_sh)\n\n  ## add the result to the data frame\n  sh_df <- rbind(sh_df, data.frame(year = i, avr_sh = year_sh))\n}\n\n# for sb\nsb_df <- data.frame(year = integer(), avr_sb = numeric())\n\nfor (i in 2015:2020) {\n  year_sb <- kbo_df %>% \n    filter(year == i) %>% \n    summarize(year_av_sb = sum(sb)/n()) %>% \n    pull(year_av_sb)\n\n  sb_df <- rbind(sb_df, data.frame(year=i, avr_sb=year_sb))\n}\n\n# for cs\ncs_df <- data.frame(year = integer(), avr_cs = numeric())\n\nfor (i in 2015:2020) {\n  year_cs <- kbo_df %>% \n    filter(year == i) %>% \n    summarize(year_av_cs = sum(cs)/n()) %>% \n    pull(year_av_cs)\n\n\n  cs_df <- rbind(cs_df, data.frame(year=i, avr_cs=year_cs))\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# print the results data frame\nsa_df<-left_join(sb_df, cs_df)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nJoining with `by = join_by(year)`\n```\n:::\n\n```{.r .cell-code}\nsa_df<-mutate(sa_df, avr_sa=avr_sb+avr_cs)\nint_da<-left_join(sh_df, sa_df)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nJoining with `by = join_by(year)`\n```\n:::\n\n```{.r .cell-code}\nint_da<-mutate(int_da, avr_int=avr_sh+avr_sa)\nint_da\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  year avr_sh avr_sb avr_cs avr_sa avr_int\n1 2015   83.4  120.2   52.6  172.8   256.2\n2 2016   65.1  105.8   54.7  160.5   225.6\n3 2017   60.0   77.8   40.7  118.5   178.5\n4 2018   44.7   92.8   41.0  133.8   178.5\n5 2019   43.6   98.9   42.3  141.2   184.8\n6 2020   48.6   89.2   37.7  126.9   175.5\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# drawing a graph\nlibrary(ggplot2)\n\nggplot(int_da, aes(x=year)) + \n  geom_line(aes(y = avr_sh, color = \"Sacrifice Hit\")) + \n  geom_line(aes(y = avr_sa, color=\"Steal Attempts\")) +\n  geom_line(aes(y = avr_int, color = \"Total Intervention\")) +\n  labs(title = \"Trend of Game Intervention in KBO League\", color = \"Variable\", y = \"Average Value\") +\n  scale_color_manual(\"\", \n                      breaks = c(\"Sacrifice Hit\", \"Steal Attempts\", \"Total Intervention\"),\n                      values = c(\"darkred\", \"steelblue\", \"purple\"))\n```\n\n::: {.cell-output-display}\n![](FP_young_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\nLooking at the frequency of intervention in the game since 2015, it can be seen that the overall trend has been downward, but the total frequency of intervention has been stable since 2017.\n\n# Hypothesis Testing: Ha(Actual Scores)\n\n## Ha-1\n\nTo verify Ha-1, each team by year is divided into three groups according to the frequency of game intervention. Teams with more than 1 sd intervention are assigned to the high group compared to the overall average frequency of intervention for the year. In the low group, on the contrary, fewer teams than 1 sd are involved, and the rest are assigned to the normal group.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# merge those data\nint_df<-merge(merge(sh_df, sb_df, by = \"year\", all = TRUE), cs_df, by=\"year\", all=TRUE)\n\n# left join to original data\ntot_df<-left_join(kbo_df, int_df)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nJoining with `by = join_by(year)`\n```\n:::\n\n```{.r .cell-code}\n# making intervention variables\ntot_df<-tot_df %>%\n  mutate(st_att=sb+cs, inter = sh+st_att, avr_inter=avr_sh+avr_sb+avr_cs)\n\ntot_df[, c('year','team','sh','st_att','inter','avr_inter')]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 60 × 6\n    year team       sh st_att inter avr_inter\n   <dbl> <chr>   <dbl>  <dbl> <dbl>     <dbl>\n 1  2015 Bears      75    158   233      256.\n 2  2015 Dinos      64    264   328      256.\n 3  2015 Eagles    139    127   266      256.\n 4  2015 Giants     80    154   234      256.\n 5  2015 Heros      61    147   208      256.\n 6  2015 Landers   110    153   263      256.\n 7  2015 Lions      76    209   285      256.\n 8  2015 Tigers     79    165   244      256.\n 9  2015 Twins      75    175   250      256.\n10  2015 Wiz        75    176   251      256.\n# ℹ 50 more rows\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# making sd of intervention by each year\nsd_int<- data.frame(year = integer(), sd_i= numeric())\n\nfor (i in 2015:2020) {\n  year_sd <- tot_df %>% \n    filter(year == i) %>% \n    summarize(year_sd_int = sd(inter)) %>% \n    pull(year_sd_int)\n\n  sd_int<- rbind(sd_int, data.frame(year = i, sd_i= year_sd))\n}\n\ntot_df<-left_join(tot_df, sd_int)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nJoining with `by = join_by(year)`\n```\n:::\n\n```{.r .cell-code}\n# making three type variables\ntot_df<-tot_df %>%\n  mutate(inter_fre_sd=ifelse(inter>avr_inter+sd_i, \"high\", \n                               ifelse(inter<avr_inter-sd_i, \"low\", \"normal\")))\n\ntot_df[, c('year','team','run_scored', 'inter_fre_sd')]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 60 × 4\n    year team    run_scored inter_fre_sd\n   <dbl> <chr>        <dbl> <chr>       \n 1  2015 Bears          807 normal      \n 2  2015 Dinos          844 high        \n 3  2015 Eagles         717 normal      \n 4  2015 Giants         765 normal      \n 5  2015 Heros          904 low         \n 6  2015 Landers        693 normal      \n 7  2015 Lions          897 normal      \n 8  2015 Tigers         648 normal      \n 9  2015 Twins          653 normal      \n10  2015 Wiz            670 normal      \n# ℹ 50 more rows\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# making table\ntable(tot_df$inter_fre_sd, tot_df$year)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        \n         2015 2016 2017 2018 2019 2020\n  high      1    2    2    2    0    2\n  low       1    2    1    1    2    2\n  normal    8    6    7    7    8    6\n```\n:::\n\n```{.r .cell-code}\ntable(tot_df$inter_fre_sd)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n  high    low normal \n     9      9     42 \n```\n:::\n:::\n\n\nOf the 60 data in the six-year period, 9 were assigned to the high group and 9 to the low group, respectively, and the rest were normal groups. Now let's verify the average difference between them.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# check the score by groups\ntot_df %>% group_by(inter_fre_sd) %>%\n  summarise(avr_run=mean(run_scored))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 2\n  inter_fre_sd avr_run\n  <chr>          <dbl>\n1 high            766.\n2 low             748.\n3 normal          755.\n```\n:::\n\n```{.r .cell-code}\n# anova\nha1<-aov(run_scored~inter_fre_sd, data=tot_df)\nsummary(ha1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n             Df Sum Sq Mean Sq F value Pr(>F)\ninter_fre_sd  2   1478     739   0.084  0.919\nResiduals    57 500775    8786               \n```\n:::\n:::\n\n\nLooking at the average difference between each group, the high group has the highest average score and the low group has the lowest average score. In other words, when compared simply, the average score of the group with a lot of game intervention is higher. However, since the **value of p as an AVONA result is 0.919**, there is no statistical significance of this result.(at the 0.05 level of significance). In other words, it is difficult to accept it as a meaningful result.\n\n## Ha-2\n\nNext, I will examine how game intervention has a relationship with scoring through regression analysis between game intervention and score.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# regression\nha2<-lm(run_scored~inter, tot_df)\nsummary(ha2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = run_scored ~ inter, data = tot_df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-192.376  -81.702    5.755   65.895  195.249 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 719.7232    58.6681  12.268   <2e-16 ***\ninter         0.1792     0.2874   0.624    0.535    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 92.75 on 58 degrees of freedom\nMultiple R-squared:  0.006658,\tAdjusted R-squared:  -0.01047 \nF-statistic: 0.3888 on 1 and 58 DF,  p-value: 0.5354\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(tot_df, aes(inter, run_scored),\n     xlab=\"Intervention\",\n     ylab=\"Run Scored\") + \n  geom_point() +\n  geom_abline(slope=0.1792, intercept = 719.7232, color =\"red\") +\n  labs(title = \"Regression of Intervention and Run Scored in KBO League\", x = \"Intervention\", y = \"Run Scored\")\n```\n\n::: {.cell-output-display}\n![](FP_young_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\nSimilar to the previous simple average comparison, the higher the number of interventions in the game, the higher the score. In other words, the coefficient of intervention in the game was 0.1792, indicating that the score per game increased by 0.1792 points. However, the R square value was 0.006658, and the randomness of game intervention was very low to explain the team's score, and the **p value of the slope of the regression equation was also 0.5354**, which was not significant at the 0.05 level.\n\nNext, I will check if there are any violations of various assumptions necessary for regression analysis.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# check the assumptions\npar(mfrow=c(2:3))\nplot(ha2, which=1:6)\n```\n\n::: {.cell-output-display}\n![](FP_young_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\nAs a result of the confirmation, there seems to be no particular violation.\n\n# Hypothesis Testing: Hb(Expected Scores)\n\n## Expected Run Scored\n\nNext, I will analyze the effect of game intervention using expected scores. First, we need to look at the meaning of expected scores.\n\nIn baseball, scoring is done through a combination of various offensive acts. For example, if a home run comes out after a hit, you will get two points, but if a double play comes out after a hit, you will not be able to score and increase the out count by two. As such, each batting event is correlated with scoring, and this relationship can be used to obtain the team's expected score, which can be said to show the team's basic offensive power.\n\nHowever, the question here is what variables will be used to predict the team's expected score.\n\nFirst, I obtained a regression equation between them and scoring using all batting indicators.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# regression with every batting stat\nexp_m_1<-lm(run_scored~hit+double+triple+hr+bb+ibb+hbp+so+sf+gidp, tot_df)\nsummary(exp_m_1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = run_scored ~ hit + double + triple + hr + bb + ibb + \n    hbp + so + sf + gidp, data = tot_df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-54.750  -9.564   0.773  12.749  33.562 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -413.66438   82.53095  -5.012 7.42e-06 ***\nhit            0.48736    0.05270   9.248 2.53e-12 ***\ndouble         0.32361    0.15117   2.141   0.0373 *  \ntriple         1.10204    0.46735   2.358   0.0224 *  \nhr             0.93490    0.11086   8.433 4.18e-11 ***\nbb             0.45364    0.05571   8.143 1.16e-10 ***\nibb           -0.09291    0.56884  -0.163   0.8709    \nhbp            0.26767    0.16555   1.617   0.1123    \nso            -0.01222    0.04394  -0.278   0.7820    \nsf             0.56138    0.39545   1.420   0.1621    \ngidp          -0.08900    0.25885  -0.344   0.7325    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 19.79 on 49 degrees of freedom\nMultiple R-squared:  0.9618,\tAdjusted R-squared:  0.954 \nF-statistic: 123.4 on 10 and 49 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\nAlthough the explanatory power was quite high (R square: 0.9618), the regression coefficient for some variables was not significant at the 0.05 level.\n\nI will now refit the model except for those variables. The results are as follows.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# regression with every significant batting stat\nexp_m_1_m<-lm(run_scored~hit+double+triple+hr+bb, tot_df)\nsummary(exp_m_1_m)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = run_scored ~ hit + double + triple + hr + bb, data = tot_df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-47.545 -14.651   2.097  16.132  32.664 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -437.25592   46.03536  -9.498 4.10e-13 ***\nhit            0.51153    0.04939  10.357 1.95e-14 ***\ndouble         0.33971    0.14676   2.315 0.024455 *  \ntriple         1.48367    0.42211   3.515 0.000899 ***\nhr             0.92489    0.09362   9.880 1.05e-13 ***\nbb             0.46009    0.05072   9.072 1.91e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 20.15 on 54 degrees of freedom\nMultiple R-squared:  0.9563,\tAdjusted R-squared:  0.9523 \nF-statistic: 236.6 on 5 and 54 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\nThe regression coefficient of all variables is significant at the 0.05 level, and the R square value is 0.9563. Now let's call this model **EM 1**(expected score model 1).\n\nNext, I will find out the on-base percentage and slugging percentage, which can be said to be a combination of these indicators, and then check the relationship between scoring and them.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# OBP = (Hits + Walks + Hit-by-Pitches) / (At-Bats + Walks + Hit-by-Pitches + Sacrifice Flies)\n\nexp_df<-tot_df %>%\n  mutate(obp=(hit+bb+ibb+hbp)/(ab+bb+ibb+hbp+sf))\n\n# SLG = (1B + 2B x 2 + 3B x 3 + HR x 4) / AB\nexp_df<-exp_df%>%\n  mutate(tb=hit-(double+triple+hr)+2*double+3*triple+4*hr)\nexp_df<-exp_df%>%\n  mutate(slg=tb/ab)\n\nexp_df[,c(\"year\", \"team\", \"run_scored\", \"obp\", \"slg\")]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 60 × 5\n    year team    run_scored   obp   slg\n   <dbl> <chr>        <dbl> <dbl> <dbl>\n 1  2015 Bears          807 0.373 0.435\n 2  2015 Dinos          844 0.370 0.455\n 3  2015 Eagles         717 0.364 0.405\n 4  2015 Giants         765 0.358 0.446\n 5  2015 Heros          904 0.374 0.486\n 6  2015 Landers        693 0.350 0.410\n 7  2015 Lions          897 0.380 0.469\n 8  2015 Tigers         648 0.328 0.392\n 9  2015 Twins          653 0.341 0.399\n10  2015 Wiz            670 0.348 0.402\n# ℹ 50 more rows\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# fitting regression model using obp and slg\nexp_m_2<-lm(run_scored~obp+slg, exp_df)\nsummary(exp_m_2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = run_scored ~ obp + slg, data = exp_df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-56.288 -18.876   1.651  19.630  46.770 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  -912.09      80.51 -11.328 3.20e-16 ***\nobp          3019.45     341.62   8.839 2.84e-12 ***\nslg          1411.78     157.31   8.975 1.70e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 25.4 on 57 degrees of freedom\nMultiple R-squared:  0.9268,\tAdjusted R-squared:  0.9242 \nF-statistic: 360.9 on 2 and 57 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\nIf you look at the regression equation derived using only the on-base rate and the slugging rate instead of numerous variables, we can explain about 93% of the randomness of the score using only the on-base rate and the slugging rate. (R Square = 0.9268). In addition, the regression coefficient of the long hit rate and the on-base rate was also found to be significant at the 0.05 level. Now let's call this model **EM 2**(expected score model 2)\n\n## Model Comparison\n\nNow let's compare the two models, EM 1 and EM 2, and decide which model to choose. First of all, when comparing the R square values, the model (EM 1) using every significant batting variables is .9563, and the model (EM 2) using the on-base rate and the slugging rate is 0.9268.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# AIC\nAIC(exp_m_1_m)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 538.3475\n```\n:::\n\n```{.r .cell-code}\nAIC(exp_m_2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 563.3476\n```\n:::\n\n```{.r .cell-code}\n# BIC\nBIC(exp_m_1_m)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 553.0079\n```\n:::\n\n```{.r .cell-code}\nBIC(exp_m_2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 571.725\n```\n:::\n\n```{.r .cell-code}\n# PRESS\nrunsco<-tot_df$run_scored\nsum((runsco - predict(exp_m_1_m, newdata = tot_df))^2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 21929.6\n```\n:::\n\n```{.r .cell-code}\nsum((runsco - predict(exp_m_2, newdata = exp_df))^2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 36763.51\n```\n:::\n:::\n\n\nAIC is 538.3, 563.3, BIC is 553.0, 571.7, and PRESS is 21929.6, 36763.5, respectively. That is, EM 1 shows better performance in all aspects. But there is one thing to consider here. It is the multicollinearity of variables. Most of the batting indicators in baseball are highly correlated. Simply put, a good batter is likely to have a lot of hits and home runs are likely to have a lot of home runs. Actual data show a high correlation between hits, doubles, and home runs.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# check the multicollinearity\npairs(tot_df[,12:16])\n```\n\n::: {.cell-output-display}\n![](FP_young_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n\n```{.r .cell-code}\ncor(tot_df[,12:16])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n             hit    double      triple          hr        bb\nhit    1.0000000 0.7380595  0.38683193  0.54309756 0.2894128\ndouble 0.7380595 1.0000000  0.28915285  0.46159048 0.1254726\ntriple 0.3868319 0.2891529  1.00000000 -0.01066422 0.2474792\nhr     0.5430976 0.4615905 -0.01066422  1.00000000 0.0922088\nbb     0.2894128 0.1254726  0.24747916  0.09220880 1.0000000\n```\n:::\n:::\n\n\nConsidering these points, I will choose EM 2 instead of EM 1. This is because EM 2 is much simpler using only two variables, and its explanatory power is not that low compared to EM 1.\n\nNow, we can use this to get the expected score of each team and the difference between the actual score and the expected score.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# get expected score by obp, slg\nexp_df$exp_score<-predict(exp_m_2, newdata = exp_df)\nexp_df<-exp_df %>%\n  mutate(run_diff=run_scored-exp_score)\nexp_df[,c(\"year\",\"team\",\"run_scored\",\"exp_score\",\"run_diff\",\"inter_fre_sd\")]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 60 × 6\n    year team    run_scored exp_score run_diff inter_fre_sd\n   <dbl> <chr>        <dbl>     <dbl>    <dbl> <chr>       \n 1  2015 Bears          807      826.  -19.2   normal      \n 2  2015 Dinos          844      847.   -2.75  high        \n 3  2015 Eagles         717      757.  -39.9   normal      \n 4  2015 Giants         765      799.  -34.3   normal      \n 5  2015 Heros          904      903.    0.924 low         \n 6  2015 Landers        693      724.  -31.4   normal      \n 7  2015 Lions          897      898.   -1.34  normal      \n 8  2015 Tigers         648      631.   16.6   normal      \n 9  2015 Twins          653      681.  -27.8   normal      \n10  2015 Wiz            670      706.  -35.8   normal      \n# ℹ 50 more rows\n```\n:::\n:::\n\n\n## Hb-1\n\nHypothesis hb1 can now be verified. The basic logic is as follows. If the manager's intervention in the game has a positive effect on the team's score, the difference between the actual score and the expected score will be high in the group with a high degree of intervention in the game. If not, the difference between the actual score of the high group and the expected score will be lower than that of the low group.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# check the score by groups\nexp_df %>% group_by(inter_fre_sd) %>%\n  summarise(avr_run_diff=mean(run_diff))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 2\n  inter_fre_sd avr_run_diff\n  <chr>               <dbl>\n1 high               -3.78 \n2 low                 8.26 \n3 normal             -0.959\n```\n:::\n\n```{.r .cell-code}\n# anova\nhb1<-aov(run_diff~inter_fre_sd, data=exp_df)\nsummary(hb1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n             Df Sum Sq Mean Sq F value Pr(>F)\ninter_fre_sd  2    782   390.8   0.619  0.542\nResiduals    57  35982   631.3               \n```\n:::\n:::\n\n\nThe result was the opposite of the result compared to the simple score discussed earlier. In other words, the difference between the actual score and the expected score of the group with high game intervention was lower than that of the group that did not. Considering the team's basic offensive power, the manager's intervention in the game rather makes the actual score lower than the team's expected score. In other words, the manager's intervention in the game rather reduces the team's scoring ability.\n\nHowever, the **ANOVA results also showed that this did not have statistical significance at the 0.05 level.**(p value: 0.542)\n\n## Hb-2\n\nNext, I will conduct a regression analysis to find out the effect of game intervention on the difference between actual and expected scores.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# regression\nhb2<-lm(run_diff~inter, exp_df)\nsummary(hb2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = run_diff ~ inter, data = exp_df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-52.554 -17.939   1.632  19.984  41.424 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)  \n(Intercept) 37.03480   15.13122   2.448   0.0174 *\ninter       -0.18531    0.07412  -2.500   0.0153 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 23.92 on 58 degrees of freedom\nMultiple R-squared:  0.09729,\tAdjusted R-squared:  0.08173 \nF-statistic: 6.251 on 1 and 58 DF,  p-value: 0.01526\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(exp_df, aes(inter, run_diff),\n     xlab=\"Intervention\",\n     ylab=\"Actual Score - Expected Score\") + \n  geom_point() +\n  geom_abline(slope=-0.18531, intercept = 37.03480, color =\"red\") +\n  labs(title = \"Regression of Intervention and Run Differential in KBO League\", x = \"Intervention\", y = \"Actual Score - Expected Score\")\n```\n\n::: {.cell-output-display}\n![](FP_young_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n\n\nAs a result of the regression analysis, the regression coefficient of the actual score and the expected score was **-0.185**. In other words, the increase in game intervention negatively affects the difference between actual and expected scores, and in interpretation, the increase in game intervention has the effect of reducing actual scores compared to the team's offensive power.\n\nThe R square value was 0.097 and the **p-value was 0.015, which was found to be significant at the 0.05 level.**\n\nFinally, as a result of checking whether there is a violation of assumptions necessary for regression analysis, it does not appear that special treatment is required.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# check the assumptions\npar(mfrow=c(2:3))\nplot(hb2, which=1:6)\n```\n\n::: {.cell-output-display}\n![](FP_young_files/figure-html/unnamed-chunk-22-1.png){width=672}\n:::\n:::\n\n\n# Conclusion\n\n## Regarding Ha\n\nFirst of all, looking at each hypothesis, in the case of Ha-1, the average score of the group with many game interventions was high (high: 765.9, normal: 754.9, low: 748.1), and in the case of Ha-2, the unit of game intervention increased the team's score by 0.1792. (Run Scored = 719.7232 + 0.1792\\*Intervention)\n\nIn other words, it was interpreted that the coach's intervention in the game had a positive effect on the team's scoring ability.\n\nHowever, in the case of Ha-1, the p value was 0.919, and in the case of Ha-2, the p value of the regression coefficient was 0.5354. In other words, **both hypotheses cannot be said to be statistically significant at the 0.05 significance level.**\n\n## Regarding Hb\n\nIn the case of analysis using expected scores, the difference between actual scores and expected scores was used as a dependent variable(Run Differential.\n\nIn the case of Hb-1, contrary to Ha, it was found that the gap between actual and expected scores was high when the intervention in the game was low. (high: -3.78, normal: -0.96, low: 8.26) This implies that intervention in the game is negative for the team's scoring ability. However, as a result of ANOVA analysis on this, the p value was 0.542, which was **not significant at the significance level of 0.05.**\n\nNext, in the case of Hb-2, it was found that game intervention had a negative effect on the gap between actual and expected scores. (Run Differential = 37.03480 -0.18531\\*Intervention)\n\nIn other words, like Hb-1, it can be interpreted that the manager's intervention in the game negatively affects the team's scoring ability. In addition, **the regression coefficient of intervention was also found to be significant at the significance level of 0.05 as the p value is 0.0153**.\n\n## Discussions\n\n**Of the four hypotheses, only Hb-2 was able to draw statistically significant conclusions, and that hypothesis was wrong and could be concluded at the significance level of 0.05.** In other words, it can be concluded that the manager's intervention in the game in KBO league baseball rather suppresses the actual score considering the team's expected score level.\n\nThis conclusion is consistent with the recent trend of negatively evaluating and avoiding the manager's intervention in the game. However, when looking at the baseball game as a whole, pitching and defense should be considered in addition to hitting. In other words, only when additional research is conducted on these aspects, more rigorous discussions on the role of managers in baseball can be made.\n\n# References\n\nLewis, M. (2004). Moneyball: The art of winning an unfair game. New York: Norton.\n\nSmart, D., & Wolfe, R. (2003). The contribution of leadership and human resources to organizational success: An empirical assessment of performance in Major League Baseball. European Sport Management Quarterly, 3, 165--188.\n\nWinfree, J., & Wolfe, R. (2008). Major League Baseball Managers: Do They Matter? Journal of Sport Management 22(3):303-321.\n\nLee, J., Kim, Y., & Lee, J. (2007). Relationship between Leadership of Korean Professional Baseball Coaches and Performance of Their Teams. Soonchunhyang Natural Science Research 13(2):145-155.\n",
    "supporting": [
      "FP_young_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}