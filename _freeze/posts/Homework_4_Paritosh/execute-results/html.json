{
  "hash": "e0b7fcbd49e1d4d0aa91c90a809d02c4",
  "result": {
    "markdown": "---\ntitle: \"Homework_4\"\nauthor: \"Paritosh G\"\ndesription: \"HW_4\"\ndate: \"05/28/2023\"\nformat:\n  html:\n    toc: true\n    code-fold: true\n    code-copy: true\n    code-tools: true\ncategories:\n  - hw1\n  - challenge1\n  - my name\n  - dataset\n  - ggplot2\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.1     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the \u001b]8;;http://conflicted.r-lib.org/\u0007conflicted package\u001b]8;;\u0007 to force all conflicts to become errors\n```\n:::\n\n```{.r .cell-code}\nlibrary(alr4)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: car\nLoading required package: carData\n\nAttaching package: 'car'\n\nThe following object is masked from 'package:dplyr':\n\n    recode\n\nThe following object is masked from 'package:purrr':\n\n    some\n\nLoading required package: effects\nlattice theme set by effectsTheme()\nSee ?effectsTheme for details.\n```\n:::\n\n```{.r .cell-code}\nlibrary(ggplot2)\nlibrary(smss)\nlibrary(magrittr)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'magrittr'\n\nThe following object is masked from 'package:purrr':\n\n    set_names\n\nThe following object is masked from 'package:tidyr':\n\n    extract\n```\n:::\n:::\n\n\n## Q.1)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n y <- function(x1,x2) { 53.8*x1 + 2.84*x2 - 10536}\n```\n:::\n\n\n## a)\n\n\n::: {.cell}\n\n```{.r .cell-code}\npredicted <- y(x1 = 1240, x2 = 18000)\n\nprint(predicted)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 107296\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nprint( 145000 - predicted)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 37704\n```\n:::\n:::\n\n\nThe model is predicting the selling price of the house to be less than actual hence the residual is positive.\n\n## b)\n\n-   For each square foot increase in home for a particular lot size which is also present in the model the price will increase by 53.8\\$\n\n## c)\n\n-   One square foot increase in lot size of the house will increase the price a by 2.84 dollars. to increase the price to 53.8dollars. we need to increase the size of houses by 53.8/2.84 equals 18.94 square feet.\n\n## Q.2)\n\ndata\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(salary)\n```\n:::\n\n\n## a)\n\nqs per question using variable sex\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_1 <- lm(salary ~ sex, data = salary)\nsummary(model_1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = salary ~ sex, data = salary)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8602.8 -4296.6  -100.8  3513.1 16687.9 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    24697        938  26.330   <2e-16 ***\nsexFemale      -3340       1808  -1.847   0.0706 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5782 on 50 degrees of freedom\nMultiple R-squared:  0.0639,\tAdjusted R-squared:  0.04518 \nF-statistic: 3.413 on 1 and 50 DF,  p-value: 0.0706\n```\n:::\n:::\n\n\nnegative value of coefficient suggests Female's are being paid less by that amount than male colleagues which is 3340 the variable is significant at 10% level but not at 5% level.\n\n## b)\n\nmodel for all predictors\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_2 <- lm(salary ~ degree + rank + year + ysdeg , data = salary) \nsummary(model_2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = salary ~ degree + rank + year + ysdeg, data = salary)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4226.9  -972.1  -293.1   612.5  9840.8 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 16311.34     666.84  24.461  < 2e-16 ***\ndegreePhD    1062.12     991.53   1.071    0.290    \nrankAssoc    4713.92    1056.09   4.464 5.18e-05 ***\nrankProf    10509.62    1270.43   8.272 1.18e-10 ***\nyear          416.56      82.75   5.034 7.84e-06 ***\nysdeg         -81.22      69.87  -1.162    0.251    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2414 on 46 degrees of freedom\nMultiple R-squared:  0.8499,\tAdjusted R-squared:  0.8336 \nF-statistic:  52.1 on 5 and 46 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\n## c)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nconfint(model_2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                 2.5 %      97.5 %\n(Intercept) 14969.0604 17653.61080\ndegreePhD    -933.7253  3057.95602\nrankAssoc    2588.1320  6839.71680\nrankProf     7952.3705 13066.87214\nyear          250.0004   583.12728\nysdeg        -221.8611    59.42616\n```\n:::\n:::\n\n\n95% confidence interval suggest 697 dollar less or 3031 dollars more for female faculty than male faculties. controlling for other variables.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(model_2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = salary ~ degree + rank + year + ysdeg, data = salary)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4226.9  -972.1  -293.1   612.5  9840.8 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 16311.34     666.84  24.461  < 2e-16 ***\ndegreePhD    1062.12     991.53   1.071    0.290    \nrankAssoc    4713.92    1056.09   4.464 5.18e-05 ***\nrankProf    10509.62    1270.43   8.272 1.18e-10 ***\nyear          416.56      82.75   5.034 7.84e-06 ***\nysdeg         -81.22      69.87  -1.162    0.251    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2414 on 46 degrees of freedom\nMultiple R-squared:  0.8499,\tAdjusted R-squared:  0.8336 \nF-statistic:  52.1 on 5 and 46 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\n-   rank: The model takes rank as an **categorical** variable, ignoring its order. The most common practice for ordered categorical variables like rank is to either treat them as just a regular categorical variable or as a numeric variable. The latter is most acceptable when the variable has lots of levels and/or the distance between each level can be reasonably thought of as equal. In this case, because there are only three levels (one more than what a dummy variable has), it makes sense to accept this as a regular categorical variable.\n\n-   degree**:** The degree variable is insignificant at all level.\n\nThe rankAssoc category suggests that Associate Professors make \\$5292 more than Assistant Professors, rankProf suggests full professors make \\$11118 more than Assistant Professors.\n\n-   if we want to test significance of whole rank variable and not an individual variable. we need to compare two models one with all variables and second without any rank dummies.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nM_3 <- lm(salary ~ ., data = salary)\nM_4 <- lm(salary ~ . -rank, data = salary)\n\nanova(M_3, M_4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Variance Table\n\nModel 1: salary ~ degree + rank + sex + year + ysdeg\nModel 2: salary ~ (degree + rank + sex + year + ysdeg) - rank\n  Res.Df       RSS Df  Sum of Sq     F    Pr(>F)    \n1     45 258858365                                  \n2     47 658649047 -2 -399790682 34.75 7.485e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\n-   rank variable is significant as a whole.\n\n-   sex: As we saw with confidence intervals, this variable is now not statistically significant at conventional levels. The coefficient suggests female faculty make \\$1166 more after everything is controlled, but interpreting coefficients when the effect is insignificant is not very meaningful.\n\n-   year: his variable is statistically significant. It suggests that every additional in current rank is associated with \\$476 more salary.\n\n-   ysdeg: The variable is insignificant. The coefficient would suggest that every additional year that passes since degree is associated with \\$124 less salary.\n\n## d)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsalary$rank <- relevel(salary$rank, ref = 'Prof')\nsummary(lm(salary ~ ., data = salary))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = salary ~ ., data = salary)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4045.2 -1094.7  -361.5   813.2  9193.1 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  26864.81    1375.29  19.534  < 2e-16 ***\ndegreePhD     1388.61    1018.75   1.363    0.180    \nrankAsst    -11118.76    1351.77  -8.225 1.62e-10 ***\nrankAssoc    -5826.40    1012.93  -5.752 7.28e-07 ***\nsexFemale     1166.37     925.57   1.260    0.214    \nyear           476.31      94.91   5.018 8.65e-06 ***\nysdeg         -124.57      77.49  -1.608    0.115    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2398 on 45 degrees of freedom\nMultiple R-squared:  0.855,\tAdjusted R-squared:  0.8357 \nF-statistic: 44.24 on 6 and 45 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\nProf. rankAsst being -11118 means Assistant Professors make 11118 less than Full Professors, controlling for other variables. rankAssoc being -5826 means Associate Professors make 5826 less than Full Professors, controlling for other variables. The same information in the previous model is presented in a different way.\n\n## e)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(lm(salary ~ . -rank, data = salary))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = salary ~ . - rank, data = salary)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8146.9 -2186.9  -491.5  2279.1 11186.6 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 17183.57    1147.94  14.969  < 2e-16 ***\ndegreePhD   -3299.35    1302.52  -2.533 0.014704 *  \nsexFemale   -1286.54    1313.09  -0.980 0.332209    \nyear          351.97     142.48   2.470 0.017185 *  \nysdeg         339.40      80.62   4.210 0.000114 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3744 on 47 degrees of freedom\nMultiple R-squared:  0.6312,\tAdjusted R-squared:  0.5998 \nF-statistic: 20.11 on 4 and 47 DF,  p-value: 1.048e-09\n```\n:::\n:::\n\n\nremoving rank variables makes variable sex to be negative but still insignificant.\n\n## f)\n\n-   As per question we need to create a new variable called new_var from ys_deg variable. We should not create highly co-related variables to avoid multicollinearity. But, as a we are creating a new variable from already present it is likely that they will be co-related.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsalary$new_var <- ifelse(salary$ysdeg <= 15, 1, 0)\ncor.test(salary$new_var, salary$ysdeg)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tPearson's product-moment correlation\n\ndata:  salary$new_var and salary$ysdeg\nt = -11.101, df = 50, p-value = 4.263e-15\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.9074548 -0.7411040\nsample estimates:\n       cor \n-0.8434239 \n```\n:::\n:::\n\n\n-   new_var and ysdeg are -0.84 co-relation which is very high so we will remove them.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(lm(salary ~ . -ysdeg, data = salary))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = salary ~ . - ysdeg, data = salary)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3403.3 -1387.0  -167.0   528.2  9233.8 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  24425.32    1107.52  22.054  < 2e-16 ***\ndegreePhD      818.93     797.48   1.027   0.3100    \nrankAsst    -11096.95    1191.00  -9.317 4.54e-12 ***\nrankAssoc    -6124.28    1028.58  -5.954 3.65e-07 ***\nsexFemale      907.14     840.54   1.079   0.2862    \nyear           434.85      78.89   5.512 1.65e-06 ***\nnew_var       2163.46    1072.04   2.018   0.0496 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2362 on 45 degrees of freedom\nMultiple R-squared:  0.8594,\tAdjusted R-squared:  0.8407 \nF-statistic: 45.86 on 6 and 45 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\n-   At 5% significance level the new dean is paying 2163 USD more to the faculties appointed under him.\n\nLet's see what would have happened if we included both variables:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(lm(salary ~ . , data = salary))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = salary ~ ., data = salary)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3621.2 -1336.8  -271.6   530.1  9247.6 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  25179.14    1901.59  13.241  < 2e-16 ***\ndegreePhD     1135.00    1031.16   1.101    0.277    \nrankAsst    -11411.45    1362.02  -8.378 1.16e-10 ***\nrankAssoc    -6177.44    1043.04  -5.923 4.39e-07 ***\nsexFemale     1084.09     921.49   1.176    0.246    \nyear           460.35      95.09   4.841 1.63e-05 ***\nysdeg          -47.86      97.71  -0.490    0.627    \nnew_var       1749.09    1372.83   1.274    0.209    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2382 on 44 degrees of freedom\nMultiple R-squared:  0.8602,\tAdjusted R-squared:  0.838 \nF-statistic: 38.68 on 7 and 44 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\n-   none of the variable is significant because of multicollinearity.\n\n## Q.3)\n\nLoading the data\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(\"house.selling.price\")\n```\n:::\n\n\n## a)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel <- lm(Price ~ Size + New, data = house.selling.price)\nsummary(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Price ~ Size + New, data = house.selling.price)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-205102  -34374   -5778   18929  163866 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -40230.867  14696.140  -2.738  0.00737 ** \nSize           116.132      8.795  13.204  < 2e-16 ***\nNew          57736.283  18653.041   3.095  0.00257 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 53880 on 97 degrees of freedom\nMultiple R-squared:  0.7226,\tAdjusted R-squared:  0.7169 \nF-statistic: 126.3 on 2 and 97 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\nsize and the new variable are associated with price, both are significant at the 5% level. A square foot increase in the size will increase the price of house by usd 116, controlling for whether the house is new. controlling for size new houses are around usd 57736 more expensive.\n\nNew houses are on average \\$57736 more expensive than old houses, controlling for size.\n\n## b)\n\nthe equation for predicted size of home is price = -40230.867 + 116.132\\*Size + 57736.283\\*new\n\n## c)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnew <- data.frame(Size = 3000, New = 1)\n\npredict(model, newdata = new)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       1 \n365900.2 \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nnot_new <- data.frame(Size = 3000, New = 0)\n\npredict(model, newdata = new)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       1 \n365900.2 \n```\n:::\n:::\n\n\n## d)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_2<- lm(Price ~ Size + New + Size * New, data = house.selling.price)\nsummary(model_2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Price ~ Size + New + Size * New, data = house.selling.price)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-175748  -28979   -6260   14693  192519 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -22227.808  15521.110  -1.432  0.15536    \nSize           104.438      9.424  11.082  < 2e-16 ***\nNew         -78527.502  51007.642  -1.540  0.12697    \nSize:New        61.916     21.686   2.855  0.00527 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 52000 on 96 degrees of freedom\nMultiple R-squared:  0.7443,\tAdjusted R-squared:  0.7363 \nF-statistic: 93.15 on 3 and 96 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\n## e)\n\ny = 61.916\\*size\\**new + -78527.502*\\*new +104.438\\*size + -22227.808\n\nfor new homes\n\ny = 61.916\\*size\\**1 + -78527.502*\\*1 +104.438\\*size + -22227.808\n\n= 166354\\*size + -100755.3\n\nfor old homes\n\ny = 61.916\\*size\\**0 + -78527.502*\\*0 +104.438\\*size + -22227.808\n\n= 104.438\\*size + -22227.808\n\n## f)\n\nThe predicted selling price, using the model with interaction terms, for a home of 3000 square feed that is new is below.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npredict(model_2, newdata = new)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       1 \n398307.5 \n```\n:::\n:::\n\n\nThe predicted selling price, using the model with interaction terms, for a home of 3000 square feed that is not new is below.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npredict(model_2, newdata = not_new)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       1 \n291087.4 \n```\n:::\n:::\n\n\n## g)\n\nThe predicted selling price, using the model with interaction terms, for a home of 1500 square feed that is new is below.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnew <- data.frame(Size = 1500, New = 1)\n\npredict(model_2, newdata = new)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       1 \n148776.1 \n```\n:::\n:::\n\n\nThe predicted selling price, using the model with interaction terms, for a home of 1500 square feed that is not new is below.\n\nCode\n\n    df_not_new <- data.frame(Size = 1500, New = 0)\n\n    predict(fit_3d, newdata = df_not_new)\n\n           1 \n    134429.8 \n\nIn comparing the predictions for part F and G, it can be observed that the difference in selling price between a new and not new home increases as the size of the home increases.\n\n## **h**\n\nI believe the model with the interaction term best represents the relationship of size and new to the outcome price. I've come to this conclusion as the model with the interaction term has a higher adjusted R-squared and lower residual standard error than the model without the interaction term.\n\n\\\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnot_new <- data.frame(Size = 1500, New = 0)\n\npredict(model_2, newdata = not_new)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       1 \n134429.8 \n```\n:::\n:::\n\n\nA new home of 1500 square feet has a predicted price of \\$148776.1. An old home of 1500 square feet has a predicted price of \\$134429.8. The difference is \\$14346.3.\n\nThe difference between new and old home prices is much more when the size of the home is larger. For 3000 sq ft homes, the difference is 107220.1 as opposed to the 14346.1 difference for homes that are 1500 sq ft. This is consistent with the positive coefficient for the interaction term.\\\n\n## h)\n\nThe model with interaction term has higher adjusted R squared even though it has a extra variable so it should be preffered.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Price ~ Size + New, data = house.selling.price)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-205102  -34374   -5778   18929  163866 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -40230.867  14696.140  -2.738  0.00737 ** \nSize           116.132      8.795  13.204  < 2e-16 ***\nNew          57736.283  18653.041   3.095  0.00257 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 53880 on 97 degrees of freedom\nMultiple R-squared:  0.7226,\tAdjusted R-squared:  0.7169 \nF-statistic: 126.3 on 2 and 97 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(model_2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Price ~ Size + New + Size * New, data = house.selling.price)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-175748  -28979   -6260   14693  192519 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -22227.808  15521.110  -1.432  0.15536    \nSize           104.438      9.424  11.082  < 2e-16 ***\nNew         -78527.502  51007.642  -1.540  0.12697    \nSize:New        61.916     21.686   2.855  0.00527 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 52000 on 96 degrees of freedom\nMultiple R-squared:  0.7443,\tAdjusted R-squared:  0.7363 \nF-statistic: 93.15 on 3 and 96 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\n## \n",
    "supporting": [
      "Homework_4_Paritosh_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}