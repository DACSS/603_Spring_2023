---
title: "Final Project Part 1"
author: "Tyler Tewksbury"
desription: "First Final Project check-in"
date: "03/21/2023"
format:
  html:
    toc: true
    code-fold: true
    code-copy: true
    code-tools: true
categories:
  - finalpart1
  - tyler tewksbury
  - chess
---

```{r}
#| label: setup
#| warning: false

library(tidyverse)
knitr::opts_chunk$set(echo = TRUE)
```

## Background and Research Question

In 2020, after the release of the Netflix series *The Queen's Gambit*, interest in chess was at an all-time high. This led many fans of the show to use popular websites such as Chess.com and Lichess.org to begin learning the game. These websites use a rating system that mimics that of official in-person chess leagues, increasing your rating number as you win and decreasing as you lose. This can be used to measure one's skill in chess, and determining if they can enter certain competitions. 

When playing chess online, as you face someone completely random that the website matches you against, there is no guarantee that you will play against someone with an identical rating. Thus, there will typically be a difference between the two players' rating. Obviously the player with the higher rating would be more likely to win, right? That is where this study comes in. By quantifying the effect of rating difference on win chance, players may be able to understand more about the match they are currently in. Knowing how likely they are to win, how likely their opponent is to win, and this could lead to further interesting research about making the most fair chess matches possible. As there are not any academic studies on the topic, there is no proven indicator that a slight discrepancy in rating has is an indicator to a player's win chance. This poses the research question: 

**How strong of a predictor is the difference between players chess rating in determining the victor?**


## Dataset

The dataset being used is sourced from Kaggle: https://www.kaggle.com/datasets/datasnaek/chess

Gathered in 2016, the dataset contains information from over 20,000 matches on Lichess.org via the Lichess API. Information on the players', their opening moves, the results of the match, and more are all columns within the dataset. 

```{r}
#reading in the dataset
chess <- read.csv("_data/chess_games.csv")
```

## Descriptive Statistics 

```{r}
str(chess)
```

The dataset contains 20058 observations across 16 variables. 

```{r}
summary(chess)
```
Looking at the summary, it is clear what variables will be used and if any new columns will be added. The following will prove relevance to the research question:

* `rated``
* `victory_status``
* `winner`
* `white_id`
* `white_rating`
* `black_id`
* `black_rating`

A new column containing the difference between the rating will be added in the next iteration for analysis. Having this added column will make the functions necessary for analysis easier, as calculating the difference will not need to be repeated for each observation. 

#### white_rating and black_rating

```{r}
range(chess$white_rating)
range(chess$black_rating)

```
The ranges of the two sides are nearly identical, and are quite large nearing 2000. This could be both good and bad for the study, as the large range could prove significant, but it may be necessary to break the models into smaller ranges. This could also be interesting, perhaps seeing if the rating differences at a lower level matter more than that of a higher level, or vice versa.


## Proposed Models

The obvious model for this question will be a a linear probability regression, as the victory status is a binary variable. Proposed models initially are: 

Linear probability including unranked
Linear probability excluding unranked

There will be more models, potentially differentiating between the different ranges as stated earlier. More possibilities include looking at exclusively drawn game data, analyzing favored openings depending on rank, or possibly finding other predictors if the rank difference is not significant. 